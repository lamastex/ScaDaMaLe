
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Evaluation" href="04_evaluate.html" />
    <link rel="prev" title="&lt;no title&gt;" href="02_dl_single_machine.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html">
     Login to databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
     Import Course Content Now!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment">
     Cloud-free Computing Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
     Multi-lingual Notebooks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Scala Crash Course
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
     Scala Crash Course Continued
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
     HOMEWORK on RDD Transformations and Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006_WordCount.html">
     Word Count on US State of the Union (SoU) Addresses
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
     Spark Sql Programming Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
     Getting Started - Exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
     Performance Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
     SQL Pivoting since Spark 2.4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
     Load Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
     Pivoting in SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
     Pivoting with Multiple Aggregate Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
     Pivoting with Multiple Grouping Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
     Pivoting with Multiple Pivot Columns
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extract Transform and Load
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
     Parsing the output from
     <code class="docutils literal notranslate">
      <span class="pre">
       IsIt1or2Coins
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
     Providing case classes for input and output for easy spark communication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Trends in Money and News
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/000_TrendsInFinancialStocksAndNewsEvents.html">
   Trends in Financial Stocks and News Events
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00a_FX1M.html">
     Historical FX-1-M Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00b_yfinance.html">
     yfinance Stock Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000a_finance_utils.html">
     Utilities Needed for Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000b_gdelt_utils.html">
     Utilities Needed for Mass Media Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/01_trend_calculus_showcase.html">
   Finding trends in oil price data.
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/02_streamable_trend_calculus.html">
     Streaming Trend Calculus with Maximum Necessary Reversals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/03_streamable_trend_calculus_estimators.html">
     Markov Model for Trend Calculus
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/030_Spark_GDELT_project_001.html">
   Plugging into GDELT Mass Media Streams
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030a_gdelt_EOI_detection.html">
     Detecting Events of Interest to OIL/GAS Price Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030b_gdelt_POI_detection.html">
     Detecting Persons of Interest to OIL/GAS Price Trends
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distributed Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
     Distributed deep learning training using TensorFlow and Keras with HorovodRunner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
     Distributed deep learning training using PyTorch with HorovodRunner for MNIST
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/01_load_data.html">
     Preprocessing and loading the relevant data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/02_logisticregression.html">
     The two cultures - Classifying threads with logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/03_word2vec.html">
     Classification using Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/04_LDA.html">
     Topic Modeling with LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed Linear Algebra
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
     Music Recommendation System
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="00_Introduction.html#our-contribution">
   Our contribution
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="01_data_and_preprocessing.html">
     Important!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="01_data_and_preprocessing.html#important-continued-from-above">
     Important (continued from above)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_evaluate.html">
     Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
     Examples
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html">
   Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome 🧬
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/02_Data_Processing.html">
     Extract (overlapping [since yet do not know which parts corresponds to coding regions]) 3-mers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html#format-data-for-apache-spark-mllib-clustering-lda-adapted-from-the-lda-course-tutorial-034lda20newsgroupssmall">
     Format data for apache.spark.mllib.clustering.LDA (adapted from the LDA course tutorial ‘034
     <em>
      LDA
     </em>
     20NewsGroupsSmall’)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html#visualise-results">
     Visualise Results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#format-data">
     Format data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#explore-data">
     Explore data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/06_Results.html">
     Results and Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
     Clustering emoticons based on tweets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
     Dynamic Tweet Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/04_conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
     Notebook for collecting tweets with country codes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
     Extended spark.streaming.twitter.TwitterUtils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
     Download Files Periodically
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_StreamToFile.html">
     Stream to parquet file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
     This notebook is for explosive analysis of features in data.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
     Statistics of invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
     Correlation between invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
     Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html">
     Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
     Visualize total cases, total deaths, new cases and new deaths during pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
     Total Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
     New Cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
     New Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/05_Clustering.html">
     Clustering of country features in the Covid 19 dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
     Prediction with Linear Regression (LR) Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
     Prediction with Time Series model - ARIMA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
     Prediction with time series model - Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
     Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html#summary-and-outlook">
     Summary and Outlook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
     Reinforcement Learning - Distributed model tuning with Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
     Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
     Notes to the elephas training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/03_resources.html">
     Resources
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html">
   Intrusion Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html#preparing-the-dataframe-for-training-classifers">
   Preparing the DataFrame for training classifers
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/00_introduction.html">
   Density Estimation via Voronoi Diagrams in High Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html">
     Robotics Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-18_group-ProjectRL/00_Problem_Description.html">
   Recommender System
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html">
     <span class="xref myst">
      The Alternating Least Squares method (ALS)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-small-dataset">
     <span class="xref myst">
      On a small dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-large-dataset-netflix-dataset">
     <span class="xref myst">
      On a large dataset - Netflix dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/02_Extensions.html">
     Extensions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Fundamental Matrix
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-20_group-Generalization/01_Background.html">
   MixUp and Generalization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/02_Random_Forest.html">
     Random Forests and MixUp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/03_CNN_MNIST.html">
     CNN for MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/04_CNN_Intel_Image.html">
     CNN for Intel Image Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-20_group-Generalization/05_Horovod_test.html">
     CNNs and MixUp with Horovod
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
     Preprocess the data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
     Generate random graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
     Compute RSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
     Analyse the eigenvalue spectrum
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-22_group-SwapWithDDP/00_Introduction.html">
   SWAP
   <em>
    With
   </em>
   DDP
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html">
     SWAP
     <em>
      With
     </em>
     DDP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/03_dl_horovod.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/03_dl_horovod.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="simple nav section-nav flex-column">
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>This notebook extends the TF v2.x code from the single machine notebook
<code class="docutils literal notranslate"><span class="pre">23_ds_single_machine</span></code>. The modification are such that the code enables
multi-machine training using the
<a class="reference external" href="https://github.com/horovod/horovod">horovod</a> framwork.</p>
<p>We will highlight the changes compared the single machine
implementation.</p>
<p>First: Check if the data is in local. If not, go to notebook
<code class="docutils literal notranslate"><span class="pre">1_data_and_preprocssing</span></code> and download the data from dbfs to local.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">sh</span>
<span class="n">ls</span> <span class="mi">06</span><span class="n">_LHC</span><span class="o">/</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LICENSE
README.md
data
h5
models
scripts
utils
</pre></div>
</div>
</div>
</div>
<p>Get the imports.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">socket</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">h5py</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">edgeitems</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">linear_sum_assignment</span>

<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span><span class="s1">&#39;scripts&#39;</span><span class="p">)</span>  
<span class="c1">#os.path.dirname(os.path.abspath(__file__))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">))</span>
<span class="kn">import</span> <span class="nn">provider</span>
<span class="kn">import</span> <span class="nn">gapnet_classify</span> <span class="k">as</span> <span class="nn">MODEL</span>
</pre></div>
</div>
</div>
</div>
<p>Get the input parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="n">parserdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_dim&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="c1">#help=&#39;Dimension of the encoding layer [Default: 3]&#39;)</span>
              <span class="s1">&#39;n_clusters&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="c1">#help=&#39;Number of clusters [Default: 3]&#39;)</span>
              <span class="s1">&#39;gpu&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1">#help=&#39;GPU to use [default: GPU 0]&#39;)</span>
              <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="s1">&#39;gapnet_clasify&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;Model name [default: gapnet_classify]&#39;)</span>
              <span class="s1">&#39;log_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;Log dir [default: log]&#39;)</span>
              <span class="s1">&#39;num_point&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="c1">#help=&#39;Point Number [default: 100]&#39;)</span>
              <span class="s1">&#39;max_epoch&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="c1">#help=&#39;Epoch to run [default: 200]&#39;)</span>
              <span class="s1">&#39;epochs_pretrain&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1">#help=&#39;Epochs to for pretraining [default: 10]&#39;)</span>
              <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="c1">#help=&#39;Batch Size during training [default: 512]&#39;)</span>
              <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="c1">#help=&#39;Initial learning rate [default: 0.01]&#39;)</span>

              <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="c1">#help=&#39;Initial momentum [default: 0.9]&#39;)</span>
              <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;adam or momentum [default: adam]&#39;)</span>
              <span class="s1">&#39;decay_step&#39;</span><span class="p">:</span> <span class="mi">500000</span><span class="p">,</span> <span class="c1">#help=&#39;Decay step for lr decay [default: 500000]&#39;)</span>
              <span class="s1">&#39;wd&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="c1">#help=&#39;Weight Decay [Default: 0.0]&#39;)</span>
              <span class="s1">&#39;decay_rate&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="c1">#help=&#39;Decay rate for lr decay [default: 0.5]&#39;)</span>
              <span class="s1">&#39;output_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;train_results&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;Directory that stores all training logs and trained models&#39;)</span>
              <span class="s1">&#39;data_dir&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span><span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">),</span> <span class="c1"># &#39;../h5&#39;, #help=&#39;directory with data [default: hdf5_data]&#39;)</span>
              <span class="s1">&#39;nfeat&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="c1">#help=&#39;Number of features [default: 8]&#39;)</span>
              <span class="s1">&#39;ncat&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="c1">#help=&#39;Number of categories [default: 20]&#39;)</span>
             <span class="p">}</span>

<span class="n">FLAGS</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">parserdict</span><span class="p">)</span>
<span class="n">H5_DIR</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">data_dir</span>

<span class="n">EPOCH_CNT</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">MAX_PRETRAIN</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">epochs_pretrain</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">NUM_POINT</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">num_point</span>
<span class="n">NUM_FEAT</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">nfeat</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">ncat</span>
<span class="n">MAX_EPOCH</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">max_epoch</span>
<span class="n">BASE_LEARNING_RATE</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">learning_rate</span>
<span class="n">GPU_INDEX</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">gpu</span>
<span class="n">MOMENTUM</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">momentum</span>
<span class="n">OPTIMIZER</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">optimizer</span>
<span class="n">DECAY_STEP</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">decay_step</span>
<span class="n">DECAY_RATE</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">decay_rate</span>

<span class="c1"># MODEL = importlib.import_module(FLAGS.model) # import network module</span>
<span class="n">MODEL_FILE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">model</span> <span class="o">+</span> <span class="s1">&#39;.py&#39;</span><span class="p">)</span>
<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span> <span class="s1">&#39;logs&#39;</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;cp </span><span class="si">%s</span><span class="s1">.py </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">MODEL_FILE</span><span class="p">,</span> <span class="n">LOG_DIR</span><span class="p">))</span>  <span class="c1"># bkp of model def</span>
<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;cp train_kmeans.py </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">LOG_DIR</span><span class="p">))</span>  <span class="c1"># bkp of train procedure</span>

<span class="n">BN_INIT_DECAY</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">BN_DECAY_DECAY_RATE</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">BN_DECAY_DECAY_STEP</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">DECAY_STEP</span><span class="p">)</span>
<span class="n">BN_DECAY_CLIP</span> <span class="o">=</span> <span class="mf">0.99</span>

<span class="n">LEARNING_RATE_CLIP</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">HOSTNAME</span> <span class="o">=</span> <span class="n">socket</span><span class="o">.</span><span class="n">gethostname</span><span class="p">()</span>

<span class="n">TRAIN_FILES</span> <span class="o">=</span> <span class="n">provider</span><span class="o">.</span><span class="n">getDataFiles</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">H5_DIR</span><span class="p">,</span> <span class="s1">&#39;train_files_wztop.txt&#39;</span><span class="p">))</span>
<span class="n">TEST_FILES</span> <span class="o">=</span> <span class="n">provider</span><span class="o">.</span><span class="n">getDataFiles</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">H5_DIR</span><span class="p">,</span> <span class="s1">&#39;test_files_wztop.txt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Define the utils functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="k">def</span> <span class="nf">get_learning_rate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">exponential_decay</span><span class="p">(</span>
        <span class="n">BASE_LEARNING_RATE</span><span class="p">,</span>  <span class="c1"># Base learning rate.</span>
        <span class="n">batch</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>  <span class="c1"># Current index into the dataset.</span>
        <span class="n">DECAY_STEP</span><span class="p">,</span>  <span class="c1"># Decay step.</span>
        <span class="n">DECAY_RATE</span><span class="p">,</span>  <span class="c1"># Decay rate.</span>
        <span class="n">staircase</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">LEARNING_RATE_CLIP</span><span class="p">)</span>  <span class="c1"># CLIP THE LEARNING RATE!</span>
    <span class="k">return</span> <span class="n">learning_rate</span>


<span class="k">def</span> <span class="nf">get_bn_decay</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">bn_momentum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">exponential_decay</span><span class="p">(</span>
        <span class="n">BN_INIT_DECAY</span><span class="p">,</span>
        <span class="n">batch</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
        <span class="n">BN_DECAY_DECAY_STEP</span><span class="p">,</span>
        <span class="n">BN_DECAY_DECAY_RATE</span><span class="p">,</span>
        <span class="n">staircase</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">bn_decay</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">BN_DECAY_CLIP</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">bn_momentum</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bn_decay</span>
</pre></div>
</div>
</div>
</div>
<p>Modification: - create checkpoint directory for horovod - directory is
user chosen</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
 
<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="s1">&#39;/dbfs/databricks/driver/06_LHC/logs/train/</span><span class="si">{}</span><span class="s1">/&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
 
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Create horovod h5 loading function: - not the rank and size is inputed.</p>
<ul class="simple">
<li><p>rank is the current device id - size is the total number of available
GPUs - we split the data in the h5 file for each device.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="k">def</span> <span class="nf">load_h5_hvd</span><span class="p">(</span><span class="n">h5_filename</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;pid&#39;</span><span class="p">][</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>
    <span class="n">seg</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">][</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loaded </span><span class="si">{0}</span><span class="s2"> events&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">seg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Main training function. Modifications are: - import packages again.
Otherwise single devices may cause problems. - initialise the horovod
runner - copy the files from local to each GPU such that they are
available for horovod. - scale the learning rate by the number of
available devices. - add a horovod specific distributed optimizer. - use
hooks for checkpoint saving ever 1000 steps. - switch from a normal TF
training session to a monitored training session.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="k">def</span> <span class="nf">train_hvd</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">horovod.tensorflow</span> <span class="k">as</span> <span class="nn">hvd</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">shutil</span>

    
    <span class="c1"># do all the imports here again in order for hvd to work nicely</span>
    <span class="kn">import</span> <span class="nn">horovod.tensorflow</span> <span class="k">as</span> <span class="nn">hvd</span>
    <span class="kn">import</span> <span class="nn">argparse</span><span class="o">,</span> <span class="nn">shlex</span>
    <span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">socket</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
    <span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
    <span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">edgeitems</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">linear_sum_assignment</span>
    <span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span><span class="s1">&#39;scripts&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">))</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">))</span>
    
    <span class="c1"># HOROVOD: initialize Horovod.</span>
    <span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
    
    <span class="c1"># HOROVOD: Copy files from local to each single GPU directory</span>
    <span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/FileStore/06_LHC&quot;</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Copying data/files to local horovod folder...&quot;</span><span class="p">)</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with copying!&quot;</span><span class="p">)</span>
    
    <span class="kn">import</span> <span class="nn">provider</span>
    <span class="kn">import</span> <span class="nn">gapnet_classify</span> <span class="k">as</span> <span class="nn">MODEL</span>
    
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/gpu:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">GPU_INDEX</span><span class="p">)):</span>
            <span class="n">pointclouds_pl</span><span class="p">,</span> <span class="n">labels_pl</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">placeholder_inputs</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_POINT</span><span class="p">,</span> <span class="n">NUM_FEAT</span><span class="p">)</span>

            <span class="n">is_training_pl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>

            <span class="c1"># Note the global_step=batch parameter to minimize.</span>
            <span class="c1"># That tells the optimizer to helpfully increment the &#39;batch&#39; parameter for you every time it trains.</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>
            <span class="n">bn_decay</span> <span class="o">=</span> <span class="n">get_bn_decay</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;bn_decay&#39;</span><span class="p">,</span> <span class="n">bn_decay</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Get model and loss&quot;</span><span class="p">)</span>

            <span class="n">pred</span><span class="p">,</span> <span class="n">max_pool</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">pointclouds_pl</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="n">is_training_pl</span><span class="p">,</span>
                                             <span class="n">bn_decay</span><span class="o">=</span><span class="n">bn_decay</span><span class="p">,</span>
                                             <span class="n">num_class</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">wd</span><span class="p">,</span>
                                             <span class="p">)</span>

            <span class="n">class_loss</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">get_focal_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels_pl</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">max_dim</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span>
                             <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># k centroids</span>
            <span class="n">kmeans_loss</span><span class="p">,</span> <span class="n">stack_dist</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">get_loss_kmeans</span><span class="p">(</span><span class="n">max_pool</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">max_dim</span><span class="p">,</span>
                                                            <span class="n">FLAGS</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

            <span class="n">full_loss</span> <span class="o">=</span> <span class="n">kmeans_loss</span> <span class="o">+</span> <span class="n">class_loss</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Get training operator&quot;</span><span class="p">)</span>
            <span class="c1"># Get training operator</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">get_learning_rate</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="c1"># HOROVOD: scale learning rade from hvd dependent number of processes (=hvd.size)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">OPTIMIZER</span> <span class="o">==</span> <span class="s1">&#39;momentum&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">momentum</span><span class="o">=</span><span class="n">MOMENTUM</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">OPTIMIZER</span> <span class="o">==</span> <span class="s1">&#39;adam&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
            <span class="c1"># HOROVOD: add Horovod Distributed Optimizer</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

            <span class="n">global_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">()</span> 
            <span class="n">train_op_full</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">full_loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span> <span class="c1">#batch)</span>
            <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">class_loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span> <span class="c1">#batch)</span>

            <span class="c1"># Add ops to save and restore all the variables.</span>
            <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
             
        <span class="c1"># HOROVOD</span>
        <span class="n">hooks</span> <span class="o">=</span> <span class="p">[</span>
          <span class="c1"># Horovod: BroadcastGlobalVariablesHook broadcasts initial variable states</span>
          <span class="c1"># from rank 0 to all other processes. This is necessary to ensure consistent</span>
          <span class="c1"># initialization of all workers when training is started with random weights</span>
          <span class="c1"># or restored from a checkpoint.</span>
          <span class="n">hvd</span><span class="o">.</span><span class="n">BroadcastGlobalVariablesHook</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
          
          <span class="c1">#checkpoint_dir_mod = checkpoint_dir if hvd.rank() == 0 else None</span>
          
          <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointSaverHook</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="o">=</span><span class="n">checkpoint_dir</span><span class="p">,</span>
                                                 <span class="n">checkpoint_basename</span><span class="o">=</span><span class="s1">&#39;cluster.ckpt&#39;</span><span class="p">,</span>
                                                 <span class="n">save_steps</span><span class="o">=</span><span class="mi">1_000</span>
                                                <span class="p">),</span>

          <span class="c1"># this one basically prints every n steps the &quot;step&quot; and the &quot;loss&quot;. Output is cleaner without</span>
          <span class="c1"># tf.compat.v1.train.LoggingTensorHook(tensors={&#39;step&#39;: global_step, &#39;loss&#39;: full_loss}, every_n_iter=75),</span>
        <span class="p">]</span>

        <span class="c1"># Create a session</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">config</span><span class="o">.</span><span class="n">allow_soft_placement</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">config</span><span class="o">.</span><span class="n">log_device_placement</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">visible_device_list</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">local_rank</span><span class="p">())</span>
        
        <span class="c1"># global variable initializer must be defined before session definition</span>
        <span class="n">init_global_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
        
        <span class="c1"># MonitoredTrainingSession</span>
        <span class="c1"># takes care of session initialization,</span>
        <span class="c1"># restoring from a checkpoint, saving to a checkpoint, and closing when done</span>
        <span class="c1"># or an error occurs.</span>
        <span class="c1">#checkpoint_dir_mod = checkpoint_dir if hvd.rank() == 0 else None</span>
        <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MonitoredTrainingSession</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">,</span>
                                                           <span class="n">hooks</span><span class="o">=</span><span class="n">hooks</span><span class="p">,</span>
                                                           <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># get one batch_data from the training files in oder to inintialise the session</span>
        <span class="n">train_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">TRAIN_FILES</span><span class="p">))</span>
        <span class="n">current_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="n">TRAIN_FILES</span><span class="p">[</span><span class="n">train_idxs</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">current_cluster</span> <span class="o">=</span> <span class="n">load_h5_hvd</span><span class="p">(</span><span class="n">current_file</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
        <span class="c1"># </span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">pointclouds_pl</span><span class="p">:</span> <span class="n">batch_data</span><span class="p">,</span>
                     <span class="n">labels_pl</span><span class="p">:</span> <span class="n">batch_label</span><span class="p">,</span>
                     <span class="n">is_training_pl</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                     <span class="n">alpha</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">EPOCH_CNT</span> <span class="o">-</span> <span class="n">MAX_PRETRAIN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),}</span>
        <span class="c1">#NOT SO CLEAR THAT init_global_step IS NECESSARY. </span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_global_step</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

        <span class="c1"># hels with merging: CHANGE THIS IF POSSIBLE</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">_unsafe_unfinalize</span><span class="p">()</span>
        <span class="c1"># Add summary writers</span>
        <span class="n">merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
        <span class="n">train_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="n">test_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        
        <span class="c1"># Init variables</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of weights for the model: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()]))</span>
        <span class="n">ops</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pointclouds_pl&#39;</span><span class="p">:</span> <span class="n">pointclouds_pl</span><span class="p">,</span>
          <span class="s1">&#39;labels_pl&#39;</span><span class="p">:</span> <span class="n">labels_pl</span><span class="p">,</span>
          <span class="s1">&#39;is_training_pl&#39;</span><span class="p">:</span> <span class="n">is_training_pl</span><span class="p">,</span>
          <span class="s1">&#39;max_pool&#39;</span><span class="p">:</span> <span class="n">max_pool</span><span class="p">,</span>
          <span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span>
          <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">alpha</span><span class="p">,</span>
          <span class="s1">&#39;mu&#39;</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span>
          <span class="s1">&#39;stack_dist&#39;</span><span class="p">:</span> <span class="n">stack_dist</span><span class="p">,</span>
          <span class="s1">&#39;class_loss&#39;</span><span class="p">:</span> <span class="n">class_loss</span><span class="p">,</span>
          <span class="s1">&#39;kmeans_loss&#39;</span><span class="p">:</span> <span class="n">kmeans_loss</span><span class="p">,</span>
          <span class="s1">&#39;train_op&#39;</span><span class="p">:</span> <span class="n">train_op</span><span class="p">,</span>
          <span class="s1">&#39;train_op_full&#39;</span><span class="p">:</span> <span class="n">train_op_full</span><span class="p">,</span>
          <span class="s1">&#39;merged&#39;</span><span class="p">:</span> <span class="n">merged</span><span class="p">,</span>
          <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">batch</span><span class="p">,</span>
          <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">learning_rate</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_EPOCH</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">**** EPOCH </span><span class="si">%03d</span><span class="s1"> ****&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            
            <span class="n">is_full_training</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">MAX_PRETRAIN</span>
            <span class="n">max_pool</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">train_writer</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">is_full_training</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">MAX_PRETRAIN</span><span class="p">:</span>
                <span class="n">centers</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_pool</span><span class="p">))</span>
                <span class="n">centers</span> <span class="o">=</span> <span class="n">centers</span><span class="o">.</span><span class="n">cluster_centers_</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">centers</span><span class="p">))</span>

            <span class="n">eval_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">test_writer</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">is_full_training</span><span class="p">)</span>
            <span class="sd">&quot;&quot;&quot;if is_full_training:</span>
<span class="sd">                save_path = saver.save(sess, os.path.join(LOG_DIR, &#39;cluster.ckpt&#39;))</span>
<span class="sd">            else:</span>
<span class="sd">                save_path = saver.save(sess, os.path.join(LOG_DIR, &#39;model.ckpt&#39;))&quot;&quot;&quot;</span>
            <span class="c1">#print(&quot;Model saved in file: %s&quot; % save_path)</span>
</pre></div>
</div>
</div>
</div>
<p>Training utils.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">):</span>
    <span class="n">batch_label</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span>


<span class="k">def</span> <span class="nf">cluster_acc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate clustering accuracy. Require scikit-learn installed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_true</span><span class="o">.</span><span class="n">max</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">w</span><span class="p">[</span><span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">linear_sum_assignment</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">])</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
</div>
<p>One epoch training and evaluation functions: - the applicable horovod
rank and size is fed into both functions. - use the rank and size to
load the correct h5 data. - remove progress bars since progress bars
from each device would overlap.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">train_writer</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">,</span> <span class="n">is_full_training</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; ops: dict mapping from string to tf ops &quot;&quot;&quot;</span>
    <span class="n">is_training</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">train_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">TRAIN_FILES</span><span class="p">))</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="n">loss_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">y_pool</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TRAIN_FILES</span><span class="p">)):</span>
        <span class="c1"># print(&#39;----&#39; + str(fn) + &#39;-----&#39;)</span>
        <span class="n">current_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="n">TRAIN_FILES</span><span class="p">[</span><span class="n">train_idxs</span><span class="p">[</span><span class="n">fn</span><span class="p">]])</span>
        <span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">current_cluster</span> <span class="o">=</span> <span class="n">load_h5_hvd</span><span class="p">(</span><span class="n">current_file</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">)</span>

        <span class="n">current_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">current_label</span><span class="p">)</span>

        <span class="n">file_size</span> <span class="o">=</span> <span class="n">current_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
        <span class="c1"># num_batches = 5</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()))</span>

        <span class="c1"># initialise progress bar</span>
        <span class="c1">#process_desc = &quot;TRAINING: Loss {:2.3e}&quot;</span>
        <span class="c1">#progress_bar = tqdm(initial=0, leave=True, total=num_batches,</span>
        <span class="c1">#                    desc=process_desc.format(0),</span>
        <span class="c1">#                    position=0)</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>

            <span class="c1"># print(batch_weight)</span>
            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;pointclouds_pl&#39;</span><span class="p">]:</span> <span class="n">batch_data</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;labels_pl&#39;</span><span class="p">]:</span> <span class="n">batch_label</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;is_training_pl&#39;</span><span class="p">]:</span> <span class="n">is_training</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]:</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">EPOCH_CNT</span> <span class="o">-</span> <span class="n">MAX_PRETRAIN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),}</span>
            <span class="k">if</span> <span class="n">is_full_training</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                                 <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;train_op_full&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;kmeans_loss&#39;</span><span class="p">],</span>
                                                                 <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;stack_dist&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]],</span>
                                                                <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

                <span class="n">batch_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">r</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">current_cluster</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]])</span>
                <span class="n">cluster_assign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cur_batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">):</span>
                    <span class="n">index_closest_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
                    <span class="n">cluster_assign</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">index_closest_cluster</span>

                <span class="n">acc</span> <span class="o">+=</span> <span class="n">cluster_acc</span><span class="p">(</span><span class="n">batch_cluster</span><span class="p">,</span> <span class="n">cluster_assign</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                                     <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;train_op&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;class_loss&#39;</span><span class="p">],</span>
                                                                     <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;max_pool&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]],</span>
                                                                    <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_pool</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">y_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_pool</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">loss_sum</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>

            <span class="c1">#train_writer.add_summary(summary, step)</span>
            <span class="k">if</span> <span class="n">hvd_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">train_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
              
              

            <span class="c1"># Update train bar</span>
            <span class="c1">#process_desc.format(loss_val)</span>
            <span class="c1">#progress_bar.update(1)</span>
        <span class="c1">#progress_bar.close()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;learning rate: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">lr</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train mean loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">loss_sum</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)))</span>
    <span class="c1">#if is_full_training:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train clustering accuracy: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">y_pool</span>


<span class="k">def</span> <span class="nf">eval_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">test_writer</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">,</span> <span class="n">is_full_training</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; ops: dict mapping from string to tf ops &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">EPOCH_CNT</span>
    <span class="n">is_training</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">test_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">TEST_FILES</span><span class="p">))</span>
    <span class="c1"># Test on all data: last batch might be smaller than BATCH_SIZE</span>
    <span class="n">loss_sum</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">acc_kmeans</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TEST_FILES</span><span class="p">)):</span>
        <span class="c1"># print(&#39;----&#39; + str(fn) + &#39;-----&#39;)</span>
        <span class="n">current_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="n">TEST_FILES</span><span class="p">[</span><span class="n">test_idxs</span><span class="p">[</span><span class="n">fn</span><span class="p">]])</span>
        <span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">current_cluster</span> <span class="o">=</span> <span class="n">load_h5_hvd</span><span class="p">(</span><span class="n">current_file</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">)</span>
        <span class="n">current_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">current_label</span><span class="p">)</span>

        <span class="n">file_size</span> <span class="o">=</span> <span class="n">current_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
        
        <span class="sd">&quot;&quot;&quot;process_desc = &quot;VALIDATION: Loss {:2.3e}&quot;</span>
<span class="sd">        progress_bar = tqdm(initial=0, leave=True, total=num_batches,</span>
<span class="sd">                        desc=process_desc.format(0),</span>
<span class="sd">                        position=0)&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>

            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;pointclouds_pl&#39;</span><span class="p">]:</span> <span class="n">batch_data</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;is_training_pl&#39;</span><span class="p">]:</span> <span class="n">is_training</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;labels_pl&#39;</span><span class="p">]:</span> <span class="n">batch_label</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]:</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">EPOCH_CNT</span> <span class="o">-</span> <span class="n">MAX_PRETRAIN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),}</span>

            <span class="k">if</span> <span class="n">is_full_training</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                                        <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;kmeans_loss&#39;</span><span class="p">],</span>
                                                                        <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;max_pool&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;stack_dist&#39;</span><span class="p">],</span>
                                                                        <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]],</span>
                                                                       <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
                
                <span class="n">batch_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">r</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">current_cluster</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]])</span>
                <span class="n">cluster_assign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cur_batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">):</span>
                    <span class="n">index_closest_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
                    <span class="n">cluster_assign</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">index_closest_cluster</span>

                <span class="n">acc</span> <span class="o">+=</span> <span class="n">cluster_acc</span><span class="p">(</span><span class="n">batch_cluster</span><span class="p">,</span> <span class="n">cluster_assign</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                    <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;class_loss&#39;</span><span class="p">]],</span>
                                                   <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

            <span class="c1">#test_writer.add_summary(summary, step)</span>
            <span class="k">if</span> <span class="n">hvd_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">test_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="n">loss_sum</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>
            
            <span class="sd">&quot;&quot;&quot;# Update train bar</span>
<span class="sd">            process_desc.format(loss_val)</span>
<span class="sd">            progress_bar.update(1)&quot;&quot;&quot;</span>
        <span class="c1">#progress_bar.close()</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">loss_sum</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;test mean loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">total_loss</span><span class="p">))</span>
    <span class="c1">#if is_full_training:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;testing clustering accuracy: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)))</span>

    <span class="n">EPOCH_CNT</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>Run the training: - initialise the Horovod runner with np=2 GPUs. The
cluster does not allow more GPUs - run the horovod runner with the given
training function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">python</span>
<span class="kn">from</span> <span class="nn">sparkdl</span> <span class="kn">import</span> <span class="n">HorovodRunner</span>
 
<span class="n">hr</span> <span class="o">=</span> <span class="n">HorovodRunner</span><span class="p">(</span><span class="n">np</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hr</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_hvd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>HorovodRunner will stream all training logs to notebook cell output. If there are too many logs, you
can adjust the log level in your train method. Or you can set driver_log_verbosity to
&#39;log_callback_only&#39; and use a HorovodRunner log  callback on the first worker to get concise
progress updates.
The global names read or written to by the pickled function are {&#39;get_bn_decay&#39;, &#39;MOMENTUM&#39;, &#39;range&#39;, &#39;NUM_CLASSES&#39;, &#39;OPTIMIZER&#39;, &#39;EPOCH_CNT&#39;, &#39;get_learning_rate&#39;, &#39;load_h5_hvd&#39;, &#39;get_batch&#39;, &#39;MAX_EPOCH&#39;, &#39;len&#39;, &#39;NUM_FEAT&#39;, &#39;GPU_INDEX&#39;, &#39;BATCH_SIZE&#39;, &#39;LOG_DIR&#39;, &#39;FLAGS&#39;, &#39;checkpoint_dir&#39;, &#39;eval_one_epoch&#39;, &#39;NUM_POINT&#39;, &#39;MAX_PRETRAIN&#39;, &#39;TRAIN_FILES&#39;, &#39;print&#39;, &#39;str&#39;, &#39;train_one_epoch&#39;}.
The pickled object size is 11055 bytes.

### How to enable Horovod Timeline? ###
HorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To
record a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the
timeline file to be created. You can then open the timeline file  using the chrome://tracing
facility of the Chrome browser.

Start training.
[1,1]&lt;stderr&gt;:2021-01-04 17:28:24.816450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2021-01-04 17:28:24.869795: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stdout&gt;:Copying data/files to local horovod folder...
[1,1]&lt;stdout&gt;:Copying data/files to local horovod folder...
[1,0]&lt;stdout&gt;:Done with copying!
[1,1]&lt;stdout&gt;:Done with copying!
[1,0]&lt;stdout&gt;:--- Get model and loss
[1,1]&lt;stdout&gt;:--- Get model and loss
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.132866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.176503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.184581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.185468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,1]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,1]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.185502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.232379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.233308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,0]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,0]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.233358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.619010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.637123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.889096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.931508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:20.936127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:20.982198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:21.453513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:21.540557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:21.560198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:21.627762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:21.679130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]&lt;stderr&gt;:2021-01-04 17:30:21.679396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:21.680404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:21.681219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,0]&lt;stdout&gt;:--- Get training operator
[1,1]&lt;stderr&gt;:2021-01-04 17:30:22.394999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2021-01-04 17:30:22.395216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:22.396223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:22.397023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,1]&lt;stdout&gt;:--- Get training operator
[1,0]&lt;stderr&gt;:INFO:tensorflow:Create CheckpointSaverHook.
[1,0]&lt;stderr&gt;:Create CheckpointSaverHook.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Create CheckpointSaverHook.
[1,0]&lt;stderr&gt;:Create CheckpointSaverHook.
[1,0]&lt;stderr&gt;:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[1,0]&lt;stderr&gt;:Instructions for updating:
[1,0]&lt;stderr&gt;:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
[1,0]&lt;stderr&gt;:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[1,0]&lt;stderr&gt;:Instructions for updating:
[1,0]&lt;stderr&gt;:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Create CheckpointSaverHook.
[1,1]&lt;stderr&gt;:Create CheckpointSaverHook.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Create CheckpointSaverHook.
[1,1]&lt;stderr&gt;:Create CheckpointSaverHook.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Graph was finalized.
[1,0]&lt;stderr&gt;:Graph was finalized.
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.378385: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,0]&lt;stderr&gt;:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.403662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.404019: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5587faad13f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.404049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.499397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.500320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5587faabc500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.500353: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.500691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,0]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,0]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501829: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.501885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.502014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.502935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.503846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,0]&lt;stderr&gt;:2021-01-04 17:30:26.503903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[1,1]&lt;stderr&gt;:Instructions for updating:
[1,1]&lt;stderr&gt;:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
[1,1]&lt;stderr&gt;:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
[1,1]&lt;stderr&gt;:Instructions for updating:
[1,1]&lt;stderr&gt;:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Graph was finalized.
[1,1]&lt;stderr&gt;:Graph was finalized.
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.413689: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,1]&lt;stderr&gt;:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.451878: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.452210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631a5a623f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.452249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.462163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.462213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.462226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.463593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.464598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.465438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -&gt; physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.565670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.566566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631a575bc90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.566604: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.568675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
[1,1]&lt;stderr&gt;:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5
[1,1]&lt;stderr&gt;:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.569919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.570828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.571633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,1]&lt;stderr&gt;:2021-01-04 17:30:27.572656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]&lt;stderr&gt;:2021-01-04 17:30:27.764091: W tensorflow/core/common_runtime/colocation_graph.cc:1139] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources&#39; devices. Current candidate devices are [
[1,0]&lt;stderr&gt;:  /job:localhost/replica:0/task:0/device:CPU:0].
[1,0]&lt;stderr&gt;:See below for details of this colocation group:
[1,0]&lt;stderr&gt;:Colocation Debug Info:
[1,0]&lt;stderr&gt;:Colocation group had the following types and supported devices:
[1,0]&lt;stderr&gt;:Root Member(assigned_device_name_index_=-1 requested_device_name_=&#39;/device:GPU:0&#39; assigned_device_name_=&#39;&#39; resource_device_name_=&#39;/device:GPU:0&#39; supported_device_types_=[CPU] possible_devices_=[]
[1,0]&lt;stderr&gt;:ReadVariableOp: GPU CPU XLA_CPU XLA_GPU
[1,0]&lt;stderr&gt;:AssignVariableOp: CPU XLA_CPU XLA_GPU
[1,0]&lt;stderr&gt;:VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU
[1,0]&lt;stderr&gt;:Const: GPU CPU XLA_CPU XLA_GPU
[1,0]&lt;stderr&gt;:VarHandleOp: CPU XLA_CPU XLA_GPU
[1,0]&lt;stderr&gt;:
[1,0]&lt;stderr&gt;:Colocation members, user-requested devices, and framework assigned devices, if any:
[1,0]&lt;stderr&gt;:  Variable/Initializer/initial_value (Const)
[1,0]&lt;stderr&gt;:  Variable (VarHandleOp) /device:GPU:0
[1,0]&lt;stderr&gt;:  Variable/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0
[1,0]&lt;stderr&gt;:  Variable/Assign (AssignVariableOp) /device:GPU:0
[1,0]&lt;stderr&gt;:  Variable/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0
[1,0]&lt;stderr&gt;:  ReadVariableOp (ReadVariableOp)
[1,0]&lt;stderr&gt;:  ReadVariableOp_4 (ReadVariableOp)
[1,0]&lt;stderr&gt;:  save/AssignVariableOp (AssignVariableOp) /device:GPU:0
[1,0]&lt;stderr&gt;:  HorovodBroadcast_Variable_0/ReadVariableOp (ReadVariableOp)
[1,0]&lt;stderr&gt;:  AssignVariableOp (AssignVariableOp)
[1,0]&lt;stderr&gt;:  ReadVariableOp_5 (ReadVariableOp)
[1,0]&lt;stderr&gt;:  report_uninitialized_variables/VarIsInitializedOp (VarIsInitializedOp)
[1,0]&lt;stderr&gt;:  report_uninitialized_variables_1/VarIsInitializedOp (VarIsInitializedOp)
[1,0]&lt;stderr&gt;:  save_1/AssignVariableOp (AssignVariableOp) /device:GPU:0
[1,0]&lt;stderr&gt;:
[1,0]&lt;stderr&gt;:INFO:tensorflow:Running local_init_op.
[1,0]&lt;stderr&gt;:Running local_init_op.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Done running local_init_op.
[1,0]&lt;stderr&gt;:Done running local_init_op.
[1,1]&lt;stderr&gt;:2021-01-04 17:30:28.981517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,1]&lt;stderr&gt;:2021-01-04 17:30:28.981570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
[1,1]&lt;stderr&gt;:2021-01-04 17:30:28.981580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
[1,1]&lt;stderr&gt;:2021-01-04 17:30:28.982650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:28.983624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]&lt;stderr&gt;:2021-01-04 17:30:28.984487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -&gt; physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)
[1,1]&lt;stderr&gt;:2021-01-04 17:30:29.296559: W tensorflow/core/common_runtime/colocation_graph.cc:1139] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources&#39; devices. Current candidate devices are [
[1,1]&lt;stderr&gt;:  /job:localhost/replica:0/task:0/device:CPU:0].
[1,1]&lt;stderr&gt;:See below for details of this colocation group:
[1,1]&lt;stderr&gt;:Colocation Debug Info:
[1,1]&lt;stderr&gt;:Colocation group had the following types and supported devices:
[1,1]&lt;stderr&gt;:Root Member(assigned_device_name_index_=-1 requested_device_name_=&#39;/device:GPU:0&#39; assigned_device_name_=&#39;&#39; resource_device_name_=&#39;/device:GPU:0&#39; supported_device_types_=[CPU] possible_devices_=[]
[1,1]&lt;stderr&gt;:ReadVariableOp: GPU CPU XLA_CPU XLA_GPU
[1,1]&lt;stderr&gt;:AssignVariableOp: CPU XLA_CPU XLA_GPU
[1,1]&lt;stderr&gt;:VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU
[1,1]&lt;stderr&gt;:Const: GPU CPU XLA_CPU XLA_GPU
[1,1]&lt;stderr&gt;:VarHandleOp: CPU XLA_CPU XLA_GPU
[1,1]&lt;stderr&gt;:
[1,1]&lt;stderr&gt;:Colocation members, user-requested devices, and framework assigned devices, if any:
[1,1]&lt;stderr&gt;:  Variable/Initializer/initial_value (Const)
[1,1]&lt;stderr&gt;:  Variable (VarHandleOp) /device:GPU:0
[1,1]&lt;stderr&gt;:  Variable/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0
[1,1]&lt;stderr&gt;:  Variable/Assign (AssignVariableOp) /device:GPU:0
[1,1]&lt;stderr&gt;:  Variable/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0
[1,1]&lt;stderr&gt;:  ReadVariableOp (ReadVariableOp)
[1,1]&lt;stderr&gt;:  ReadVariableOp_4 (ReadVariableOp)
[1,1]&lt;stderr&gt;:  save/AssignVariableOp (AssignVariableOp) /device:GPU:0
[1,1]&lt;stderr&gt;:  HorovodBroadcast_Variable_0/ReadVariableOp (ReadVariableOp)
[1,1]&lt;stderr&gt;:  AssignVariableOp (AssignVariableOp)
[1,1]&lt;stderr&gt;:  ReadVariableOp_5 (ReadVariableOp)
[1,1]&lt;stderr&gt;:  report_uninitialized_variables/VarIsInitializedOp (VarIsInitializedOp)
[1,1]&lt;stderr&gt;:  report_uninitialized_variables_1/VarIsInitializedOp (VarIsInitializedOp)
[1,1]&lt;stderr&gt;:  save_1/AssignVariableOp (AssignVariableOp) /device:GPU:0
[1,1]&lt;stderr&gt;:
[1,1]&lt;stderr&gt;:INFO:tensorflow:Running local_init_op.
[1,1]&lt;stderr&gt;:Running local_init_op.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Done running local_init_op.
[1,1]&lt;stderr&gt;:Done running local_init_op.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 0...
[1,0]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,0]&lt;stderr&gt;:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 0...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,1]&lt;stderr&gt;:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 0...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 0...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 0...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,1]&lt;stderr&gt;:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.

*** WARNING: skipped 5495 bytes of output ***

[1,0]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.38528
[1,0]&lt;stderr&gt;:global_step/sec: 2.38528
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.34714
[1,1]&lt;stderr&gt;:global_step/sec: 2.34714
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 3.0324
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 3.03245
[1,0]&lt;stderr&gt;:global_step/sec: 3.0324
[1,1]&lt;stderr&gt;:global_step/sec: 3.03245
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 3.825902
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.000000
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 4.023047
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.000000
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,0]&lt;stderr&gt;:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
[1,1]&lt;stdout&gt;:test mean loss: 1.974160
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.000000
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 001 ****
[1,0]&lt;stdout&gt;:test mean loss: 1.894498[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.000000
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 001 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:32:45.264640
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:32:45.838243
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.04904
[1,0]&lt;stderr&gt;:global_step/sec: 2.04904
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.04898
[1,1]&lt;stderr&gt;:global_step/sec: 2.04898
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.93649
[1,0]&lt;stderr&gt;:global_step/sec: 2.93649
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.93658
[1,1]&lt;stderr&gt;:global_step/sec: 2.93658
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.89172
[1,0]&lt;stderr&gt;:global_step/sec: 2.89172
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.89167
[1,1]&lt;stderr&gt;:global_step/sec: 2.89167
[1,0]&lt;stdout&gt;:learning rate: 0.001000
[1,0]&lt;stdout&gt;:train mean loss: 1.479257
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.000000
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 1.611109
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.000000
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 1.255668
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.000000
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 002 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:34:44.019857
[1,0]&lt;stdout&gt;:test mean loss: 2.434365[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.000000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 002 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:34:44.976721
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.81088
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.8109
[1,0]&lt;stderr&gt;:global_step/sec: 1.81088
[1,1]&lt;stderr&gt;:global_step/sec: 1.8109
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84508
[1,0]&lt;stderr&gt;:global_step/sec: 2.84508
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84507
[1,1]&lt;stderr&gt;:global_step/sec: 2.84507
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84237
[1,0]&lt;stderr&gt;:global_step/sec: 2.84237
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84234
[1,1]&lt;stderr&gt;:global_step/sec: 2.84234
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.073204
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.565135
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.029733
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.590128
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 0.035144
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.583770
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 003 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:36:46.278189
[1,0]&lt;stdout&gt;:test mean loss: 0.073979[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.535852
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 003 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:36:47.495020
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.95912
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.95915
[1,1]&lt;stderr&gt;:global_step/sec: 1.95915
[1,0]&lt;stderr&gt;:global_step/sec: 1.95912
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.8459
[1,1]&lt;stderr&gt;:global_step/sec: 2.8459
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84588
[1,0]&lt;stderr&gt;:global_step/sec: 2.84588
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 1000...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,1]&lt;stderr&gt;:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 1000...
[1,0]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,0]&lt;stderr&gt;:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 1000...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 1000...
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.6452
[1,1]&lt;stderr&gt;:global_step/sec: 2.6452
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.64518
[1,0]&lt;stderr&gt;:global_step/sec: 2.64518
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.047254
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.592644
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.028695
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.583104
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 0.032069
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.577938
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 004 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:38:48.063939
[1,0]&lt;stdout&gt;:test mean loss: 0.046610[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.558246
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 004 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:38:49.158460
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.98098
[1,0]&lt;stderr&gt;:global_step/sec: 1.98098
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.98091
[1,1]&lt;stderr&gt;:global_step/sec: 1.98091
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84389
[1,1]&lt;stderr&gt;:global_step/sec: 2.84389
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84377
[1,0]&lt;stderr&gt;:global_step/sec: 2.84377
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84688
[1,0]&lt;stderr&gt;:global_step/sec: 2.84688
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84681
[1,1]&lt;stderr&gt;:global_step/sec: 2.84681
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.033857
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.608349
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.026509
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.584607
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1475...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 1475...
[1,0]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,0]&lt;stderr&gt;:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1475...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 1475...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,1]&lt;stderr&gt;:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1475...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 1475...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1475...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 1475...
[1,1]&lt;stdout&gt;:test mean loss: 0.033016
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.577536
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 005 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:40:50.403813
[1,0]&lt;stdout&gt;:test mean loss: 0.033497[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.544601
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 005 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:40:52.117234
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.837
[1,1]&lt;stderr&gt;:global_step/sec: 1.837
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.83696
[1,0]&lt;stderr&gt;:global_step/sec: 1.83696
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.84922
[1,0]&lt;stderr&gt;:global_step/sec: 2.84922
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.8491
[1,1]&lt;stderr&gt;:global_step/sec: 2.8491
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.86428
[1,0]&lt;stderr&gt;:global_step/sec: 2.86428
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.86434
[1,1]&lt;stderr&gt;:global_step/sec: 2.86434
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.026064
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.643836[1,0]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.025038
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.584362
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 0.027497
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.562982
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 006 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:42:49.541722
[1,0]&lt;stdout&gt;:test mean loss: 0.025077[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.560493
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 006 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:42:50.501567
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.99568
[1,1]&lt;stderr&gt;:global_step/sec: 1.99568
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.99566
[1,0]&lt;stderr&gt;:global_step/sec: 1.99566
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85026
[1,0]&lt;stderr&gt;:global_step/sec: 2.85026
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85017
[1,1]&lt;stderr&gt;:global_step/sec: 2.85017
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85591
[1,0]&lt;stderr&gt;:global_step/sec: 2.85591
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85594
[1,1]&lt;stderr&gt;:global_step/sec: 2.85594
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 2000...
[1,0]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,0]&lt;stderr&gt;:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 2000...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,1]&lt;stderr&gt;:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 2000...
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 2000...
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.021587
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.646451
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.023550
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.584812
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 0.025361
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.553805
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 007 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:44:50.785483
[1,0]&lt;stdout&gt;:test mean loss: 0.022237[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.557256
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 007 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:44:51.680681
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.89396
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.89394
[1,1]&lt;stderr&gt;:global_step/sec: 1.89396
[1,0]&lt;stderr&gt;:global_step/sec: 1.89394
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85501
[1,0]&lt;stderr&gt;:global_step/sec: 2.85501
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85498
[1,1]&lt;stderr&gt;:global_step/sec: 2.85498
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85526
[1,0]&lt;stderr&gt;:global_step/sec: 2.85526
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85522
[1,1]&lt;stderr&gt;:global_step/sec: 2.85522
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.019167
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.631786
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.021949
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.579774
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 0.022571
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.561590
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 008 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:46:49.376643
[1,0]&lt;stdout&gt;:test mean loss: 0.019591[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.596399
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 008 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:46:50.271701
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.98749
[1,0]&lt;stderr&gt;:global_step/sec: 1.98749
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.98748
[1,1]&lt;stderr&gt;:global_step/sec: 1.98748
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85509
[1,1]&lt;stderr&gt;:global_step/sec: 2.85509
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.855
[1,0]&lt;stderr&gt;:global_step/sec: 2.855
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85604
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85601
[1,1]&lt;stderr&gt;:global_step/sec: 2.85601
[1,0]&lt;stderr&gt;:global_step/sec: 2.85604
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.017833
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.612758
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.019644
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.571921
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:test mean loss: 0.019357
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.568440
[1,1]&lt;stdout&gt;:
[1,1]&lt;stdout&gt;:**** EPOCH 009 ****
[1,1]&lt;stdout&gt;:loaded 151332 events
[1,1]&lt;stdout&gt;:2021-01-04 17:48:47.868751
[1,0]&lt;stdout&gt;:test mean loss: 0.018919[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.638806[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:**** EPOCH 009 ****
[1,0]&lt;stdout&gt;:loaded 151332 events
[1,0]&lt;stdout&gt;:2021-01-04 17:48:48.844865
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.98952
[1,0]&lt;stderr&gt;:global_step/sec: 1.98952
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 1.9895
[1,1]&lt;stderr&gt;:global_step/sec: 1.9895
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85433
[1,0]&lt;stderr&gt;:global_step/sec: 2.85433
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.8543
[1,1]&lt;stderr&gt;:global_step/sec: 2.8543
[1,0]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85624
[1,1]&lt;stderr&gt;:INFO:tensorflow:global_step/sec: 2.85631
[1,1]&lt;stderr&gt;:global_step/sec: 2.85631
[1,0]&lt;stderr&gt;:global_step/sec: 2.85624
[1,1]&lt;stdout&gt;:learning rate: 0.001000
[1,1]&lt;stdout&gt;:train mean loss: 0.017083
[1,1]&lt;stdout&gt;:train clustering accuracy: 0.566671
[1,0]&lt;stdout&gt;:learning rate: 0.001000[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:train mean loss: 0.017304
[1,0]&lt;stdout&gt;:train clustering accuracy: 0.599682
[1,0]&lt;stdout&gt;:loaded 37833 events
[1,1]&lt;stdout&gt;:loaded 37833 events
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2950...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 2950...
[1,0]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,0]&lt;stderr&gt;:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2950...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners before saving checkpoint 2950...
[1,1]&lt;stderr&gt;:INFO:tensorflow:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,1]&lt;stderr&gt;:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.
[1,0]&lt;stderr&gt;:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
[1,0]&lt;stderr&gt;:Instructions for updating:
[1,0]&lt;stderr&gt;:Use standard file APIs to delete files with this prefix.
[1,0]&lt;stderr&gt;:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
[1,0]&lt;stderr&gt;:Instructions for updating:
[1,0]&lt;stderr&gt;:Use standard file APIs to delete files with this prefix.
[1,0]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2950...
[1,0]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 2950...
[1,1]&lt;stderr&gt;:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
[1,1]&lt;stderr&gt;:Instructions for updating:
[1,1]&lt;stderr&gt;:Use standard file APIs to delete files with this prefix.
[1,1]&lt;stderr&gt;:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
[1,1]&lt;stderr&gt;:Instructions for updating:
[1,1]&lt;stderr&gt;:Use standard file APIs to delete files with this prefix.
[1,1]&lt;stderr&gt;:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2950...
[1,1]&lt;stderr&gt;:Calling checkpoint listeners after saving checkpoint 2950...
[1,1]&lt;stdout&gt;:test mean loss: 0.015524
[1,1]&lt;stdout&gt;:testing clustering accuracy: 0.553644
[1,0]&lt;stdout&gt;:test mean loss: 0.018224[1,0]&lt;stdout&gt;:
[1,0]&lt;stdout&gt;:testing clustering accuracy: 0.600920[1,0]&lt;stdout&gt;:
</pre></div>
</div>
</div>
</div>
<p>Results: - Execution of the command for np=2 GPUs takes 3.39 hours. -
Plot below show the validation accuracy vs epoch. - Note that we switch
to the full loss after n=10 epochs. - We observe an improvement in the
cluster validation set accuracy after around 50 epochs. - Highest
cluster validation set accuracy lies at about 68%. - Output of the
algorithm is the stored model.</p>
<p><img alt="The StandardModel" src="https://raw.githubusercontent.com/Tarnekar/bitstarter/master/validation_accuracy.png" /></p>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-06_group-ParticleClustering"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="02_dl_single_machine.html" title="previous page">&lt;no title&gt;</a>
    <a class='right-next' id="next-link" href="04_evaluate.html" title="next page">Evaluation</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>