
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html">
   databricks community edition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#essentials-of-databricks-cloud-dbc-in-a-big-hurry">
   Essentials of Databricks Cloud (DBC) in a Big Hurry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-what-is-databricks-cloud">
   DBC Essentials: What is Databricks Cloud?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-shard-cluster-notebook-and-dashboard">
   DBC Essentials: Shard, Cluster, Notebook and Dashboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-team-state-collaboration-elastic-resources">
   DBC Essentials: Team, State, Collaboration, Elastic Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Introduction to Scala through Scala Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-in-your-own-computer">
   Scala in your own computer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-resources">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Letâ€™s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Letâ€™s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006_WordCount.html">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distribute Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
   Distributed deep learning training using TensorFlow and Keras with HorovodRunner
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
   Distributed deep learning training using PyTorch with HorovodRunner for MNIST
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Voluntary Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html">
   Plugging into GDELT Streams - TODO - IN PROGRESS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/old notebooks/22_dl_horovord_tf1.15.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/old notebooks/22_dl_horovord_tf1.15.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="simple nav section-nav flex-column">
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>This is currently just a copy paste from the github repository of the
file <code class="docutils literal notranslate"><span class="pre">train_kmean.py</span></code>. For distributed learning see the next notebook</p>
<p>install correct version of tensorflow</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#pip uninstall tensorflow</span>
<span class="c1">#pip install tensorflow==1.15</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">show</span> <span class="n">tensorflow</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Name: tensorflow
Version: 2.3.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages
Requires: astunparse, tensorflow-estimator, termcolor, wrapt, numpy, h5py, opt-einsum, protobuf, google-pasta, keras-preprocessing, six, scipy, gast, grpcio, absl-py, tensorboard, wheel
Required-by: spark-tensorflow-distributor
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">install</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">cpu</span><span class="o">==</span><span class="mf">1.15</span><span class="o">.*</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Python interpreter will be restarted.
Collecting tensorflow-cpu==1.15.*
  Using cached tensorflow_cpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (110.8 MB)
Collecting tensorboard&lt;1.16.0,&gt;=1.15.0
  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)
Requirement already satisfied: termcolor&gt;=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.1.0)
Requirement already satisfied: wrapt&gt;=1.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.11.2)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.1.2)
Requirement already satisfied: astor&gt;=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.8.0)
Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.18.1)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (3.3.0)
Processing /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3/gast-0.2.2-py3-none-any.whl
Requirement already satisfied: six&gt;=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.14.0)
Requirement already satisfied: protobuf&gt;=3.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (3.11.4)
Requirement already satisfied: grpcio&gt;=1.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.27.2)
Collecting tensorflow-estimator==1.15.1
  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)
Collecting keras-applications&gt;=1.0.8
  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)
Requirement already satisfied: google-pasta&gt;=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.2.0)
Requirement already satisfied: absl-py&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.9.0)
Requirement already satisfied: wheel&gt;=0.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.34.2)
Requirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow-cpu==1.15.*) (3.1.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow-cpu==1.15.*) (45.2.0.post20200210)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow-cpu==1.15.*) (1.0.0)
Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from keras-applications&gt;=1.0.8-&gt;tensorflow-cpu==1.15.*) (2.10.0)
ERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you&#39;ll have gast 0.2.2 which is incompatible.
ERROR: tensorflow 2.3.0 has requirement tensorboard&lt;3,&gt;=2.3.0, but you&#39;ll have tensorboard 1.15.0 which is incompatible.
ERROR: tensorflow 2.3.0 has requirement tensorflow-estimator&lt;2.4.0,&gt;=2.3.0, but you&#39;ll have tensorflow-estimator 1.15.1 which is incompatible.
Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow-cpu
  Attempting uninstall: tensorboard
    Found existing installation: tensorboard 2.3.0
    Uninstalling tensorboard-2.3.0:
      Successfully uninstalled tensorboard-2.3.0
  Attempting uninstall: gast
    Found existing installation: gast 0.3.3
    Uninstalling gast-0.3.3:
      Successfully uninstalled gast-0.3.3
  Attempting uninstall: tensorflow-estimator
    Found existing installation: tensorflow-estimator 2.3.0
    Uninstalling tensorflow-estimator-2.3.0:
      Successfully uninstalled tensorflow-estimator-2.3.0
Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-cpu-1.15.0 tensorflow-estimator-1.15.1
Python interpreter will be restarted.
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">install</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">gpu</span><span class="o">==</span><span class="mf">1.15</span><span class="o">.*</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Python interpreter will be restarted.
Collecting tensorflow-gpu==1.15.*
  Downloading tensorflow_gpu-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)
Requirement already satisfied: tensorboard&lt;1.16.0,&gt;=1.15.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.15.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.1.0)
Requirement already satisfied: wrapt&gt;=1.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.11.2)
Requirement already satisfied: wheel&gt;=0.26; python_version &gt;= &quot;3&quot; in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.34.2)
Requirement already satisfied: numpy&lt;1.19.0,&gt;=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.18.1)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.1.2)
Requirement already satisfied: astor&gt;=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.8.0)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (3.3.0)
Requirement already satisfied: six&gt;=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.14.0)
Requirement already satisfied: gast==0.2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.2.2)
Requirement already satisfied: protobuf&gt;=3.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (3.11.4)
Requirement already satisfied: grpcio&gt;=1.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.27.2)
Requirement already satisfied: tensorflow-estimator==1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.15.1)
Requirement already satisfied: keras-applications&gt;=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.0.8)
Requirement already satisfied: google-pasta&gt;=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.2.0)
Requirement already satisfied: absl-py&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.9.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow-gpu==1.15.*) (3.1.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow-gpu==1.15.*) (45.2.0.post20200210)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow-gpu==1.15.*) (1.0.0)
Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from keras-applications&gt;=1.0.8-&gt;tensorflow-gpu==1.15.*) (2.10.0)
Installing collected packages: tensorflow-gpu
Successfully installed tensorflow-gpu-1.15.4
Python interpreter will be restarted.
</pre></div>
</div>
</div></blockquote>
<p>This apparently the way to get tensorflow 1.15 gpu on databricks 7.2 ml
(so might work for databricks 7.3 ml, which is what this cluster is
using)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">install</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">databricks</span><span class="o">-</span><span class="n">prod</span><span class="o">-</span><span class="n">cloudfront</span><span class="o">.</span><span class="n">cloud</span><span class="o">.</span><span class="n">databricks</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">artifacts</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">/</span><span class="n">runtime</span><span class="o">-</span><span class="mf">7.</span><span class="n">x</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">-</span><span class="mf">1.15</span><span class="o">.</span><span class="mi">3</span><span class="o">-</span><span class="n">cp37</span><span class="o">-</span><span class="n">cp37m</span><span class="o">-</span><span class="n">linux_x86_64</span><span class="o">.</span><span class="n">whl</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Python interpreter will be restarted.
Collecting tensorflow==1.15.3
  Using cached https://databricks-prod-cloudfront.cloud.databricks.com/artifacts/tensorflow/runtime-7.x/tensorflow-1.15.3-cp37-cp37m-linux_x86_64.whl (310.3 MB)
Requirement already satisfied: tensorboard&lt;1.16.0,&gt;=1.15.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.15.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.1.0)
Requirement already satisfied: wrapt&gt;=1.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.11.2)
Requirement already satisfied: wheel&gt;=0.26; python_version &gt;= &quot;3&quot; in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.34.2)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.1.2)
Requirement already satisfied: astor&gt;=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.8.0)
Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.18.1)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (3.3.0)
Requirement already satisfied: gast==0.2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.2.2)
Requirement already satisfied: six&gt;=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.14.0)
Requirement already satisfied: protobuf&gt;=3.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (3.11.4)
Requirement already satisfied: grpcio&gt;=1.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.27.2)
Requirement already satisfied: tensorflow-estimator==1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.15.1)
Requirement already satisfied: keras-applications&gt;=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.0.8)
Requirement already satisfied: google-pasta&gt;=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.2.0)
Requirement already satisfied: absl-py&gt;=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.9.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.3) (3.1.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.3) (45.2.0.post20200210)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.3) (1.0.0)
Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages (from keras-applications&gt;=1.0.8-&gt;tensorflow==1.15.3) (2.10.0)
ERROR: spark-tensorflow-distributor 0.1.0 has requirement tensorflow&gt;=2.1.0, but you&#39;ll have tensorflow 1.15.3 which is incompatible.
Installing collected packages: tensorflow
  Attempting uninstall: tensorflow
    Found existing installation: tensorflow 2.3.0
    Uninstalling tensorflow-2.3.0:
      Successfully uninstalled tensorflow-2.3.0
Successfully installed tensorflow-1.15.3
Python interpreter will be restarted.
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="n">databricks</span><span class="o">/</span><span class="n">driver</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>get the imports</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span><span class="o">,</span> <span class="nn">shlex</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">socket</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">edgeitems</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">linear_sum_assignment</span>

<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span><span class="s1">&#39;scripts&#39;</span><span class="p">)</span>  <span class="c1">#os.path.dirname(os.path.abspath(__file__))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">))</span>
<span class="kn">import</span> <span class="nn">provider</span>
<span class="kn">import</span> <span class="nn">gapnet_classify</span> <span class="k">as</span> <span class="nn">MODEL</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Out[2]: &#39;1.15.3&#39;
</pre></div>
</div>
</div></blockquote>
<p>Get the arguments (we hvae to create the namespace like this with a
dictionary since notebooks donâ€™t easily incorporate argument parsing)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="n">databricks</span><span class="o">/</span><span class="n">driver</span><span class="o">/</span><span class="mi">06</span><span class="n">_LHC</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>

<span class="n">parserdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_dim&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="c1">#help=&#39;Dimension of the encoding layer [Default: 3]&#39;)</span>
              <span class="s1">&#39;n_clusters&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="c1">#help=&#39;Number of clusters [Default: 3]&#39;)</span>
              <span class="s1">&#39;gpu&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1">#help=&#39;GPU to use [default: GPU 0]&#39;)</span>
              <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="s1">&#39;gapnet_clasify&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;Model name [default: gapnet_classify]&#39;)</span>
              <span class="s1">&#39;log_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;Log dir [default: log]&#39;)</span>
              <span class="s1">&#39;num_point&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="c1">#help=&#39;Point Number [default: 100]&#39;)</span>
              <span class="s1">&#39;max_epoch&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1">#help=&#39;Epoch to run [default: 200]&#39;)</span>
              <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="c1">#help=&#39;Batch Size during training [default: 512]&#39;)</span>
              <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="c1">#help=&#39;Initial learning rate [default: 0.01]&#39;)</span>

              <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="c1">#help=&#39;Initial momentum [default: 0.9]&#39;)</span>
              <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;adam or momentum [default: adam]&#39;)</span>
              <span class="s1">&#39;decay_step&#39;</span><span class="p">:</span> <span class="mi">500000</span><span class="p">,</span> <span class="c1">#help=&#39;Decay step for lr decay [default: 500000]&#39;)</span>
              <span class="s1">&#39;wd&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="c1">#help=&#39;Weight Decay [Default: 0.0]&#39;)</span>
              <span class="s1">&#39;decay_rate&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="c1">#help=&#39;Decay rate for lr decay [default: 0.5]&#39;)</span>
              <span class="s1">&#39;output_dir&#39;</span><span class="p">:</span> <span class="s1">&#39;train_results&#39;</span><span class="p">,</span> <span class="c1">#help=&#39;Directory that stores all training logs and trained models&#39;)</span>
              <span class="s1">&#39;data_dir&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span><span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">),</span> <span class="c1"># &#39;../h5&#39;, #help=&#39;directory with data [default: hdf5_data]&#39;)</span>
              <span class="s1">&#39;nfeat&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="c1">#help=&#39;Number of features [default: 8]&#39;)</span>
              <span class="s1">&#39;ncat&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="c1">#help=&#39;Number of categories [default: 20]&#39;)</span>
             <span class="p">}</span>

<span class="n">FLAGS</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">parserdict</span><span class="p">)</span>

<span class="n">H5_DIR</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">data_dir</span>

<span class="n">EPOCH_CNT</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">MAX_PRETRAIN</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">NUM_POINT</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">num_point</span>
<span class="n">NUM_FEAT</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">nfeat</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">ncat</span>
<span class="n">MAX_EPOCH</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">max_epoch</span>
<span class="n">BASE_LEARNING_RATE</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">learning_rate</span>
<span class="n">GPU_INDEX</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">gpu</span>
<span class="n">MOMENTUM</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">momentum</span>
<span class="n">OPTIMIZER</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">optimizer</span>
<span class="n">DECAY_STEP</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">decay_step</span>
<span class="n">DECAY_RATE</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">decay_rate</span>

<span class="c1"># MODEL = importlib.import_module(FLAGS.model) # import network module</span>
<span class="n">MODEL_FILE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">model</span> <span class="o">+</span> <span class="s1">&#39;.py&#39;</span><span class="p">)</span>
<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;logs&#39;</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;cp </span><span class="si">%s</span><span class="s1">.py </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">MODEL_FILE</span><span class="p">,</span> <span class="n">LOG_DIR</span><span class="p">))</span>  <span class="c1"># bkp of model def</span>
<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;cp train_kmeans.py </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">LOG_DIR</span><span class="p">))</span>  <span class="c1"># bkp of train procedure</span>

<span class="n">BN_INIT_DECAY</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">BN_DECAY_DECAY_RATE</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">BN_DECAY_DECAY_STEP</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">DECAY_STEP</span><span class="p">)</span>
<span class="n">BN_DECAY_CLIP</span> <span class="o">=</span> <span class="mf">0.99</span>

<span class="n">LEARNING_RATE_CLIP</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">HOSTNAME</span> <span class="o">=</span> <span class="n">socket</span><span class="o">.</span><span class="n">gethostname</span><span class="p">()</span>

<span class="n">TRAIN_FILES</span> <span class="o">=</span> <span class="n">provider</span><span class="o">.</span><span class="n">getDataFiles</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">H5_DIR</span><span class="p">,</span> <span class="s1">&#39;train_files_wztop.txt&#39;</span><span class="p">))</span>
<span class="n">TEST_FILES</span> <span class="o">=</span> <span class="n">provider</span><span class="o">.</span><span class="n">getDataFiles</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">H5_DIR</span><span class="p">,</span> <span class="s1">&#39;test_files_wztop.txt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>define utilisation functions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_learning_rate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">exponential_decay</span><span class="p">(</span>
        <span class="n">BASE_LEARNING_RATE</span><span class="p">,</span>  <span class="c1"># Base learning rate.</span>
        <span class="n">batch</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>  <span class="c1"># Current index into the dataset.</span>
        <span class="n">DECAY_STEP</span><span class="p">,</span>  <span class="c1"># Decay step.</span>
        <span class="n">DECAY_RATE</span><span class="p">,</span>  <span class="c1"># Decay rate.</span>
        <span class="n">staircase</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">LEARNING_RATE_CLIP</span><span class="p">)</span>  <span class="c1"># CLIP THE LEARNING RATE!</span>
    <span class="k">return</span> <span class="n">learning_rate</span>


<span class="k">def</span> <span class="nf">get_bn_decay</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">bn_momentum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">exponential_decay</span><span class="p">(</span>
        <span class="n">BN_INIT_DECAY</span><span class="p">,</span>
        <span class="n">batch</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
        <span class="n">BN_DECAY_DECAY_STEP</span><span class="p">,</span>
        <span class="n">BN_DECAY_DECAY_RATE</span><span class="p">,</span>
        <span class="n">staircase</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">bn_decay</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">BN_DECAY_CLIP</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">bn_momentum</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bn_decay</span>
</pre></div>
</div>
</div>
</div>
<p>create checkpoint directory</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
 
<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="s1">&#39;/dbfs/databricks/driver/06_LHC/logs/train/</span><span class="si">{}</span><span class="s1">/&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
 
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_h5_hvd</span><span class="p">(</span><span class="n">h5_filename</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;pid&#39;</span><span class="p">][</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>
    <span class="n">seg</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">][</span><span class="n">rank</span><span class="p">::</span><span class="n">size</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loaded </span><span class="si">{0}</span><span class="s2"> events&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">seg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_hvd</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">horovod.tensorflow</span> <span class="k">as</span> <span class="nn">hvd</span>
    
    
    <span class="kn">import</span> <span class="nn">argparse</span><span class="o">,</span> <span class="nn">shlex</span>
    <span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">socket</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
    <span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

    <span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">edgeitems</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

    <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">linear_sum_assignment</span>

    <span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;06_LHC&#39;</span><span class="p">,</span><span class="s1">&#39;scripts&#39;</span><span class="p">)</span>  <span class="c1">#os.path.dirname(os.path.abspath(__file__))</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">))</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">))</span>
    <span class="kn">import</span> <span class="nn">provider</span>
    <span class="kn">import</span> <span class="nn">gapnet_classify</span> <span class="k">as</span> <span class="nn">MODEL</span>
    
  
    <span class="c1"># Horovod: initialize Horovod.</span>
    <span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
        
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/gpu:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">GPU_INDEX</span><span class="p">)):</span>
            <span class="n">pointclouds_pl</span><span class="p">,</span> <span class="n">labels_pl</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">placeholder_inputs</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_POINT</span><span class="p">,</span> <span class="n">NUM_FEAT</span><span class="p">)</span>

            <span class="n">is_training_pl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>

            <span class="c1"># Note the global_step=batch parameter to minimize.</span>
            <span class="c1"># That tells the optimizer to helpfully increment the &#39;batch&#39; parameter for you every time it trains.</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>
            <span class="n">bn_decay</span> <span class="o">=</span> <span class="n">get_bn_decay</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;bn_decay&#39;</span><span class="p">,</span> <span class="n">bn_decay</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Get model and loss&quot;</span><span class="p">)</span>

            <span class="n">pred</span><span class="p">,</span> <span class="n">max_pool</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">pointclouds_pl</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="n">is_training_pl</span><span class="p">,</span>
                                             <span class="n">bn_decay</span><span class="o">=</span><span class="n">bn_decay</span><span class="p">,</span>
                                             <span class="n">num_class</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">wd</span><span class="p">,</span>
                                             <span class="p">)</span>

            <span class="n">class_loss</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">get_focal_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels_pl</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">max_dim</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mu&quot;</span><span class="p">,</span>
                             <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># k centroids</span>
            <span class="n">kmeans_loss</span><span class="p">,</span> <span class="n">stack_dist</span> <span class="o">=</span> <span class="n">MODEL</span><span class="o">.</span><span class="n">get_loss_kmeans</span><span class="p">(</span><span class="n">max_pool</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">max_dim</span><span class="p">,</span>
                                                            <span class="n">FLAGS</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

            <span class="n">full_loss</span> <span class="o">=</span> <span class="n">kmeans_loss</span> <span class="o">+</span> <span class="n">class_loss</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Get training operator&quot;</span><span class="p">)</span>
            <span class="c1"># Get training operator</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">get_learning_rate</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
            <span class="c1"># scale learning rate from horovod dependent on number of processes (=hvd.size)</span>
            <span class="k">if</span> <span class="n">OPTIMIZER</span> <span class="o">==</span> <span class="s1">&#39;momentum&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">momentum</span><span class="o">=</span><span class="n">MOMENTUM</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">OPTIMIZER</span> <span class="o">==</span> <span class="s1">&#39;adam&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
            <span class="c1"># Horovod: add Horovod Distributed Optimizer</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

            <span class="n">train_op_full</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">full_loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">class_loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># Add ops to save and restore all the variables.</span>
            <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
        
        <span class="n">hooks</span> <span class="o">=</span> <span class="p">[</span>
          <span class="c1"># Horovod: BroadcastGlobalVariablesHook broadcasts initial variable states</span>
          <span class="c1"># from rank 0 to all other processes. This is necessary to ensure consistent</span>
          <span class="c1"># initialization of all workers when training is started with random weights</span>
          <span class="c1"># or restored from a checkpoint.</span>
          <span class="n">hvd</span><span class="o">.</span><span class="n">BroadcastGlobalVariablesHook</span><span class="p">(</span><span class="mi">0</span><span class="p">),]</span>
  

        <span class="c1"># Create a session</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">config</span><span class="o">.</span><span class="n">allow_soft_placement</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">config</span><span class="o">.</span><span class="n">log_device_placement</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">visible_device_list</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">local_rank</span><span class="p">())</span>
        
        <span class="c1"># MonitoredTrainingSession</span>
        <span class="c1"># takes care of session initialization,</span>
        <span class="c1"># restoring from a checkpoint, saving to a checkpoint, and closing when done</span>
        <span class="c1"># or an error occurs.</span>
        <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MonitoredSession</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="o">=</span><span class="n">checkpoint_dir</span><span class="p">,</span>
                                         <span class="n">hooks</span><span class="o">=</span><span class="n">hooks</span><span class="p">,</span>
                                         <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        
        <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

        <span class="c1"># Add summary writers</span>
        <span class="n">merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
        <span class="n">train_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="n">test_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

        <span class="c1"># Init variables</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of weights for the model: &quot;</span><span class="p">,</span>
              <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()]))</span>
        <span class="n">ops</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pointclouds_pl&#39;</span><span class="p">:</span> <span class="n">pointclouds_pl</span><span class="p">,</span>
               <span class="s1">&#39;labels_pl&#39;</span><span class="p">:</span> <span class="n">labels_pl</span><span class="p">,</span>
               <span class="s1">&#39;is_training_pl&#39;</span><span class="p">:</span> <span class="n">is_training_pl</span><span class="p">,</span>
               <span class="s1">&#39;max_pool&#39;</span><span class="p">:</span> <span class="n">max_pool</span><span class="p">,</span>
               <span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span>
               <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">alpha</span><span class="p">,</span>
               <span class="s1">&#39;mu&#39;</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span>
               <span class="s1">&#39;stack_dist&#39;</span><span class="p">:</span> <span class="n">stack_dist</span><span class="p">,</span>
               <span class="s1">&#39;class_loss&#39;</span><span class="p">:</span> <span class="n">class_loss</span><span class="p">,</span>
               <span class="s1">&#39;kmeans_loss&#39;</span><span class="p">:</span> <span class="n">kmeans_loss</span><span class="p">,</span>
               <span class="s1">&#39;train_op&#39;</span><span class="p">:</span> <span class="n">train_op</span><span class="p">,</span>
               <span class="s1">&#39;train_op_full&#39;</span><span class="p">:</span> <span class="n">train_op_full</span><span class="p">,</span>
               <span class="s1">&#39;merged&#39;</span><span class="p">:</span> <span class="n">merged</span><span class="p">,</span>
               <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">batch</span><span class="p">,</span>
               <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">learning_rate</span>
               <span class="p">}</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_EPOCH</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;**** EPOCH </span><span class="si">%03d</span><span class="s1"> ****&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

            <span class="n">is_full_training</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">MAX_PRETRAIN</span>
            <span class="n">max_pool</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">train_writer</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">is_full_training</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">MAX_PRETRAIN</span><span class="p">:</span>
                <span class="n">centers</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_pool</span><span class="p">))</span>
                <span class="n">centers</span> <span class="o">=</span> <span class="n">centers</span><span class="o">.</span><span class="n">cluster_centers_</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">centers</span><span class="p">))</span>

            <span class="n">eval_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">test_writer</span><span class="p">,</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">is_full_training</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_full_training</span><span class="p">:</span>
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s1">&#39;cluster.ckpt&#39;</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s1">&#39;model.ckpt&#39;</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model saved in file: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">save_path</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">):</span>
    <span class="n">batch_label</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span>


<span class="k">def</span> <span class="nf">cluster_acc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate clustering accuracy. Require scikit-learn installed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">y_true</span><span class="o">.</span><span class="n">max</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">w</span><span class="p">[</span><span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">linear_sum_assignment</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">])</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">size</span>


<span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">train_writer</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">,</span> <span class="n">is_full_training</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; ops: dict mapping from string to tf ops &quot;&quot;&quot;</span>
    <span class="n">is_training</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">train_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">TRAIN_FILES</span><span class="p">))</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="n">loss_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">y_pool</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TRAIN_FILES</span><span class="p">)):</span>
        <span class="c1"># print(&#39;----&#39; + str(fn) + &#39;-----&#39;)</span>
        <span class="n">current_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">H5_DIR</span><span class="p">,</span> <span class="n">TRAIN_FILES</span><span class="p">[</span><span class="n">train_idxs</span><span class="p">[</span><span class="n">fn</span><span class="p">]])</span>
        <span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">current_cluster</span> <span class="o">=</span> <span class="n">load_h5_hvd</span><span class="p">(</span><span class="n">current_file</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">)</span>

        <span class="n">current_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">current_label</span><span class="p">)</span>

        <span class="n">file_size</span> <span class="o">=</span> <span class="n">current_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
        <span class="c1"># num_batches = 5</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()))</span>

        <span class="c1"># initialise progress bar</span>
        <span class="n">process_desc</span> <span class="o">=</span> <span class="s2">&quot;Loss </span><span class="si">{:2.3e}</span><span class="s2">&quot;</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">initial</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span>
                            <span class="n">desc</span><span class="o">=</span><span class="n">process_desc</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                            <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>

            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;pointclouds_pl&#39;</span><span class="p">]:</span> <span class="n">batch_data</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;labels_pl&#39;</span><span class="p">]:</span> <span class="n">batch_label</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;is_training_pl&#39;</span><span class="p">]:</span> <span class="n">is_training</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]:</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">EPOCH_CNT</span> <span class="o">-</span> <span class="n">MAX_PRETRAIN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),}</span>
            <span class="k">if</span> <span class="n">is_full_training</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                                 <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;train_op_full&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;kmeans_loss&#39;</span><span class="p">],</span>
                                                                 <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;stack_dist&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]],</span>
                                                                <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

                <span class="n">batch_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">r</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">current_cluster</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]])</span>
                <span class="n">cluster_assign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cur_batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">):</span>
                    <span class="n">index_closest_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
                    <span class="n">cluster_assign</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">index_closest_cluster</span>

                <span class="n">acc</span> <span class="o">+=</span> <span class="n">cluster_acc</span><span class="p">(</span><span class="n">batch_cluster</span><span class="p">,</span> <span class="n">cluster_assign</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                                     <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;train_op&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;class_loss&#39;</span><span class="p">],</span>
                                                                     <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;max_pool&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]],</span>
                                                                    <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_pool</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">y_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_pool</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">loss_sum</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>

            <span class="n">train_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="c1"># Update train bar</span>
            <span class="n">process_desc</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;learning rate: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">lr</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train mean loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">loss_sum</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train clustering accuracy: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">y_pool</span>


<span class="k">def</span> <span class="nf">eval_one_epoch</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">test_writer</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">,</span> <span class="n">is_full_training</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; ops: dict mapping from string to tf ops &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">EPOCH_CNT</span>
    <span class="n">is_training</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">test_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">TEST_FILES</span><span class="p">))</span>
    <span class="c1"># Test on all data: last batch might be smaller than BATCH_SIZE</span>
    <span class="n">loss_sum</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">acc_kmeans</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TEST_FILES</span><span class="p">)):</span>
        <span class="c1"># print(&#39;----&#39; + str(fn) + &#39;-----&#39;)</span>
        <span class="n">current_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">H5_DIR</span><span class="p">,</span> <span class="n">TEST_FILES</span><span class="p">[</span><span class="n">test_idxs</span><span class="p">[</span><span class="n">fn</span><span class="p">]])</span>
        <span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">current_cluster</span> <span class="o">=</span> <span class="n">load_h5_hvd</span><span class="p">(</span><span class="n">current_file</span><span class="p">,</span> <span class="n">hvd_rank</span><span class="p">,</span> <span class="n">hvd_size</span><span class="p">)</span>
        <span class="n">current_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">current_label</span><span class="p">)</span>

        <span class="n">file_size</span> <span class="o">=</span> <span class="n">current_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
        <span class="c1"># num_batches = 5</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">BATCH_SIZE</span>
            <span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">current_data</span><span class="p">,</span> <span class="n">current_label</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span>

            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;pointclouds_pl&#39;</span><span class="p">]:</span> <span class="n">batch_data</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;is_training_pl&#39;</span><span class="p">]:</span> <span class="n">is_training</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;labels_pl&#39;</span><span class="p">]:</span> <span class="n">batch_label</span><span class="p">,</span>
                         <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]:</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">EPOCH_CNT</span> <span class="o">-</span> <span class="n">MAX_PRETRAIN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),}</span>

            <span class="k">if</span> <span class="n">is_full_training</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="n">max_pool</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                                        <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;kmeans_loss&#39;</span><span class="p">],</span>
                                                                        <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;max_pool&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;stack_dist&#39;</span><span class="p">],</span>
                                                                        <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;mu&#39;</span><span class="p">]],</span>
                                                                       <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mu: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
                <span class="n">batch_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">r</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">current_cluster</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]])</span>
                <span class="n">cluster_assign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cur_batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">):</span>
                    <span class="n">index_closest_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
                    <span class="n">cluster_assign</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">index_closest_cluster</span>

                <span class="n">acc</span> <span class="o">+=</span> <span class="n">cluster_acc</span><span class="p">(</span><span class="n">batch_cluster</span><span class="p">,</span> <span class="n">cluster_assign</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ops</span><span class="p">[</span><span class="s1">&#39;merged&#39;</span><span class="p">],</span> <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span>
                                                    <span class="n">ops</span><span class="p">[</span><span class="s1">&#39;class_loss&#39;</span><span class="p">]],</span>
                                                   <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

            <span class="n">test_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="n">loss_sum</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">loss_sum</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;test mean loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">total_loss</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;testing clustering accuracy: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_batches</span><span class="p">)))</span>

    <span class="n">EPOCH_CNT</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>run the training</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sparkdl</span> <span class="kn">import</span> <span class="n">HorovodRunner</span>
 
<span class="n">hr</span> <span class="o">=</span> <span class="n">HorovodRunner</span><span class="p">(</span><span class="n">np</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hr</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_hvd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>HorovodRunner will stream all training logs to notebook cell output. If there are too many logs, you
can adjust the log level in your train method. Or you can set driver_log_verbosity to
&#39;log_callback_only&#39; and use a HorovodRunner log  callback on the first worker to get concise
progress updates.
The global names read or written to by the pickled function are {&#39;get_bn_decay&#39;, &#39;MOMENTUM&#39;, &#39;range&#39;, &#39;NUM_CLASSES&#39;, &#39;OPTIMIZER&#39;, &#39;get_learning_rate&#39;, &#39;MAX_EPOCH&#39;, &#39;NUM_FEAT&#39;, &#39;GPU_INDEX&#39;, &#39;BATCH_SIZE&#39;, &#39;LOG_DIR&#39;, &#39;FLAGS&#39;, &#39;checkpoint_dir&#39;, &#39;eval_one_epoch&#39;, &#39;NUM_POINT&#39;, &#39;MAX_PRETRAIN&#39;, &#39;print&#39;, &#39;str&#39;, &#39;train_one_epoch&#39;}.
The pickled object size is 10641 bytes.

### How to enable Horovod Timeline? ###
HorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To
record a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the
timeline file to be created. You can then open the timeline file  using the chrome://tracing
facility of the Chrome browser.

Start training.
[1,0]&lt;stderr&gt;:Traceback (most recent call last):
[1,0]&lt;stderr&gt;:  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
[1,0]&lt;stderr&gt;:  File &quot;/databricks/.python_edge_libs/sparkdl/horovod/runner.py&quot;, line 222, in wrapped_main
[1,0]&lt;stderr&gt;:    return_value = main(**kwargs)
[1,0]&lt;stderr&gt;:  File &quot;&lt;command-178059608683696&gt;&quot;, line 2, in train_hvd
[1,0]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/horovod/tensorflow/__init__.py&quot;, line 28, in &lt;module&gt;
[1,0]&lt;stderr&gt;:    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce
[1,0]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py&quot;, line 49, in &lt;module&gt;
[1,0]&lt;stderr&gt;:    MPI_LIB = _load_library(&#39;mpi_lib&#39; + get_ext_suffix())
[1,0]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py&quot;, line 45, in _load_library
[1,0]&lt;stderr&gt;:    library = load_library.load_op_library(filename)
[1,0]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py&quot;, line 61, in load_op_library
[1,0]&lt;stderr&gt;:    lib_handle = py_tf.TF_LoadLibrary(library_filename)
[1,0]&lt;stderr&gt;:tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[1,1]&lt;stderr&gt;:Traceback (most recent call last):
[1,1]&lt;stderr&gt;:  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
[1,1]&lt;stderr&gt;:  File &quot;/databricks/.python_edge_libs/sparkdl/horovod/runner.py&quot;, line 222, in wrapped_main
[1,1]&lt;stderr&gt;:    return_value = main(**kwargs)
[1,1]&lt;stderr&gt;:  File &quot;&lt;command-178059608683696&gt;&quot;, line 2, in train_hvd
[1,1]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/horovod/tensorflow/__init__.py&quot;, line 28, in &lt;module&gt;
[1,1]&lt;stderr&gt;:    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce
[1,1]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py&quot;, line 49, in &lt;module&gt;
[1,1]&lt;stderr&gt;:    MPI_LIB = _load_library(&#39;mpi_lib&#39; + get_ext_suffix())
[1,1]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py&quot;, line 45, in _load_library
[1,1]&lt;stderr&gt;:    library = load_library.load_op_library(filename)
[1,1]&lt;stderr&gt;:  File &quot;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f326b9f3-c400-4f6e-be35-a40e35942671/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py&quot;, line 61, in load_op_library
[1,1]&lt;stderr&gt;:    lib_handle = py_tf.TF_LoadLibrary(library_filename)
[1,1]&lt;stderr&gt;:tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[39501,1],0]
  Exit code:    1
--------------------------------------------------------------------------
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/old notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>