
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CNN for Intel Image Classification &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="CNNs and MixUp with Horovod" href="05_Horovod_test.html" />
    <link rel="prev" title="CNN for MNIST" href="03_CNN_MNIST.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html">
     Login to databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
     Import Course Content Now!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment">
     Cloud-free Computing Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
     Multi-lingual Notebooks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Scala Crash Course
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
     Scala Crash Course Continued
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
     HOMEWORK on RDD Transformations and Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/006_WordCount.html">
     Word Count on US State of the Union (SoU) Addresses
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
     Spark Sql Programming Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
     Getting Started - Exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
     Performance Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
     SQL Pivoting since Spark 2.4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
     Load Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
     Pivoting in SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
     Pivoting with Multiple Aggregate Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
     Pivoting with Multiple Grouping Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
     Pivoting with Multiple Pivot Columns
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extract Transform and Load
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
     Parsing the output from
     <code class="docutils literal notranslate">
      <span class="pre">
       IsIt1or2Coins
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
     Providing case classes for input and output for easy spark communication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Trends in Money and News
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/000_TrendsInFinancialStocksAndNewsEvents.html">
   Trends in Financial Stocks and News Events
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00a_FX1M.html">
     Historical FX-1-M Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/00b_yfinance.html">
     yfinance Stock Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000a_finance_utils.html">
     Utilities Needed for Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/000b_gdelt_utils.html">
     Utilities Needed for Mass Media Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/01_trend_calculus_showcase.html">
   Finding trends in oil price data.
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/02_streamable_trend_calculus.html">
     Streaming Trend Calculus with Maximum Necessary Reversals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/03_streamable_trend_calculus_estimators.html">
     Markov Model for Trend Calculus
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_9-sds-3-x-trends/030_Spark_GDELT_project_001.html">
   Plugging into GDELT Mass Media Streams
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030a_gdelt_EOI_detection.html">
     Detecting Events of Interest to OIL/GAS Price Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_9-sds-3-x-trends/030b_gdelt_POI_detection.html">
     Detecting Persons of Interest to OIL/GAS Price Trends
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distribute Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
     Distributed deep learning training using TensorFlow and Keras with HorovodRunner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
     Distributed deep learning training using PyTorch with HorovodRunner for MNIST
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/01_load_data.html">
     Preprocessing and loading the relevant data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/02_logisticregression.html">
     The two cultures - Classifying threads with logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/03_word2vec.html">
     Classification using Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-01_group-TheTwoCultures/04_LDA.html">
     Topic Modeling with LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed Linear Algebra
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
     Music Recommendation System
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-06_group-ParticleClustering/00_Introduction.html#our-contribution">
   Our contribution
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
     Important!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html#important-continued-from-above">
     Important (continued from above)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-06_group-ParticleClustering/04_evaluate.html">
     Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
     Examples
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html">
   Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-08_group-DistributedEnsemble/00_project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome 🧬
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/02_Data_Processing.html">
     Extract (overlapping [since yet do not know which parts corresponds to coding regions]) 3-mers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html#format-data-for-apache-spark-mllib-clustering-lda-adapted-from-the-lda-course-tutorial-034lda20newsgroupssmall">
     Format data for apache.spark.mllib.clustering.LDA (adapted from the LDA course tutorial ‘034
     <em>
      LDA
     </em>
     20NewsGroupsSmall’)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/03_LDA.html#visualise-results">
     Visualise Results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#format-data">
     Format data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/04_Classification_CountVector.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#explore-data">
     Explore data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/05_Classification.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-09_group-TopicModeling/06_Results.html">
     Results and Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
     Clustering emoticons based on tweets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
     Dynamic Tweet Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/04_conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
     Notebook for collecting tweets with country codes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
     Extended spark.streaming.twitter.TwitterUtils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
     Download Files Periodically
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/01_StreamToFile.html">
     Stream to parquet file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
     This notebook is for explosive analysis of features in data.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
     Statistics of invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
     Correlation between invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
     Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html">
     Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
     Visualize total cases, total deaths, new cases and new deaths during pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
     Total Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
     New Cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
     New Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/05_Clustering.html">
     Clustering of country features in the Covid 19 dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
     Prediction with Linear Regression (LR) Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
     Prediction with Time Series model - ARIMA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
     Prediction with time series model - Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
     Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html#summary-and-outlook">
     Summary and Outlook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
     Reinforcement Learning - Distributed model tuning with Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
     Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
     Notes to the elephas training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-15_group-FinancialDataStreams/03_resources.html">
     Resources
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html">
   Intrusion Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-16_group-IntrusionDetection/00_Introduction.html#preparing-the-dataframe-for-training-classifers">
   Preparing the DataFrame for training classifers
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/00_introduction.html">
   Density Estimation via Voronoi Diagrams in High Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html">
     Robotics Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-18_group-ProjectRL/00_Problem_Description.html">
   Recommender System
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html">
     <span class="xref myst">
      The Alternating Least Squares method (ALS)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-small-dataset">
     <span class="xref myst">
      On a small dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-large-dataset-netflix-dataset">
     <span class="xref myst">
      On a large dataset - Netflix dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-18_group-ProjectRL/02_Extensions.html">
     Extensions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Fundamental Matrix
  </a>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="01_Background.html">
   MixUp and Generalization
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="02_Random_Forest.html">
     Random Forests and MixUp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_CNN_MNIST.html">
     CNN for MNIST
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     CNN for Intel Image Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_Horovod_test.html">
     CNNs and MixUp with Horovod
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
     Preprocess the data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
     Generate random graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
     Compute RSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
     Analyse the eigenvalue spectrum
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../student-project-22_group-SwapWithDDP/00_Introduction.html">
   SWAP
   <em>
    With
   </em>
   DDP
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html">
     SWAP
     <em>
      With
     </em>
     DDP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/000_0-sds-3-x-projects/student-project-20_group-Generalization/04_CNN_Intel_Image.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-20_group-Generalization/04_CNN_Intel_Image.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="cnn-for-intel-image-classification">
<h1>CNN for Intel Image Classification<a class="headerlink" href="#cnn-for-intel-image-classification" title="Permalink to this headline">¶</a></h1>
<p>We will now implement and test the MixUp preprocessing method for a
slightly harder CNN example, the Intel Image Classification data set.
Again, this notebook runs on CPUs, but the hyperparameter search is
scalable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Conv2D</span><span class="p">,</span><span class="n">Flatten</span><span class="p">,</span><span class="n">BatchNormalization</span><span class="p">,</span><span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">tune</span>
<span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">CLIReporter</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># Fixes the issue &quot;AttributeError: &#39;ConsoleBuffer has no attribute &#39;fileno&#39;&quot;</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">fileno</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<p>We will use the Intel Image Classification data set [[3]]. It
consists of 25k 150x150 RBG images from 6 different classes: buildings,
forest, glacier, mountain, sea, or street. However when we load the data
to our model we will rescale the images to 32x32 RBG images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Global parameters for training.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">img_height</span><span class="p">,</span><span class="n">img_width</span><span class="p">,</span><span class="n">channels</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_data_dir</span><span class="p">,</span><span class="n">test_data_dir</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train/&quot;</span><span class="p">,</span> <span class="s2">&quot;dbfs/FileStore/tables/Group20/seg_test/seg_test/&quot;</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="c1"># Degree of mixup is ~ Beta(alpha,alpha)</span>
</pre></div>
</div>
</div>
</div>
<p>To create MixUp data, we will define a custom data generator. It takes
an underlying image generator as argument, and outputs convex
combinations of two randomly selected (example,label) pairs drawn
according to the underlying generator.</p>
<p>Note that, in order to speed up the data generators, we need to make the
data more accessible. We do this by copying the data from the dbfs to
the working directory. This is done with our copy_data function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">shutil</span>
<span class="k">def</span> <span class="nf">copy_data</span><span class="p">():</span>
  <span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train&quot;</span>
  <span class="n">dst</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;seg_train&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Copying data to working folder&quot;</span><span class="p">)</span>
  <span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with copying!&quot;</span><span class="p">)</span>
  <span class="n">train_data_dir</span> <span class="o">=</span> <span class="n">dst</span>

  <span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;/dbfs/FileStore/tables/Group20/seg_test/seg_test&quot;</span>
  <span class="n">dst</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;seg_test&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Copying data to working folder&quot;</span><span class="p">)</span>
  <span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with copying!&quot;</span><span class="p">)</span>
  <span class="n">test_data_dir</span> <span class="o">=</span> <span class="n">dst</span>

  <span class="k">return</span> <span class="n">train_data_dir</span><span class="p">,</span><span class="n">test_data_dir</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MixupImageDataGenerator</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">Sequence</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">directory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="c1"># First iterator yielding tuples of (x, y)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator1</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span>
                                                        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span>
                                                            <span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
                                                        <span class="n">class_mode</span><span class="o">=</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                        <span class="n">subset</span><span class="o">=</span><span class="n">subset</span><span class="p">)</span>

        <span class="c1"># Second iterator yielding tuples of (x, y)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator2</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span>
                                                        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span>
                                                            <span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
                                                        <span class="n">class_mode</span><span class="o">=</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                        <span class="n">subset</span><span class="o">=</span><span class="n">subset</span><span class="p">)</span>

        <span class="c1"># Number of images across all classes in image directory.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator1</span><span class="o">.</span><span class="n">samples</span>


    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># returns the number of batches</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># Get a pair of inputs and outputs from two iterators.</span>
        <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator1</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
        <span class="n">X2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator2</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>


        <span class="c1"># random sample the lambda value from beta distribution.</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">X_l</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y_l</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>


        <span class="c1"># Perform the mixup.</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X1</span> <span class="o">*</span> <span class="n">X_l</span> <span class="o">+</span> <span class="n">X2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X_l</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">*</span> <span class="n">y_l</span> <span class="o">+</span> <span class="n">y2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_l</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">reset_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset the generator indexes array.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generator1</span><span class="o">.</span><span class="n">_set_index_array</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator2</span><span class="o">.</span><span class="n">_set_index_array</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A method that gives us the different dataloaders that we need for training and validation.</span>

<span class="sd">With for_training set to True, the model gives us the dataloaders</span>
<span class="sd">* train_mix_loader: Gives us mixed data for training</span>
<span class="sd">* train_loader:     Gives us the unmixed training data</span>
<span class="sd">* val_mix_loader:   Gives us mixed validation data</span>
<span class="sd">* val_loader:       Gives us unmixed validation data</span>

<span class="sd">By setting for_training to False, the method gives us the dataloader</span>
<span class="sd">* test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_data_loaders</span><span class="p">(</span><span class="n">train_data_dir</span><span class="p">,</span><span class="n">test_data_dir</span><span class="p">,</span><span class="n">for_training</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
  
    <span class="c1">#For training data</span>
    <span class="k">if</span> <span class="n">for_training</span><span class="p">:</span>
        <span class="n">datagen_train_val</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
                                <span class="n">rotation_range</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                <span class="n">height_shift_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                <span class="n">zoom_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">brightness_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">),</span>
                                <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">fill_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span>
                                <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

        <span class="n">train_mix_loader</span> <span class="o">=</span> <span class="n">MixupImageDataGenerator</span><span class="p">(</span><span class="n">generator</span> <span class="o">=</span> <span class="n">datagen_train_val</span><span class="p">,</span>
                                                   <span class="n">directory</span> <span class="o">=</span> <span class="n">train_data_dir</span><span class="p">,</span>
                                                   <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">img_height</span> <span class="o">=</span> <span class="n">img_height</span><span class="p">,</span>
                                                   <span class="n">img_width</span> <span class="o">=</span> <span class="n">img_width</span><span class="p">,</span>
                                                   <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
                                                   <span class="n">subset</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>
        
        <span class="n">val_mix_loader</span> <span class="o">=</span> <span class="n">MixupImageDataGenerator</span><span class="p">(</span><span class="n">generator</span> <span class="o">=</span> <span class="n">datagen_train_val</span><span class="p">,</span>
                                                 <span class="n">directory</span> <span class="o">=</span> <span class="n">train_data_dir</span><span class="p">,</span>
                                                 <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
                                                 <span class="n">img_height</span> <span class="o">=</span> <span class="n">img_height</span><span class="p">,</span>
                                                 <span class="n">img_width</span> <span class="o">=</span> <span class="n">img_width</span><span class="p">,</span>
                                                 <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
                                                 <span class="n">subset</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">)</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">datagen_train_val</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">train_data_dir</span><span class="p">,</span>
                                                        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
                                                        <span class="n">class_mode</span><span class="o">=</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                        <span class="n">subset</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>

        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">datagen_train_val</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">train_data_dir</span><span class="p">,</span>
                                                        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
                                                        <span class="n">class_mode</span><span class="o">=</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                        <span class="n">subset</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">train_mix_loader</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_mix_loader</span><span class="p">,</span> <span class="n">val_loader</span>

    <span class="c1">#For test data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">datagen_test</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
                                <span class="n">rotation_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">width_shift_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">height_shift_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">shear_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">zoom_range</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                <span class="n">brightness_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">fill_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span>
                                <span class="n">validation_split</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">datagen_test</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">test_data_dir</span><span class="p">,</span>
                                                    <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
                                                        <span class="n">class_mode</span><span class="o">=</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                        <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">test_loader</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we define the function for creating the CNN.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">creates the CNN with number_conv convolutional layers followed by number_dense dense layers. The model is compiled with a SGD optimizer and a categorical crossentropy loss.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">number_conv</span><span class="p">,</span><span class="n">number_dense</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span><span class="n">channels</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">number_conv</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">24</span><span class="o">+</span><span class="mi">12</span><span class="o">*</span><span class="n">s</span><span class="p">,</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_dense</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span> <span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>This is the function that the ray.tune method will run. The steps in the
function is to generate the dataloaders that will load the data from the
working dictionary, create the model based on the hyperparameters given
in the config dictionary, train the model and evaluate the model on the
different datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_function</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Hyperparameters</span>
    <span class="n">number_conv</span><span class="p">,</span> <span class="n">number_dense</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;number_conv&quot;</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;number_dense&quot;</span><span class="p">]</span>
    <span class="n">train_with_mixed_data</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_with_mixed_data&quot;</span><span class="p">]</span>
    
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the different dataloaders</span>
<span class="sd">    One with training data using mixing</span>
<span class="sd">    One with training without mixing</span>
<span class="sd">    One with validation data with mixing</span>
<span class="sd">    One with validation without mixing</span>
<span class="sd">    Set for_training to False to get testing data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#train_data_dir,test_data_dir = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train&quot;,&quot;/dbfs/FileStore/tables/Group20/seg_test/seg_test&quot;</span>

    <span class="c1">#train_data_dir, test_data_dir = copy_data()</span>
    <span class="n">train_mix_dataloader</span><span class="p">,</span><span class="n">train_dataloader</span><span class="p">,</span><span class="n">val_mix_dataloader</span><span class="p">,</span><span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">get_data_loaders</span><span class="p">(</span><span class="n">train_data_dir</span><span class="p">,</span> <span class="n">test_data_dir</span><span class="p">,</span> <span class="n">for_training</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct the model based on hyperparameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span> <span class="n">number_conv</span><span class="p">,</span><span class="n">number_dense</span> <span class="p">)</span>

    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span><span class="n">min_delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span><span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train the model and give the training history.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">train_with_mixed_data</span><span class="p">:</span>
      <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">train_mix_dataloader</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="n">val_dataloader</span><span class="p">,</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span><span class="p">,</span><span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="n">val_dataloader</span><span class="p">,</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span><span class="p">,</span><span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logg the results</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#x_mix, y_mix = mixup_data( x_val, y_val)</span>
    <span class="c1">#mix_loss, mix_acc = model.evaluate( x_mix, y_mix )</span>
    <span class="n">train_loss_unmix</span><span class="p">,</span> <span class="n">train_acc_unmix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span> <span class="n">train_dataloader</span> <span class="p">)</span>
    <span class="n">val_mix_loss</span><span class="p">,</span> <span class="n">val_mix_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span> <span class="n">val_mix_dataloader</span> <span class="p">)</span>
    <span class="n">ind_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">])</span>
    <span class="n">train_mix_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">][</span><span class="n">ind_max</span><span class="p">]</span>
    <span class="n">train_mix_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">][</span><span class="n">ind_max</span><span class="p">]</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="n">ind_max</span><span class="p">]</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="n">ind_max</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="n">ind_max</span><span class="p">]</span>
    
    <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">mean_loss</span><span class="o">=</span><span class="n">train_mix_loss</span><span class="p">,</span> <span class="n">train_mix_accuracy</span> <span class="o">=</span> <span class="n">train_mix_acc</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">train_acc_unmix</span><span class="p">,</span> <span class="n">val_mix_accuracy</span> <span class="o">=</span> <span class="n">val_mix_acc</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">val_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_data_dir</span><span class="p">,</span><span class="n">test_data_dir</span> <span class="o">=</span> <span class="n">copy_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Copying data/files to local horovod folder...
Done with copying!
Copying data/files to local horovod folder...
Done with copying!
</pre></div>
</div>
</div></blockquote>
<p>First, we will train our neural networks using a standard procedure,
with normal training data. We then measure their performance on a
validation set as well as on a MixUp version of the same validation set,
the idea being to study the connection between these metrics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Limit the number of rows.</span>
<span class="n">reporter</span> <span class="o">=</span> <span class="n">CLIReporter</span><span class="p">(</span><span class="n">max_progress_rows</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># Add a custom metric column, in addition to the default metrics.</span>
<span class="c1"># Note that this must be a metric that is returned in your training results.</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;val_mix_accuracy&quot;</span><span class="p">)</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">)</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;train_accuracy&quot;</span><span class="p">)</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;train_mix_accuracy&quot;</span><span class="p">)</span>

<span class="c1">#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}</span>
<span class="c1">#training_function(config)</span>

<span class="c1">#get_data_loaders()</span>

<span class="n">analysis</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">training_function</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;number_conv&quot;</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span>
        <span class="s2">&quot;number_dense&quot;</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span>
        <span class="s2">&quot;train_with_mixed_data&quot;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">},</span>
    <span class="n">local_dir</span><span class="o">=</span><span class="s1">&#39;ray_results&#39;</span><span class="p">,</span>
    <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span>
<span class="p">)</span> 
  <span class="c1">#resources_per_trial={&#39;gpu&#39;: 1})</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best config: &quot;</span><span class="p">,</span> <span class="n">analysis</span><span class="o">.</span><span class="n">get_best_config</span><span class="p">(</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">))</span>

<span class="c1">#Get a dataframe for analyzing trial results.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">analysis</span><span class="o">.</span><span class="n">results_df</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>2021-01-13 08:43:03,776	WARNING tune.py:409 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={&#39;gpu&#39;: 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.
== Status ==
Memory usage on this node: 10.6/10.8 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)
Result logdir: /databricks/driver/ray_results/training_function_2021-01-13_08-43-03
Number of trials: 1/4 (1 RUNNING)
+-------------------------------+----------+-------+---------------+----------------+
| Trial name                    | status   | loc   |   number_conv |   number_dense |
|-------------------------------+----------+-------+---------------+----------------|
| training_function_599d5_00000 | RUNNING  |       |             2 |              0 |
+-------------------------------+----------+-------+---------------+----------------+


(pid=28210)  36/395 [=&gt;............................] - ETA: 13:21 - loss: 1.5431 - accuracy: 0.3429
(pid=22602) 271/395 [===================&gt;..........] - ETA: 4:42 - loss: 1.1429 - accuracy: 0.5845
(pid=24812)  37/395 [=&gt;............................] - ETA: 13:07 - loss: 1.4478 - accuracy: 0.3860
(pid=24044)  37/395 [=&gt;............................] - ETA: 13:10 - loss: 1.1538 - accuracy: 0.5988
(pid=28210)  37/395 [=&gt;............................] - ETA: 13:19 - loss: 1.5424 - accuracy: 0.3412
(pid=22602) 272/395 [===================&gt;..........] - ETA: 4:40 - loss: 1.1428 - accuracy: 0.5848
(pid=24812)  38/395 [=&gt;............................] - ETA: 13:04 - loss: 1.4463 - accuracy: 0.3914
(pid=24044)  38/395 [=&gt;............................] - ETA: 13:09 - loss: 1.1510 - accuracy: 0.5979
(pid=28210)  38/395 [=&gt;............................] - ETA: 13:17 - loss: 1.5432 - accuracy: 0.3421
(pid=22602) 273/395 [===================&gt;..........] - ETA: 4:38 - loss: 1.1423 - accuracy: 0.5851
(pid=24812)  39/395 [=&gt;............................] - ETA: 13:01 - loss: 1.4439 - accuracy: 0.3918
(pid=24044)  39/395 [=&gt;............................] - ETA: 13:07 - loss: 1.1542 - accuracy: 0.5986
(pid=28210)  39/395 [=&gt;............................] - ETA: 13:19 - loss: 1.5482 - accuracy: 0.3429
(pid=24812)  40/395 [==&gt;...........................] - ETA: 13:01 - loss: 1.4436 - accuracy: 0.3922
(pid=22602) 274/395 [===================&gt;..........] - ETA: 4:36 - loss: 1.1419 - accuracy: 0.5854
2021-01-13 08:43:12,451	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff18b0341001000000 cannot be scheduled right now. It requires {CPU: 1.000000} for placement, but this node only has remaining {GPU: 1.000000}, {accelerator_type:T4: 1.000000}, {node:10.149.224.88: 1.000000}, {object_store_memory: 0.830078 GiB}, {memory: 2.490234 GiB}. In total there are 0 pending tasks and 4 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
(pid=24044)  40/395 [==&gt;...........................] - ETA: 13:10 - loss: 1.1449 - accuracy: 0.6023
(pid=28210)  40/395 [==&gt;...........................] - ETA: 13:20 - loss: 1.5494 - accuracy: 0.3445
(pid=24812)  41/395 [==&gt;...........................] - ETA: 13:00 - loss: 1.4408 - accuracy: 0.3979
(pid=22602) 275/395 [===================&gt;..........] - ETA: 4:33 - loss: 1.1422 - accuracy: 0.5856
(pid=24044)  41/395 [==&gt;...........................] - ETA: 13:11 - loss: 1.1477 - accuracy: 0.6014
(pid=28210)  41/395 [==&gt;...........................] - ETA: 13:17 - loss: 1.5478 - accuracy: 0.3491
(pid=24812)  42/395 [==&gt;...........................] - ETA: 13:02 - loss: 1.4418 - accuracy: 0.3973
(pid=22602) 276/395 [===================&gt;..........] - ETA: 4:31 - loss: 1.1424 - accuracy: 0.5854
(pid=24044)  42/395 [==&gt;...........................] - ETA: 13:11 - loss: 1.1454 - accuracy: 0.6019
(pid=28210)  42/395 [==&gt;...........................] - ETA: 13:17 - loss: 1.5489 - accuracy: 0.3460
(pid=22602) 277/395 [====================&gt;.........] - ETA: 4:29 - loss: 1.1424 - accuracy: 0.5855
(pid=24812)  43/395 [==&gt;...........................] - ETA: 13:02 - loss: 1.4421 - accuracy: 0.3997
(pid=24044)  43/395 [==&gt;...........................] - ETA: 13:14 - loss: 1.1466 - accuracy: 0.6010
(pid=28210)  43/395 [==&gt;...........................] - ETA: 13:16 - loss: 1.5476 - accuracy: 0.3438
(pid=22602) 278/395 [====================&gt;.........] - ETA: 4:27 - loss: 1.1420 - accuracy: 0.5857
(pid=24812)  44/395 [==&gt;...........................] - ETA: 13:02 - loss: 1.4418 - accuracy: 0.3977
(pid=24044)  44/395 [==&gt;...........................] - ETA: 13:13 - loss: 1.1464 - accuracy: 0.6001
(pid=22602) 279/395 [====================&gt;.........] - ETA: 4:24 - loss: 1.1417 - accuracy: 0.5859
(pid=28210)  44/395 [==&gt;...........................] - ETA: 13:18 - loss: 1.5476 - accuracy: 0.3438
(pid=24812)  45/395 [==&gt;...........................] - ETA: 13:00 - loss: 1.4420 - accuracy: 0.3986
(pid=24044)  45/395 [==&gt;...........................] - ETA: 13:12 - loss: 1.1450 - accuracy: 0.6000
(pid=28210)  45/395 [==&gt;...........................] - ETA: 13:15 - loss: 1.5472 - accuracy: 0.3438
(pid=22602) 280/395 [====================&gt;.........] - ETA: 4:22 - loss: 1.1416 - accuracy: 0.5860
(pid=24812)  46/395 [==&gt;...........................] - ETA: 12:58 - loss: 1.4401 - accuracy: 0.4015
(pid=24044)  46/395 [==&gt;...........................] - ETA: 13:11 - loss: 1.1479 - accuracy: 0.5985
(pid=28210)  46/395 [==&gt;...........................] - ETA: 13:12 - loss: 1.5475 - accuracy: 0.3444
(pid=24812)  47/395 [==&gt;...........................] - ETA: 12:55 - loss: 1.4404 - accuracy: 0.4003
(pid=22602) 281/395 [====================&gt;.........] - ETA: 4:20 - loss: 1.1410 - accuracy: 0.5863
(pid=24044)  47/395 [==&gt;...........................] - ETA: 13:07 - loss: 1.1465 - accuracy: 0.5971
(pid=28210)  47/395 [==&gt;...........................] - ETA: 13:09 - loss: 1.5512 - accuracy: 0.3411
(pid=22602) 282/395 [====================&gt;.........] - ETA: 4:18 - loss: 1.1422 - accuracy: 0.5858
(pid=24812)  48/395 [==&gt;...........................] - ETA: 12:54 - loss: 1.4391 - accuracy: 0.3997
(pid=28210)  48/395 [==&gt;...........................] - ETA: 13:05 - loss: 1.5506 - accuracy: 0.3398
(pid=24044)  48/395 [==&gt;...........................] - ETA: 13:09 - loss: 1.1484 - accuracy: 0.6003
(pid=24812)  49/395 [==&gt;...........................] - ETA: 12:54 - loss: 1.4373 - accuracy: 0.3980
(pid=22602) 283/395 [====================&gt;.........] - ETA: 4:15 - loss: 1.1421 - accuracy: 0.5858
(pid=28210)  49/395 [==&gt;...........................] - ETA: 13:06 - loss: 1.5459 - accuracy: 0.3425
(pid=24044)  49/395 [==&gt;...........................] - ETA: 13:07 - loss: 1.1439 - accuracy: 0.6027
(pid=22602) 284/395 [====================&gt;.........] - ETA: 4:13 - loss: 1.1415 - accuracy: 0.5860
(pid=24812)  50/395 [==&gt;...........................] - ETA: 12:53 - loss: 1.4404 - accuracy: 0.3956
(pid=28210)  50/395 [==&gt;...........................] - ETA: 13:01 - loss: 1.5487 - accuracy: 0.3438
(pid=24044)  50/395 [==&gt;...........................] - ETA: 13:05 - loss: 1.1415 - accuracy: 0.6037
(pid=22602) 285/395 [====================&gt;.........] - ETA: 4:11 - loss: 1.1416 - accuracy: 0.5861
(pid=24812)  51/395 [==&gt;...........................] - ETA: 12:53 - loss: 1.4410 - accuracy: 0.3983
(pid=28210)  51/395 [==&gt;...........................] - ETA: 12:57 - loss: 1.5491 - accuracy: 0.3438
(pid=24044)  51/395 [==&gt;...........................] - ETA: 13:02 - loss: 1.1427 - accuracy: 0.6029
(pid=22602) 286/395 [====================&gt;.........] - ETA: 4:08 - loss: 1.1430 - accuracy: 0.5857
(pid=24812)  52/395 [==&gt;...........................] - ETA: 12:51 - loss: 1.4416 - accuracy: 0.3996
(pid=28210)  52/395 [==&gt;...........................] - ETA: 12:56 - loss: 1.5493 - accuracy: 0.3425
(pid=24044)  52/395 [==&gt;...........................] - ETA: 13:00 - loss: 1.1406 - accuracy: 0.6046
(pid=22602) 287/395 [====================&gt;.........] - ETA: 4:06 - loss: 1.1439 - accuracy: 0.5860
(pid=24812)  53/395 [===&gt;..........................] - ETA: 12:50 - loss: 1.4402 - accuracy: 0.4004
(pid=28210)  53/395 [===&gt;..........................] - ETA: 12:55 - loss: 1.5483 - accuracy: 0.3432
(pid=22602) 288/395 [====================&gt;.........] - ETA: 4:04 - loss: 1.1431 - accuracy: 0.5867
(pid=24044)  53/395 [===&gt;..........................] - ETA: 13:01 - loss: 1.1388 - accuracy: 0.6044
(pid=24812)  54/395 [===&gt;..........................] - ETA: 12:47 - loss: 1.4392 - accuracy: 0.3993
(pid=28210)  54/395 [===&gt;..........................] - ETA: 12:53 - loss: 1.5479 - accuracy: 0.3426
(pid=22602) 289/395 [====================&gt;.........] - ETA: 4:02 - loss: 1.1439 - accuracy: 0.5861
(pid=24044)  54/395 [===&gt;..........................] - ETA: 12:59 - loss: 1.1406 - accuracy: 0.6030
(pid=24812)  55/395 [===&gt;..........................] - ETA: 12:45 - loss: 1.4418 - accuracy: 0.3977
(pid=28210)  55/395 [===&gt;..........................] - ETA: 12:51 - loss: 1.5461 - accuracy: 0.3426
(pid=24044)  55/395 [===&gt;..........................] - ETA: 12:55 - loss: 1.1415 - accuracy: 0.6034
(pid=22602) 290/395 [=====================&gt;........] - ETA: 4:00 - loss: 1.1432 - accuracy: 0.5862
(pid=24812)  56/395 [===&gt;..........................] - ETA: 12:44 - loss: 1.4413 - accuracy: 0.3996
(pid=28210)  56/395 [===&gt;..........................] - ETA: 12:50 - loss: 1.5451 - accuracy: 0.3426
(pid=24044)  56/395 [===&gt;..........................] - ETA: 12:52 - loss: 1.1412 - accuracy: 0.6044
(pid=22602) 291/395 [=====================&gt;........] - ETA: 3:57 - loss: 1.1431 - accuracy: 0.5863
(pid=24812)  57/395 [===&gt;..........................] - ETA: 12:41 - loss: 1.4400 - accuracy: 0.3997
(pid=28210)  57/395 [===&gt;..........................] - ETA: 12:48 - loss: 1.5480 - accuracy: 0.3421
(pid=24044)  57/395 [===&gt;..........................] - ETA: 12:51 - loss: 1.1451 - accuracy: 0.6025
(pid=22602) 292/395 [=====================&gt;........] - ETA: 3:55 - loss: 1.1428 - accuracy: 0.5866
(pid=24812)  58/395 [===&gt;..........................] - ETA: 12:40 - loss: 1.4387 - accuracy: 0.4019
(pid=28210)  58/395 [===&gt;..........................] - ETA: 12:47 - loss: 1.5472 - accuracy: 0.3427
(pid=24044)  58/395 [===&gt;..........................] - ETA: 12:49 - loss: 1.1452 - accuracy: 0.6045
(pid=22602) 293/395 [=====================&gt;........] - ETA: 3:53 - loss: 1.1431 - accuracy: 0.5867
(pid=24812)  59/395 [===&gt;..........................] - ETA: 12:37 - loss: 1.4374 - accuracy: 0.4020
(pid=28210)  59/395 [===&gt;..........................] - ETA: 12:44 - loss: 1.5474 - accuracy: 0.3432
(pid=24044)  59/395 [===&gt;..........................] - ETA: 12:47 - loss: 1.1472 - accuracy: 0.6043
(pid=22602) 294/395 [=====================&gt;........] - ETA: 3:50 - loss: 1.1434 - accuracy: 0.5864
(pid=24812)  60/395 [===&gt;..........................] - ETA: 12:35 - loss: 1.4401 - accuracy: 0.4021
(pid=28210)  60/395 [===&gt;..........................] - ETA: 12:41 - loss: 1.5481 - accuracy: 0.3411
(pid=24044)  60/395 [===&gt;..........................] - ETA: 12:44 - loss: 1.1489 - accuracy: 0.6026
(pid=24812)  61/395 [===&gt;..........................] - ETA: 12:32 - loss: 1.4390 - accuracy: 0.4022
(pid=22602) 295/395 [=====================&gt;........] - ETA: 3:48 - loss: 1.1428 - accuracy: 0.5869
(pid=28210)  61/395 [===&gt;..........................] - ETA: 12:38 - loss: 1.5483 - accuracy: 0.3422
(pid=24044)  61/395 [===&gt;..........................] - ETA: 12:44 - loss: 1.1518 - accuracy: 0.6019
(pid=22602) 296/395 [=====================&gt;........] - ETA: 3:46 - loss: 1.1437 - accuracy: 0.5866
(pid=24812)  62/395 [===&gt;..........................] - ETA: 12:33 - loss: 1.4444 - accuracy: 0.4007
(pid=28210)  62/395 [===&gt;..........................] - ETA: 12:38 - loss: 1.5464 - accuracy: 0.3427
(pid=24044)  62/395 [===&gt;..........................] - ETA: 12:42 - loss: 1.1514 - accuracy: 0.6028
(pid=24812)  63/395 [===&gt;..........................] - ETA: 12:30 - loss: 1.4434 - accuracy: 0.3993
(pid=22602) 297/395 [=====================&gt;........] - ETA: 3:44 - loss: 1.1435 - accuracy: 0.5870
(pid=28210)  63/395 [===&gt;..........................] - ETA: 12:35 - loss: 1.5461 - accuracy: 0.3413
(pid=24044)  63/395 [===&gt;..........................] - ETA: 12:39 - loss: 1.1500 - accuracy: 0.6032
(pid=22602) 298/395 [=====================&gt;........] - ETA: 3:41 - loss: 1.1437 - accuracy: 0.5867
(pid=24812)  64/395 [===&gt;..........................] - ETA: 12:27 - loss: 1.4450 - accuracy: 0.3984
(pid=28210)  64/395 [===&gt;..........................] - ETA: 12:34 - loss: 1.5455 - accuracy: 0.3394
(pid=24044)  64/395 [===&gt;..........................] - ETA: 12:36 - loss: 1.1502 - accuracy: 0.6016
(pid=24812)  65/395 [===&gt;..........................] - ETA: 12:25 - loss: 1.4440 - accuracy: 0.3995
(pid=22602) 299/395 [=====================&gt;........] - ETA: 3:39 - loss: 1.1434 - accuracy: 0.5872

*** WARNING: skipped 13835348 bytes of output ***

(pid=6548) 356/395 [==========================&gt;...] - ETA: 25s - loss: 0.9658 - accuracy: 0.7235
(pid=6548) 357/395 [==========================&gt;...] - ETA: 24s - loss: 0.9657 - accuracy: 0.7239
(pid=6548) 358/395 [==========================&gt;...] - ETA: 24s - loss: 0.9656 - accuracy: 0.7239
(pid=6548) 359/395 [==========================&gt;...] - ETA: 23s - loss: 0.9659 - accuracy: 0.7238
(pid=6548) 360/395 [==========================&gt;...] - ETA: 22s - loss: 0.9661 - accuracy: 0.7237
(pid=6548) 361/395 [==========================&gt;...] - ETA: 22s - loss: 0.9658 - accuracy: 0.7239
(pid=6548) 362/395 [==========================&gt;...] - ETA: 21s - loss: 0.9657 - accuracy: 0.7240
(pid=6548) 363/395 [==========================&gt;...] - ETA: 20s - loss: 0.9658 - accuracy: 0.7240
(pid=6548) 364/395 [==========================&gt;...] - ETA: 20s - loss: 0.9660 - accuracy: 0.7239
(pid=6548) 365/395 [==========================&gt;...] - ETA: 19s - loss: 0.9661 - accuracy: 0.7241
(pid=6548) 366/395 [==========================&gt;...] - ETA: 18s - loss: 0.9662 - accuracy: 0.7237
(pid=6548) 367/395 [==========================&gt;...] - ETA: 18s - loss: 0.9663 - accuracy: 0.7234
(pid=6548) 368/395 [==========================&gt;...] - ETA: 17s - loss: 0.9661 - accuracy: 0.7236
(pid=6548) 369/395 [===========================&gt;..] - ETA: 16s - loss: 0.9659 - accuracy: 0.7237
(pid=6548) 370/395 [===========================&gt;..] - ETA: 16s - loss: 0.9664 - accuracy: 0.7236
(pid=6548) 371/395 [===========================&gt;..] - ETA: 15s - loss: 0.9663 - accuracy: 0.7237
(pid=6548) 372/395 [===========================&gt;..] - ETA: 15s - loss: 0.9660 - accuracy: 0.7242
(pid=6548) 373/395 [===========================&gt;..] - ETA: 14s - loss: 0.9662 - accuracy: 0.7241
(pid=6548) 374/395 [===========================&gt;..] - ETA: 13s - loss: 0.9659 - accuracy: 0.7244
(pid=6548) 375/395 [===========================&gt;..] - ETA: 13s - loss: 0.9659 - accuracy: 0.7245
(pid=6548) 376/395 [===========================&gt;..] - ETA: 12s - loss: 0.9664 - accuracy: 0.7243
(pid=6548) 377/395 [===========================&gt;..] - ETA: 11s - loss: 0.9661 - accuracy: 0.7246
(pid=6548) 378/395 [===========================&gt;..] - ETA: 11s - loss: 0.9660 - accuracy: 0.7250
(pid=6548) 379/395 [===========================&gt;..] - ETA: 10s - loss: 0.9658 - accuracy: 0.7250
(pid=6548) 380/395 [===========================&gt;..] - ETA: 9s - loss: 0.9661 - accuracy: 0.7248 
(pid=6548) 381/395 [===========================&gt;..] - ETA: 9s - loss: 0.9663 - accuracy: 0.7249
(pid=6548) 382/395 [============================&gt;.] - ETA: 8s - loss: 0.9663 - accuracy: 0.7249
(pid=6548) 383/395 [============================&gt;.] - ETA: 7s - loss: 0.9663 - accuracy: 0.7250
(pid=6548) 384/395 [============================&gt;.] - ETA: 7s - loss: 0.9664 - accuracy: 0.7250
(pid=6548) 385/395 [============================&gt;.] - ETA: 6s - loss: 0.9662 - accuracy: 0.7252
(pid=6548) 386/395 [============================&gt;.] - ETA: 5s - loss: 0.9660 - accuracy: 0.7251
(pid=6548) 387/395 [============================&gt;.] - ETA: 5s - loss: 0.9662 - accuracy: 0.7252
(pid=6548) 388/395 [============================&gt;.] - ETA: 4s - loss: 0.9661 - accuracy: 0.7255
(pid=6548) 389/395 [============================&gt;.] - ETA: 3s - loss: 0.9656 - accuracy: 0.7256
(pid=6548) 390/395 [============================&gt;.] - ETA: 3s - loss: 0.9658 - accuracy: 0.7255
(pid=6548) 391/395 [============================&gt;.] - ETA: 2s - loss: 0.9660 - accuracy: 0.7255
(pid=6548) 392/395 [============================&gt;.] - ETA: 1s - loss: 0.9665 - accuracy: 0.7253
(pid=6548) 393/395 [============================&gt;.] - ETA: 1s - loss: 0.9668 - accuracy: 0.7252
(pid=6548) 394/395 [============================&gt;.] - ETA: 0s - loss: 0.9666 - accuracy: 0.7255
(pid=6548) 395/395 [==============================] - ETA: 0s - loss: 0.9666 - accuracy: 0.7254395/395 [==============================] - 257s 651ms/step - loss: 0.9666 - accuracy: 0.7254
(pid=6548)  1/44 [..............................] - ETA: 0s - loss: 1.4518 - accuracy: 0.8438
(pid=6548)  2/44 [&gt;.............................] - ETA: 25s - loss: 1.3556 - accuracy: 0.7500
(pid=6548)  3/44 [=&gt;............................] - ETA: 33s - loss: 1.3191 - accuracy: 0.6875
(pid=6548)  4/44 [=&gt;............................] - ETA: 36s - loss: 1.3422 - accuracy: 0.6328
(pid=6548)  5/44 [==&gt;...........................] - ETA: 38s - loss: 1.2835 - accuracy: 0.6375
(pid=6548)  6/44 [===&gt;..........................] - ETA: 39s - loss: 1.2732 - accuracy: 0.6354
(pid=6548)  7/44 [===&gt;..........................] - ETA: 39s - loss: 1.2579 - accuracy: 0.6384
(pid=6548)  8/44 [====&gt;.........................] - ETA: 39s - loss: 1.2317 - accuracy: 0.6680
(pid=6548)  9/44 [=====&gt;........................] - ETA: 39s - loss: 1.2165 - accuracy: 0.6736
(pid=6548) 10/44 [=====&gt;........................] - ETA: 39s - loss: 1.2245 - accuracy: 0.6625
(pid=6548) 11/44 [======&gt;.......................] - ETA: 38s - loss: 1.2336 - accuracy: 0.6562
(pid=6548) 12/44 [=======&gt;......................] - ETA: 37s - loss: 1.2329 - accuracy: 0.6641
(pid=6548) 13/44 [=======&gt;......................] - ETA: 36s - loss: 1.2219 - accuracy: 0.6587
(pid=6548) 14/44 [========&gt;.....................] - ETA: 35s - loss: 1.2219 - accuracy: 0.6540
(pid=6548) 15/44 [=========&gt;....................] - ETA: 33s - loss: 1.2347 - accuracy: 0.6583
(pid=6548) 16/44 [=========&gt;....................] - ETA: 32s - loss: 1.2483 - accuracy: 0.6602
(pid=6548) 17/44 [==========&gt;...................] - ETA: 31s - loss: 1.2542 - accuracy: 0.6581
(pid=6548) 18/44 [===========&gt;..................] - ETA: 30s - loss: 1.2486 - accuracy: 0.6615
(pid=6548) 19/44 [===========&gt;..................] - ETA: 29s - loss: 1.2645 - accuracy: 0.6612
(pid=6548) 20/44 [============&gt;.................] - ETA: 28s - loss: 1.2730 - accuracy: 0.6594
(pid=6548) 21/44 [=============&gt;................] - ETA: 27s - loss: 1.2676 - accuracy: 0.6548
(pid=6548) 22/44 [==============&gt;...............] - ETA: 26s - loss: 1.2722 - accuracy: 0.6548
(pid=6548) 23/44 [==============&gt;...............] - ETA: 24s - loss: 1.2640 - accuracy: 0.6576
(pid=6548) 24/44 [===============&gt;..............] - ETA: 23s - loss: 1.2751 - accuracy: 0.6523
(pid=6548) 25/44 [================&gt;.............] - ETA: 22s - loss: 1.2711 - accuracy: 0.6562
(pid=6548) 26/44 [================&gt;.............] - ETA: 21s - loss: 1.2664 - accuracy: 0.6526
(pid=6548) 27/44 [=================&gt;............] - ETA: 20s - loss: 1.2615 - accuracy: 0.6516
(pid=6548) 28/44 [==================&gt;...........] - ETA: 19s - loss: 1.2742 - accuracy: 0.6462
(pid=6548) 29/44 [==================&gt;...........] - ETA: 18s - loss: 1.2709 - accuracy: 0.6444
(pid=6548) 30/44 [===================&gt;..........] - ETA: 17s - loss: 1.2656 - accuracy: 0.6448
(pid=6548) 31/44 [====================&gt;.........] - ETA: 16s - loss: 1.2639 - accuracy: 0.6502
(pid=6548) 32/44 [====================&gt;.........] - ETA: 14s - loss: 1.2592 - accuracy: 0.6533
(pid=6548) 33/44 [=====================&gt;........] - ETA: 13s - loss: 1.2572 - accuracy: 0.6553
(pid=6548) 34/44 [======================&gt;.......] - ETA: 12s - loss: 1.2561 - accuracy: 0.6535
(pid=6548) 35/44 [======================&gt;.......] - ETA: 11s - loss: 1.2593 - accuracy: 0.6518
(pid=6548) 36/44 [=======================&gt;......] - ETA: 9s - loss: 1.2554 - accuracy: 0.6536 
(pid=6548) 37/44 [========================&gt;.....] - ETA: 8s - loss: 1.2601 - accuracy: 0.6554
(pid=6548) 38/44 [========================&gt;.....] - ETA: 7s - loss: 1.2582 - accuracy: 0.6546
(pid=6548) 39/44 [=========================&gt;....] - ETA: 6s - loss: 1.2539 - accuracy: 0.6538
(pid=6548) 40/44 [==========================&gt;...] - ETA: 4s - loss: 1.2556 - accuracy: 0.6555
(pid=6548) 41/44 [==========================&gt;...] - ETA: 3s - loss: 1.2530 - accuracy: 0.6593
(pid=6548) 42/44 [===========================&gt;..] - ETA: 2s - loss: 1.2527 - accuracy: 0.6562
(pid=6548) 43/44 [============================&gt;.] - ETA: 1s - loss: 1.2526 - accuracy: 0.6569
(pid=6548) 44/44 [==============================] - ETA: 0s - loss: 1.2539 - accuracy: 0.653444/44 [==============================] - 54s 1s/step - loss: 1.2539 - accuracy: 0.6534
Result for training_function_599d5_00003:
  date: 2021-01-13_18-41-59
  done: false
  experiment_id: 9c7eefbea72e4010866a528e8fe30416
  hostname: 1120-144117-apses921-10-149-224-88
  iterations_since_restore: 1
  mean_loss: 1.2502855062484741
  neg_mean_loss: -1.2502855062484741
  node_ip: 10.149.224.88
  pid: 6548
  time_since_restore: 14116.892048120499
  time_this_iter_s: 14116.892048120499
  time_total_s: 14116.892048120499
  timestamp: 1610563319
  timesteps_since_restore: 0
  train_accuracy: 0.725380003452301
  train_mix_accuracy: 0.4630303978919983
  training_iteration: 1
  trial_id: 599d5_00003
  val_accuracy: 0.7068473696708679
  val_mix_accuracy: 0.6533523797988892
  
== Status ==
Memory usage on this node: 4.7/10.8 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)
Result logdir: /databricks/driver/ray_results/training_function_2021-01-13_08-43-03
Number of trials: 4/4 (3 ERROR, 1 RUNNING)
+-------------------------------+----------+--------------------+---------------+----------------+---------+--------+------------------+--------------------+----------------+------------------+----------------------+
| Trial name                    | status   | loc                |   number_conv |   number_dense |    loss |   iter |   total time (s) |   val_mix_accuracy |   val_accuracy |   train_accuracy |   train_mix_accuracy |
|-------------------------------+----------+--------------------+---------------+----------------+---------+--------+------------------+--------------------+----------------+------------------+----------------------|
| training_function_599d5_00003 | RUNNING  | 10.149.224.88:6548 |             5 |              2 | 1.25029 |      1 |         14116.9  |           0.653352 |       0.706847 |         0.72538  |             0.46303  |
| training_function_599d5_00000 | ERROR    |                    |             2 |              0 | 1.95385 |      1 |         10352.5  |           0.592725 |       0.636947 |         0.655082 |             0.631016 |
| training_function_599d5_00001 | ERROR    |                    |             5 |              0 | 2.17334 |      1 |         10054.3  |           0.629815 |       0.673324 |         0.688252 |             0.651678 |
| training_function_599d5_00002 | ERROR    |                    |             2 |              2 | 1.35401 |      1 |          8314.58 |           0.544936 |       0.588445 |         0.581381 |             0.400174 |
+-------------------------------+----------+--------------------+---------------+----------------+---------+--------+------------------+--------------------+----------------+------------------+----------------------+
Number of errored trials: 3
+-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                    |   # failures | error file                                                                                                                                                      |
|-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| training_function_599d5_00000 |            1 | /databricks/driver/ray_results/training_function_2021-01-13_08-43-03/training_function_599d5_00000_0_number_conv=2,number_dense=0_2021-01-13_08-43-03/error.txt |
| training_function_599d5_00001 |            1 | /databricks/driver/ray_results/training_function_2021-01-13_08-43-03/training_function_599d5_00001_1_number_conv=5,number_dense=0_2021-01-13_08-43-03/error.txt |
| training_function_599d5_00002 |            1 | /databricks/driver/ray_results/training_function_2021-01-13_08-43-03/training_function_599d5_00002_2_number_conv=2,number_dense=2_2021-01-13_08-43-03/error.txt |
+-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+

Result for training_function_599d5_00003:
  date: 2021-01-13_18-41-59
  done: true
  experiment_id: 9c7eefbea72e4010866a528e8fe30416
  experiment_tag: 3_number_conv=5,number_dense=2
  hostname: 1120-144117-apses921-10-149-224-88
  iterations_since_restore: 1
  mean_loss: 1.2502855062484741
  neg_mean_loss: -1.2502855062484741
  node_ip: 10.149.224.88
  pid: 6548
  time_since_restore: 14116.892048120499
  time_this_iter_s: 14116.892048120499
  time_total_s: 14116.892048120499
  timestamp: 1610563319
  timesteps_since_restore: 0
  train_accuracy: 0.725380003452301
  train_mix_accuracy: 0.4630303978919983
  training_iteration: 1
  trial_id: 599d5_00003
  val_accuracy: 0.7068473696708679
  val_mix_accuracy: 0.6533523797988892
  
== Status ==
Memory usage on this node: 4.7/10.8 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)
Result logdir: /databricks/driver/ray_results/training_function_2021-01-13_08-43-03
Number of trials: 4/4 (3 ERROR, 1 TERMINATED)
+-------------------------------+------------+-------+---------------+----------------+---------+--------+------------------+--------------------+----------------+------------------+----------------------+
| Trial name                    | status     | loc   |   number_conv |   number_dense |    loss |   iter |   total time (s) |   val_mix_accuracy |   val_accuracy |   train_accuracy |   train_mix_accuracy |
|-------------------------------+------------+-------+---------------+----------------+---------+--------+------------------+--------------------+----------------+------------------+----------------------|
| training_function_599d5_00003 | TERMINATED |       |             5 |              2 | 1.25029 |      1 |         14116.9  |           0.653352 |       0.706847 |         0.72538  |             0.46303  |
| training_function_599d5_00000 | ERROR      |       |             2 |              0 | 1.95385 |      1 |         10352.5  |           0.592725 |       0.636947 |         0.655082 |             0.631016 |
| training_function_599d5_00001 | ERROR      |       |             5 |              0 | 2.17334 |      1 |         10054.3  |           0.629815 |       0.673324 |         0.688252 |             0.651678 |
| training_function_599d5_00002 | ERROR      |       |             2 |              2 | 1.35401 |      1 |          8314.58 |           0.544936 |       0.588445 |         0.581381 |             0.400174 |
+-------------------------------+------------+-------+---------------+----------------+---------+--------+------------------+--------------------+----------------+------------------+----------------------+
Number of errored trials: 3
+-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name                    |   # failures | error file                                                                                                                                                      |
|-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| training_function_599d5_00000 |            1 | /databricks/driver/ray_results/training_function_2021-01-13_08-43-03/training_function_599d5_00000_0_number_conv=2,number_dense=0_2021-01-13_08-43-03/error.txt |
| training_function_599d5_00001 |            1 | /databricks/driver/ray_results/training_function_2021-01-13_08-43-03/training_function_599d5_00001_1_number_conv=5,number_dense=0_2021-01-13_08-43-03/error.txt |
| training_function_599d5_00002 |            1 | /databricks/driver/ray_results/training_function_2021-01-13_08-43-03/training_function_599d5_00002_2_number_conv=2,number_dense=2_2021-01-13_08-43-03/error.txt |
+-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<p>We now check whether directly training on MixUp data has a positive
effect on network performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Limit the number of rows.</span>
<span class="n">reporter</span> <span class="o">=</span> <span class="n">CLIReporter</span><span class="p">(</span><span class="n">max_progress_rows</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># Add a custom metric column, in addition to the default metrics.</span>
<span class="c1"># Note that this must be a metric that is returned in your training results.</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;val_mix_accuracy&quot;</span><span class="p">)</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">)</span>
<span class="n">reporter</span><span class="o">.</span><span class="n">add_metric_column</span><span class="p">(</span><span class="s2">&quot;train_accuracy&quot;</span><span class="p">)</span>

<span class="c1">#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}</span>
<span class="c1">#training_function(config)</span>

<span class="c1">#get_data_loaders()</span>

<span class="n">analysis</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">training_function</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;number_conv&quot;</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span>
        <span class="s2">&quot;number_dense&quot;</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()),</span>
        <span class="s2">&quot;train_with_mixed_data&quot;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">},</span>
    <span class="n">local_dir</span><span class="o">=</span><span class="s1">&#39;ray_results&#39;</span><span class="p">,</span>
    <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">)</span>
    
  <span class="c1">#resources_per_trial={&#39;gpu&#39;: 1})</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best config: &quot;</span><span class="p">,</span> <span class="n">analysis</span><span class="o">.</span><span class="n">get_best_config</span><span class="p">(</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">))</span>

<span class="c1">#Get a dataframe for analyzing trial results.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">analysis</span><span class="o">.</span><span class="n">results_df</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>2021-01-13 18:42:01,359	WARNING tune.py:409 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={&#39;gpu&#39;: 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.
== Status ==
Memory usage on this node: 4.9/10.8 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)
Result logdir: /databricks/driver/ray_results/training_function_2021-01-13_18-42-01
Number of trials: 1/4 (1 RUNNING)
+-------------------------------+----------+-------+---------------+----------------+
| Trial name                    | status   | loc   |   number_conv |   number_dense |
|-------------------------------+----------+-------+---------------+----------------|
| training_function_06148_00000 | RUNNING  |       |             2 |              0 |
+-------------------------------+----------+-------+---------------+----------------+


(pid=12677) 2021-01-13 18:42:03.496801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
(pid=12679) 2021-01-13 18:42:03.492543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
(pid=12673) 2021-01-13 18:42:03.492543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
(pid=12675) 2021-01-13 18:42:03.494678: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
(pid=12673) Found 12632 images belonging to 6 classes.
(pid=12677) Found 12632 images belonging to 6 classes.
(pid=12675) Found 12632 images belonging to 6 classes.
(pid=12679) Found 12632 images belonging to 6 classes.
(pid=12673) Found 12632 images belonging to 6 classes.
(pid=12677) Found 12632 images belonging to 6 classes.
(pid=12675) Found 12632 images belonging to 6 classes.
(pid=12679) Found 12632 images belonging to 6 classes.
(pid=12673) Found 1402 images belonging to 6 classes.
(pid=12677) Found 1402 images belonging to 6 classes.
(pid=12675) Found 1402 images belonging to 6 classes.
(pid=12679) Found 1402 images belonging to 6 classes.
(pid=12673) Found 1402 images belonging to 6 classes.
(pid=12677) Found 1402 images belonging to 6 classes.
(pid=12675) Found 1402 images belonging to 6 classes.
(pid=12679) Found 1402 images belonging to 6 classes.
(pid=12679) Found 12632 images belonging to 6 classes.
(pid=12673) Found 12632 images belonging to 6 classes.
(pid=12677) Found 12632 images belonging to 6 classes.
(pid=12675) Found 12632 images belonging to 6 classes.
(pid=12677) 2021-01-13 18:42:20.843659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
(pid=12673) 2021-01-13 18:42:20.843659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
(pid=12675) 2021-01-13 18:42:20.843661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
(pid=12673) Found 1402 images belonging to 6 classes.
(pid=12677) Found 1402 images belonging to 6 classes.
(pid=12675) Found 1402 images belonging to 6 classes.
(pid=12679) Found 1402 images belonging to 6 classes.
(pid=12677) 2021-01-13 18:42:20.885524: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
(pid=12677) 2021-01-13 18:42:20.885606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88
(pid=12677) 2021-01-13 18:42:20.885624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88
(pid=12677) 2021-01-13 18:42:20.885746: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2
(pid=12677) 2021-01-13 18:42:20.885789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2
(pid=12677) 2021-01-13 18:42:20.885803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2
(pid=12677) 2021-01-13 18:42:20.886184: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
(pid=12677) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
(pid=12677) 2021-01-13 18:42:20.900871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
(pid=12677) 2021-01-13 18:42:20.901206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff5443105f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=12677) 2021-01-13 18:42:20.901240: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=12673) 2021-01-13 18:42:20.873422: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
(pid=12673) 2021-01-13 18:42:20.873495: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88
(pid=12673) 2021-01-13 18:42:20.873513: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88
(pid=12673) 2021-01-13 18:42:20.873647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2
(pid=12673) 2021-01-13 18:42:20.873704: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2
(pid=12673) 2021-01-13 18:42:20.873723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2
(pid=12673) 2021-01-13 18:42:20.874080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
(pid=12673) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
(pid=12673) 2021-01-13 18:42:20.889058: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
(pid=12673) 2021-01-13 18:42:20.889426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f28c830f780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=12673) 2021-01-13 18:42:20.889461: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=12675) 2021-01-13 18:42:20.866880: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
(pid=12675) 2021-01-13 18:42:20.866971: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88
(pid=12675) 2021-01-13 18:42:20.866989: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88
(pid=12675) 2021-01-13 18:42:20.867105: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2
(pid=12675) 2021-01-13 18:42:20.867142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2
(pid=12675) 2021-01-13 18:42:20.867156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2
(pid=12675) 2021-01-13 18:42:20.867576: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
(pid=12675) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
(pid=12675) 2021-01-13 18:42:20.883221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
(pid=12675) 2021-01-13 18:42:20.883529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7d3c30fe20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=12675) 2021-01-13 18:42:20.883570: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=12679) 2021-01-13 18:42:20.940985: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
(pid=12679) 2021-01-13 18:42:20.961165: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
(pid=12679) 2021-01-13 18:42:20.961226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88
(pid=12679) 2021-01-13 18:42:20.961245: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88
(pid=12679) 2021-01-13 18:42:20.961360: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2
(pid=12679) 2021-01-13 18:42:20.961404: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2
(pid=12679) 2021-01-13 18:42:20.961420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2
(pid=12679) 2021-01-13 18:42:20.961841: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
(pid=12679) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
(pid=12679) 2021-01-13 18:42:20.989188: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
(pid=12679) 2021-01-13 18:42:20.989554: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f436030fd70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=12679) 2021-01-13 18:42:20.989622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=12673) WARNING:tensorflow:From &lt;command-685894176419834&gt;:35: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
(pid=12673) Instructions for updating:
(pid=12673) Please use Model.fit, which supports generators.
(pid=12677) WARNING:tensorflow:From &lt;command-685894176419834&gt;:35: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
(pid=12677) Instructions for updating:
(pid=12677) Please use Model.fit, which supports generators.
(pid=12675) WARNING:tensorflow:From &lt;command-685894176419834&gt;:35: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
(pid=12675) Instructions for updating:
(pid=12675) Please use Model.fit, which supports generators.
(pid=12679) WARNING:tensorflow:From &lt;command-685894176419834&gt;:35: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
(pid=12679) Instructions for updating:
(pid=12679) Please use Model.fit, which supports generators.
(pid=12675) Epoch 1/200
(pid=12673) Epoch 1/200
(pid=12677) Epoch 1/200
(pid=12679) Epoch 1/200
(pid=12677)   1/395 [..............................] - ETA: 0s - loss: 1.9563 - accuracy: 0.2500
(pid=12673)   1/395 [..............................] - ETA: 0s - loss: 3.2781 - accuracy: 0.0312
(pid=12675)   1/395 [..............................] - ETA: 0s - loss: 2.0109 - accuracy: 0.3125
(pid=12679)   1/395 [..............................] - ETA: 0s - loss: 2.4135 - accuracy: 0.1250
(pid=12677)   2/395 [..............................] - ETA: 4:31 - loss: 1.8397 - accuracy: 0.2812
(pid=12673)   2/395 [..............................] - ETA: 4:44 - loss: 3.5183 - accuracy: 0.1562
(pid=12675)   2/395 [..............................] - ETA: 3:44 - loss: 1.9892 - accuracy: 0.2500
(pid=12679)   2/395 [..............................] - ETA: 4:13 - loss: 2.4185 - accuracy: 0.2188
(pid=12677)   3/395 [..............................] - ETA: 5:34 - loss: 1.8799 - accuracy: 0.2708
(pid=12673)   3/395 [..............................] - ETA: 5:59 - loss: 3.1350 - accuracy: 0.2396
(pid=12675)   3/395 [..............................] - ETA: 5:19 - loss: 2.0241 - accuracy: 0.2188
(pid=12679)   3/395 [..............................] - ETA: 5:39 - loss: 2.3704 - accuracy: 0.2917
(pid=12677)   4/395 [..............................] - ETA: 6:16 - loss: 1.8927 - accuracy: 0.2344
(pid=12673)   4/395 [..............................] - ETA: 6:35 - loss: 3.1345 - accuracy: 0.2891
(pid=12675)   4/395 [..............................] - ETA: 6:20 - loss: 1.9437 - accuracy: 0.2344
(pid=12679)   4/395 [..............................] - ETA: 6:22 - loss: 2.4922 - accuracy: 0.3203
(pid=12677)   5/395 [..............................] - ETA: 6:39 - loss: 1.9056 - accuracy: 0.2125
(pid=12673)   5/395 [..............................] - ETA: 6:55 - loss: 2.9643 - accuracy: 0.3125
(pid=12675)   5/395 [..............................] - ETA: 6:46 - loss: 1.9152 - accuracy: 0.2250
(pid=12679)   5/395 [..............................] - ETA: 6:45 - loss: 2.6319 - accuracy: 0.3500
(pid=12677)   6/395 [..............................] - ETA: 7:07 - loss: 1.9388 - accuracy: 0.1979
(pid=12673)   6/395 [..............................] - ETA: 7:01 - loss: 2.8815 - accuracy: 0.3333
(pid=12675)   6/395 [..............................] - ETA: 7:34 - loss: 1.9327 - accuracy: 0.2240
(pid=12679)   6/395 [..............................] - ETA: 7:20 - loss: 2.8113 - accuracy: 0.3594
(pid=12677)   7/395 [..............................] - ETA: 7:24 - loss: 1.9297 - accuracy: 0.2054
(pid=12673)   7/395 [..............................] - ETA: 7:22 - loss: 2.8512 - accuracy: 0.3571
(pid=12675)   7/395 [..............................] - ETA: 7:48 - loss: 1.9184 - accuracy: 0.2321
(pid=12679)   7/395 [..............................] - ETA: 7:34 - loss: 2.7947 - accuracy: 0.3482
(pid=12677)   8/395 [..............................] - ETA: 7:36 - loss: 1.9102 - accuracy: 0.2188
(pid=12673)   8/395 [..............................] - ETA: 7:40 - loss: 2.7967 - accuracy: 0.3750
(pid=12675)   8/395 [..............................] - ETA: 8:03 - loss: 1.9078 - accuracy: 0.2344
(pid=12679)   8/395 [..............................] - ETA: 7:48 - loss: 2.9031 - accuracy: 0.3516
(pid=12677)   9/395 [..............................] - ETA: 7:46 - loss: 1.9297 - accuracy: 0.2257
(pid=12673)   9/395 [..............................] - ETA: 7:45 - loss: 2.7938 - accuracy: 0.3854
(pid=12675)   9/395 [..............................] - ETA: 8:09 - loss: 1.9164 - accuracy: 0.2396
(pid=12679)   9/395 [..............................] - ETA: 7:52 - loss: 2.9179 - accuracy: 0.3576
(pid=12677)  10/395 [..............................] - ETA: 7:52 - loss: 1.9528 - accuracy: 0.2156
(pid=12673)  10/395 [..............................] - ETA: 7:50 - loss: 2.7693 - accuracy: 0.3750
(pid=12675)  10/395 [..............................] - ETA: 8:06 - loss: 1.9311 - accuracy: 0.2438
(pid=12679)  10/395 [..............................] - ETA: 7:52 - loss: 2.7885 - accuracy: 0.3719
(pid=12677)  11/395 [..............................] - ETA: 7:53 - loss: 1.9405 - accuracy: 0.2244
(pid=12673)  11/395 [..............................] - ETA: 7:54 - loss: 2.8538 - accuracy: 0.3750
(pid=12679)  11/395 [..............................] - ETA: 7:47 - loss: 2.7757 - accuracy: 0.3864
(pid=12675)  11/395 [..............................] - ETA: 8:04 - loss: 1.9473 - accuracy: 0.2415
(pid=12677)  12/395 [..............................] - ETA: 7:52 - loss: 1.9379 - accuracy: 0.2214
(pid=12673)  12/395 [..............................] - ETA: 7:59 - loss: 2.9035 - accuracy: 0.3672
(pid=12679)  12/395 [..............................] - ETA: 7:51 - loss: 2.8265 - accuracy: 0.3802
(pid=12675)  12/395 [..............................] - ETA: 8:05 - loss: 1.9581 - accuracy: 0.2396
(pid=12677)  13/395 [..............................] - ETA: 7:54 - loss: 1.9348 - accuracy: 0.2236
(pid=12673)  13/395 [..............................] - ETA: 8:08 - loss: 2.8746 - accuracy: 0.3750
(pid=12679)  13/395 [..............................] - ETA: 7:53 - loss: 2.9115 - accuracy: 0.3894
(pid=12675)  13/395 [..............................] - ETA: 8:09 - loss: 1.9556 - accuracy: 0.2332
(pid=12677)  14/395 [&gt;.............................] - ETA: 7:58 - loss: 1.9512 - accuracy: 0.2210
(pid=12673)  14/395 [&gt;.............................] - ETA: 8:08 - loss: 2.8421 - accuracy: 0.3839
(pid=12679)  14/395 [&gt;.............................] - ETA: 7:53 - loss: 2.8786 - accuracy: 0.4040
(pid=12675)  14/395 [&gt;.............................] - ETA: 8:11 - loss: 1.9369 - accuracy: 0.2299
(pid=12677)  15/395 [&gt;.............................] - ETA: 7:59 - loss: 1.9540 - accuracy: 0.2208
(pid=12673)  15/395 [&gt;.............................] - ETA: 8:09 - loss: 2.8357 - accuracy: 0.3896
(pid=12679)  15/395 [&gt;.............................] - ETA: 7:53 - loss: 2.8906 - accuracy: 0.4042
(pid=12675)  15/395 [&gt;.............................] - ETA: 8:14 - loss: 1.9405 - accuracy: 0.2333
(pid=12677)  16/395 [&gt;.............................] - ETA: 8:02 - loss: 1.9416 - accuracy: 0.2207
(pid=12673)  16/395 [&gt;.............................] - ETA: 8:11 - loss: 2.8011 - accuracy: 0.3906

*** WARNING: skipped 79254 bytes of output ***

(pid=12679) 116/395 [=======&gt;......................] - ETA: 6:04 - loss: 3.6603 - accuracy: 0.4472
(pid=12675) 116/395 [=======&gt;......................] - ETA: 6:06 - loss: 1.7900 - accuracy: 0.2737
(pid=12673) 115/395 [=======&gt;......................] - ETA: 6:12 - loss: 2.8279 - accuracy: 0.4620
(pid=12677) 117/395 [=======&gt;......................] - ETA: 6:04 - loss: 1.8799 - accuracy: 0.2294
(pid=12679) 117/395 [=======&gt;......................] - ETA: 6:03 - loss: 3.6662 - accuracy: 0.4460
(pid=12675) 117/395 [=======&gt;......................] - ETA: 6:04 - loss: 1.7889 - accuracy: 0.2740
(pid=12673) 116/395 [=======&gt;......................] - ETA: 6:10 - loss: 2.8318 - accuracy: 0.4620
(pid=12677) 118/395 [=======&gt;......................] - ETA: 6:02 - loss: 1.8827 - accuracy: 0.2288
(pid=12679) 118/395 [=======&gt;......................] - ETA: 6:01 - loss: 3.6686 - accuracy: 0.4454
(pid=12675) 118/395 [=======&gt;......................] - ETA: 6:03 - loss: 1.7877 - accuracy: 0.2746
(pid=12673) 117/395 [=======&gt;......................] - ETA: 6:08 - loss: 2.8267 - accuracy: 0.4623
(pid=12677) 119/395 [========&gt;.....................] - ETA: 6:01 - loss: 1.8822 - accuracy: 0.2287
(pid=12679) 119/395 [========&gt;.....................] - ETA: 6:00 - loss: 3.6670 - accuracy: 0.4464
(pid=12675) 119/395 [========&gt;.....................] - ETA: 6:01 - loss: 1.7879 - accuracy: 0.2752
(pid=12673) 118/395 [=======&gt;......................] - ETA: 6:07 - loss: 2.8186 - accuracy: 0.4640
(pid=12677) 120/395 [========&gt;.....................] - ETA: 5:59 - loss: 1.8819 - accuracy: 0.2289
(pid=12679) 120/395 [========&gt;.....................] - ETA: 5:59 - loss: 3.6698 - accuracy: 0.4464
(pid=12675) 120/395 [========&gt;.....................] - ETA: 6:00 - loss: 1.7872 - accuracy: 0.2760
(pid=12673) 119/395 [========&gt;.....................] - ETA: 6:06 - loss: 2.8168 - accuracy: 0.4645
(pid=12677) 121/395 [========&gt;.....................] - ETA: 5:59 - loss: 1.8829 - accuracy: 0.2283
(pid=12679) 121/395 [========&gt;.....................] - ETA: 5:58 - loss: 3.6667 - accuracy: 0.4473
(pid=12675) 121/395 [========&gt;.....................] - ETA: 6:00 - loss: 1.7857 - accuracy: 0.2756
(pid=12673) 120/395 [========&gt;.....................] - ETA: 6:05 - loss: 2.8111 - accuracy: 0.4659
(pid=12677) 122/395 [========&gt;.....................] - ETA: 5:58 - loss: 1.8819 - accuracy: 0.2287
(pid=12679) 122/395 [========&gt;.....................] - ETA: 5:57 - loss: 3.6650 - accuracy: 0.4483
(pid=12675) 122/395 [========&gt;.....................] - ETA: 5:58 - loss: 1.7855 - accuracy: 0.2754
(pid=12673) 121/395 [========&gt;.....................] - ETA: 6:04 - loss: 2.8071 - accuracy: 0.4654
(pid=12677) 123/395 [========&gt;.....................] - ETA: 5:57 - loss: 1.8820 - accuracy: 0.2289
(pid=12679) 123/395 [========&gt;.....................] - ETA: 5:56 - loss: 3.6696 - accuracy: 0.4482
(pid=12675) 123/395 [========&gt;.....................] - ETA: 5:57 - loss: 1.7853 - accuracy: 0.2759
(pid=12673) 122/395 [========&gt;.....................] - ETA: 6:03 - loss: 2.8081 - accuracy: 0.4659
(pid=12677) 124/395 [========&gt;.....................] - ETA: 5:56 - loss: 1.8824 - accuracy: 0.2296
(pid=12679) 124/395 [========&gt;.....................] - ETA: 5:55 - loss: 3.6758 - accuracy: 0.4488
(pid=12675) 124/395 [========&gt;.....................] - ETA: 5:56 - loss: 1.7836 - accuracy: 0.2770
(pid=12673) 123/395 [========&gt;.....................] - ETA: 6:02 - loss: 2.8073 - accuracy: 0.4672
(pid=12677) 125/395 [========&gt;.....................] - ETA: 5:55 - loss: 1.8797 - accuracy: 0.2307
(pid=12679) 125/395 [========&gt;.....................] - ETA: 5:53 - loss: 3.6706 - accuracy: 0.4500
(pid=12675) 125/395 [========&gt;.....................] - ETA: 5:55 - loss: 1.7839 - accuracy: 0.2765
(pid=12673) 124/395 [========&gt;.....................] - ETA: 6:00 - loss: 2.8128 - accuracy: 0.4655
(pid=12677) 126/395 [========&gt;.....................] - ETA: 5:53 - loss: 1.8777 - accuracy: 0.2302
(pid=12679) 126/395 [========&gt;.....................] - ETA: 5:52 - loss: 3.6696 - accuracy: 0.4492
(pid=12675) 126/395 [========&gt;.....................] - ETA: 5:53 - loss: 1.7823 - accuracy: 0.2770
(pid=12673) 125/395 [========&gt;.....................] - ETA: 5:59 - loss: 2.8096 - accuracy: 0.4652
(pid=12677) 127/395 [========&gt;.....................] - ETA: 5:52 - loss: 1.8775 - accuracy: 0.2313
(pid=12679) 127/395 [========&gt;.....................] - ETA: 5:50 - loss: 3.6652 - accuracy: 0.4498
(pid=12675) 127/395 [========&gt;.....................] - ETA: 5:52 - loss: 1.7812 - accuracy: 0.2773
(pid=12673) 126/395 [========&gt;.....................] - ETA: 5:57 - loss: 2.8119 - accuracy: 0.4645
(pid=12677) 128/395 [========&gt;.....................] - ETA: 5:50 - loss: 1.8769 - accuracy: 0.2314
(pid=12679) 128/395 [========&gt;.....................] - ETA: 5:49 - loss: 3.6579 - accuracy: 0.4509
(pid=12675) 128/395 [========&gt;.....................] - ETA: 5:50 - loss: 1.7797 - accuracy: 0.2778
(pid=12673) 127/395 [========&gt;.....................] - ETA: 5:56 - loss: 2.8152 - accuracy: 0.4651
(pid=12677) 129/395 [========&gt;.....................] - ETA: 5:49 - loss: 1.8771 - accuracy: 0.2309
(pid=12679) 129/395 [========&gt;.....................] - ETA: 5:48 - loss: 3.6753 - accuracy: 0.4503
(pid=12675) 129/395 [========&gt;.....................] - ETA: 5:49 - loss: 1.7807 - accuracy: 0.2771
(pid=12673) 128/395 [========&gt;.....................] - ETA: 5:54 - loss: 2.8152 - accuracy: 0.4641
(pid=12677) 130/395 [========&gt;.....................] - ETA: 5:47 - loss: 1.8762 - accuracy: 0.2313
(pid=12675) 130/395 [========&gt;.....................] - ETA: 5:48 - loss: 1.7813 - accuracy: 0.2764
(pid=12679) 130/395 [========&gt;.....................] - ETA: 5:47 - loss: 3.7002 - accuracy: 0.4495
(pid=12673) 129/395 [========&gt;.....................] - ETA: 5:53 - loss: 2.8076 - accuracy: 0.4644
(pid=12677) 131/395 [========&gt;.....................] - ETA: 5:46 - loss: 1.8759 - accuracy: 0.2304
(pid=12675) 131/395 [========&gt;.....................] - ETA: 5:46 - loss: 1.7793 - accuracy: 0.2774
(pid=12679) 131/395 [========&gt;.....................] - ETA: 5:45 - loss: 3.7175 - accuracy: 0.4485
(pid=12673) 130/395 [========&gt;.....................] - ETA: 5:52 - loss: 2.8074 - accuracy: 0.4635
(pid=12677) 132/395 [=========&gt;....................] - ETA: 5:44 - loss: 1.8744 - accuracy: 0.2306
(pid=12675) 132/395 [=========&gt;....................] - ETA: 5:45 - loss: 1.7786 - accuracy: 0.2782
(pid=12679) 132/395 [=========&gt;....................] - ETA: 5:44 - loss: 3.7215 - accuracy: 0.4489
(pid=12673) 131/395 [========&gt;.....................] - ETA: 5:50 - loss: 2.8078 - accuracy: 0.4637
(pid=12677) 133/395 [=========&gt;....................] - ETA: 5:43 - loss: 1.8726 - accuracy: 0.2312
(pid=12675) 133/395 [=========&gt;....................]
(pid=12675)  - ETA: 5:43 - loss: 1.7772 - accuracy: 0.2787
(pid=12679) 133/395 [=========&gt;....................] - ETA: 5:43 - loss: 3.7273 - accuracy: 0.4495
(pid=12673) 132/395 [=========&gt;....................] - ETA: 5:48 - loss: 2.7998 - accuracy: 0.4650
(pid=12677) 134/395 [=========&gt;....................] - ETA: 5:42 - loss: 1.8713 - accuracy: 0.2306
(pid=12675) 134/395 [=========&gt;....................] - ETA: 5:42 - loss: 1.7759 - accuracy: 0.2792
(pid=12679) 134/395 [=========&gt;....................] - ETA: 5:42 - loss: 3.7318 - accuracy: 0.4499
(pid=12673) 133/395 [=========&gt;....................] - ETA: 5:47 - loss: 2.8042 - accuracy: 0.4648
(pid=12677) 135/395 [=========&gt;....................] - ETA: 5:41 - loss: 1.8703 - accuracy: 0.2310
(pid=12675) 135/395 [=========&gt;....................] - ETA: 5:41 - loss: 1.7753 - accuracy: 0.2789
(pid=12679) 135/395 [=========&gt;....................] - ETA: 5:40 - loss: 3.7436 - accuracy: 0.4493
(pid=12673) 134/395 [=========&gt;....................] - ETA: 5:46 - loss: 2.8092 - accuracy: 0.4643
(pid=12677) 136/395 [=========&gt;....................] - ETA: 5:39 - loss: 1.8684 - accuracy: 0.2316
(pid=12679) 136/395 [=========&gt;....................] - ETA: 5:38 - loss: 3.7444 - accuracy: 0.4499
(pid=12675) 136/395 [=========&gt;....................] - ETA: 5:39 - loss: 1.7732 - accuracy: 0.2794
(pid=12673) 135/395 [=========&gt;....................] - ETA: 5:44 - loss: 2.8108 - accuracy: 0.4639
(pid=12677) 137/395 [=========&gt;....................] - ETA: 5:38 - loss: 1.8668 - accuracy: 0.2324
(pid=12675) 137/395 [=========&gt;....................] - ETA: 5:38 - loss: 1.7722 - accuracy: 0.2787
(pid=12679) 137/395 [=========&gt;....................] - ETA: 5:37 - loss: 3.7454 - accuracy: 0.4505
(pid=12673) 136/395 [=========&gt;....................] - ETA: 5:43 - loss: 2.8102 - accuracy: 0.4639
(pid=12677) 138/395 [=========&gt;....................] - ETA: 5:37 - loss: 1.8664 - accuracy: 0.2330
(pid=12675) 138/395 [=========&gt;....................] - ETA: 5:36 - loss: 1.7701 - accuracy: 0.2810
(pid=12679) 138/395 [=========&gt;....................] - ETA: 5:36 - loss: 3.7494 - accuracy: 0.4509
(pid=12673) 137/395 [=========&gt;....................] - ETA: 5:42 - loss: 2.8074 - accuracy: 0.4649
(pid=12677) 139/395 [=========&gt;....................] - ETA: 5:36 - loss: 1.8677 - accuracy: 0.2329
(pid=12675) 139/395 [=========&gt;....................] - ETA: 5:35 - loss: 1.7701 - accuracy: 0.2806
(pid=12679) 139/395 [=========&gt;....................] - ETA: 5:35 - loss: 3.7416 - accuracy: 0.4528
(pid=12673) 138/395 [=========&gt;....................] - ETA: 5:40 - loss: 2.8037 - accuracy: 0.4658
(pid=12677) 140/395 [=========&gt;....................] - ETA: 5:34 - loss: 1.8664 - accuracy: 0.2339
(pid=12675) 140/395 [=========&gt;....................] - ETA: 5:33 - loss: 1.7690 - accuracy: 0.2812
(pid=12679) 140/395 [=========&gt;....................] - ETA: 5:33 - loss: 3.7420 - accuracy: 0.4533
(pid=12673) 139/395 [=========&gt;....................] - ETA: 5:39 - loss: 2.8016 - accuracy: 0.4661
(pid=12677) 141/395 [=========&gt;....................] - ETA: 5:32 - loss: 1.8673 - accuracy: 0.2347
(pid=12675) 141/395 [=========&gt;....................] - ETA: 5:32 - loss: 1.7688 - accuracy: 0.2812
(pid=12679) 141/395 [=========&gt;....................] - ETA: 5:32 - loss: 3.7366 - accuracy: 0.4543
(pid=12673) 140/395 [=========&gt;....................] - ETA: 5:37 - loss: 2.8100 - accuracy: 0.4661
(pid=12677) 142/395 [=========&gt;....................] - ETA: 5:31 - loss: 1.8660 - accuracy: 0.2344
(pid=12675) 142/395 [=========&gt;....................] - ETA: 5:31 - loss: 1.7691 - accuracy: 0.2815
(pid=12679) 142/395 [=========&gt;....................] - ETA: 5:30 - loss: 3.7444 - accuracy: 0.4540
(pid=12673) 141/395 [=========&gt;....................] - ETA: 5:36 - loss: 2.8162 - accuracy: 0.4654
(pid=12677) 143/395 [=========&gt;....................] - ETA: 5:30 - loss: 1.8631 - accuracy: 0.2351
(pid=12675) 143/395 [=========&gt;....................] - ETA: 5:29 - loss: 1.7686 - accuracy: 0.2815
(pid=12679) 143/395 [=========&gt;....................] - ETA: 5:29 - loss: 3.7410 - accuracy: 0.4545
(pid=12673) 142/395 [=========&gt;....................] - ETA: 5:34 - loss: 2.8144 - accuracy: 0.4657
(pid=12677) 144/395 [=========&gt;....................] - ETA: 5:28 - loss: 1.8628 - accuracy: 0.2352
(pid=12675) 144/395 [=========&gt;....................] - ETA: 5:28 - loss: 1.7680 - accuracy: 0.2819
(pid=12679) 144/395 [=========&gt;....................] - ETA: 5:28 - loss: 3.7463 - accuracy: 0.4544
(pid=12673) 143/395 [=========&gt;....................] - ETA: 5:33 - loss: 2.8204 - accuracy: 0.4661
(pid=12677) 145/395 [==========&gt;...................] - ETA: 5:27 - loss: 1.8624 - accuracy: 0.2353
(pid=12675) 145/395 [==========&gt;...................] - ETA: 5:26 - loss: 1.7661 - accuracy: 0.2828
(pid=12679) 145/395 [==========&gt;...................] - ETA: 5:26 - loss: 3.7586 - accuracy: 0.4543
(pid=12673) 144/395 [=========&gt;....................] - ETA: 5:32 - loss: 2.8162 - accuracy: 0.4666
(pid=12675) 146/395 [==========&gt;...................] - ETA: 5:25 - loss: 1.7654 - accuracy: 0.2825
(pid=12677) 146/395 [==========&gt;...................] - ETA: 5:26 - loss: 1.8607 - accuracy: 0.2363
(pid=12679) 146/395 [==========&gt;...................] - ETA: 5:25 - loss: 3.7719 - accuracy: 0.4529
(pid=12673) 145/395 [==========&gt;...................] - ETA: 5:30 - loss: 2.8131 - accuracy: 0.4664
(pid=12675) 147/395 [==========&gt;...................] - ETA: 5:23 - loss: 1.7646 - accuracy: 0.2830
(pid=12677) 147/395 [==========&gt;...................] - ETA: 5:24 - loss: 1.8592 - accuracy: 0.2372
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(pid=12673) 147/395 [==========&gt;...................] - ETA: 5:27 - loss: 2.8066 - accuracy: 0.4673
(pid=12675) 149/395 [==========&gt;...................] - ETA: 5:21 - loss: 1.7628 - accuracy: 0.2840
</pre></div>
</div>
</div></blockquote>
<p><strong>Conclusions</strong></p>
<p>We found that training a CNN using the Ray package was harder than we
thought from the beginning. This is probably due to the GPU usage and
that we had problems assigning the Keras model to the correct GPU. In
other words, Ray requested GPU usage but the code only ever ran on CPU,
which took an unfeasible amount of time.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-20_group-Generalization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="03_CNN_MNIST.html" title="previous page">CNN for MNIST</a>
    <a class='right-next' id="next-link" href="05_Horovod_test.html" title="next page">CNNs and MixUp with Horovod</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>