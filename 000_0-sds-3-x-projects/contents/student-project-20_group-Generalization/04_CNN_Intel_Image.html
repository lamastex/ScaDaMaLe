<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>04_CNN_Intel_Image - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../intro.html">Introduction</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/00_download_data.html"><strong aria-hidden="true">1.</strong> Student-project-01_group_TheTwoCultures_00_download_data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/01_load_data.html"><strong aria-hidden="true">1.1.</strong> 01_load_data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/01b_show_data.html"><strong aria-hidden="true">1.2.</strong> 01b_show_data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/02_logisticregression.html"><strong aria-hidden="true">1.3.</strong> 02_logisticregression</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/03_word2vec.html"><strong aria-hidden="true">1.4.</strong> 03_word2vec</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-01_group-TheTwoCultures/04_LDA.html"><strong aria-hidden="true">1.5.</strong> 04_LDA</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html"><strong aria-hidden="true">2.</strong> Student-project-02_group_LiUUmeaSceneGraphMotifs_01_SceneGraphMotifs</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-03_group-GuangyiZhang/01_triads.html"><strong aria-hidden="true">3.</strong> Student-project-03_group_GuangyiZhang_01_triads</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html"><strong aria-hidden="true">4.</strong> Student-project-04_group_DistributedLinearAlgebra_01_DistributedSVD</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html"><strong aria-hidden="true">4.1.</strong> 02_CollaborativeFiltering</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html"><strong aria-hidden="true">5.</strong> Student-project-05_group_LundDirichletAnalysts_01_Wikipedia_LDA_Analysis</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/00_Introduction.html"><strong aria-hidden="true">6.</strong> Student-project-06_group-ParticleClustering_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/01_data_and_preprocessing.html"><strong aria-hidden="true">6.1.</strong> 01_data_and_preprocessing</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/02_dl_single_machine.html"><strong aria-hidden="true">6.2.</strong> 02_dl_single_machine</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/03_dl_horovod.html"><strong aria-hidden="true">6.3.</strong> 03_dl_horovod</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/04_evaluate.html"><strong aria-hidden="true">6.4.</strong> 04_evaluate</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-06_group-ParticleClustering/TF1version.html"><strong aria-hidden="true">6.5.</strong> TF1version</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-07_group-MathAtKTH/01_Coding_Motifs.html"><strong aria-hidden="true">7.</strong> Student-project-07_group-MathAtKTH_01_Coding_Motifs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-07_group-MathAtKTH/02_Data_Processing.html"><strong aria-hidden="true">7.1.</strong> 02_Data_Processing</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-07_group-MathAtKTH/03_graph_string_converter.html"><strong aria-hidden="true">7.2.</strong> 03_graph_string_converter</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-08_group-DistributedEnsemble/00_project.html"><strong aria-hidden="true">8.</strong> Student-project-08_group-DistributedEnsemble_00_project</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/01_Introduction.html"><strong aria-hidden="true">9.</strong> Student-project-09_group-TopicModeling_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/02_Data_Processing.html"><strong aria-hidden="true">9.1.</strong> 02_Data_Processing</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/03_LDA.html"><strong aria-hidden="true">9.2.</strong> 03_LDA</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/04_Classification_CountVector.html"><strong aria-hidden="true">9.3.</strong> 04_Classification_CountVector</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/05_Classification.html"><strong aria-hidden="true">9.4.</strong> 05_Classification</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-09_group-TopicModeling/06_Results.html"><strong aria-hidden="true">9.5.</strong> 06_Results</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/01_Introduction.html"><strong aria-hidden="true">10.</strong> Student-project-10_group-Geosmus_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html"><strong aria-hidden="true">10.1.</strong> 02_ClusteringEmoticonsBasedOnTweets</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html"><strong aria-hidden="true">10.2.</strong> 03_Dynamic_Tweet_Maps</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/04_conclusion.html"><strong aria-hidden="true">10.3.</strong> 04_conclusion</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/05_appendix_get-cc-data.html"><strong aria-hidden="true">10.4.</strong> 05_appendix_get-cc-data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/06_appendix_tweet_carto_functions.html"><strong aria-hidden="true">10.5.</strong> 06_appendix_tweet_carto_functions</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html"><strong aria-hidden="true">10.6.</strong> 07_a_appendix_extendedTwitterUtils2run</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html"><strong aria-hidden="true">10.7.</strong> 07_b_appendix_TTTDFfunctions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-11_group-Sketchings/00_QuantileEstimation.html"><strong aria-hidden="true">11.</strong> Student-project-11_group-Sketchings_00_QuantileEstimation</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html"><strong aria-hidden="true">12.</strong> Student-project-12_group-CovidPandemic_00_ProjectDescriptionAndPlanning</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html"><strong aria-hidden="true">12.1.</strong> 01_DownloadFilesPeriodicallyScript</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/01_StreamToFile.html"><strong aria-hidden="true">12.2.</strong> 01_StreamToFile</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/02_DataPreprocess.html"><strong aria-hidden="true">12.3.</strong> 02_DataPreprocess</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html"><strong aria-hidden="true">12.4.</strong> 021_DataPreprocess_Explain</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html"><strong aria-hidden="true">12.5.</strong> 03_ExplosiveAnalysis</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/04_DataVisualize.html"><strong aria-hidden="true">12.6.</strong> 04_DataVisualize</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/05_Clustering.html"><strong aria-hidden="true">12.7.</strong> 05_Clustering</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/06_DataPredicton_LR.html"><strong aria-hidden="true">12.8.</strong> 06_DataPredicton_LR</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html"><strong aria-hidden="true">12.9.</strong> 07_DataPredicton_ARIMA</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-12_group-CovidPandemic/08_DataPrediction_GP.html"><strong aria-hidden="true">12.10.</strong> 08_DataPrediction_GP</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-13_group-Genomics/01_1000genomes.html"><strong aria-hidden="true">13.</strong> Student-project-13_group-Genomics_01_1000genomes</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html"><strong aria-hidden="true">14.</strong> Student-project-14_group-NullHypothesisEvaluationCriteria_00_distributed_combinatorial_bandit</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/00_video.html"><strong aria-hidden="true">15.</strong> Student-project-15_group-FinancialDataStreams_00_video</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html"><strong aria-hidden="true">15.1.</strong> 01_rl_intraday_trading</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html"><strong aria-hidden="true">15.2.</strong> 02_rl_intraday_trading_elephas</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-15_group-FinancialDataStreams/03_resources.html"><strong aria-hidden="true">15.3.</strong> 03_resources</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-16_group-IntrusionDetection/00_Introduction.html"><strong aria-hidden="true">16.</strong> Student-project-16_group-IntrusionDetection_00_Introduction</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/00_introduction.html"><strong aria-hidden="true">17.</strong> Student-project-17_group-TowardsScalableTDA_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/01_methodology.html"><strong aria-hidden="true">17.1.</strong> 01_methodology</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/02_gaussian_analysis.html"><strong aria-hidden="true">17.2.</strong> 02_gaussian_analysis</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html"><strong aria-hidden="true">17.3.</strong> 03_robotics_dataset</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-18_group-ProjectRL/00_Problem_Description.html"><strong aria-hidden="true">18.</strong> Student-project-18_group-ProjectRL_00_Problem_Description</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-18_group-ProjectRL/01_The_ALS_method.html"><strong aria-hidden="true">18.1.</strong> 01_The_ALS_method</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-18_group-ProjectRL/02_Extensions.html"><strong aria-hidden="true">18.2.</strong> 02_Extensions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-19_group-Featuring/01_FundamentalMatrix.html"><strong aria-hidden="true">19.</strong> Student-project-19_group-Featuring_01_FundamentalMatrix</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/01_Background.html"><strong aria-hidden="true">20.</strong> Student-project-20_group-Generalization_01_Background</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/02_Random_Forest.html"><strong aria-hidden="true">20.1.</strong> 02_Random_Forest</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/03_CNN_MNIST.html"><strong aria-hidden="true">20.2.</strong> 03_CNN_MNIST</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/04_CNN_Intel_Image.html" class="active"><strong aria-hidden="true">20.3.</strong> 04_CNN_Intel_Image</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-20_group-Generalization/05_Horovod_test.html"><strong aria-hidden="true">20.4.</strong> 05_Horovod_test</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/00_introduction.html"><strong aria-hidden="true">21.</strong> Student-project-21_group-GraphSpectralAnalysis_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html"><strong aria-hidden="true">21.1.</strong> 01_preprocess_data</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html"><strong aria-hidden="true">21.2.</strong> 02_generate_graphs</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html"><strong aria-hidden="true">21.3.</strong> 03_compute_rsvd.</a></li><li class="chapter-item expanded "><a href="../../contents/student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html"><strong aria-hidden="true">21.4.</strong> 04_analyse_eigenvalues</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/student-project-22_group-SwapWithDDP/00_Introduction.html"><strong aria-hidden="true">22.</strong> Student-project-22_group-SwapWithDDP_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html"><strong aria-hidden="true">22.1.</strong> 01_SWAP_with_DDP</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/00_Introduction.html"><strong aria-hidden="true">23.</strong> Voluntary-student-project-01_group-DDLInMining_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/01_ImageSegmentation_UNet.html"><strong aria-hidden="true">23.1.</strong> 01_ImageSegmentation_UNet</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/02_ImageSegmenation_PSPNet.html"><strong aria-hidden="true">23.2.</strong> 02_ImageSegmenation_PSPNet</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/03_ICNet_Function.html"><strong aria-hidden="true">23.3.</strong> 03_ICNet_Function</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/04_ICNet_Function_hvd.html"><strong aria-hidden="true">23.4.</strong> 04_ICNet_Function_hvd</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/05_ICNet_Function_Tuning_parallel.html"><strong aria-hidden="true">23.5.</strong> 05_ICNet_Function_Tuning_parallel</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XX_ICNet_Class.html"><strong aria-hidden="true">23.6.</strong> XX_ICNet_Class</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XX_ICNet_Function_hvd_tuning.html"><strong aria-hidden="true">23.7.</strong> XX_ICNet_Function_hvd_tuning</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XX_ImageSegmentation_ICNet.html"><strong aria-hidden="true">23.8.</strong> XX_ImageSegmentation_ICNet</a></li><li class="chapter-item expanded "><a href="../../contents/voluntary-student-project-01_group-DDLInMining/XXNOTWORKING_ICNet_Function_Tuning.html"><strong aria-hidden="true">23.9.</strong> XXNOTWORKING_ICNet_Function_Tuning</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<p>ScaDaMaLe Course <a href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and <a href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
</div>
<div class="cell markdown">
<h2 id="cnn-for-intel-image-classification"><a class="header" href="#cnn-for-intel-image-classification">CNN for Intel Image Classification</a></h2>
<p>We will now implement and test the MixUp preprocessing method for a slightly harder CNN example, the Intel Image Classification data set. Again, this notebook runs on CPUs, but the hyperparameter search is scalable.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Imports
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout
from tensorflow.keras import Sequential
from ray import tune
from ray.tune import CLIReporter
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from functools import partial

# Fixes the issue &quot;AttributeError: 'ConsoleBuffer has no attribute 'fileno'&quot;
import sys
sys.stdout.fileno = lambda: False
</code></pre>
</div>
<div class="cell markdown">
<p>We will use the Intel Image Classification data set [[3]]. It consists of 25k 150x150 RBG images from 6 different classes: buildings, forest, glacier, mountain, sea, or street. However when we load the data to our model we will rescale the images to 32x32 RBG images.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
Global parameters for training.
&quot;&quot;&quot;

img_height,img_width,channels = 32,32,3
batch_size = 32
train_data_dir,test_data_dir = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train/&quot;, &quot;dbfs/FileStore/tables/Group20/seg_test/seg_test/&quot;
num_classes = 6
alpha = 0.2 # Degree of mixup is ~ Beta(alpha,alpha)
</code></pre>
</div>
<div class="cell markdown">
<p>To create MixUp data, we will define a custom data generator. It takes an underlying image generator as argument, and outputs convex combinations of two randomly selected (example,label) pairs drawn according to the underlying generator.</p>
<p>Note that, in order to speed up the data generators, we need to make the data more accessible. We do this by copying the data from the dbfs to the working directory. This is done with our copy_data function.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import os, shutil
def copy_data():
  src = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train&quot;
  dst = os.path.join(os.getcwd(), 'seg_train')
  print(&quot;Copying data to working folder&quot;)
  shutil.copytree(src, dst)
  print(&quot;Done with copying!&quot;)
  train_data_dir = dst

  src = &quot;/dbfs/FileStore/tables/Group20/seg_test/seg_test&quot;
  dst = os.path.join(os.getcwd(), 'seg_test')
  print(&quot;Copying data to working folder&quot;)
  shutil.copytree(src, dst)
  print(&quot;Done with copying!&quot;)
  test_data_dir = dst

  return train_data_dir,test_data_dir
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">class MixupImageDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):
        self.batch_size = batch_size
        self.batch_index = 0
        self.alpha = alpha

        # First iterator yielding tuples of (x, y)
        self.generator1 = generator.flow_from_directory(directory,
                                                        target_size=(
                                                            img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=subset)

        # Second iterator yielding tuples of (x, y)
        self.generator2 = generator.flow_from_directory(directory,
                                                        target_size=(
                                                            img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=subset)

        # Number of images across all classes in image directory.
        self.n = self.generator1.samples


    def __len__(self):
        # returns the number of batches
        return (self.n + self.batch_size - 1) // self.batch_size

    def __getitem__(self, index):
        # Get a pair of inputs and outputs from two iterators.
        X1, y1 = self.generator1.next()
        X2, y2 = self.generator2.next()


        # random sample the lambda value from beta distribution.
        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])

        X_l = l.reshape(X1.shape[0], 1, 1, 1)
        y_l = l.reshape(X1.shape[0], 1)


        # Perform the mixup.
        X = X1 * X_l + X2 * (1 - X_l)
        y = y1 * y_l + y2 * (1 - y_l)
        return X, y

    def reset_index(self):
        &quot;&quot;&quot;Reset the generator indexes array.
        &quot;&quot;&quot;

        self.generator1._set_index_array()
        self.generator2._set_index_array()


    def on_epoch_end(self):
        self.reset_index()
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
A method that gives us the different dataloaders that we need for training and validation.

With for_training set to True, the model gives us the dataloaders
* train_mix_loader: Gives us mixed data for training
* train_loader:     Gives us the unmixed training data
* val_mix_loader:   Gives us mixed validation data
* val_loader:       Gives us unmixed validation data

By setting for_training to False, the method gives us the dataloader
* test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.
&quot;&quot;&quot;
def get_data_loaders(train_data_dir,test_data_dir,for_training = True):
  
    #For training data
    if for_training:
        datagen_train_val = ImageDataGenerator(rescale=1./255,
                                rotation_range=5,
                                width_shift_range=0.05,
                                height_shift_range=0,
                                shear_range=0.05,
                                zoom_range=0,
                                brightness_range=(1, 1.3),
                                horizontal_flip=True,
                                fill_mode='nearest',
                                validation_split=0.1)

        train_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,
                                                   directory = train_data_dir,
                                                   batch_size = batch_size,
                                                   img_height = img_height,
                                                   img_width = img_width,
                                                   alpha=alpha,
                                                   subset=&quot;training&quot;)
        
        val_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,
                                                 directory = train_data_dir,
                                                 batch_size = batch_size,
                                                 img_height = img_height,
                                                 img_width = img_width,
                                                 alpha=alpha,
                                                 subset=&quot;validation&quot;)

        train_loader = datagen_train_val.flow_from_directory(train_data_dir,
                                                        target_size=(img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=&quot;training&quot;)

        val_loader = datagen_train_val.flow_from_directory(train_data_dir,
                                                        target_size=(img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=True,
                                                        subset=&quot;validation&quot;)
        
        return train_mix_loader,train_loader, val_mix_loader, val_loader

    #For test data
    else:
        datagen_test = ImageDataGenerator(rescale=1./255,
                                rotation_range=0,
                                width_shift_range=0,
                                height_shift_range=0,
                                shear_range=0,
                                zoom_range=0,
                                brightness_range=(1, 1),
                                horizontal_flip=False,
                                fill_mode='nearest',
                                validation_split=0)

        test_loader = datagen_test.flow_from_directory(test_data_dir,
                                                    target_size=(img_height, img_width),
                                                        class_mode=&quot;categorical&quot;,
                                                        batch_size=batch_size,
                                                        shuffle=False,
                                                        subset=None)

        return test_loader
</code></pre>
</div>
<div class="cell markdown">
<p>Next, we define the function for creating the CNN.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">&quot;&quot;&quot;
creates the CNN with number_conv convolutional layers followed by number_dense dense layers. The model is compiled with a SGD optimizer and a categorical crossentropy loss.
&quot;&quot;&quot;
def create_model(number_conv,number_dense):
    model = Sequential()
    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=&quot;same&quot;, input_shape=(img_height, img_width,channels)))
    model.add(BatchNormalization())
    for s in range(1,number_conv):
        model.add(Conv2D(24+12*s,kernel_size = 3,padding=&quot;same&quot;, activation = 'relu'))
        model.add(BatchNormalization())
    model.add(Flatten())
    model.add(Dropout(0.4))
    for s in range(number_dense):
        model.add(Dense(units=num_classes, activation='relu'))
        model.add(Dropout(0.4))
    model.add(BatchNormalization())
    model.add(Dense(num_classes,activation= &quot;softmax&quot;))
    model.compile(optimizer=&quot;adam&quot;, loss='categorical_crossentropy', metrics=['accuracy'])
    return model
</code></pre>
</div>
<div class="cell markdown">
<p>This is the function that the ray.tune method will run. The steps in the function is to generate the dataloaders that will load the data from the working dictionary, create the model based on the hyperparameters given in the config dictionary, train the model and evaluate the model on the different datasets.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def training_function(config, checkpoint_dir=None):
    # Hyperparameters
    number_conv, number_dense = config[&quot;number_conv&quot;], config[&quot;number_dense&quot;]
    train_with_mixed_data = config[&quot;train_with_mixed_data&quot;]
    
    
    &quot;&quot;&quot;
    Get the different dataloaders
    One with training data using mixing
    One with training without mixing
    One with validation data with mixing
    One with validation without mixing
    Set for_training to False to get testing data
    &quot;&quot;&quot;
    #train_data_dir,test_data_dir = &quot;/dbfs/FileStore/tables/Group20/seg_train/seg_train&quot;,&quot;/dbfs/FileStore/tables/Group20/seg_test/seg_test&quot;

    #train_data_dir, test_data_dir = copy_data()
    train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(train_data_dir, test_data_dir, for_training = True)

    &quot;&quot;&quot;
    Construct the model based on hyperparameters
    &quot;&quot;&quot;
    model = create_model( number_conv,number_dense )

    
    &quot;&quot;&quot;
    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?
    &quot;&quot;&quot;
    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10,monitor=&quot;val_accuracy&quot;,min_delta=0.01,restore_best_weights=True)]

    &quot;&quot;&quot;
    Train the model and give the training history.
    &quot;&quot;&quot;
    if train_with_mixed_data:
      history = model.fit_generator(train_mix_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)
    else:
      history = model.fit_generator(train_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)
    
    &quot;&quot;&quot;
    Logg the results
    &quot;&quot;&quot;
    #x_mix, y_mix = mixup_data( x_val, y_val)
    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )
    train_loss_unmix, train_acc_unmix = model.evaluate( train_dataloader )
    val_mix_loss, val_mix_acc = model.evaluate( val_mix_dataloader )
    ind_max = np.argmax(history.history['val_accuracy'])
    train_mix_acc = history.history['accuracy'][ind_max]
    train_mix_loss = history.history[&quot;loss&quot;][ind_max]
    train_loss = history.history['loss'][ind_max]
    val_acc = history.history['val_accuracy'][ind_max]
    val_loss = history.history['val_loss'][ind_max]
    
    tune.report(mean_loss=train_mix_loss, train_mix_accuracy = train_mix_acc, train_accuracy = train_acc_unmix, val_mix_accuracy = val_mix_acc, val_accuracy = val_acc)
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">train_data_dir,test_data_dir = copy_data()
</code></pre>
<div class="output execute_result plain_result" execution_count="1">
<pre><code>Copying data/files to local horovod folder...
Done with copying!
Copying data/files to local horovod folder...
Done with copying!
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>First, we will train our neural networks using a standard procedure, with normal training data. We then measure their performance on a validation set as well as on a MixUp version of the same validation set, the idea being to study the connection between these metrics.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Limit the number of rows.
reporter = CLIReporter(max_progress_rows=10)
# Add a custom metric column, in addition to the default metrics.
# Note that this must be a metric that is returned in your training results.
reporter.add_metric_column(&quot;val_mix_accuracy&quot;)
reporter.add_metric_column(&quot;val_accuracy&quot;)
reporter.add_metric_column(&quot;train_accuracy&quot;)
reporter.add_metric_column(&quot;train_mix_accuracy&quot;)

#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}
#training_function(config)

#get_data_loaders()

analysis = tune.run(
    training_function,
    config={
        &quot;number_conv&quot;: tune.grid_search(np.arange(2,7,3).tolist()),
        &quot;number_dense&quot;: tune.grid_search(np.arange(0,3,2).tolist()),
        &quot;train_with_mixed_data&quot;: False
    },
    local_dir='ray_results',
    progress_reporter=reporter
) 
  #resources_per_trial={'gpu': 1})

print(&quot;Best config: &quot;, analysis.get_best_config(
    metric=&quot;val_accuracy&quot;, mode=&quot;max&quot;))

#Get a dataframe for analyzing trial results.
df = analysis.results_df
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">df
</code></pre>
</div>
<div class="cell markdown">
<p>We now check whether directly training on MixUp data has a positive effect on network performance.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Limit the number of rows.
reporter = CLIReporter(max_progress_rows=10)
# Add a custom metric column, in addition to the default metrics.
# Note that this must be a metric that is returned in your training results.
reporter.add_metric_column(&quot;val_mix_accuracy&quot;)
reporter.add_metric_column(&quot;val_accuracy&quot;)
reporter.add_metric_column(&quot;train_accuracy&quot;)

#config = {&quot;number_conv&quot; : 3,&quot;number_dense&quot; : 5}
#training_function(config)

#get_data_loaders()

analysis = tune.run(
    training_function,
    config={
        &quot;number_conv&quot;: tune.grid_search(np.arange(2,7,3).tolist()),
        &quot;number_dense&quot;: tune.grid_search(np.arange(0,3,2).tolist()),
        &quot;train_with_mixed_data&quot;: True
    },
    local_dir='ray_results',
    progress_reporter=reporter)
    
  #resources_per_trial={'gpu': 1})

print(&quot;Best config: &quot;, analysis.get_best_config(
    metric=&quot;val_accuracy&quot;, mode=&quot;max&quot;))

#Get a dataframe for analyzing trial results.
df = analysis.results_df
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">df
</code></pre>
</div>
<div class="cell markdown">
<p><strong>Conclusions</strong></p>
<p>We found that training a CNN using the Ray package was harder than we thought from the beginning. This is probably due to the GPU usage and that we had problems assigning the Keras model to the correct GPU. In other words, Ray requested GPU usage but the code only ever ran on CPU, which took an unfeasible amount of time.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../contents/student-project-20_group-Generalization/03_CNN_MNIST.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../contents/student-project-20_group-Generalization/05_Horovod_test.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../contents/student-project-20_group-Generalization/03_CNN_MNIST.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../contents/student-project-20_group-Generalization/05_Horovod_test.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
