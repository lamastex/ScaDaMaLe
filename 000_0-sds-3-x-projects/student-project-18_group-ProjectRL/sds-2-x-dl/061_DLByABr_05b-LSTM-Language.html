
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SDS-2.x, Scalable Data Engineering Science &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/001_whySpark.html">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html">
   databricks community edition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#essentials-of-databricks-cloud-dbc-in-a-big-hurry">
   Essentials of Databricks Cloud (DBC) in a Big Hurry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-what-is-databricks-cloud">
   DBC Essentials: What is Databricks Cloud?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-shard-cluster-notebook-and-dashboard">
   DBC Essentials: Shard, Cluster, Notebook and Dashboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#dbc-essentials-team-state-collaboration-elastic-resources">
   DBC Essentials: Team, State, Collaboration, Elastic Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html">
   Introduction to Scala through Scala Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-in-your-own-computer">
   Scala in your own computer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-resources">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Letâ€™s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html">
   Scala Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Letâ€™s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/005_RDDsTransformationsActionsHOMEWORK.html">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/006_WordCount.html">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007a_SparkSQLProgGuide_HW.html">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007e_SparkSQLProgGuide_HW.html">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distribute Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
   Distributed deep learning training using TensorFlow and Keras with HorovodRunner
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
   Distributed deep learning training using PyTorch with HorovodRunner for MNIST
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/01_load_data.html">
   Preprocessing and loading the relevant data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/02_logisticregression.html">
   The two cultures - Classifying threads with logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/03_word2vec.html">
   Classification using Word2Vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-01_group-TheTwoCultures/04_LDA.html">
   Topic Modeling with LDA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-02_group-LiUUmeaSceneGraphMotifs/01_Loading_GQA-JSON.html">
   Reading GQA JSON files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-02_group-LiUUmeaSceneGraphMotifs/02_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-02_group-LiUUmeaSceneGraphMotifs/02_SceneGraphMotifs.html#general-discussion">
   General discussion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed singular value decomposition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
   Music Recommender System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#folders-and-files">
   Folders and Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#downloading">
   Downloading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#extracting-and-filtering">
   Extracting and Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#prepare-for-lda">
   Prepare for LDA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#lda">
   LDA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html#looking-at-the-model">
   Looking at the model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#introduction">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#background">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#the-uclusted-algorithm">
   The UClusted algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#motivation">
   Motivation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/00_Introduction.html#our-contribution">
   Our contribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
   Important!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/01_data_and_preprocessing.html#important-continued-from-above">
   Important (continued from above)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-06_group-ParticleClustering/04_evaluate.html">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/02_Data_Processing.html">
   Data Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/03_graph_string_converter.html">
   Intro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
   Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/00_Introduction.html">
   Lit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/00_Introduction.html#docs">
   Docs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/model_2.html">
   MLP with auto-inferred
   <code class="docutils literal notranslate">
    <span class="pre">
     shapes
    </span>
   </code>
   param
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html">
   ScaDaMaLe project: Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#imports">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#data">
   Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#distributed-ensemble-of-neural-networks">
   Distributed ensemble of neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-08_group-DistributedEnsemble/project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome ðŸ§¬
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/02_Data_Processing.html">
   Extract (overlapping [since yet do not know which parts corresponds to coding regions]) 3-mers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/03_LDA.html">
   Load processed data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/03_LDA.html#format-data-for-apache-spark-mllib-clustering-lda-adapted-from-the-lda-course-tutorial-034lda20newsgroupssmall">
   Format data for apache.spark.mllib.clustering.LDA (adapted from the LDA course tutorial â€˜034
   <em>
    LDA
   </em>
   20NewsGroupsSmallâ€™)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/03_LDA.html#visualise-results">
   Visualise Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html">
   Load processed data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html#format-data">
   Format data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html#classification">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/04_Classification_CountVector.html#evaluation">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html">
   Load processed data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html#explore-data">
   Explore data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html#classification">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/05_Classification.html#evaluation">
   Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-09_group-TopicModeling/06_Results.html">
   Results and Conclusion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
   Clustering emoticons based on tweets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
   Dynamic Tweet Maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/04_conclusion.html">
   Conclusion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
   Notebook for collecting tweets with country codes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
   Note, this notebook has been edited slightly from the one supplied by Raaz.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#scadamale-scalable-data-science-and-distributed-machine-learning">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
   Extended spark.streaming.twitter.TwitterUtils
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
   Note, this notebook has been edited slightly from the one supplied by Raaz.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html#scadamale-scalable-data-science-and-distributed-machine-learning">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
   Download Files Periodically
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/01_StreamToFile.html">
   Stream to parquet file
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
   Loading data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/02_DataPreprocess.html">
   Loading data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
   This notebook is for explosive analysis of features in data.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
   Statistics of invariant features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
   Correlation between invariant features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
   Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html">
   Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
   Visualize total cases, total deaths, new cases and new deaths during pandemic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
   Total Deaths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
   New Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
   New Deaths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/05_Clustering.html">
   Clustering of country features in the Covid 19 dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
   Prediction with Linear Regression (LR) Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
   Prediction with Time Series model - ARIMA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
   Prediction with time series model - Gaussian Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-14_group-NullHypothesisEvaluationCriteria/distributed_combinatorial_bandit.html">
   Distributional combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
   Reinforcement Learning for Intraday Trading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
   Reinforcement Learning for Intraday Trading - Distributed model tuning with Elephas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
   Elephas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
   Notes to the elephas training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#id1">
   Notes to the elephas training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#environment">
   Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#rl-algorithms">
   RL-Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#scalable-dl">
   Scalable DL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#spark-scalability-monitoring">
   Spark scalability monitoring
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-15_group-FinancialDataStreams/03_resources.html#raaz-to-group">
   Raaz to groupâ€¦
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-16_group-IntrusionDetection/00_Introduction.html">
   Problem Definition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-16_group-IntrusionDetection/00_Introduction.html#loading-and-preprocessing-data">
   Loading and Preprocessing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Intro.html#problem-description">
   Problem description
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Link to our video explaining the 1) theory, 2) preprocessing the dataset, 3) algorithm and 4) results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html#https-drive-google-com-drive-folders-1zewj6jsjeuu9f8q5xy-avwxq3yj9oi7z-usp-sharing">
   https://drive.google.com/drive/folders/1zEWj6JsJEUu9f8Q5Xy_avwxQ3yJ9oI7Z?usp=sharing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html#problem-formulation">
   Problem formulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-19_group-Featuring/01_FundamentalMatrix.html#results">
   Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/01_Background.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/01_Background.html#project-description">
   Project description
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html">
   The data set
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#mixup-data-generator">
   MixUp data generator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#training-function">
   Training function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#connection-between-mixup-performance-and-generalization">
   Connection between MixUp performance and generalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#directly-training-on-mixup-data">
   Directly training on MixUp data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-20_group-Generalization/02_CNNs.html#conclusions">
   Conclusions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
   Preprocess the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
   Generate random graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
   Compute RSVD
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
   Analyse the eigenvalue spectrum
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Voluntary Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html">
   Plugging into GDELT Streams - TODO - IN PROGRESS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../000_1-sds-3-x/030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/000_0-sds-3-x-projects/student-project-18_group-ProjectRL/sds-2-x-dl/061_DLByABr_05b-LSTM-Language.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_0-sds-3-x-projects/student-project-18_group-ProjectRL/sds-2-x-dl/061_DLByABr_05b-LSTM-Language.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sds-2-x-scalable-data-engineering-science">
<h1><a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/2/x/">SDS-2.x, Scalable Data Engineering Science</a><a class="headerlink" href="#sds-2-x-scalable-data-engineering-science" title="Permalink to this headline">Â¶</a></h1>
<p>This is a 2019 augmentation and update of <a class="reference external" href="https://www.linkedin.com/in/adbreind">Adam
Breindel</a>â€™s initial notebooks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;Example script to generate text from Nietzsche&#39;s writings.</span>

<span class="sd">At least 20 epochs are required before the generated text</span>
<span class="sd">starts sounding coherent.</span>

<span class="sd">It is recommended to run this script on GPU, as recurrent</span>
<span class="sd">networks are quite computationally intensive.</span>

<span class="sd">If you try this script on new data, make sure your corpus</span>
<span class="sd">has at least ~100k characters. ~1M is better.</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">RMSprop</span>
<span class="kn">from</span> <span class="nn">keras.utils.data_utils</span> <span class="kn">import</span> <span class="n">get_file</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">get_file</span><span class="p">(</span><span class="s1">&#39;nietzsche.txt&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;https://s3.amazonaws.com/text-datasets/nietzsche.txt&#39;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;corpus length:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

<span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total chars:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
<span class="n">char_indices</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
<span class="n">indices_char</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>

<span class="c1"># cut the text in semi-redundant sequences of maxlen characters</span>
<span class="n">maxlen</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">step</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">next_chars</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">maxlen</span><span class="p">])</span>
    <span class="n">next_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">maxlen</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;nb sequences:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Vectorization...&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">char</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">next_chars</span><span class="p">[</span><span class="n">i</span><span class="p">]]]</span> <span class="o">=</span> <span class="mi">1</span>


<span class="c1"># build the model: a single LSTM</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Build model...&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="c1"># helper function to sample an index from a probability array</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span>
    <span class="n">exp_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">exp_preds</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_preds</span><span class="p">)</span>
    <span class="n">probas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probas</span><span class="p">)</span>

<span class="c1"># train the model, output generated text after each iteration</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
              <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">start_index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">diversity</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----- diversity:&#39;</span><span class="p">,</span> <span class="n">diversity</span><span class="p">)</span>

        <span class="n">generated</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">maxlen</span><span class="p">]</span>
        <span class="n">generated</span> <span class="o">+=</span> <span class="n">sentence</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----- Generating with seed: &quot;&#39;</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">400</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
            <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
                <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">char</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">next_index</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">diversity</span><span class="p">)</span>
            <span class="n">next_char</span> <span class="o">=</span> <span class="n">indices_char</span><span class="p">[</span><span class="n">next_index</span><span class="p">]</span>

            <span class="n">generated</span> <span class="o">+=</span> <span class="n">next_char</span>
            <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">next_char</span>

            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">next_char</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Using TensorFlow backend.
Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt

 16384/600901 [..............................] - ETA: 0s
 24576/600901 [&gt;.............................] - ETA: 1s
 57344/600901 [=&gt;............................] - ETA: 1s
139264/600901 [=====&gt;........................] - ETA: 0s
303104/600901 [==============&gt;...............] - ETA: 0s
606208/600901 [==============================] - 0s 0us/step

614400/600901 [==============================] - 0s 0us/step
corpus length: 600901
total chars: 59
nb sequences: 200287
Vectorization...
Build model...
WARNING:tensorflow:From /databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.

--------------------------------------------------
Iteration 1
WARNING:tensorflow:From /databricks/python/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/1

   128/200287 [..............................] - ETA: 16:02 - loss: 4.0839
   256/200287 [..............................] - ETA: 9:16 - loss: 3.8942 
   384/200287 [..............................] - ETA: 6:59 - loss: 3.9822
   512/200287 [..............................] - ETA: 5:49 - loss: 3.8959
   640/200287 [..............................] - ETA: 5:08 - loss: 3.8016
   768/200287 [..............................] - ETA: 4:41 - loss: 3.6985
   896/200287 [..............................] - ETA: 4:20 - loss: 3.6066
  1024/200287 [..............................] - ETA: 4:05 - loss: 3.5509
  1152/200287 [..............................] - ETA: 3:53 - loss: 3.4982
  1280/200287 [..............................] - ETA: 3:44 - loss: 3.4572
  1408/200287 [..............................] - ETA: 3:36 - loss: 3.4184
  1536/200287 [..............................] - ETA: 3:30 - loss: 3.3912
  1664/200287 [..............................] - ETA: 3:24 - loss: 3.3591
  1792/200287 [..............................] - ETA: 3:19 - loss: 3.3321
  1920/200287 [..............................] - ETA: 3:15 - loss: 3.3156
  2048/200287 [..............................] - ETA: 3:12 - loss: 3.2956
  2176/200287 [..............................] - ETA: 3:09 - loss: 3.2771
  2304/200287 [..............................] - ETA: 3:06 - loss: 3.2685
  2432/200287 [..............................] - ETA: 3:04 - loss: 3.2512
  2560/200287 [..............................] - ETA: 3:01 - loss: 3.2443
  2688/200287 [..............................] - ETA: 2:59 - loss: 3.2235
  2816/200287 [..............................] - ETA: 2:57 - loss: 3.2178
  2944/200287 [..............................] - ETA: 2:56 - loss: 3.2054
  3072/200287 [..............................] - ETA: 2:54 - loss: 3.1919
  3200/200287 [..............................] - ETA: 2:53 - loss: 3.1835
  3328/200287 [..............................] - ETA: 2:51 - loss: 3.1701
  3456/200287 [..............................] - ETA: 2:50 - loss: 3.1651
  3584/200287 [..............................] - ETA: 2:49 - loss: 3.1694
  3712/200287 [..............................] - ETA: 2:48 - loss: 3.1606
  3840/200287 [..............................] - ETA: 2:47 - loss: 3.1624
  3968/200287 [..............................] - ETA: 2:46 - loss: 3.1551
  4096/200287 [..............................] - ETA: 2:45 - loss: 3.1463
  4224/200287 [..............................] - ETA: 2:44 - loss: 3.1350
  4352/200287 [..............................] - ETA: 2:43 - loss: 3.1332
  4480/200287 [..............................] - ETA: 2:43 - loss: 3.1294
  4608/200287 [..............................] - ETA: 2:42 - loss: 3.1231
  4736/200287 [..............................] - ETA: 2:41 - loss: 3.1206
  4864/200287 [..............................] - ETA: 2:40 - loss: 3.1167
  4992/200287 [..............................] - ETA: 2:40 - loss: 3.1124
  5120/200287 [..............................] - ETA: 2:39 - loss: 3.1045
  5248/200287 [..............................] - ETA: 2:38 - loss: 3.1017
  5376/200287 [..............................] - ETA: 2:38 - loss: 3.0951
  5504/200287 [..............................] - ETA: 2:37 - loss: 3.0877
  5632/200287 [..............................] - ETA: 2:37 - loss: 3.0805
  5760/200287 [..............................] - ETA: 2:36 - loss: 3.0795
  5888/200287 [..............................] - ETA: 2:35 - loss: 3.0719
  6016/200287 [..............................] - ETA: 2:35 - loss: 3.0690
  6144/200287 [..............................] - ETA: 2:34 - loss: 3.0648
  6272/200287 [..............................] - ETA: 2:34 - loss: 3.0596
  6400/200287 [..............................] - ETA: 2:34 - loss: 3.0539
  6528/200287 [..............................] - ETA: 2:33 - loss: 3.0468
  6656/200287 [..............................] - ETA: 2:33 - loss: 3.0399
  6784/200287 [&gt;.............................] - ETA: 2:33 - loss: 3.0347
  6912/200287 [&gt;.............................] - ETA: 2:32 - loss: 3.0260
  7040/200287 [&gt;.............................] - ETA: 2:32 - loss: 3.0204
  7168/200287 [&gt;.............................] - ETA: 2:32 - loss: 3.0162
  7296/200287 [&gt;.............................] - ETA: 2:31 - loss: 3.0065
  7424/200287 [&gt;.............................] - ETA: 2:31 - loss: 2.9983
  7552/200287 [&gt;.............................] - ETA: 2:31 - loss: 2.9908
  7680/200287 [&gt;.............................] - ETA: 2:30 - loss: 2.9868
  7808/200287 [&gt;.............................] - ETA: 2:30 - loss: 2.9825
  7936/200287 [&gt;.............................] - ETA: 2:30 - loss: 2.9790
  8064/200287 [&gt;.............................] - ETA: 2:29 - loss: 2.9735
  8192/200287 [&gt;.............................] - ETA: 2:29 - loss: 2.9676
  8320/200287 [&gt;.............................] - ETA: 2:29 - loss: 2.9644
  8448/200287 [&gt;.............................] - ETA: 2:28 - loss: 2.9606
  8576/200287 [&gt;.............................] - ETA: 2:28 - loss: 2.9558
  8704/200287 [&gt;.............................] - ETA: 2:28 - loss: 2.9543
  8832/200287 [&gt;.............................] - ETA: 2:28 - loss: 2.9486
  8960/200287 [&gt;.............................] - ETA: 2:27 - loss: 2.9429
  9088/200287 [&gt;.............................] - ETA: 2:27 - loss: 2.9384
  9216/200287 [&gt;.............................] - ETA: 2:27 - loss: 2.9334
  9344/200287 [&gt;.............................] - ETA: 2:27 - loss: 2.9272
  9472/200287 [&gt;.............................] - ETA: 2:26 - loss: 2.9243
  9600/200287 [&gt;.............................] - ETA: 2:26 - loss: 2.9207
  9728/200287 [&gt;.............................] - ETA: 2:26 - loss: 2.9161
  9856/200287 [&gt;.............................] - ETA: 2:26 - loss: 2.9117
  9984/200287 [&gt;.............................] - ETA: 2:25 - loss: 2.9099
 10112/200287 [&gt;.............................] - ETA: 2:25 - loss: 2.9037
 10240/200287 [&gt;.............................] - ETA: 2:25 - loss: 2.9005
 10368/200287 [&gt;.............................] - ETA: 2:25 - loss: 2.8964
 10496/200287 [&gt;.............................] - ETA: 2:24 - loss: 2.8934
 10624/200287 [&gt;.............................] - ETA: 2:24 - loss: 2.8901
 10752/200287 [&gt;.............................] - ETA: 2:24 - loss: 2.8876
 10880/200287 [&gt;.............................] - ETA: 2:24 - loss: 2.8810
 11008/200287 [&gt;.............................] - ETA: 2:24 - loss: 2.8751
 11136/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8703
 11264/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8664
 11392/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8611
 11520/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8578
 11648/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8537
 11776/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8474
 11904/200287 [&gt;.............................] - ETA: 2:23 - loss: 2.8470
 12032/200287 [&gt;.............................] - ETA: 2:22 - loss: 2.8435
 12160/200287 [&gt;.............................] - ETA: 2:22 - loss: 2.8400
 12288/200287 [&gt;.............................] - ETA: 2:22 - loss: 2.8385
 12416/200287 [&gt;.............................] - ETA: 2:22 - loss: 2.8354
 12544/200287 [&gt;.............................] - ETA: 2:22 - loss: 2.8327
 12672/200287 [&gt;.............................] - ETA: 2:22 - loss: 2.8309
 12800/200287 [&gt;.............................] - ETA: 2:21 - loss: 2.8279
 12928/200287 [&gt;.............................] - ETA: 2:21 - loss: 2.8250
 13056/200287 [&gt;.............................] - ETA: 2:21 - loss: 2.8211
 13184/200287 [&gt;.............................] - ETA: 2:21 - loss: 2.8202
 13312/200287 [&gt;.............................] - ETA: 2:21 - loss: 2.8199
 13440/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8197
 13568/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8174
 13696/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8153
 13824/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8107
 13952/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8079
 14080/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8054
 14208/200287 [=&gt;............................] - ETA: 2:20 - loss: 2.8020
 14336/200287 [=&gt;............................] - ETA: 2:19 - loss: 2.7991
 14464/200287 [=&gt;............................] - ETA: 2:19 - loss: 2.7960
 14592/200287 [=&gt;............................] - ETA: 2:19 - loss: 2.7918
 14720/200287 [=&gt;............................] - ETA: 2:19 - loss: 2.7887
 14848/200287 [=&gt;............................] - ETA: 2:19 - loss: 2.7872
 14976/200287 [=&gt;............................] - ETA: 2:19 - loss: 2.7852
 15104/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7820
 15232/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7792
 15360/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7762
 15488/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7728
 15616/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7695
 15744/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7679
 15872/200287 [=&gt;............................] - ETA: 2:18 - loss: 2.7653
 16000/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7642
 16128/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7608
 16256/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7569
 16384/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7540
 16512/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7515
 16640/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7500
 16768/200287 [=&gt;............................] - ETA: 2:17 - loss: 2.7477
 16896/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7449
 17024/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7428
 17152/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7393
 17280/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7369
 17408/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7360
 17536/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7346
 17664/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7320
 17792/200287 [=&gt;............................] - ETA: 2:16 - loss: 2.7295
 17920/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7261
 18048/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7241
 18176/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7216
 18304/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7206
 18432/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7187
 18560/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7165
 18688/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7145
 18816/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7118
 18944/200287 [=&gt;............................] - ETA: 2:15 - loss: 2.7098
 19072/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.7073
 19200/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.7057
 19328/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.7041
 19456/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.7019
 19584/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.7006
 19712/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.6993
 19840/200287 [=&gt;............................] - ETA: 2:14 - loss: 2.6976
 19968/200287 [=&gt;............................] - ETA: 2:13 - loss: 2.6962
 20096/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6933
 20224/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6915
 20352/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6904
 20480/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6881
 20608/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6859
 20736/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6832
 20864/200287 [==&gt;...........................] - ETA: 2:13 - loss: 2.6809
 20992/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6797
 21120/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6787
 21248/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6756
 21376/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6730
 21504/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6722
 21632/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6700
 21760/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6675
 21888/200287 [==&gt;...........................] - ETA: 2:12 - loss: 2.6656
 22016/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6637
 22144/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6611
 22272/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6586
 22400/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6573
 22528/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6552
 22656/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6544
 22784/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6526
 22912/200287 [==&gt;...........................] - ETA: 2:11 - loss: 2.6509
 23040/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6499
 23168/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6476
 23296/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6460
 23424/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6440
 23552/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6423
 23680/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6393
 23808/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6369
 23936/200287 [==&gt;...........................] - ETA: 2:10 - loss: 2.6363
 24064/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6341
 24192/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6324
 24320/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6306
 24448/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6284
 24576/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6260
 24704/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6237
 24832/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6221
 24960/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6197
 25088/200287 [==&gt;...........................] - ETA: 2:09 - loss: 2.6179
 25216/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6154
 25344/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6150
 25472/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6136
 25600/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6119
 25728/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6103
 25856/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6094
 25984/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6074
 26112/200287 [==&gt;...........................] - ETA: 2:08 - loss: 2.6054
 26240/200287 [==&gt;...........................] - ETA: 2:07 - loss: 2.6039
 26368/200287 [==&gt;...........................] - ETA: 2:07 - loss: 2.6030
 26496/200287 [==&gt;...........................] - ETA: 2:07 - loss: 2.6014
 26624/200287 [==&gt;...........................] - ETA: 2:07 - loss: 2.5993
 26752/200287 [===&gt;..........................] - ETA: 2:07 - loss: 2.5974
 26880/200287 [===&gt;..........................] - ETA: 2:07 - loss: 2.5959
 27008/200287 [===&gt;..........................] - ETA: 2:07 - loss: 2.5947
 27136/200287 [===&gt;..........................] - ETA: 2:07 - loss: 2.5921
 27264/200287 [===&gt;..........................] - ETA: 2:07 - loss: 2.5904
 27392/200287 [===&gt;..........................] - ETA: 2:07 - loss: 2.5893
 27520/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5878
 27648/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5864
 27776/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5849
 27904/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5833
 28032/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5819
 28160/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5812
 28288/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5791
 28416/200287 [===&gt;..........................] - ETA: 2:06 - loss: 2.5782
 28544/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5767
 28672/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5761
 28800/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5745
 28928/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5739
 29056/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5727
 29184/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5708
 29312/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5690
 29440/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5677
 29568/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5664
 29696/200287 [===&gt;..........................] - ETA: 2:05 - loss: 2.5649
 29824/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5632
 29952/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5610
 30080/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5586
 30208/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5570
 30336/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5560
 30464/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5548
 30592/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5536
 30720/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5530
 30848/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5520
 30976/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5514
 31104/200287 [===&gt;..........................] - ETA: 2:04 - loss: 2.5500
 31232/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5481
 31360/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5464
 31488/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5459
 31616/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5444
 31744/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5429
 31872/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5422
 32000/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5411
 32128/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5398
 32256/200287 [===&gt;..........................] - ETA: 2:03 - loss: 2.5389
 32384/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5378
 32512/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5369
 32640/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5359
 32768/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5348
 32896/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5330
 33024/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5329
 33152/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5310
 33280/200287 [===&gt;..........................] - ETA: 2:02 - loss: 2.5300
 33408/200287 [====&gt;.........................] - ETA: 2:02 - loss: 2.5287
 33536/200287 [====&gt;.........................] - ETA: 2:02 - loss: 2.5276
 33664/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5262
 33792/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5252
 33920/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5244
 34048/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5224
 34176/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5210
 34304/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5202
 34432/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5188
 34560/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5177
 34688/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5168
 34816/200287 [====&gt;.........................] - ETA: 2:01 - loss: 2.5157
 34944/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5145
 35072/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5129
 35200/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5127
 35328/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5121
 35456/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5100
 35584/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5094
 35712/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5083
 35840/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5071
 35968/200287 [====&gt;.........................] - ETA: 2:00 - loss: 2.5057
 36096/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.5047
 36224/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.5037
 36352/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.5024
 36480/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.5013
 36608/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.5003
 36736/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.4993
 36864/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.4978
 36992/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.4973
 37120/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.4961
 37248/200287 [====&gt;.........................] - ETA: 1:59 - loss: 2.4950
 37376/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4938
 37504/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4924
 37632/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4913
 37760/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4901
 37888/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4892
 38016/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4883
 38144/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4876
 38272/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4865
 38400/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4854
 38528/200287 [====&gt;.........................] - ETA: 1:58 - loss: 2.4849
 38656/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4842
 38784/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4837
 38912/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4828
 39040/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4816
 39168/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4808
 39296/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4802
 39424/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4790
 39552/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4777
 39680/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4756
 39808/200287 [====&gt;.........................] - ETA: 1:57 - loss: 2.4746
 39936/200287 [====&gt;.........................] - ETA: 1:56 - loss: 2.4740
 40064/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4724
 40192/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4719
 40320/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4706
 40448/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4697
 40576/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4689
 40704/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4686
 40832/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4675
 40960/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4664
 41088/200287 [=====&gt;........................] - ETA: 1:56 - loss: 2.4655

*** WARNING: skipped 6400810 bytes of output ***

160128/200287 [======================&gt;.......] - ETA: 28s - loss: 1.2923
160256/200287 [=======================&gt;......] - ETA: 28s - loss: 1.2924
160384/200287 [=======================&gt;......] - ETA: 28s - loss: 1.2924
160512/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2927
160640/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2927
160768/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2925
160896/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2926
161024/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2926
161152/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2926
161280/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2926
161408/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2924
161536/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2925
161664/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2924
161792/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2924
161920/200287 [=======================&gt;......] - ETA: 27s - loss: 1.2924
162048/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2925
162176/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2925
162304/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2924
162432/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2924
162560/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2923
162688/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2924
162816/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2922
162944/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2921
163072/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2922
163200/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2921
163328/200287 [=======================&gt;......] - ETA: 26s - loss: 1.2919
163456/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2921
163584/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2920
163712/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2920
163840/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2921
163968/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2922
164096/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2922
164224/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2922
164352/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2923
164480/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2925
164608/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2927
164736/200287 [=======================&gt;......] - ETA: 25s - loss: 1.2929
164864/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2928
164992/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2927
165120/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2927
165248/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2927
165376/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2927
165504/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2928
165632/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2928
165760/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2927
165888/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2927
166016/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2928
166144/200287 [=======================&gt;......] - ETA: 24s - loss: 1.2929
166272/200287 [=======================&gt;......] - ETA: 23s - loss: 1.2930
166400/200287 [=======================&gt;......] - ETA: 23s - loss: 1.2931
166528/200287 [=======================&gt;......] - ETA: 23s - loss: 1.2932
166656/200287 [=======================&gt;......] - ETA: 23s - loss: 1.2932
166784/200287 [=======================&gt;......] - ETA: 23s - loss: 1.2934
166912/200287 [========================&gt;.....] - ETA: 23s - loss: 1.2932
167040/200287 [========================&gt;.....] - ETA: 23s - loss: 1.2932
167168/200287 [========================&gt;.....] - ETA: 23s - loss: 1.2932
167296/200287 [========================&gt;.....] - ETA: 23s - loss: 1.2932
167424/200287 [========================&gt;.....] - ETA: 23s - loss: 1.2932
167552/200287 [========================&gt;.....] - ETA: 23s - loss: 1.2933
167680/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2932
167808/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2933
167936/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2934
168064/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2934
168192/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2935
168320/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2934
168448/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2933
168576/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2935
168704/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2936
168832/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2937
168960/200287 [========================&gt;.....] - ETA: 22s - loss: 1.2939
169088/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2938
169216/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2937
169344/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2938
169472/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2938
169600/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2937
169728/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2936
169856/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2938
169984/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2938
170112/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2938
170240/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2937
170368/200287 [========================&gt;.....] - ETA: 21s - loss: 1.2937
170496/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2936
170624/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2938
170752/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2937
170880/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2937
171008/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2936
171136/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2937
171264/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2936
171392/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2936
171520/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2935
171648/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2934
171776/200287 [========================&gt;.....] - ETA: 20s - loss: 1.2934
171904/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2934
172032/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2934
172160/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2933
172288/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2931
172416/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2930
172544/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2930
172672/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2929
172800/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2930
172928/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2930
173056/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2931
173184/200287 [========================&gt;.....] - ETA: 19s - loss: 1.2930
173312/200287 [========================&gt;.....] - ETA: 18s - loss: 1.2930
173440/200287 [========================&gt;.....] - ETA: 18s - loss: 1.2929
173568/200287 [========================&gt;.....] - ETA: 18s - loss: 1.2929
173696/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2929
173824/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2928
173952/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2928
174080/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2928
174208/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2928
174336/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2930
174464/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2929
174592/200287 [=========================&gt;....] - ETA: 18s - loss: 1.2931
174720/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2932
174848/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2933
174976/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2932
175104/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2932
175232/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2932
175360/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2931
175488/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2931
175616/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2930
175744/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2930
175872/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2931
176000/200287 [=========================&gt;....] - ETA: 17s - loss: 1.2933
176128/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2935
176256/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2935
176384/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2935
176512/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2934
176640/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2937
176768/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2937
176896/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2936
177024/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2936
177152/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2936
177280/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2936
177408/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2936
177536/200287 [=========================&gt;....] - ETA: 16s - loss: 1.2934
177664/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2934
177792/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2935
177920/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2935
178048/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2936
178176/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2935
178304/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2936
178432/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2936
178560/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2935
178688/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2933
178816/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2932
178944/200287 [=========================&gt;....] - ETA: 15s - loss: 1.2931
179072/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2930
179200/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2930
179328/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2931
179456/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2932
179584/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2932
179712/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2932
179840/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2932
179968/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2933
180096/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2934
180224/200287 [=========================&gt;....] - ETA: 14s - loss: 1.2934
180352/200287 [==========================&gt;...] - ETA: 14s - loss: 1.2934
180480/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
180608/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
180736/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
180864/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
180992/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
181120/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2932
181248/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
181376/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
181504/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2932
181632/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2932
181760/200287 [==========================&gt;...] - ETA: 13s - loss: 1.2933
181888/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2933
182016/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2933
182144/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2933
182272/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2934
182400/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2933
182528/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2934
182656/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2934
182784/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2933
182912/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2933
183040/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2934
183168/200287 [==========================&gt;...] - ETA: 12s - loss: 1.2934
183296/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2934
183424/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2936
183552/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2935
183680/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2938
183808/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2937
183936/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2937
184064/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2935
184192/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2937
184320/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2935
184448/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2937
184576/200287 [==========================&gt;...] - ETA: 11s - loss: 1.2936
184704/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2938
184832/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2937
184960/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2938
185088/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2939
185216/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2939
185344/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2938
185472/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2938
185600/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2940
185728/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2940
185856/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2940
185984/200287 [==========================&gt;...] - ETA: 10s - loss: 1.2939
186112/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2939 
186240/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2940
186368/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2940
186496/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2940
186624/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2941
186752/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2940
186880/200287 [==========================&gt;...] - ETA: 9s - loss: 1.2940
187008/200287 [===========================&gt;..] - ETA: 9s - loss: 1.2938
187136/200287 [===========================&gt;..] - ETA: 9s - loss: 1.2937
187264/200287 [===========================&gt;..] - ETA: 9s - loss: 1.2937
187392/200287 [===========================&gt;..] - ETA: 9s - loss: 1.2936
187520/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2936
187648/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2936
187776/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2939
187904/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2939
188032/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2938
188160/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2937
188288/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2937
188416/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2938
188544/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2938
188672/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2937
188800/200287 [===========================&gt;..] - ETA: 8s - loss: 1.2937
188928/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2935
189056/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2935
189184/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2936
189312/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2935
189440/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2935
189568/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2934
189696/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2934
189824/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2934
189952/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2935
190080/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2936
190208/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2937
190336/200287 [===========================&gt;..] - ETA: 7s - loss: 1.2936
190464/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2934
190592/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2936
190720/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2936
190848/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2936
190976/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2935
191104/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2936
191232/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2937
191360/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2937
191488/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2937
191616/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2938
191744/200287 [===========================&gt;..] - ETA: 6s - loss: 1.2938
191872/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2939
192000/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2938
192128/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2939
192256/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2939
192384/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2942
192512/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2942
192640/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2942
192768/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2941
192896/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2940
193024/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2941
193152/200287 [===========================&gt;..] - ETA: 5s - loss: 1.2940
193280/200287 [===========================&gt;..] - ETA: 4s - loss: 1.2942
193408/200287 [===========================&gt;..] - ETA: 4s - loss: 1.2942
193536/200287 [===========================&gt;..] - ETA: 4s - loss: 1.2942
193664/200287 [============================&gt;.] - ETA: 4s - loss: 1.2943
193792/200287 [============================&gt;.] - ETA: 4s - loss: 1.2944
193920/200287 [============================&gt;.] - ETA: 4s - loss: 1.2944
194048/200287 [============================&gt;.] - ETA: 4s - loss: 1.2944
194176/200287 [============================&gt;.] - ETA: 4s - loss: 1.2944
194304/200287 [============================&gt;.] - ETA: 4s - loss: 1.2945
194432/200287 [============================&gt;.] - ETA: 4s - loss: 1.2945
194560/200287 [============================&gt;.] - ETA: 4s - loss: 1.2945
194688/200287 [============================&gt;.] - ETA: 3s - loss: 1.2945
194816/200287 [============================&gt;.] - ETA: 3s - loss: 1.2946
194944/200287 [============================&gt;.] - ETA: 3s - loss: 1.2945
195072/200287 [============================&gt;.] - ETA: 3s - loss: 1.2945
195200/200287 [============================&gt;.] - ETA: 3s - loss: 1.2946
195328/200287 [============================&gt;.] - ETA: 3s - loss: 1.2945
195456/200287 [============================&gt;.] - ETA: 3s - loss: 1.2946
195584/200287 [============================&gt;.] - ETA: 3s - loss: 1.2947
195712/200287 [============================&gt;.] - ETA: 3s - loss: 1.2946
195840/200287 [============================&gt;.] - ETA: 3s - loss: 1.2945
195968/200287 [============================&gt;.] - ETA: 3s - loss: 1.2945
196096/200287 [============================&gt;.] - ETA: 2s - loss: 1.2944
196224/200287 [============================&gt;.] - ETA: 2s - loss: 1.2945
196352/200287 [============================&gt;.] - ETA: 2s - loss: 1.2944
196480/200287 [============================&gt;.] - ETA: 2s - loss: 1.2945
196608/200287 [============================&gt;.] - ETA: 2s - loss: 1.2946
196736/200287 [============================&gt;.] - ETA: 2s - loss: 1.2946
196864/200287 [============================&gt;.] - ETA: 2s - loss: 1.2945
196992/200287 [============================&gt;.] - ETA: 2s - loss: 1.2946
197120/200287 [============================&gt;.] - ETA: 2s - loss: 1.2945
197248/200287 [============================&gt;.] - ETA: 2s - loss: 1.2946
197376/200287 [============================&gt;.] - ETA: 2s - loss: 1.2947
197504/200287 [============================&gt;.] - ETA: 1s - loss: 1.2947
197632/200287 [============================&gt;.] - ETA: 1s - loss: 1.2949
197760/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
197888/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
198016/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
198144/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
198272/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
198400/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
198528/200287 [============================&gt;.] - ETA: 1s - loss: 1.2950
198656/200287 [============================&gt;.] - ETA: 1s - loss: 1.2951
198784/200287 [============================&gt;.] - ETA: 1s - loss: 1.2951
198912/200287 [============================&gt;.] - ETA: 0s - loss: 1.2952
199040/200287 [============================&gt;.] - ETA: 0s - loss: 1.2952
199168/200287 [============================&gt;.] - ETA: 0s - loss: 1.2952
199296/200287 [============================&gt;.] - ETA: 0s - loss: 1.2954
199424/200287 [============================&gt;.] - ETA: 0s - loss: 1.2955
199552/200287 [============================&gt;.] - ETA: 0s - loss: 1.2955
199680/200287 [============================&gt;.] - ETA: 0s - loss: 1.2956
199808/200287 [============================&gt;.] - ETA: 0s - loss: 1.2955
199936/200287 [============================&gt;.] - ETA: 0s - loss: 1.2957
200064/200287 [============================&gt;.] - ETA: 0s - loss: 1.2958
200192/200287 [============================&gt;.] - ETA: 0s - loss: 1.2958
200287/200287 [==============================] - 141s 704us/step - loss: 1.2958

----- diversity: 0.2
----- Generating with seed: &quot;e things exist
(although in point of fac&quot;
e things exist
(although in point of fact that the last in the same reamity of the same philosophy and the streen and the science of the most sense and actions and the primitive the soul of the problem of the protection of the spirit of the process of the soul of the same mankind, and the strange of the process to the strange, and with the strength of the soul and the streen and all the same reaming the strength of the contemplation of 

----- diversity: 0.5
----- Generating with seed: &quot;e things exist
(although in point of fac&quot;
e things exist
(although in point of fact against
the fundamental manking and the lapses in a thought to see through the same rumpotive to an endeaves and the propestible, and a soul of the most case of superiors, and a constitution of the same and strength and are necessary and that every schopenhauerd of the books and deceived to the designative, process always body and sympathy of the nature with another be in the strange and into th

----- diversity: 1.0
----- Generating with seed: &quot;e things exist
(although in point of fac&quot;
e things exist
(although in point of faceoric there under tyrannian
to its
ardt
hearts anying one of soul yet it is affinie, we might are
scheepjessed and if to begin has enwalled number certain se subtlest neighbory much is inligios of ;     scloymis of deceion nederate and plency of the feeling of the historily causes: one must suscreds, to
weary on
masture
is circumstance of the race
simply andumanily, fly was anything about to prion

----- diversity: 1.2
----- Generating with seed: &quot;e things exist
(although in point of fac&quot;
e things exist
(although in point of fact all
powers--rule about to dejess set
and ibbreond of the
chiralitical
and tapabfecician.


1w him the time one may have togal tpil
againist
mankind. even of him; at the prirfom presenth by german that the crual blice of bort to able that nowadays  iheat, with otherso indo if theh. perhaps an
power.

o
</pre></div>
</div>
</div></blockquote>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_0-sds-3-x-projects/student-project-18_group-ProjectRL/sds-2-x-dl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>