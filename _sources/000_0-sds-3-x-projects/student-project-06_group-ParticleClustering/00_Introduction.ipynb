{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised clustering of particle physics data with distributed training\n",
    "==========================================================================\n",
    "\n",
    "Authors: Karl Bengtsson Bernander, Colin Desmarais, Daniel Gedon, Olga\n",
    "Sunneborn Gudnadottir  \n",
    "Video walk-through of the notebooks:\n",
    "https://drive.google.com/file/d/1D6DPETd2qVMpSJOLTRiVPjIdz\\_-VbNVn/view?usp=sharing\n",
    "\n",
    "This notebook contains a short introduction to the collider particle\n",
    "physics needed to understand the data and the model, a short introcution\n",
    "to the method and a short motivation for developing the method. If you\n",
    "want to jump directly to the code, skip to the next notebook!\n",
    "\n",
    "Introduction\n",
    "============\n",
    "\n",
    "At the European Organization for Nuclear Research, CERN, the inner\n",
    "workings of particle physics are probed by accelerating particles to\n",
    "close to the speed of light and letting them collide. In the collisions,\n",
    "the energy contained in the colliding particles reforms into new\n",
    "particles, and by studying this process a lot can be learned about their\n",
    "interactions. Several experiments have operated as part of CERN since it\n",
    "was founded in [1955](https://home.cern/about/who-we-are/our-history)\n",
    "and as of 2019, a total of [330\n",
    "petabytes](https://home.cern/science/computing/data-preservation) of\n",
    "particle physics data was stored by the organization. By 2030 the volume\n",
    "of the stored data is expected to be of the order of exabytes.\n",
    "\n",
    "In addition to the disk space needed for such datasets, the experiments\n",
    "also require immense computing resources. These are used for translating\n",
    "the electrical signals of the particle detectors into formats\n",
    "appropriate for data analysis, simulating particle collisions and\n",
    "detectors, and analysing data. Much data processing is paralellized and\n",
    "distributed among machines connected to the [Worldwide LHC Computing\n",
    "Grid](https://home.cern/science/computing/grid).\n",
    "\n",
    "#### Look around inside the CERN computing center\n",
    "\n",
    "  \n",
    "\n",
    "#### See the activity of the Grid\n",
    "\n",
    "[source](https://home.cern/science/computing/grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayHTML(\"\"\"<iframe scrolling=\"no\" src=\"https://videos.cern.ch/video/OPEN-VIDEO-2018-041-001\" width=\"99%\" height=\"300\" frameborder=\"0\" allowfullscreen></iframe>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "#### In these notebooks\n",
    "\n",
    "As the datasets collected at CERN get bigger and the effects searched\n",
    "for in data get smaller, the challenge is to find new and more efficient\n",
    "methods to process data. Not surprisingly, machine learning is garnering\n",
    "more and more attention within the experiments, and a lot of machine\n",
    "learning methods have been developed in recent years to do everything\n",
    "from simulating detectors to data analysis. With datasets sometimes on\n",
    "the order of TBs even after preprocessing, however, distributed learning\n",
    "is a valuable tool. In this and the accompanying notebooks we present\n",
    "the UCluster method developed by Mikuni and Canelli for unsupervised\n",
    "clustering of particle physics data. We have adapted the code for use in\n",
    "notebooks and added the functionality of distributed training. The\n",
    "original code and the paper accompanying it can be found below.\n",
    "\n",
    "&lt;a href=\"https://github.com/ViniciusMikuni/UCluster\"&gt;\\[Original\n",
    "code\\]\\[1\\]&lt;/a&gt; &lt;a\n",
    "href=\"https://arxiv.org/pdf/2010.07106.pdf\"&gt;\\[Paper\\]\\[2\\]&lt;/a&gt;\n",
    "\\[1\\]: https://major.io/wp-content/uploads/2014/08/github-150x150.png\n",
    "\\[2\\]:\n",
    "https://assets2.sorryapp.com/brand\\_logos/files/000/005/662/original/arxiv-lg-bold-512-cropped.png?1575381539\n",
    "\n",
    "Background\n",
    "==========\n",
    "\n",
    "Elementary particles\n",
    "--------------------\n",
    "\n",
    "Everything around us -- that we can see, touch, and interact with -- is\n",
    "made up of tiny particles called atoms, which in turn are made up of\n",
    "even smaller particles: protons, neutrons and electrons. The protons and\n",
    "neutrons are also made up of even smaller particles -- the quarks. As\n",
    "far as we know, the quarks and the electrons are elementary particles,\n",
    "which means that they cannot be divided further into other particles.\n",
    "These three particles, two quarks and the electron, actually make up\n",
    "everything in our ordinary life. That's not the whole picture, though.\n",
    "Both the quarks and the electron exist in three generations, each\n",
    "generation heavier than the last but sharing the same fundamental\n",
    "nature. These are all matter particles, fermions, which includes also\n",
    "the almost massless neutrinos. In addition there are the force carriers,\n",
    "bosons, which is how the matter particles interact, and the Higgs boson\n",
    "which gives mass to the fermions. Theser particles and how they interact\n",
    "is contained in the Standard Model of Particle Physics, schematically\n",
    "depicted below:\n",
    "\n",
    "![The Standard\n",
    "Model](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Standard_Model_of_Elementary_Particles.svg/1280px-Standard_Model_of_Elementary_Particles.svg.png)\n",
    "\n",
    "The Large Hadron Collider and particle detectors\n",
    "------------------------------------------------\n",
    "\n",
    "To create the heavier particles of the Standard model than the ones we\n",
    "are surrounded with daily, we need higher energies. This is because mass\n",
    "and energy are related through Einstein's famous formula $$E=mc^2$$ At\n",
    "CERN, The Large Hadron Collider (LHC) gives kinetic energy to protons by\n",
    "accelerating them through a long chain of more and more powerful\n",
    "accelerators. They are then made to collide with each other, and in that\n",
    "collision new particles form using the total energy that the protons had\n",
    "when they collided. At the collision points of the LHC there are\n",
    "particle detectors designed to detect all of the different products of\n",
    "the collision and their properties. Below is a simulation of the CMS\n",
    "detector, one of the two general purpose detectors at the LHC. Going\n",
    "inside the detector, we follow the two protons (in blue) as they collide\n",
    "and produce new particles. The tracks coming out from the collision are\n",
    "made by charged particles, and the rectangles are the different modules\n",
    "of the detector that register a signal as the particles transverse the\n",
    "detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayHTML(\"\"\"<iframe scrolling=\"no\" src=\"https://videos.cern.ch/video/CERN-VIDEO-2011-192-001\" width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Jets\n",
    "----\n",
    "\n",
    "Using sophisticated algorithms developed over decades the collisions are\n",
    "reconstructed from the electric signals from the detector. They\n",
    "determine which types of particles were present in the products of the\n",
    "collision and their kinetic properties, energy and momentum. Some\n",
    "particles need to be reconstructed in several steps, since they decay to\n",
    "other particles before they even reach the detector. Some particles,\n",
    "such as quarks, form so many new particles so rapidly, that their\n",
    "signature in the detector looks like a jet. They are identified by\n",
    "clustering the particles together into a cone, which is then identified\n",
    "as a jet. In some cases, it can be beneficial to include other particles\n",
    "in the jet too, if they share an origin with the quark.\n",
    "\n",
    "The picture below shows a typical quark jet on the left, and a \"fat\" jet\n",
    "on the right, containing three quark jets, two of which come from the\n",
    "W-boson also contained in the jet and one directly from the top-quark,\n",
    "which is the particle being reconstructed.\n",
    "\n",
    "&lt;a&gt; &lt;img border=\"0\" alt=\"Jet cone with tracks\"\n",
    "src=\"https://www.quantumdiaries.org/wp-content/uploads/2011/06/JetConeAndPFJetCALVIEW3.png\"\n",
    "width=\"300\" height=\"300\"&gt; &lt;/a&gt; &lt;a&gt;!\\[1\\]&lt;/a&gt; \\[1\\]:\n",
    "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTML-vd7DejQvpeHGmpV-CDVOc1yw78luh\\_YQ&usqp=CAU\n",
    "\n",
    "The UClusted algorithm\n",
    "======================\n",
    "\n",
    "Now that we have the particle data background needed, let's try to\n",
    "understand the code and the data we will be working with. Most, if not\n",
    "all, of the algorithms used to reconstruct particles at the large LHC\n",
    "experiments right now are either traditional algorithms without machine\n",
    "learning or supervised machine learning. These methods could have the\n",
    "disadvantage of being biased, however, when it comes to discovering new\n",
    "particles or interactions. A lot of machine learning interested\n",
    "physicists are therefore looking toward unsupervised methods for object\n",
    "(particle) reconstruction and data analysis. One such approach is taken\n",
    "by **V. Mikuni and F. Canellia** in the 2020 paper **Unsupervised\n",
    "clustering for collider physics**, shown below.\n",
    "\n",
    "### UCluster\n",
    "\n",
    "In the paper, Mikuni and Canelli present UCluster, which is an\n",
    "unsupervised clustering algorithm for particle physics data. In the\n",
    "paper, they apply it to one multiclass classification problem and one\n",
    "anomaly detection problem. In these notebooks, we present only the\n",
    "first.\n",
    "\n",
    "### Jet classification\n",
    "\n",
    "Given a jet, in the form of a list of particles contained in the it and\n",
    "their properties, the task is to match it to the particle it came from.\n",
    "We choose three types of particles that can be reconstructed using fat\n",
    "jets: W bosons, Z bosons and top quarks. The dataset can be found\n",
    "[here](https://zenodo.org/record/3602254#.X8f8oRNKjP8). We start by\n",
    "preprocessing it to get it on the format we want and throwing away\n",
    "information we don't need. We keep only the names and properties of the\n",
    "constituent particles. The properties include trajectory angles, energy,\n",
    "momentum and distances to center of jet. They are used as input feature\n",
    "in a deep neural graph net, in which each particle is represented by a\n",
    "node. It is pre-trained, and then a clustering step is added, before the\n",
    "whole thing is trained again. The authors report a 81% classification\n",
    "accuracy using the Hungarian method. The clusters formed can be seen\n",
    "below to the right and should be compared to the ground truth shown on\n",
    "the left.\n",
    "\n",
    "&lt;a&gt;!\\[1\\]!\\[2\\]&lt;/a&gt; \\[1\\]:\n",
    "https://inspirehep.net/files/b6a600d849d1a252d7d6e2510ee29354 \\[2\\]:\n",
    "https://inspirehep.net/files/05018da0d0f3d6aaef76c17ec17f6dee\n",
    "\n",
    "This type of task arises in many particle physics data analyses\n",
    "\n",
    "Motivation\n",
    "==========\n",
    "\n",
    "The type of task described above, in which particles are classified\n",
    "according to which process they come from, is a common one in particle\n",
    "physics data analyses. Whether a new process is searched for or the\n",
    "parameters of an already known process are measured, the analysis boild\n",
    "down to extracting a small signal from a large dataset. Most of the data\n",
    "is easy to get rid of -- if it doesn't contain the particles that the\n",
    "sought after decay produces for example -- but a lot of it becomes a\n",
    "background that needs to be accounted for. In many cases, Monte Carlo\n",
    "simulations exist to accurately enough estiamte this background, but in\n",
    "others they don't. In those cases datadriven methods have to be used,\n",
    "which can quickly become a very complicated task if background from more\n",
    "than one process has to be estimated that way. Unsupervised\n",
    "classification could be used directly on data to estimate the background\n",
    "from different processes.\n",
    "\n",
    "Our contribution\n",
    "================\n",
    "\n",
    "The code we use comes from the UCluster git repository. Our contribution\n",
    "was to add the functionality of training the model in a distributed\n",
    "fashion. To do this, we use the Horovod runner, which necessitated a\n",
    "migration to TensorFlow 2 (from TensorFlow 1)."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
