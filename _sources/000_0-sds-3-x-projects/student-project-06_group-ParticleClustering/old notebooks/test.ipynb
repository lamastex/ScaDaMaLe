{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import org.apache.spark.sql.functions._\n",
    "\n",
    "print('Hello World!')\n",
    "\n",
    "\n",
    "# The notebooks are based on code from here:\n",
    "#https://docs.databricks.com/applications/machine-learning/train-model/distributed-training/horovod-runner.html\n",
    "#https://docs.databricks.com/applications/machine-learning/train-model/distributed-training/mnist-tensorflow-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Hello World!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old stuff\n",
    "#%sh\n",
    "#pip install tensorflow==1.15 \n",
    "\n",
    "#pip install horovod==0.18.1 --force-reinstall --no-deps --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Collecting tensorflow==1.15\n",
    ">       Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
    ">     Collecting tensorboard<1.16.0,>=1.15.0\n",
    ">       Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
    ">     Requirement already satisfied: termcolor>=1.1.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
    ">     Requirement already satisfied: wrapt>=1.11.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\n",
    ">     Requirement already satisfied: keras-preprocessing>=1.0.5 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\n",
    ">     Requirement already satisfied: astor>=0.6.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.0)\n",
    ">     Requirement already satisfied: numpy<2.0,>=1.16.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.1)\n",
    ">     Requirement already satisfied: opt-einsum>=2.3.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\n",
    ">     Processing /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3/gast-0.2.2-py3-none-any.whl\n",
    ">     Requirement already satisfied: six>=1.10.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)\n",
    ">     Requirement already satisfied: protobuf>=3.6.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (3.11.4)\n",
    ">     Requirement already satisfied: grpcio>=1.8.6 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.27.2)\n",
    ">     Collecting tensorflow-estimator==1.15.1\n",
    ">       Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
    ">     Collecting keras-applications>=1.0.8\n",
    ">       Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
    ">     Requirement already satisfied: google-pasta>=0.1.6 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
    ">     Requirement already satisfied: absl-py>=0.7.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\n",
    ">     Requirement already satisfied: wheel>=0.26 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\n",
    ">     Requirement already satisfied: markdown>=2.6.8 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
    ">     Requirement already satisfied: setuptools>=41.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (45.2.0.post20200210)\n",
    ">     Requirement already satisfied: werkzeug>=0.11.15 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.0)\n",
    ">     Requirement already satisfied: h5py in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
    ">     ERROR: spark-tensorflow-distributor 0.1.0 has requirement tensorflow>=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\n",
    ">     Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow\n",
    ">       Attempting uninstall: tensorboard\n",
    ">         Found existing installation: tensorboard 2.3.0\n",
    ">         Uninstalling tensorboard-2.3.0:\n",
    ">           Successfully uninstalled tensorboard-2.3.0\n",
    ">       Attempting uninstall: gast\n",
    ">         Found existing installation: gast 0.3.3\n",
    ">         Uninstalling gast-0.3.3:\n",
    ">           Successfully uninstalled gast-0.3.3\n",
    ">       Attempting uninstall: tensorflow-estimator\n",
    ">         Found existing installation: tensorflow-estimator 2.3.0\n",
    ">         Uninstalling tensorflow-estimator-2.3.0:\n",
    ">           Successfully uninstalled tensorflow-estimator-2.3.0\n",
    ">       Attempting uninstall: tensorflow\n",
    ">         Found existing installation: tensorflow 2.3.0\n",
    ">         Uninstalling tensorflow-2.3.0:\n",
    ">           Successfully uninstalled tensorflow-2.3.0\n",
    ">     Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall -y tensorflow \n",
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     WARNING: Skipping tensorflow as it is not installed.\n",
    ">     Collecting tensorflow\n",
    ">       Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
    ">     Collecting flatbuffers~=1.12.0\n",
    ">       Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
    ">     Requirement already satisfied: google-pasta~=0.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
    ">     Collecting six~=1.15.0\n",
    ">       Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
    ">     Requirement already satisfied: opt-einsum~=3.3.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
    ">     Collecting numpy~=1.19.2\n",
    ">       Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
    ">     Collecting tensorboard~=2.4\n",
    ">       Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
    ">     Collecting grpcio~=1.32.0\n",
    ">       Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
    ">     Requirement already satisfied: termcolor~=1.1.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
    ">     Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
    ">       Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
    ">     Collecting typing-extensions~=3.7.4\n",
    ">       Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
    ">     Collecting wheel~=0.35\n",
    ">       Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
    ">     Requirement already satisfied: protobuf>=3.9.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (3.11.4)\n",
    ">     Requirement already satisfied: h5py~=2.10.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
    ">     Requirement already satisfied: astunparse~=1.6.3 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
    ">     Collecting wrapt~=1.12.1\n",
    ">       Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
    ">     Collecting absl-py~=0.10\n",
    ">       Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
    ">     Collecting gast==0.3.3\n",
    ">       Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
    ">     Requirement already satisfied: keras-preprocessing~=1.1.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
    ">     Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.4.1)\n",
    ">     Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
    ">     Requirement already satisfied: requests<3,>=2.21.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.22.0)\n",
    ">     Requirement already satisfied: markdown>=2.6.8 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (3.1.1)\n",
    ">     Requirement already satisfied: setuptools>=41.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (45.2.0.post20200210)\n",
    ">     Requirement already satisfied: werkzeug>=0.11.15 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.0.0)\n",
    ">     Requirement already satisfied: google-auth<2,>=1.6.3 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.11.2)\n",
    ">     Requirement already satisfied: requests-oauthlib>=0.7.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
    ">     Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.8)\n",
    ">     Requirement already satisfied: certifi>=2017.4.17 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
    ">     Requirement already satisfied: idna<2.9,>=2.5 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.8)\n",
    ">     Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
    ">     Requirement already satisfied: cachetools<5.0,>=2.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.1)\n",
    ">     Requirement already satisfied: rsa<4.1,>=3.1.4 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.0)\n",
    ">     Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.7)\n",
    ">     Requirement already satisfied: oauthlib>=3.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
    ">     Requirement already satisfied: pyasn1>=0.1.3 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
    ">     Building wheels for collected packages: wrapt\n",
    ">       Building wheel for wrapt (setup.py): started\n",
    ">       Building wheel for wrapt (setup.py): finished with status 'done'\n",
    ">       Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70965 sha256=9013a5324ef1603be53ec36b5a9eddc537c7dd7c9a5ccdbee3a409d0783d8790\n",
    ">       Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
    ">     Successfully built wrapt\n",
    ">     ERROR: petastorm 0.9.5 requires pyspark>=2.1.0, which is not installed.\n",
    ">     ERROR: mlflow 1.11.0 requires alembic<=1.4.1, which is not installed.\n",
    ">     ERROR: mlflow 1.11.0 requires prometheus-flask-exporter, which is not installed.\n",
    ">     ERROR: mlflow 1.11.0 requires sqlalchemy<=1.3.13, which is not installed.\n",
    ">     ERROR: koalas 1.2.0 has requirement numpy<1.19.0,>=1.14, but you'll have numpy 1.19.4 which is incompatible.\n",
    ">     Installing collected packages: flatbuffers, six, numpy, absl-py, wheel, grpcio, tensorboard, tensorflow-estimator, typing-extensions, wrapt, gast, tensorflow\n",
    ">       Attempting uninstall: six\n",
    ">         Found existing installation: six 1.14.0\n",
    ">         Uninstalling six-1.14.0:\n",
    ">           Successfully uninstalled six-1.14.0\n",
    ">       Attempting uninstall: numpy\n",
    ">         Found existing installation: numpy 1.18.1\n",
    ">         Uninstalling numpy-1.18.1:\n",
    ">           Successfully uninstalled numpy-1.18.1\n",
    ">       Attempting uninstall: absl-py\n",
    ">         Found existing installation: absl-py 0.9.0\n",
    ">         Uninstalling absl-py-0.9.0:\n",
    ">           Successfully uninstalled absl-py-0.9.0\n",
    ">       Attempting uninstall: wheel\n",
    ">         Found existing installation: wheel 0.34.2\n",
    ">         Uninstalling wheel-0.34.2:\n",
    ">           Successfully uninstalled wheel-0.34.2\n",
    ">       Attempting uninstall: grpcio\n",
    ">         Found existing installation: grpcio 1.27.2\n",
    ">         Uninstalling grpcio-1.27.2:\n",
    ">           Successfully uninstalled grpcio-1.27.2\n",
    ">       Attempting uninstall: tensorboard\n",
    ">         Found existing installation: tensorboard 1.15.0\n",
    ">         Uninstalling tensorboard-1.15.0:\n",
    ">           Successfully uninstalled tensorboard-1.15.0\n",
    ">       Attempting uninstall: tensorflow-estimator\n",
    ">         Found existing installation: tensorflow-estimator 1.15.1\n",
    ">         Uninstalling tensorflow-estimator-1.15.1:\n",
    ">           Successfully uninstalled tensorflow-estimator-1.15.1\n",
    ">       Attempting uninstall: wrapt\n",
    ">         Found existing installation: wrapt 1.11.2\n",
    ">         Uninstalling wrapt-1.11.2:\n",
    ">           Successfully uninstalled wrapt-1.11.2\n",
    ">       Attempting uninstall: gast\n",
    ">         Found existing installation: gast 0.2.2\n",
    ">         Uninstalling gast-0.2.2:\n",
    ">           Successfully uninstalled gast-0.2.2\n",
    ">     Successfully installed absl-py-0.11.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 numpy-1.19.4 six-1.15.0 tensorboard-2.4.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wheel-0.36.2 wrapt-1.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.constant(100, name='x')\n",
    "y = tf.Variable(x + 50, name='y')\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     <tf.Variable 'y_2:0' shape=() dtype=int32_ref>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cmake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Requirement already satisfied: cmake in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (3.18.4.post1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install horovod --force-reinstall --no-deps --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Collecting horovod\n",
    ">       Downloading horovod-0.21.0.tar.gz (3.2 MB)\n",
    ">     Building wheels for collected packages: horovod\n",
    ">       Building wheel for horovod (setup.py): started\n",
    ">       Building wheel for horovod (setup.py): still running...\n",
    ">       Building wheel for horovod (setup.py): still running...\n",
    ">       Building wheel for horovod (setup.py): finished with status 'done'\n",
    ">       Created wheel for horovod: filename=horovod-0.21.0-cp37-cp37m-linux_x86_64.whl size=21178022 sha256=af6755bbb486085898ad30d312963e003de6a73267845db5b5e0b9374e2204ad\n",
    ">       Stored in directory: /tmp/pip-ephem-wheel-cache-ob5dy761/wheels/4a/7a/ad/e3a4e235dc846369995b95d1bf7eaed1dfa311c5f4d30a4a79\n",
    ">     Successfully built horovod\n",
    ">     Installing collected packages: horovod\n",
    ">       Attempting uninstall: horovod\n",
    ">         Found existing installation: horovod 0.19.5\n",
    ">         Uninstalling horovod-0.19.5:\n",
    ">           Successfully uninstalled horovod-0.19.5\n",
    ">     Successfully installed horovod-0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import horovod.tensorflow as hvd\n",
    "#import horovod as hvd\n",
    "#hvd.init()\n",
    "\n",
    "print('We\"ve made it this far.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     We\"ve made it this far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    " \n",
    "\n",
    "checkpoint_dir = '/dbfs/ml/MNISTDemo/train/{}/'.format(time.time())\n",
    "\n",
    " \n",
    "\n",
    "os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_classes, rank=0, size=1):\n",
    "\n",
    "  from tensorflow import keras\n",
    "\n",
    "  \n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data('MNIST-data-%d' % rank)\n",
    "\n",
    "  x_train = x_train[rank::size]\n",
    "\n",
    "  y_train = y_train[rank::size]\n",
    "\n",
    "  x_test = x_test[rank::size]\n",
    "\n",
    "  y_test = y_test[rank::size]\n",
    "\n",
    "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "\n",
    "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "  x_train = x_train.astype('float32')\n",
    "\n",
    "  x_test = x_test.astype('float32')\n",
    "\n",
    "  x_train /= 255\n",
    "\n",
    "  x_test /= 255\n",
    "\n",
    "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "\n",
    "  from tensorflow.keras import models\n",
    "\n",
    "  from tensorflow.keras import layers\n",
    "\n",
    "  \n",
    "\n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "\n",
    "                   activation='relu',\n",
    "\n",
    "                   input_shape=(28, 28, 1)))\n",
    "\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(layers.Dropout(0.25))\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "\n",
    "  model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "  model.add(layers.Dropout(0.5))\n",
    "\n",
    "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training parameters\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "num_classes = 10        \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "def train(learning_rate=1.0):\n",
    "\n",
    "  from tensorflow import keras\n",
    "\n",
    "  \n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = get_dataset(num_classes)\n",
    "\n",
    "  model = get_model(num_classes)\n",
    "\n",
    " \n",
    "\n",
    "  # Specify the optimizer (Adadelta in this example), using the learning rate input parameter of the function so that Horovod can adjust the learning rate during training\n",
    "\n",
    "  optimizer = keras.optimizers.Adadelta(lr=learning_rate)\n",
    "\n",
    " \n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "\n",
    "                loss='categorical_crossentropy',\n",
    "\n",
    "                metrics=['accuracy'])\n",
    "\n",
    " \n",
    "\n",
    "  model.fit(x_train, y_train,\n",
    "\n",
    "            batch_size=batch_size,\n",
    "\n",
    "            epochs=epochs,\n",
    "\n",
    "            verbose=2,\n",
    "\n",
    "            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    ">         8192/11490434 [..............................] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  368640/11490434 [..............................] - ETA: 1s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  753664/11490434 [>.............................] - ETA: 1s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 1114112/11490434 [=>............................] - ETA: 1s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 1556480/11490434 [===>..........................] - ETA: 1s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 2113536/11490434 [====>.........................] - ETA: 1s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 2801664/11490434 [======>.......................] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 3670016/11490434 [========>.....................] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 4849664/11490434 [===========>..................] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 6422528/11490434 [===============>..............] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 8503296/11490434 [=====================>........] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000811436032/11490434 [============================>.] - ETA: 0s\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000811493376/11490434 [==============================] - 1s 0us/step\n",
    ">     WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
    ">     Instructions for updating:\n",
    ">     If using Keras pass *_constraint arguments to layers.\n",
    ">     Train on 60000 samples, validate on 10000 samples\n",
    ">     Epoch 1/5\n",
    ">     60000/60000 - 49s - loss: 0.6314 - acc: 0.8082 - val_loss: 0.2323 - val_acc: 0.9313\n",
    ">     Epoch 2/5\n",
    ">     60000/60000 - 49s - loss: 0.3002 - acc: 0.9107 - val_loss: 0.1538 - val_acc: 0.9536\n",
    ">     Epoch 3/5\n",
    ">     60000/60000 - 48s - loss: 0.2279 - acc: 0.9330 - val_loss: 0.1164 - val_acc: 0.9642\n",
    ">     Epoch 4/5\n",
    ">     60000/60000 - 49s - loss: 0.1808 - acc: 0.9473 - val_loss: 0.0931 - val_acc: 0.9715\n",
    ">     Epoch 5/5\n",
    ">     60000/60000 - 50s - loss: 0.1488 - acc: 0.9566 - val_loss: 0.0770 - val_acc: 0.9754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hvd(learning_rate=1.0):\n",
    "\n",
    "  # Import tensorflow modules to each worker\n",
    "\n",
    "  from tensorflow.keras import backend as K\n",
    "\n",
    "  from tensorflow.keras.models import Sequential\n",
    "\n",
    "  import tensorflow as tf\n",
    "\n",
    "  from tensorflow import keras\n",
    "\n",
    "  import horovod.tensorflow.keras as hvd\n",
    "\n",
    "  \n",
    "\n",
    "  # Initialize Horovod\n",
    "\n",
    "  hvd.init()\n",
    "\n",
    " \n",
    "\n",
    "  # Pin GPU to be used to process local rank (one GPU per process)\n",
    "\n",
    "  # These steps are skipped on a CPU cluster\n",
    "\n",
    "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "  for gpu in gpus:\n",
    "\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "  if gpus:\n",
    "\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "\n",
    " \n",
    "\n",
    "  # Call the get_dataset function you created, this time with the Horovod rank and size\n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = get_dataset(num_classes, hvd.rank(), hvd.size())\n",
    "\n",
    "  model = get_model(num_classes)\n",
    "\n",
    " \n",
    "\n",
    "  # Adjust learning rate based on number of GPUs\n",
    "\n",
    "  optimizer = keras.optimizers.Adadelta(lr=learning_rate * hvd.size())\n",
    "\n",
    " \n",
    "\n",
    "  # Use the Horovod Distributed Optimizer\n",
    "\n",
    "  optimizer = hvd.DistributedOptimizer(optimizer)\n",
    "\n",
    " \n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "\n",
    "                loss='categorical_crossentropy',\n",
    "\n",
    "                metrics=['accuracy'])\n",
    "\n",
    " \n",
    "\n",
    "  # Create a callback to broadcast the initial variable states from rank 0 to all other processes.\n",
    "\n",
    "  # This is required to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.\n",
    "\n",
    "  callbacks = [\n",
    "\n",
    "      hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "\n",
    "  ]\n",
    "\n",
    " \n",
    "\n",
    "  # Save checkpoints only on worker 0 to prevent conflicts between workers\n",
    "\n",
    "  if hvd.rank() == 0:\n",
    "\n",
    "      callbacks.append(keras.callbacks.ModelCheckpoint(checkpoint_dir + '/checkpoint-{epoch}.ckpt', save_weights_only = True))\n",
    "\n",
    " \n",
    "\n",
    "  model.fit(x_train, y_train,\n",
    "\n",
    "            batch_size=batch_size,\n",
    "\n",
    "            callbacks=callbacks,\n",
    "\n",
    "            epochs=epochs,\n",
    "\n",
    "            verbose=2,\n",
    "\n",
    "            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I added all these installs because the final box of the tutorial is not working right now /Karl 201211 1650\n",
    "\n",
    "#Removed installs, things work with latest version of tensorflow and horovodrunner /Karl 201216 1606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Collecting sparkdl\n",
    ">       Downloading sparkdl-0.2.2-py3-none-any.whl (99 kB)\n",
    ">     Installing collected packages: sparkdl\n",
    ">     Successfully installed sparkdl-0.2.2\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    "\n",
    "  \n",
    "\n",
    ">     Collecting pillow\n",
    ">       Downloading Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
    ">     Installing collected packages: pillow\n",
    ">     Successfully installed pillow-8.0.1\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    "\n",
    "  \n",
    "\n",
    ">     Collecting keras==2.3.1\n",
    ">       Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
    ">     Requirement already satisfied: six>=1.9.0 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.14.0)\n",
    ">     Requirement already satisfied: h5py in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (3.1.0)\n",
    ">     Requirement already satisfied: keras-applications>=1.0.6 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.0.8)\n",
    ">     Requirement already satisfied: scipy>=0.14 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.4.1)\n",
    ">     Requirement already satisfied: keras-preprocessing>=1.0.5 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)\n",
    ">     Requirement already satisfied: pyyaml in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (5.3.1)\n",
    ">     Requirement already satisfied: numpy>=1.9.1 in /databricks/python3/lib/python3.7/site-packages (from keras==2.3.1) (1.18.1)\n",
    ">     Requirement already satisfied: cached-property; python_version < \"3.8\" in /databricks/python3/lib/python3.7/site-packages (from h5py->keras==2.3.1) (1.5.2)\n",
    ">     Installing collected packages: keras\n",
    ">       Attempting uninstall: keras\n",
    ">         Found existing installation: Keras 2.4.3\n",
    ">         Uninstalling Keras-2.4.3:\n",
    ">           Successfully uninstalled Keras-2.4.3\n",
    ">     Successfully installed keras-2.3.1\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    "\n",
    "  \n",
    "\n",
    ">     Collecting tensorframes\n",
    ">       Downloading tensorframes-0.2.9-py3-none-any.whl (10 kB)\n",
    ">     Installing collected packages: tensorframes\n",
    ">     Successfully installed tensorframes-0.2.9\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    "\n",
    "  \n",
    "\n",
    ">     Collecting kafka-python\n",
    ">       Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
    ">     Installing collected packages: kafka-python\n",
    ">     Successfully installed kafka-python-2.0.2\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    "\n",
    "  \n",
    "\n",
    ">     Collecting tensorflowonspark\n",
    ">       Downloading tensorflowonspark-2.2.1-py2.py3-none-any.whl (44 kB)\n",
    ">     Collecting packaging\n",
    ">       Downloading packaging-20.7-py2.py3-none-any.whl (35 kB)\n",
    ">     Requirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.7/site-packages (from packaging->tensorflowonspark) (2.4.6)\n",
    ">     Installing collected packages: packaging, tensorflowonspark\n",
    ">     Successfully installed packaging-20.7 tensorflowonspark-2.2.1\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    "\n",
    "  \n",
    "\n",
    ">     Collecting jieba\n",
    ">       Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
    ">     2020-12-11 14:59:42,250 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,252 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,252 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,253 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,254 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,254 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,254 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,255 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,350 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,451 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,551 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,583 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,585 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,585 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,585 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,586 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,652 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,753 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,853 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:42,954 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,055 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,085 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,085 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,086 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,088 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,155 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,256 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,357 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,457 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     Building wheels for collected packages: jieba\n",
    ">       Building wheel for jieba (setup.py): started\n",
    ">     2020-12-11 14:59:43,558 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,586 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,587 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,587 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,588 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,588 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,588 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,589 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,589 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,658 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,759 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,860 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:43,960 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,061 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,088 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,089 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,090 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,162 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,262 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,363 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,464 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,565 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,588 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,588 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,588 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,589 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,589 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,590 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,590 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,590 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,665 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,766 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,867 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:44,967 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,068 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,089 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,090 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,090 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,091 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,091 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,091 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,092 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,092 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,168 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,269 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,370 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,470 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,571 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,590 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,591 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,591 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,592 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,592 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,593 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,595 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,595 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,672 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,772 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,873 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:45,973 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,074 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,091 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,092 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,092 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,093 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,175 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">       Building wheel for jieba (setup.py): finished with status 'done'\n",
    ">       Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=41cd8913a83e4b41c56953eb933ba612cab830b3c75ed86d69ee29a77b5fde61\n",
    ">       Stored in directory: /root/.cache/pip/wheels/24/aa/17/5bc7c72e9a37990a9620cc3aad0acad1564dcff6dbc2359de3\n",
    ">     Successfully built jieba\n",
    ">     2020-12-11 14:59:46,275 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,376 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,477 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     Installing collected packages: jieba\n",
    ">     2020-12-11 14:59:46,577 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,592 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,592 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,593 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,593 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,594 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,594 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,594 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,595 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,678 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,778 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,879 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:46,980 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,080 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,094 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,094 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,096 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,097 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,097 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,097 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,098 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,098 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,181 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,281 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,382 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,483 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,583 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,595 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,596 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,596 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,597 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,597 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,597 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,598 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,598 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,684 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,785 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,885 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:47,986 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,087 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,099 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,099 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,099 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,100 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,100 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,101 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,101 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,102 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,187 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,288 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     Successfully installed jieba-0.42.1\n",
    ">     WARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
    ">     You should consider upgrading via the '/databricks/python3/bin/python3.7 -m pip install --upgrade pip' command.\n",
    ">     2020-12-11 14:59:48,389 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,489 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,490 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,490 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,490 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,491 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,491 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,491 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,492 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,492 INFO (Thread-21-17548) Received command c on object id p0\n",
    ">     2020-12-11 14:59:48,492 INFO (Thread-21-17548) Received command c on object id p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hvd.init()\n",
    "\n",
    "from sparkdl import HorovodRunner\n",
    "\n",
    " \n",
    "\n",
    "hr = HorovodRunner(np=2)\n",
    "\n",
    "hr.run(train_hvd, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     HorovodRunner will stream all training logs to notebook cell output. If there are too many logs, you\n",
    ">     can adjust the log level in your train method. Or you can set driver_log_verbosity to\n",
    ">     'log_callback_only' and use a HorovodRunner log  callback on the first worker to get concise\n",
    ">     progress updates.\n",
    ">     The global names read or written to by the pickled function are {'checkpoint_dir', 'num_classes', 'batch_size', 'epochs', 'get_model', 'get_dataset'}.\n",
    ">     The pickled object size is 3562 bytes.\n",
    ">\n",
    ">     ### How to enable Horovod Timeline? ###\n",
    ">     HorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To\n",
    ">     record a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the\n",
    ">     timeline file to be created. You can then open the timeline file  using the chrome://tracing\n",
    ">     facility of the Chrome browser.\n",
    ">\n",
    ">     Start training.\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:03.477687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:03.483544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.720962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.721840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.746571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.747430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,1]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,1]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.747462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.748081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.749096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,0]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,0]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.749177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.749268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.751923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.754095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.754477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.750963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.751257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.753072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.754093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.756663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.757757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.758266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.758398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.759281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:04.760069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,1]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.762185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.762398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.763383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:04.764224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,0]<stdout>:Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    ">     [1,1]<stdout>:[1,1]<stdout>:    8192/11490434 [..............................] - ETA: 0s[1,0]<stdout>:[1,0]<stdout>:    8192/11490434 [..............................][1,0]<stdout>: - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:  139264/11490434 [..............................] - ETA: 4s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>:  163840/11490434 [..............................] - ETA: 3s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:  294912/11490434 [..............................] - ETA: 3s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>:  360448/11490434 [..............................] - ETA: 3s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:  483328/11490434 [>.............................] - ETA: 3s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>:  573440/11490434 [>.............................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:  671744/11490434 [>.............................] - ETA: 3s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>:  786432/11490434 [=>............................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:  860160/11490434 [=>............................] - ETA: 3s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>:  999424/11490434 [=>............................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 1048576/11490434 [=>............................] - ETA: 3s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 1212416/11490434 [==>...........................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 1228800/11490434 [==>...........................] - ETA: 3s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 1441792/11490434 [==>...........................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 1425408/11490434 [==>...........................] - ETA: 2s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 1671168/11490434 [===>..........................][1,0]<stdout>: - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 1622016/11490434 [===>..........................] - ETA: 2s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 1900544/11490434 [===>..........................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 1818624/11490434 [===>..........................] - ETA: 2s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 2129920/11490434 [====>.........................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 2015232/11490434 [====>.........................] - ETA: 2s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 2359296/11490434 [=====>........................][1,0]<stdout>: - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 2211840/11490434 [====>.........................] - ETA: 2s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,0]<stdout>: 2588672/11490434 [=====>........................] - ETA: 2s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>: 2408448/11490434 [=====>........................] - ETA: 2s[1,0]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008...(truncated)\n",
    ">     [1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:10076160/11490434 [=========================>....] - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:10272768/11490434 [=========================>....] - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:10469376/11490434 [==========================>...] - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:10665984/11490434 [==========================>...] - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:10862592/11490434 [===========================>..] - ETA: 0s[1,0]<stderr>:2020-12-16 15:07:08.044663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     [1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     [1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:11059200/11490434 [===========================>..] - ETA: 0s[1,0]<stderr>:2020-12-16 15:07:08.067575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.067883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ebcb26b50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.067912: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     [1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:11255808/11490434 [============================>.] - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:11452416/11490434 [============================>.] - ETA: 0s[1,1]<stdout>:\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008[1,1]<stdout>:11493376/11490434 [==============================] - 3s 0us/step\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.164198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.165116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ebca72240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.165145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.165407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,0]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,0]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.166619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.167558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.168355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.168416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.455620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     [1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.481287: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.481655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561aac3674c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.481688: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.571052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.571962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561aac35e6d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.571997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.572298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,1]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,1]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.573575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.574487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.575287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:08.575343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.760606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.760663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.760675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.760950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.761899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:08.762742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n",
    ">     [1,0]<stdout>:Epoch 1/5\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.174137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.174194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.174209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.174504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.175465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.176297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:09.323552: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,1]<stdout>:Epoch 1/5\n",
    ">     [1,0]<stderr>:2020-12-16 15:07:09.574013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.734054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,1]<stderr>:2020-12-16 15:07:09.982296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Bootstrap : Using [0]eth0:10.149.251.184<0>\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO NET/Socket : Using [0]eth0:10.149.251.184<0>\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Using network Socket\n",
    ">     [1,0]<stdout>:NCCL version 2.7.3+cuda10.1\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Bootstrap : Using [0]eth0:10.149.231.123<0>\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO NET/Socket : Using [0]eth0:10.149.231.123<0>\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Using network Socket\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 00/02 :    0   1\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 01/02 :    0   1\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] -1/-1/-1->0->1|1->0->-1/-1/-1\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Trees [0] -1/-1/-1->1->0|0->1->-1/-1/-1 [1] 0/-1/-1->1->-1|-1->1->0/-1/-1\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 00 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 00 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 00 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 00 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 01 : 1[1e0] -> 0[1e0] [receive] via NET/Socket/0\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 01 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Channel 01 : 0[1e0] -> 1[1e0] [send] via NET/Socket/0\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO Channel 01 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO comm 0x7fad4cbf9c40 rank 0 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\n",
    ">     [1,1]<stdout>:1120-144117-apses921-10-149-231-123:3822:3825 [0] NCCL INFO comm 0x7f9578300cf0 rank 1 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n",
    ">     [1,0]<stdout>:1120-144117-apses921-10-149-251-184:3592:3595 [0] NCCL INFO Launch mode Parallel\n",
    ">     [1,1]<stdout>:235/235 - 3s - loss: 0.5739 - accuracy: 0.8248 - val_loss: 0.2239 - val_accuracy: 0.9330\n",
    ">     [1,1]<stdout>:Epoch 2/5\n",
    ">     [1,0]<stdout>:235/235 - 5s - loss: 0.7358 - accuracy: 0.7720 - val_loss: 0.2235 - val_accuracy: 0.9346\n",
    ">     [1,0]<stdout>:Epoch 2/5\n",
    ">     [1,1]<stdout>:235/235 - 3s - loss: 0.2218 - accuracy: 0.9349 - val_loss: 0.1524 - val_accuracy: 0.9536\n",
    ">     [1,1]<stdout>:Epoch 3/5\n",
    ">     [1,0]<stdout>:235/235 - 5s - loss: 0.3690 - accuracy: 0.8885 - val_loss: 0.1502 - val_accuracy: 0.9568\n",
    ">     [1,0]<stdout>:Epoch 3/5\n",
    ">     [1,1]<stdout>:235/235 - 3s - loss: 0.1549 - accuracy: 0.9548 - val_loss: 0.1154 - val_accuracy: 0.9618\n",
    ">     [1,1]<stdout>:Epoch 4/5\n",
    ">     [1,0]<stdout>:235/235 - 5s - loss: 0.2786 - accuracy: 0.9145 - val_loss: 0.1119 - val_accuracy: 0.9656\n",
    ">     [1,0]<stdout>:Epoch 4/5\n",
    ">     [1,1]<stdout>:235/235 - 3s - loss: 0.1178 - accuracy: 0.9667 - val_loss: 0.0876 - val_accuracy: 0.9716\n",
    ">     [1,1]<stdout>:Epoch 5/5\n",
    ">     [1,0]<stdout>:235/235 - 5s - loss: 0.2151 - accuracy: 0.9358 - val_loss: 0.0827 - val_accuracy: 0.9750\n",
    ">     [1,0]<stdout>:Epoch 5/5\n",
    ">     [1,1]<stdout>:235/235 - 3s - loss: 0.0908 - accuracy: 0.9749 - val_loss: 0.0702 - val_accuracy: 0.9786\n",
    ">     [1,0]<stdout>:235/235 - 5s - loss: 0.1805 - accuracy: 0.9453 - val_loss: 0.0656 - val_accuracy: 0.9780"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
