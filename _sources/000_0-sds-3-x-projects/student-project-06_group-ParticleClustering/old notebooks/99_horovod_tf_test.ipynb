{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Distributed deep learning training using TensorFlow and Keras with HorovodRunner\n",
    "=========================================================================================\n",
    "\n",
    "from\n",
    "https://docs.databricks.com/applications/machine-learning/train-model/distributed-training/mnist-tensorflow-keras.html\n",
    "\n",
    "Set up correct versions of packages for our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==1.15 \n",
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Found existing installation: tensorflow 2.3.0\n",
    ">     Uninstalling tensorflow-2.3.0:\n",
    ">       Would remove:\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/estimator_ckpt_converter\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/saved_model_cli\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/tensorboard\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/tf_upgrade_v2\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/tflite_convert\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/toco\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/bin/toco_from_protos\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow-2.3.0.dist-info/*\n",
    ">         /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow/*\n",
    ">     ERROR: Exception:\n",
    ">     Traceback (most recent call last):\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 186, in _main\n",
    ">         status = self.run(options, args)\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/commands/uninstall.py\", line 79, in run\n",
    ">         auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 687, in uninstall\n",
    ">         uninstalled_pathset.remove(auto_confirm, verbose)\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 388, in remove\n",
    ">         if auto_confirm or self._allowed_to_proceed(verbose):\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 431, in _allowed_to_proceed\n",
    ">         return ask('Proceed (y/n)? ', ('y', 'n')) == 'y'\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 240, in ask\n",
    ">         _check_no_input(message)\n",
    ">       File \"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 232, in _check_no_input\n",
    ">         message\n",
    ">     Exception: No input was expected ($PIP_NO_INPUT set); question: Proceed (y/n)? \n",
    ">     Collecting tensorflow==1.15\n",
    ">       Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
    ">     Collecting tensorboard<1.16.0,>=1.15.0\n",
    ">       Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
    ">     Requirement already satisfied: termcolor>=1.1.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
    ">     Requirement already satisfied: wrapt>=1.11.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\n",
    ">     Requirement already satisfied: keras-preprocessing>=1.0.5 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\n",
    ">     Requirement already satisfied: astor>=0.6.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.0)\n",
    ">     Requirement already satisfied: numpy<2.0,>=1.16.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.1)\n",
    ">     Requirement already satisfied: opt-einsum>=2.3.2 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\n",
    ">     Collecting gast==0.2.2\n",
    ">       Downloading gast-0.2.2.tar.gz (10 kB)\n",
    ">     Requirement already satisfied: six>=1.10.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)\n",
    ">     Requirement already satisfied: protobuf>=3.6.1 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (3.11.4)\n",
    ">     Requirement already satisfied: grpcio>=1.8.6 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (1.27.2)\n",
    ">     Collecting tensorflow-estimator==1.15.1\n",
    ">       Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
    ">     Collecting keras-applications>=1.0.8\n",
    ">       Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
    ">     Requirement already satisfied: google-pasta>=0.1.6 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
    ">     Requirement already satisfied: absl-py>=0.7.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\n",
    ">     Requirement already satisfied: wheel>=0.26 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\n",
    ">     Requirement already satisfied: markdown>=2.6.8 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
    ">     Requirement already satisfied: setuptools>=41.0.0 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (45.2.0.post20200210)\n",
    ">     Requirement already satisfied: werkzeug>=0.11.15 in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.0)\n",
    ">     Requirement already satisfied: h5py in /databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
    ">     Building wheels for collected packages: gast\n",
    ">       Building wheel for gast (setup.py): started\n",
    ">       Building wheel for gast (setup.py): finished with status 'done'\n",
    ">       Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=dff4f82b6a0364dcfb9ae8f35ade6178dc888a22198e108d3192db9b3b586df8\n",
    ">       Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
    ">     Successfully built gast\n",
    ">     ERROR: spark-tensorflow-distributor 0.1.0 has requirement tensorflow>=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\n",
    ">     Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow\n",
    ">       Attempting uninstall: tensorboard\n",
    ">         Found existing installation: tensorboard 2.3.0\n",
    ">         Uninstalling tensorboard-2.3.0:\n",
    ">           Successfully uninstalled tensorboard-2.3.0\n",
    ">       Attempting uninstall: gast\n",
    ">         Found existing installation: gast 0.3.3\n",
    ">         Uninstalling gast-0.3.3:\n",
    ">           Successfully uninstalled gast-0.3.3\n",
    ">       Attempting uninstall: tensorflow-estimator\n",
    ">         Found existing installation: tensorflow-estimator 2.3.0\n",
    ">         Uninstalling tensorflow-estimator-2.3.0:\n",
    ">           Successfully uninstalled tensorflow-estimator-2.3.0\n",
    ">       Attempting uninstall: tensorflow\n",
    ">         Found existing installation: tensorflow 2.3.0\n",
    ">         Uninstalling tensorflow-2.3.0:\n",
    ">           Successfully uninstalled tensorflow-2.3.0\n",
    ">     Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
    "\n",
    "  \n",
    "\n",
    "Set up checkpoint location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    " \n",
    "checkpoint_dir = '/dbfs/ml/MNISTDemo/train/{}/'.format(time.time())\n",
    " \n",
    "os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Create function to prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_classes, rank=0, size=1):\n",
    "  from tensorflow import keras\n",
    "  \n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data('MNIST-data-%d' % rank)\n",
    "  x_train = x_train[rank::size]\n",
    "  y_train = y_train[rank::size]\n",
    "  x_test = x_test[rank::size]\n",
    "  y_test = y_test[rank::size]\n",
    "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "  x_train = x_train.astype('float32')\n",
    "  x_test = x_test.astype('float32')\n",
    "  x_train /= 255\n",
    "  x_test /= 255\n",
    "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "  return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Create function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "  from tensorflow.keras import models\n",
    "  from tensorflow.keras import layers\n",
    "  \n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   input_shape=(28, 28, 1)))\n",
    "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(layers.Dropout(0.25))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(128, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Run training on single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training parameters\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "num_classes = 10        \n",
    " \n",
    " \n",
    "def train(learning_rate=1.0):\n",
    "  from tensorflow import keras\n",
    "  \n",
    "  (x_train, y_train), (x_test, y_test) = get_dataset(num_classes)\n",
    "  print(x_train.shape)\n",
    "  print(y_train.shape)\n",
    "  print(x_test.shape)\n",
    "  print(y_test.shape)\n",
    "  model = get_model(num_classes)\n",
    " \n",
    "  # Specify the optimizer (Adadelta in this example), using the learning rate input parameter of the function so that Horovod can adjust the learning rate during training\n",
    "  optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    " \n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    " \n",
    "  model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=2,\n",
    "            validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # run the training\n",
    "  train(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     (60000, 28, 28, 1)\n",
    ">     (60000, 10)\n",
    ">     (10000, 28, 28, 1)\n",
    ">     (10000, 10)\n",
    ">     Train on 60000 samples, validate on 10000 samples\n",
    ">     Epoch 1/20\n",
    ">     60000/60000 - 51s - loss: 3.8806 - acc: 0.1048 - val_loss: 2.3070 - val_acc: 0.0958\n",
    ">     Epoch 2/20\n",
    "\n",
    "  \n",
    "\n",
    "Migrate to HorovodRunner for distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hvd(learning_rate=1.0):\n",
    "  # Import tensorflow modules to each worker\n",
    "  from tensorflow.keras import backend as K\n",
    "  from tensorflow.keras.models import Sequential\n",
    "  import tensorflow as tf\n",
    "  from tensorflow import keras\n",
    "  import horovod.tensorflow.keras as hvd\n",
    "  \n",
    "  # Initialize Horovod\n",
    "  hvd.init()\n",
    " \n",
    "  # Pin GPU to be used to process local rank (one GPU per process)\n",
    "  # These steps are skipped on a CPU cluster\n",
    "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "  for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    " \n",
    "  # Call the get_dataset function you created, this time with the Horovod rank and size\n",
    "  print(\"HVD RANK AND SIZE\")\n",
    "  print(hvd.rank())\n",
    "  print(hvd.size())\n",
    "  \n",
    "  (x_train, y_train), (x_test, y_test) = get_dataset(num_classes, hvd.rank(), hvd.size())\n",
    "  print(x_train.shape)\n",
    "  print(y_train.shape)\n",
    "  print(x_test.shape)\n",
    "  print(y_test.shape)\n",
    "  model = get_model(num_classes)\n",
    " \n",
    "  # Adjust learning rate based on number of GPUs\n",
    "  optimizer = keras.optimizers.Adam(lr=learning_rate * hvd.size())\n",
    "  # Use the Horovod Distributed Optimizer\n",
    "  optimizer = hvd.DistributedOptimizer(optimizer)\n",
    " \n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    " \n",
    "  # Create a callback to broadcast the initial variable states from rank 0 to all other processes.\n",
    "  # This is required to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.\n",
    "  callbacks = [hvd.callbacks.BroadcastGlobalVariablesCallback(0)]\n",
    " \n",
    "  # Save checkpoints only on worker 0 to prevent conflicts between workers\n",
    "  if hvd.rank() == 0:\n",
    "      callbacks.append(keras.callbacks.ModelCheckpoint(checkpoint_dir + '/checkpoint-{epoch}.ckpt', save_weights_only = True))\n",
    " \n",
    "  model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            epochs=epochs,\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkdl import HorovodRunner\n",
    " \n",
    "hr = HorovodRunner(np=2)\n",
    "hr.run(train_hvd, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     HorovodRunner will stream all training logs to notebook cell output. If there are too many logs, you\n",
    ">     can adjust the log level in your train method. Or you can set driver_log_verbosity to\n",
    ">     'log_callback_only' and use a HorovodRunner log  callback on the first worker to get concise\n",
    ">     progress updates.\n",
    ">     The global names read or written to by the pickled function are {'checkpoint_dir', 'num_classes', 'batch_size', 'epochs', 'get_model', 'print', 'get_dataset'}.\n",
    ">     The pickled object size is 3648 bytes.\n",
    ">\n",
    ">     ### How to enable Horovod Timeline? ###\n",
    ">     HorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To\n",
    ">     record a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the\n",
    ">     timeline file to be created. You can then open the timeline file  using the chrome://tracing\n",
    ">     facility of the Chrome browser.\n",
    ">\n",
    ">     Start training.\n",
    ">     [1,1]<stderr>:Traceback (most recent call last):\n",
    ">     [1,1]<stderr>:  File \"<string>\", line 1, in <module>\n",
    ">     [1,1]<stderr>:  File \"/databricks/.python_edge_libs/sparkdl/horovod/runner.py\", line 222, in wrapped_main\n",
    ">     [1,1]<stderr>:    return_value = main(**kwargs)\n",
    ">     [1,1]<stderr>:  File \"<command-1173833896357973>\", line 7, in train_hvd\n",
    ">     [1,1]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/horovod/tensorflow/__init__.py\", line 28, in <module>\n",
    ">     [1,1]<stderr>:    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\n",
    ">     [1,1]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py\", line 49, in <module>\n",
    ">     [1,1]<stderr>:    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\n",
    ">     [1,1]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py\", line 45, in _load_library\n",
    ">     [1,1]<stderr>:    library = load_library.load_op_library(filename)\n",
    ">     [1,1]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\n",
    ">     [1,1]<stderr>:    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
    ">     [1,1]<stderr>:tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory\n",
    ">     --------------------------------------------------------------------------\n",
    ">     Primary job  terminated normally, but 1 process returned\n",
    ">     a non-zero exit code. Per user-direction, the job has been aborted.\n",
    ">     --------------------------------------------------------------------------\n",
    ">     [1,0]<stderr>:Traceback (most recent call last):\n",
    ">     [1,0]<stderr>:  File \"<string>\", line 1, in <module>\n",
    ">     [1,0]<stderr>:  File \"/databricks/.python_edge_libs/sparkdl/horovod/runner.py\", line 222, in wrapped_main\n",
    ">     [1,0]<stderr>:    return_value = main(**kwargs)\n",
    ">     [1,0]<stderr>:  File \"<command-1173833896357973>\", line 7, in train_hvd\n",
    ">     [1,0]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/horovod/tensorflow/__init__.py\", line 28, in <module>\n",
    ">     [1,0]<stderr>:    from horovod.tensorflow.mpi_ops import allgather, broadcast, _allreduce\n",
    ">     [1,0]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py\", line 49, in <module>\n",
    ">     [1,0]<stderr>:    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())\n",
    ">     [1,0]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/horovod/tensorflow/mpi_ops.py\", line 45, in _load_library\n",
    ">     [1,0]<stderr>:    library = load_library.load_op_library(filename)\n",
    ">     [1,0]<stderr>:  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\n",
    ">     [1,0]<stderr>:    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
    ">     [1,0]<stderr>:tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory\n",
    ">     --------------------------------------------------------------------------\n",
    ">     mpirun detected that one or more processes exited with non-zero status, thus causing\n",
    ">     the job to be terminated. The first process to do so was:\n",
    ">\n",
    ">       Process name: [[24816,1],1]\n",
    ">       Exit code:    1\n",
    ">     --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install tensorflow-cpu==1.15.*\n",
    "%pip install tensorflow-gpu==1.15.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Python interpreter will be restarted.\n",
    ">     Requirement already satisfied: tensorflow-cpu==1.15.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (1.15.0)\n",
    ">     Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.15.0)\n",
    ">     Requirement already satisfied: termcolor>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.1.0)\n",
    ">     Requirement already satisfied: wrapt>=1.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.11.2)\n",
    ">     Requirement already satisfied: keras-preprocessing>=1.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.1.2)\n",
    ">     Requirement already satisfied: astor>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.8.0)\n",
    ">     Requirement already satisfied: numpy<2.0,>=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.18.1)\n",
    ">     Requirement already satisfied: opt-einsum>=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (3.3.0)\n",
    ">     Requirement already satisfied: gast==0.2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.2.2)\n",
    ">     Requirement already satisfied: six>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.14.0)\n",
    ">     Requirement already satisfied: protobuf>=3.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (3.11.4)\n",
    ">     Requirement already satisfied: grpcio>=1.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.27.2)\n",
    ">     Requirement already satisfied: tensorflow-estimator==1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.15.1)\n",
    ">     Requirement already satisfied: keras-applications>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (1.0.8)\n",
    ">     Requirement already satisfied: google-pasta>=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.2.0)\n",
    ">     Requirement already satisfied: absl-py>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.9.0)\n",
    ">     Requirement already satisfied: wheel>=0.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-cpu==1.15.*) (0.34.2)\n",
    ">     Requirement already satisfied: markdown>=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-cpu==1.15.*) (3.1.1)\n",
    ">     Requirement already satisfied: setuptools>=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-cpu==1.15.*) (45.2.0.post20200210)\n",
    ">     Requirement already satisfied: werkzeug>=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-cpu==1.15.*) (1.0.0)\n",
    ">     Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow-cpu==1.15.*) (2.10.0)\n",
    ">     Python interpreter will be restarted.\n",
    ">     Python interpreter will be restarted.\n",
    ">     Collecting tensorflow-gpu==1.15.*\n",
    ">       Using cached tensorflow_gpu-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
    ">     Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.15.0)\n",
    ">     Requirement already satisfied: termcolor>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.1.0)\n",
    ">     Requirement already satisfied: wrapt>=1.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.11.2)\n",
    ">     Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.34.2)\n",
    ">     Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.18.1)\n",
    ">     Requirement already satisfied: keras-preprocessing>=1.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.1.2)\n",
    ">     Requirement already satisfied: astor>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.8.0)\n",
    ">     Requirement already satisfied: opt-einsum>=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (3.3.0)\n",
    ">     Requirement already satisfied: six>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.14.0)\n",
    ">     Requirement already satisfied: gast==0.2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.2.2)\n",
    ">     Requirement already satisfied: protobuf>=3.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (3.11.4)\n",
    ">     Requirement already satisfied: grpcio>=1.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.27.2)\n",
    ">     Requirement already satisfied: tensorflow-estimator==1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.15.1)\n",
    ">     Requirement already satisfied: keras-applications>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (1.0.8)\n",
    ">     Requirement already satisfied: google-pasta>=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.2.0)\n",
    ">     Requirement already satisfied: absl-py>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow-gpu==1.15.*) (0.9.0)\n",
    ">     Requirement already satisfied: markdown>=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.*) (3.1.1)\n",
    ">     Requirement already satisfied: setuptools>=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.*) (45.2.0.post20200210)\n",
    ">     Requirement already satisfied: werkzeug>=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.*) (1.0.0)\n",
    ">     Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.*) (2.10.0)\n",
    ">     Installing collected packages: tensorflow-gpu\n",
    ">     Successfully installed tensorflow-gpu-1.15.4\n",
    ">     Python interpreter will be restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install https://databricks-prod-cloudfront.cloud.databricks.com/artifacts/tensorflow/runtime-7.x/tensorflow-1.15.3-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Python interpreter will be restarted.\n",
    ">     Collecting tensorflow==1.15.3\n",
    ">       Using cached https://databricks-prod-cloudfront.cloud.databricks.com/artifacts/tensorflow/runtime-7.x/tensorflow-1.15.3-cp37-cp37m-linux_x86_64.whl (310.3 MB)\n",
    ">     Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.15.0)\n",
    ">     Requirement already satisfied: termcolor>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.1.0)\n",
    ">     Requirement already satisfied: wrapt>=1.11.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.11.2)\n",
    ">     Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.34.2)\n",
    ">     Requirement already satisfied: keras-preprocessing>=1.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.1.2)\n",
    ">     Requirement already satisfied: astor>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.8.0)\n",
    ">     Requirement already satisfied: numpy<2.0,>=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.18.1)\n",
    ">     Requirement already satisfied: opt-einsum>=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (3.3.0)\n",
    ">     Requirement already satisfied: gast==0.2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.2.2)\n",
    ">     Requirement already satisfied: six>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.14.0)\n",
    ">     Requirement already satisfied: protobuf>=3.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (3.11.4)\n",
    ">     Requirement already satisfied: grpcio>=1.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.27.2)\n",
    ">     Requirement already satisfied: tensorflow-estimator==1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.15.1)\n",
    ">     Requirement already satisfied: keras-applications>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.0.8)\n",
    ">     Requirement already satisfied: google-pasta>=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.2.0)\n",
    ">     Requirement already satisfied: absl-py>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.9.0)\n",
    ">     Requirement already satisfied: markdown>=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (3.1.1)\n",
    ">     Requirement already satisfied: setuptools>=41.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (45.2.0.post20200210)\n",
    ">     Requirement already satisfied: werkzeug>=0.11.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (1.0.0)\n",
    ">     Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa69c28f-c2d6-4acc-b96b-82dc9a083c73/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.3) (2.10.0)\n",
    ">     ERROR: spark-tensorflow-distributor 0.1.0 has requirement tensorflow>=2.1.0, but you'll have tensorflow 1.15.3 which is incompatible.\n",
    ">     Installing collected packages: tensorflow\n",
    ">       Attempting uninstall: tensorflow\n",
    ">         Found existing installation: tensorflow 2.3.0\n",
    ">         Uninstalling tensorflow-2.3.0:\n",
    ">           Successfully uninstalled tensorflow-2.3.0\n",
    ">     Successfully installed tensorflow-1.15.3\n",
    ">     Python interpreter will be restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     1.15.3"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
