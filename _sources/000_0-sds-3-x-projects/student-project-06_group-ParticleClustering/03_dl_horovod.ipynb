{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extends the TF v2.x code from the single machine notebook\n",
    "`23_ds_single_machine`. The modification are such that the code enables\n",
    "multi-machine training using the\n",
    "[horovod](https://github.com/horovod/horovod) framwork.\n",
    "\n",
    "We will highlight the changes compared the single machine\n",
    "implementation.\n",
    "\n",
    "First: Check if the data is in local. If not, go to notebook\n",
    "`1_data_and_preprocssing` and download the data from dbfs to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls 06_LHC/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     LICENSE\n",
    ">     README.md\n",
    ">     data\n",
    ">     h5\n",
    ">     models\n",
    ">     scripts\n",
    ">     utils\n",
    "\n",
    "  \n",
    "\n",
    "Get the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import Namespace\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "import os\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "np.set_printoptions(edgeitems=1000)\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "BASE_DIR = os.path.join(os.getcwd(), '06_LHC','scripts')  \n",
    "#os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.append(BASE_DIR)\n",
    "sys.path.append(os.path.join(BASE_DIR, '..', 'models'))\n",
    "sys.path.append(os.path.join(BASE_DIR, '..', 'utils'))\n",
    "import provider\n",
    "import gapnet_classify as MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Get the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parserdict = {'max_dim': 3, #help='Dimension of the encoding layer [Default: 3]')\n",
    "              'n_clusters': 3, #help='Number of clusters [Default: 3]')\n",
    "              'gpu': 0, #help='GPU to use [default: GPU 0]')\n",
    "              'model': 'gapnet_clasify', #help='Model name [default: gapnet_classify]')\n",
    "              'log_dir': 'log', #help='Log dir [default: log]')\n",
    "              'num_point': 100, #help='Point Number [default: 100]')\n",
    "              'max_epoch': 10, #help='Epoch to run [default: 200]')\n",
    "              'epochs_pretrain': 1, #help='Epochs to for pretraining [default: 10]')\n",
    "              'batch_size': 512, #help='Batch Size during training [default: 512]')\n",
    "              'learning_rate': 0.001, #help='Initial learning rate [default: 0.01]')\n",
    "\n",
    "              'momentum': 0.9, #help='Initial momentum [default: 0.9]')\n",
    "              'optimizer': 'adam', #help='adam or momentum [default: adam]')\n",
    "              'decay_step': 500000, #help='Decay step for lr decay [default: 500000]')\n",
    "              'wd': 0.0, #help='Weight Decay [Default: 0.0]')\n",
    "              'decay_rate': 0.5, #help='Decay rate for lr decay [default: 0.5]')\n",
    "              'output_dir': 'train_results', #help='Directory that stores all training logs and trained models')\n",
    "              'data_dir': os.path.join(os.getcwd(),'06_LHC', 'h5'), # '../h5', #help='directory with data [default: hdf5_data]')\n",
    "              'nfeat': 8, #help='Number of features [default: 8]')\n",
    "              'ncat': 20, #help='Number of categories [default: 20]')\n",
    "             }\n",
    "\n",
    "FLAGS = Namespace(**parserdict)\n",
    "H5_DIR = FLAGS.data_dir\n",
    "\n",
    "EPOCH_CNT = 0\n",
    "MAX_PRETRAIN = FLAGS.epochs_pretrain\n",
    "BATCH_SIZE = FLAGS.batch_size\n",
    "NUM_POINT = FLAGS.num_point\n",
    "NUM_FEAT = FLAGS.nfeat\n",
    "NUM_CLASSES = FLAGS.ncat\n",
    "MAX_EPOCH = FLAGS.max_epoch\n",
    "BASE_LEARNING_RATE = FLAGS.learning_rate\n",
    "GPU_INDEX = FLAGS.gpu\n",
    "MOMENTUM = FLAGS.momentum\n",
    "OPTIMIZER = FLAGS.optimizer\n",
    "DECAY_STEP = FLAGS.decay_step\n",
    "DECAY_RATE = FLAGS.decay_rate\n",
    "\n",
    "# MODEL = importlib.import_module(FLAGS.model) # import network module\n",
    "MODEL_FILE = os.path.join(BASE_DIR, 'models', FLAGS.model + '.py')\n",
    "LOG_DIR = os.path.join(os.getcwd(), '06_LHC', 'logs', FLAGS.log_dir)\n",
    "\n",
    "if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)\n",
    "os.system('cp %s.py %s' % (MODEL_FILE, LOG_DIR))  # bkp of model def\n",
    "os.system('cp train_kmeans.py %s' % (LOG_DIR))  # bkp of train procedure\n",
    "\n",
    "BN_INIT_DECAY = 0.5\n",
    "BN_DECAY_DECAY_RATE = 0.5\n",
    "BN_DECAY_DECAY_STEP = float(DECAY_STEP)\n",
    "BN_DECAY_CLIP = 0.99\n",
    "\n",
    "LEARNING_RATE_CLIP = 1e-5\n",
    "HOSTNAME = socket.gethostname()\n",
    "\n",
    "TRAIN_FILES = provider.getDataFiles(os.path.join(H5_DIR, 'train_files_wztop.txt'))\n",
    "TEST_FILES = provider.getDataFiles(os.path.join(H5_DIR, 'test_files_wztop.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Define the utils functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(batch):\n",
    "    learning_rate = tf.compat.v1.train.exponential_decay(\n",
    "        BASE_LEARNING_RATE,  # Base learning rate.\n",
    "        batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "        DECAY_STEP,  # Decay step.\n",
    "        DECAY_RATE,  # Decay rate.\n",
    "        staircase=True)\n",
    "    learning_rate = tf.maximum(learning_rate, LEARNING_RATE_CLIP)  # CLIP THE LEARNING RATE!\n",
    "    return learning_rate\n",
    "\n",
    "\n",
    "def get_bn_decay(batch):\n",
    "    bn_momentum = tf.compat.v1.train.exponential_decay(\n",
    "        BN_INIT_DECAY,\n",
    "        batch * BATCH_SIZE,\n",
    "        BN_DECAY_DECAY_STEP,\n",
    "        BN_DECAY_DECAY_RATE,\n",
    "        staircase=True)\n",
    "    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "    return bn_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Modification: - create checkpoint directory for horovod - directory is\n",
    "user chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    " \n",
    "checkpoint_dir = '/dbfs/databricks/driver/06_LHC/logs/train/{}/'.format(time.time())\n",
    " \n",
    "os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Create horovod h5 loading function: - not the rank and size is inputed.\n",
    "- rank is the current device id - size is the total number of available\n",
    "GPUs - we split the data in the h5 file for each device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_hvd(h5_filename, rank=0, size=1):\n",
    "    f = h5py.File(h5_filename, 'r')\n",
    "    data = f['data'][rank::size]\n",
    "    label = f['pid'][rank::size]\n",
    "    seg = f['label'][rank::size]\n",
    "    print(\"loaded {0} events\".format(len(data)))\n",
    "\n",
    "    return (data, label, seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Main training function. Modifications are: - import packages again.\n",
    "Otherwise single devices may cause problems. - initialise the horovod\n",
    "runner - copy the files from local to each GPU such that they are\n",
    "available for horovod. - scale the learning rate by the number of\n",
    "available devices. - add a horovod specific distributed optimizer. - use\n",
    "hooks for checkpoint saving ever 1000 steps. - switch from a normal TF\n",
    "training session to a monitored training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hvd():\n",
    "    import horovod.tensorflow as hvd\n",
    "    import tensorflow as tf\n",
    "    import shutil\n",
    "\n",
    "    \n",
    "    # do all the imports here again in order for hvd to work nicely\n",
    "    import horovod.tensorflow as hvd\n",
    "    import argparse, shlex\n",
    "    from datetime import datetime\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import socket\n",
    "    import os\n",
    "    import sys\n",
    "    from sklearn.cluster import KMeans\n",
    "    from tqdm import tqdm\n",
    "    np.set_printoptions(edgeitems=1000)\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    BASE_DIR = os.path.join(os.getcwd(), '06_LHC','scripts')\n",
    "    sys.path.append(BASE_DIR)\n",
    "    sys.path.append(os.path.join(BASE_DIR, '..', 'models'))\n",
    "    sys.path.append(os.path.join(BASE_DIR, '..', 'utils'))\n",
    "    \n",
    "    # HOROVOD: initialize Horovod.\n",
    "    hvd.init()\n",
    "    \n",
    "    # HOROVOD: Copy files from local to each single GPU directory\n",
    "    src = \"/dbfs/FileStore/06_LHC\"\n",
    "    dst = os.path.join(os.getcwd(), '06_LHC')\n",
    "    print(\"Copying data/files to local horovod folder...\")\n",
    "    shutil.copytree(src, dst)\n",
    "    print(\"Done with copying!\")\n",
    "    \n",
    "    import provider\n",
    "    import gapnet_classify as MODEL\n",
    "    \n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:' + str(GPU_INDEX)):\n",
    "            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT, NUM_FEAT)\n",
    "\n",
    "            is_training_pl = tf.compat.v1.placeholder(tf.bool, shape=())\n",
    "\n",
    "            # Note the global_step=batch parameter to minimize.\n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            alpha = tf.compat.v1.placeholder(dtype=tf.float32, shape=())\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.compat.v1.summary.scalar('bn_decay', bn_decay)\n",
    "            print(\"--- Get model and loss\")\n",
    "\n",
    "            pred, max_pool = MODEL.get_model(pointclouds_pl, is_training=is_training_pl,\n",
    "                                             bn_decay=bn_decay,\n",
    "                                             num_class=NUM_CLASSES, weight_decay=FLAGS.wd,\n",
    "                                             )\n",
    "\n",
    "            class_loss = MODEL.get_focal_loss(pred, labels_pl, NUM_CLASSES)\n",
    "            mu = tf.Variable(tf.zeros(shape=(FLAGS.n_clusters, FLAGS.max_dim)), name=\"mu\",\n",
    "                             trainable=True)  # k centroids\n",
    "            kmeans_loss, stack_dist = MODEL.get_loss_kmeans(max_pool, mu, FLAGS.max_dim,\n",
    "                                                            FLAGS.n_clusters, alpha)\n",
    "\n",
    "            full_loss = kmeans_loss + class_loss\n",
    "\n",
    "            print(\"--- Get training operator\")\n",
    "            # Get training operator\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            # HOROVOD: scale learning rade from hvd dependent number of processes (=hvd.size)\n",
    "            tf.compat.v1.summary.scalar('learning_rate', learning_rate * hvd.size())\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate * hvd.size(), momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate * hvd.size())\n",
    "            # HOROVOD: add Horovod Distributed Optimizer\n",
    "            optimizer = hvd.DistributedOptimizer(optimizer)\n",
    "\n",
    "            global_step = tf.compat.v1.train.get_or_create_global_step() \n",
    "            train_op_full = optimizer.minimize(full_loss, global_step=global_step) #batch)\n",
    "            train_op = optimizer.minimize(class_loss, global_step=global_step) #batch)\n",
    "\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "             \n",
    "        # HOROVOD\n",
    "        hooks = [\n",
    "          # Horovod: BroadcastGlobalVariablesHook broadcasts initial variable states\n",
    "          # from rank 0 to all other processes. This is necessary to ensure consistent\n",
    "          # initialization of all workers when training is started with random weights\n",
    "          # or restored from a checkpoint.\n",
    "          hvd.BroadcastGlobalVariablesHook(0),\n",
    "          \n",
    "          #checkpoint_dir_mod = checkpoint_dir if hvd.rank() == 0 else None\n",
    "          \n",
    "          tf.compat.v1.train.CheckpointSaverHook(checkpoint_dir=checkpoint_dir,\n",
    "                                                 checkpoint_basename='cluster.ckpt',\n",
    "                                                 save_steps=1_000\n",
    "                                                ),\n",
    "\n",
    "          # this one basically prints every n steps the \"step\" and the \"loss\". Output is cleaner without\n",
    "          # tf.compat.v1.train.LoggingTensorHook(tensors={'step': global_step, 'loss': full_loss}, every_n_iter=75),\n",
    "        ]\n",
    "\n",
    "        # Create a session\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "        \n",
    "        # global variable initializer must be defined before session definition\n",
    "        init_global_step = tf.compat.v1.global_variables_initializer()\n",
    "        \n",
    "        # MonitoredTrainingSession\n",
    "        # takes care of session initialization,\n",
    "        # restoring from a checkpoint, saving to a checkpoint, and closing when done\n",
    "        # or an error occurs.\n",
    "        #checkpoint_dir_mod = checkpoint_dir if hvd.rank() == 0 else None\n",
    "        sess = tf.compat.v1.train.MonitoredTrainingSession(checkpoint_dir=checkpoint,\n",
    "                                                           hooks=hooks,\n",
    "                                                           config=config)\n",
    "\n",
    "        # get one batch_data from the training files in oder to inintialise the session\n",
    "        train_idxs = np.arange(0, len(TRAIN_FILES))\n",
    "        current_file = os.path.join(os.getcwd(), '06_LHC', 'h5', TRAIN_FILES[train_idxs[0]])\n",
    "        current_data, current_label, current_cluster = load_h5_hvd(current_file, hvd.rank(), hvd.size())\n",
    "        batch_data, batch_label = get_batch(current_data, current_label, 0, BATCH_SIZE)\n",
    "        # \n",
    "        feed_dict = {pointclouds_pl: batch_data,\n",
    "                     labels_pl: batch_label,\n",
    "                     is_training_pl: False,\n",
    "                     alpha: 2 * (EPOCH_CNT - MAX_PRETRAIN + 1),}\n",
    "        #NOT SO CLEAR THAT init_global_step IS NECESSARY. \n",
    "        sess.run(init_global_step, feed_dict=feed_dict)\n",
    "\n",
    "        # hels with merging: CHANGE THIS IF POSSIBLE\n",
    "        sess.graph._unsafe_unfinalize()\n",
    "        # Add summary writers\n",
    "        merged = tf.compat.v1.summary.merge_all()\n",
    "        train_writer = tf.compat.v1.summary.FileWriter(os.path.join(LOG_DIR, 'train'), sess.graph)\n",
    "        test_writer = tf.compat.v1.summary.FileWriter(os.path.join(LOG_DIR, 'test'), sess.graph)\n",
    "        \n",
    "        # Init variables\n",
    "        print(\"Total number of weights for the model: \", np.sum([np.prod(v.get_shape().as_list()) for v in tf.compat.v1.trainable_variables()]))\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "          'labels_pl': labels_pl,\n",
    "          'is_training_pl': is_training_pl,\n",
    "          'max_pool': max_pool,\n",
    "          'pred': pred,\n",
    "          'alpha': alpha,\n",
    "          'mu': mu,\n",
    "          'stack_dist': stack_dist,\n",
    "          'class_loss': class_loss,\n",
    "          'kmeans_loss': kmeans_loss,\n",
    "          'train_op': train_op,\n",
    "          'train_op_full': train_op_full,\n",
    "          'merged': merged,\n",
    "          'step': batch,\n",
    "          'learning_rate': learning_rate\n",
    "        }\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "            print('\\n**** EPOCH %03d ****' % (epoch))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            is_full_training = epoch > MAX_PRETRAIN\n",
    "            max_pool = train_one_epoch(sess, ops, train_writer, hvd.rank(), hvd.size(), is_full_training)\n",
    "            if epoch == MAX_PRETRAIN:\n",
    "                centers = KMeans(n_clusters=FLAGS.n_clusters).fit(np.squeeze(max_pool))\n",
    "                centers = centers.cluster_centers_\n",
    "                sess.run(tf.compat.v1.assign(mu, centers))\n",
    "\n",
    "            eval_one_epoch(sess, ops, test_writer, hvd.rank(), hvd.size(), is_full_training)\n",
    "            \"\"\"if is_full_training:\n",
    "                save_path = saver.save(sess, os.path.join(LOG_DIR, 'cluster.ckpt'))\n",
    "            else:\n",
    "                save_path = saver.save(sess, os.path.join(LOG_DIR, 'model.ckpt'))\"\"\"\n",
    "            #print(\"Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Training utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, label, start_idx, end_idx):\n",
    "    batch_label = label[start_idx:end_idx]\n",
    "    batch_data = data[start_idx:end_idx, :, :]\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    ind = linear_sum_assignment(w.max() - w)\n",
    "    ind = np.asarray(ind)\n",
    "    ind = np.transpose(ind)\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "One epoch training and evaluation functions: - the applicable horovod\n",
    "rank and size is fed into both functions. - use the rank and size to\n",
    "load the correct h5 data. - remove progress bars since progress bars\n",
    "from each device would overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(sess, ops, train_writer, hvd_rank, hvd_size, is_full_training):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = True\n",
    "\n",
    "    train_idxs = np.arange(0, len(TRAIN_FILES))\n",
    "\n",
    "    acc = loss_sum = 0\n",
    "    y_pool = []\n",
    "    for fn in range(len(TRAIN_FILES)):\n",
    "        # print('----' + str(fn) + '-----')\n",
    "        current_file = os.path.join(os.getcwd(), '06_LHC', 'h5', TRAIN_FILES[train_idxs[fn]])\n",
    "        current_data, current_label, current_cluster = load_h5_hvd(current_file, hvd_rank, hvd_size)\n",
    "\n",
    "        current_label = np.squeeze(current_label)\n",
    "\n",
    "        file_size = current_data.shape[0]\n",
    "        num_batches = file_size // BATCH_SIZE\n",
    "        # num_batches = 5\n",
    "        print(str(datetime.now()))\n",
    "\n",
    "        # initialise progress bar\n",
    "        #process_desc = \"TRAINING: Loss {:2.3e}\"\n",
    "        #progress_bar = tqdm(initial=0, leave=True, total=num_batches,\n",
    "        #                    desc=process_desc.format(0),\n",
    "        #                    position=0)\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = (batch_idx + 1) * BATCH_SIZE\n",
    "            batch_data, batch_label = get_batch(current_data, current_label, start_idx, end_idx)\n",
    "            cur_batch_size = end_idx - start_idx\n",
    "\n",
    "            # print(batch_weight)\n",
    "            feed_dict = {ops['pointclouds_pl']: batch_data,\n",
    "                         ops['labels_pl']: batch_label,\n",
    "                         ops['is_training_pl']: is_training,\n",
    "                         ops['alpha']: 2 * (EPOCH_CNT - MAX_PRETRAIN + 1),}\n",
    "            if is_full_training:\n",
    "                summary, step, _, loss_val, dist, lr = sess.run([ops['merged'], ops['step'],\n",
    "                                                                 ops['train_op_full'], ops['kmeans_loss'],\n",
    "                                                                 ops['stack_dist'], ops['learning_rate']],\n",
    "                                                                feed_dict=feed_dict)\n",
    "\n",
    "                batch_cluster = np.array([np.where(r == 1)[0][0] for r in current_cluster[start_idx:end_idx]])\n",
    "                cluster_assign = np.zeros((cur_batch_size), dtype=int)\n",
    "\n",
    "                for i in range(cur_batch_size):\n",
    "                    index_closest_cluster = np.argmin(dist[:, i])\n",
    "                    cluster_assign[i] = index_closest_cluster\n",
    "\n",
    "                acc += cluster_acc(batch_cluster, cluster_assign)\n",
    "            else:\n",
    "                summary, step, _, loss_val, max_pool, lr = sess.run([ops['merged'], ops['step'],\n",
    "                                                                     ops['train_op'], ops['class_loss'],\n",
    "                                                                     ops['max_pool'], ops['learning_rate']],\n",
    "                                                                    feed_dict=feed_dict)\n",
    "\n",
    "                if len(y_pool) == 0:\n",
    "                    y_pool = np.squeeze(max_pool)\n",
    "                else:\n",
    "                    y_pool = np.concatenate((y_pool, np.squeeze(max_pool)), axis=0)\n",
    "\n",
    "            loss_sum += np.mean(loss_val)\n",
    "\n",
    "            #train_writer.add_summary(summary, step)\n",
    "            if hvd_rank == 0:\n",
    "                train_writer.add_summary(summary, step)\n",
    "              \n",
    "              \n",
    "\n",
    "            # Update train bar\n",
    "            #process_desc.format(loss_val)\n",
    "            #progress_bar.update(1)\n",
    "        #progress_bar.close()\n",
    "\n",
    "    print('learning rate: %f' % (lr))\n",
    "    print('train mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    #if is_full_training:\n",
    "    print('train clustering accuracy: %f' % (acc / float(num_batches)))\n",
    "    return y_pool\n",
    "\n",
    "\n",
    "def eval_one_epoch(sess, ops, test_writer, hvd_rank, hvd_size, is_full_training):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    global EPOCH_CNT\n",
    "    is_training = False\n",
    "    test_idxs = np.arange(0, len(TEST_FILES))\n",
    "    # Test on all data: last batch might be smaller than BATCH_SIZE\n",
    "    loss_sum = acc = 0\n",
    "    acc_kmeans = 0\n",
    "\n",
    "    for fn in range(len(TEST_FILES)):\n",
    "        # print('----' + str(fn) + '-----')\n",
    "        current_file = os.path.join(os.getcwd(), '06_LHC', 'h5', TEST_FILES[test_idxs[fn]])\n",
    "        current_data, current_label, current_cluster = load_h5_hvd(current_file, hvd_rank, hvd_size)\n",
    "        current_label = np.squeeze(current_label)\n",
    "\n",
    "        file_size = current_data.shape[0]\n",
    "        num_batches = file_size // BATCH_SIZE\n",
    "        \n",
    "        \"\"\"process_desc = \"VALIDATION: Loss {:2.3e}\"\n",
    "        progress_bar = tqdm(initial=0, leave=True, total=num_batches,\n",
    "                        desc=process_desc.format(0),\n",
    "                        position=0)\"\"\"\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = (batch_idx + 1) * BATCH_SIZE\n",
    "            batch_data, batch_label = get_batch(current_data, current_label, start_idx, end_idx)\n",
    "            cur_batch_size = end_idx - start_idx\n",
    "\n",
    "            feed_dict = {ops['pointclouds_pl']: batch_data,\n",
    "                         ops['is_training_pl']: is_training,\n",
    "                         ops['labels_pl']: batch_label,\n",
    "                         ops['alpha']: 2 * (EPOCH_CNT - MAX_PRETRAIN + 1),}\n",
    "\n",
    "            if is_full_training:\n",
    "                summary, step, loss_val, max_pool, dist, mu = sess.run([ops['merged'], ops['step'],\n",
    "                                                                        ops['kmeans_loss'],\n",
    "                                                                        ops['max_pool'], ops['stack_dist'],\n",
    "                                                                        ops['mu']],\n",
    "                                                                       feed_dict=feed_dict)\n",
    "                \n",
    "                batch_cluster = np.array([np.where(r == 1)[0][0] for r in current_cluster[start_idx:end_idx]])\n",
    "                cluster_assign = np.zeros((cur_batch_size), dtype=int)\n",
    "                for i in range(cur_batch_size):\n",
    "                    index_closest_cluster = np.argmin(dist[:, i])\n",
    "                    cluster_assign[i] = index_closest_cluster\n",
    "\n",
    "                acc += cluster_acc(batch_cluster, cluster_assign)\n",
    "\n",
    "            else:\n",
    "                summary, step, loss_val = sess.run([ops['merged'], ops['step'],\n",
    "                                                    ops['class_loss']],\n",
    "                                                   feed_dict=feed_dict)\n",
    "\n",
    "            #test_writer.add_summary(summary, step)\n",
    "            if hvd_rank == 0:\n",
    "                test_writer.add_summary(summary, step)\n",
    "\n",
    "            loss_sum += np.mean(loss_val)\n",
    "            \n",
    "            \"\"\"# Update train bar\n",
    "            process_desc.format(loss_val)\n",
    "            progress_bar.update(1)\"\"\"\n",
    "        #progress_bar.close()\n",
    "\n",
    "    total_loss = loss_sum * 1.0 / float(num_batches)\n",
    "    print('test mean loss: %f' % (total_loss))\n",
    "    #if is_full_training:\n",
    "    print('testing clustering accuracy: %f' % (acc / float(num_batches)))\n",
    "\n",
    "    EPOCH_CNT += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Run the training: - initialise the Horovod runner with np=2 GPUs. The\n",
    "cluster does not allow more GPUs - run the horovod runner with the given\n",
    "training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkdl import HorovodRunner\n",
    " \n",
    "hr = HorovodRunner(np=2)\n",
    "hr.run(train_hvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     HorovodRunner will stream all training logs to notebook cell output. If there are too many logs, you\n",
    ">     can adjust the log level in your train method. Or you can set driver_log_verbosity to\n",
    ">     'log_callback_only' and use a HorovodRunner log  callback on the first worker to get concise\n",
    ">     progress updates.\n",
    ">     The global names read or written to by the pickled function are {'get_bn_decay', 'MOMENTUM', 'range', 'NUM_CLASSES', 'OPTIMIZER', 'EPOCH_CNT', 'get_learning_rate', 'load_h5_hvd', 'get_batch', 'MAX_EPOCH', 'len', 'NUM_FEAT', 'GPU_INDEX', 'BATCH_SIZE', 'LOG_DIR', 'FLAGS', 'checkpoint_dir', 'eval_one_epoch', 'NUM_POINT', 'MAX_PRETRAIN', 'TRAIN_FILES', 'print', 'str', 'train_one_epoch'}.\n",
    ">     The pickled object size is 11055 bytes.\n",
    ">\n",
    ">     ### How to enable Horovod Timeline? ###\n",
    ">     HorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To\n",
    ">     record a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the\n",
    ">     timeline file to be created. You can then open the timeline file  using the chrome://tracing\n",
    ">     facility of the Chrome browser.\n",
    ">\n",
    ">     Start training.\n",
    ">     [1,1]<stderr>:2021-01-04 17:28:24.816450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2021-01-04 17:28:24.869795: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stdout>:Copying data/files to local horovod folder...\n",
    ">     [1,1]<stdout>:Copying data/files to local horovod folder...\n",
    ">     [1,0]<stdout>:Done with copying!\n",
    ">     [1,1]<stdout>:Done with copying!\n",
    ">     [1,0]<stdout>:--- Get model and loss\n",
    ">     [1,1]<stdout>:--- Get model and loss\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.132866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.176503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.184581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.185468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,1]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,1]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.185502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.232379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.233308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,0]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,0]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.233358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.619010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.637123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.889096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.931508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:20.936127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:20.982198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:21.453513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:21.540557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:21.560198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:21.627762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:21.679130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:21.679396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:21.680404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:21.681219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,0]<stdout>:--- Get training operator\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:22.394999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:22.395216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:22.396223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:22.397023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,1]<stdout>:--- Get training operator\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\n",
    ">     [1,0]<stderr>:Create CheckpointSaverHook.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\n",
    ">     [1,0]<stderr>:Create CheckpointSaverHook.\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
    ">     [1,0]<stderr>:Instructions for updating:\n",
    ">     [1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
    ">     [1,0]<stderr>:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
    ">     [1,0]<stderr>:Instructions for updating:\n",
    ">     [1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\n",
    ">     [1,1]<stderr>:Create CheckpointSaverHook.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\n",
    ">     [1,1]<stderr>:Create CheckpointSaverHook.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Graph was finalized.\n",
    ">     [1,0]<stderr>:Graph was finalized.\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.378385: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     [1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.403662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.404019: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5587faad13f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.404049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.499397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.500320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5587faabc500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.500353: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.500691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,0]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,0]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501829: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.501885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.502014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.502935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.503846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:26.503903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
    ">     [1,1]<stderr>:Instructions for updating:\n",
    ">     [1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
    ">     [1,1]<stderr>:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
    ">     [1,1]<stderr>:Instructions for updating:\n",
    ">     [1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Graph was finalized.\n",
    ">     [1,1]<stderr>:Graph was finalized.\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.413689: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     [1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.451878: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.452210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631a5a623f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.452249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.462163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.462213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.462226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.463593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.464598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.465438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.565670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.566566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631a575bc90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.566604: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.568675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\n",
    ">     [1,1]<stderr>:pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     [1,1]<stderr>:coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.569919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.570828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.571633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:27.572656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     [1,0]<stderr>:2021-01-04 17:30:27.764091: W tensorflow/core/common_runtime/colocation_graph.cc:1139] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
    ">     [1,0]<stderr>:  /job:localhost/replica:0/task:0/device:CPU:0].\n",
    ">     [1,0]<stderr>:See below for details of this colocation group:\n",
    ">     [1,0]<stderr>:Colocation Debug Info:\n",
    ">     [1,0]<stderr>:Colocation group had the following types and supported devices:\n",
    ">     [1,0]<stderr>:Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
    ">     [1,0]<stderr>:ReadVariableOp: GPU CPU XLA_CPU XLA_GPU\n",
    ">     [1,0]<stderr>:AssignVariableOp: CPU XLA_CPU XLA_GPU\n",
    ">     [1,0]<stderr>:VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU\n",
    ">     [1,0]<stderr>:Const: GPU CPU XLA_CPU XLA_GPU\n",
    ">     [1,0]<stderr>:VarHandleOp: CPU XLA_CPU XLA_GPU\n",
    ">     [1,0]<stderr>:\n",
    ">     [1,0]<stderr>:Colocation members, user-requested devices, and framework assigned devices, if any:\n",
    ">     [1,0]<stderr>:  Variable/Initializer/initial_value (Const)\n",
    ">     [1,0]<stderr>:  Variable (VarHandleOp) /device:GPU:0\n",
    ">     [1,0]<stderr>:  Variable/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
    ">     [1,0]<stderr>:  Variable/Assign (AssignVariableOp) /device:GPU:0\n",
    ">     [1,0]<stderr>:  Variable/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
    ">     [1,0]<stderr>:  ReadVariableOp (ReadVariableOp)\n",
    ">     [1,0]<stderr>:  ReadVariableOp_4 (ReadVariableOp)\n",
    ">     [1,0]<stderr>:  save/AssignVariableOp (AssignVariableOp) /device:GPU:0\n",
    ">     [1,0]<stderr>:  HorovodBroadcast_Variable_0/ReadVariableOp (ReadVariableOp)\n",
    ">     [1,0]<stderr>:  AssignVariableOp (AssignVariableOp)\n",
    ">     [1,0]<stderr>:  ReadVariableOp_5 (ReadVariableOp)\n",
    ">     [1,0]<stderr>:  report_uninitialized_variables/VarIsInitializedOp (VarIsInitializedOp)\n",
    ">     [1,0]<stderr>:  report_uninitialized_variables_1/VarIsInitializedOp (VarIsInitializedOp)\n",
    ">     [1,0]<stderr>:  save_1/AssignVariableOp (AssignVariableOp) /device:GPU:0\n",
    ">     [1,0]<stderr>:\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Running local_init_op.\n",
    ">     [1,0]<stderr>:Running local_init_op.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\n",
    ">     [1,0]<stderr>:Done running local_init_op.\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:28.981517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:28.981570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:28.981580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:28.982650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:28.983624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:28.984487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13943 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5)\n",
    ">     [1,1]<stderr>:2021-01-04 17:30:29.296559: W tensorflow/core/common_runtime/colocation_graph.cc:1139] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
    ">     [1,1]<stderr>:  /job:localhost/replica:0/task:0/device:CPU:0].\n",
    ">     [1,1]<stderr>:See below for details of this colocation group:\n",
    ">     [1,1]<stderr>:Colocation Debug Info:\n",
    ">     [1,1]<stderr>:Colocation group had the following types and supported devices:\n",
    ">     [1,1]<stderr>:Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
    ">     [1,1]<stderr>:ReadVariableOp: GPU CPU XLA_CPU XLA_GPU\n",
    ">     [1,1]<stderr>:AssignVariableOp: CPU XLA_CPU XLA_GPU\n",
    ">     [1,1]<stderr>:VarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU\n",
    ">     [1,1]<stderr>:Const: GPU CPU XLA_CPU XLA_GPU\n",
    ">     [1,1]<stderr>:VarHandleOp: CPU XLA_CPU XLA_GPU\n",
    ">     [1,1]<stderr>:\n",
    ">     [1,1]<stderr>:Colocation members, user-requested devices, and framework assigned devices, if any:\n",
    ">     [1,1]<stderr>:  Variable/Initializer/initial_value (Const)\n",
    ">     [1,1]<stderr>:  Variable (VarHandleOp) /device:GPU:0\n",
    ">     [1,1]<stderr>:  Variable/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:GPU:0\n",
    ">     [1,1]<stderr>:  Variable/Assign (AssignVariableOp) /device:GPU:0\n",
    ">     [1,1]<stderr>:  Variable/Read/ReadVariableOp (ReadVariableOp) /device:GPU:0\n",
    ">     [1,1]<stderr>:  ReadVariableOp (ReadVariableOp)\n",
    ">     [1,1]<stderr>:  ReadVariableOp_4 (ReadVariableOp)\n",
    ">     [1,1]<stderr>:  save/AssignVariableOp (AssignVariableOp) /device:GPU:0\n",
    ">     [1,1]<stderr>:  HorovodBroadcast_Variable_0/ReadVariableOp (ReadVariableOp)\n",
    ">     [1,1]<stderr>:  AssignVariableOp (AssignVariableOp)\n",
    ">     [1,1]<stderr>:  ReadVariableOp_5 (ReadVariableOp)\n",
    ">     [1,1]<stderr>:  report_uninitialized_variables/VarIsInitializedOp (VarIsInitializedOp)\n",
    ">     [1,1]<stderr>:  report_uninitialized_variables_1/VarIsInitializedOp (VarIsInitializedOp)\n",
    ">     [1,1]<stderr>:  save_1/AssignVariableOp (AssignVariableOp) /device:GPU:0\n",
    ">     [1,1]<stderr>:\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Running local_init_op.\n",
    ">     [1,1]<stderr>:Running local_init_op.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\n",
    ">     [1,1]<stderr>:Done running local_init_op.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners before saving checkpoint 0...\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,0]<stderr>:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners before saving checkpoint 0...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,1]<stderr>:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners after saving checkpoint 0...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners after saving checkpoint 0...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners before saving checkpoint 0...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,1]<stderr>:Saving checkpoints for 0 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">\n",
    ">     *** WARNING: skipped 5495 bytes of output ***\n",
    ">\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.38528\n",
    ">     [1,0]<stderr>:global_step/sec: 2.38528\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.34714\n",
    ">     [1,1]<stderr>:global_step/sec: 2.34714\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 3.0324\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 3.03245\n",
    ">     [1,0]<stderr>:global_step/sec: 3.0324\n",
    ">     [1,1]<stderr>:global_step/sec: 3.03245\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 3.825902\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.000000\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 4.023047\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.000000\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,0]<stderr>:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 295 vs previous value: 295. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
    ">     [1,1]<stdout>:test mean loss: 1.974160\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.000000\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 001 ****\n",
    ">     [1,0]<stdout>:test mean loss: 1.894498[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.000000\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 001 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:32:45.264640\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:32:45.838243\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.04904\n",
    ">     [1,0]<stderr>:global_step/sec: 2.04904\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.04898\n",
    ">     [1,1]<stderr>:global_step/sec: 2.04898\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.93649\n",
    ">     [1,0]<stderr>:global_step/sec: 2.93649\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.93658\n",
    ">     [1,1]<stderr>:global_step/sec: 2.93658\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.89172\n",
    ">     [1,0]<stderr>:global_step/sec: 2.89172\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.89167\n",
    ">     [1,1]<stderr>:global_step/sec: 2.89167\n",
    ">     [1,0]<stdout>:learning rate: 0.001000\n",
    ">     [1,0]<stdout>:train mean loss: 1.479257\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.000000\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 1.611109\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.000000\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 1.255668\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.000000\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 002 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:34:44.019857\n",
    ">     [1,0]<stdout>:test mean loss: 2.434365[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.000000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 002 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:34:44.976721\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.81088\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.8109\n",
    ">     [1,0]<stderr>:global_step/sec: 1.81088\n",
    ">     [1,1]<stderr>:global_step/sec: 1.8109\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.84508\n",
    ">     [1,0]<stderr>:global_step/sec: 2.84508\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.84507\n",
    ">     [1,1]<stderr>:global_step/sec: 2.84507\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.84237\n",
    ">     [1,0]<stderr>:global_step/sec: 2.84237\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.84234\n",
    ">     [1,1]<stderr>:global_step/sec: 2.84234\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.073204\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.565135\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.029733\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.590128\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 0.035144\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.583770\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 003 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:36:46.278189\n",
    ">     [1,0]<stdout>:test mean loss: 0.073979[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.535852\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 003 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:36:47.495020\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.95912\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.95915\n",
    ">     [1,1]<stderr>:global_step/sec: 1.95915\n",
    ">     [1,0]<stderr>:global_step/sec: 1.95912\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.8459\n",
    ">     [1,1]<stderr>:global_step/sec: 2.8459\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.84588\n",
    ">     [1,0]<stderr>:global_step/sec: 2.84588\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners before saving checkpoint 1000...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,1]<stderr>:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners before saving checkpoint 1000...\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,0]<stderr>:Saving checkpoints for 1000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners after saving checkpoint 1000...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners after saving checkpoint 1000...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.6452\n",
    ">     [1,1]<stderr>:global_step/sec: 2.6452\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.64518\n",
    ">     [1,0]<stderr>:global_step/sec: 2.64518\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.047254\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.592644\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.028695\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.583104\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 0.032069\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.577938\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 004 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:38:48.063939\n",
    ">     [1,0]<stdout>:test mean loss: 0.046610[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.558246\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 004 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:38:49.158460\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.98098\n",
    ">     [1,0]<stderr>:global_step/sec: 1.98098\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.98091\n",
    ">     [1,1]<stderr>:global_step/sec: 1.98091\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.84389\n",
    ">     [1,1]<stderr>:global_step/sec: 2.84389\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.84377\n",
    ">     [1,0]<stderr>:global_step/sec: 2.84377\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.84688\n",
    ">     [1,0]<stderr>:global_step/sec: 2.84688\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.84681\n",
    ">     [1,1]<stderr>:global_step/sec: 2.84681\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.033857\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.608349\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.026509\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.584607\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1475...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners before saving checkpoint 1475...\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,0]<stderr>:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1475...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners before saving checkpoint 1475...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,1]<stderr>:Saving checkpoints for 1475 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1475...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners after saving checkpoint 1475...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1475...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners after saving checkpoint 1475...\n",
    ">     [1,1]<stdout>:test mean loss: 0.033016\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.577536\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 005 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:40:50.403813\n",
    ">     [1,0]<stdout>:test mean loss: 0.033497[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.544601\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 005 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:40:52.117234\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.837\n",
    ">     [1,1]<stderr>:global_step/sec: 1.837\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.83696\n",
    ">     [1,0]<stderr>:global_step/sec: 1.83696\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.84922\n",
    ">     [1,0]<stderr>:global_step/sec: 2.84922\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.8491\n",
    ">     [1,1]<stderr>:global_step/sec: 2.8491\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.86428\n",
    ">     [1,0]<stderr>:global_step/sec: 2.86428\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.86434\n",
    ">     [1,1]<stderr>:global_step/sec: 2.86434\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.026064\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.643836[1,0]<stdout>:\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.025038\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.584362\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 0.027497\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.562982\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 006 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:42:49.541722\n",
    ">     [1,0]<stdout>:test mean loss: 0.025077[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.560493\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 006 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:42:50.501567\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.99568\n",
    ">     [1,1]<stderr>:global_step/sec: 1.99568\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.99566\n",
    ">     [1,0]<stderr>:global_step/sec: 1.99566\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85026\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85026\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85017\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85017\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85591\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85591\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85594\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85594\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners before saving checkpoint 2000...\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,0]<stderr>:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners before saving checkpoint 2000...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,1]<stderr>:Saving checkpoints for 2000 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/cluster.ckpt.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners after saving checkpoint 2000...\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners after saving checkpoint 2000...\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.021587\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.646451\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.023550\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.584812\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 0.025361\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.553805\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 007 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:44:50.785483\n",
    ">     [1,0]<stdout>:test mean loss: 0.022237[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.557256\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 007 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:44:51.680681\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.89396\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.89394\n",
    ">     [1,1]<stderr>:global_step/sec: 1.89396\n",
    ">     [1,0]<stderr>:global_step/sec: 1.89394\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85501\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85501\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85498\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85498\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85526\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85526\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85522\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85522\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.019167\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.631786\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.021949\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.579774\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 0.022571\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.561590\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 008 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:46:49.376643\n",
    ">     [1,0]<stdout>:test mean loss: 0.019591[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.596399\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 008 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:46:50.271701\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.98749\n",
    ">     [1,0]<stderr>:global_step/sec: 1.98749\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.98748\n",
    ">     [1,1]<stderr>:global_step/sec: 1.98748\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85509\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85509\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.855\n",
    ">     [1,0]<stderr>:global_step/sec: 2.855\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85604\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85601\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85601\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85604\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.017833\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.612758\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.019644\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.571921\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:test mean loss: 0.019357\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.568440\n",
    ">     [1,1]<stdout>:\n",
    ">     [1,1]<stdout>:**** EPOCH 009 ****\n",
    ">     [1,1]<stdout>:loaded 151332 events\n",
    ">     [1,1]<stdout>:2021-01-04 17:48:47.868751\n",
    ">     [1,0]<stdout>:test mean loss: 0.018919[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.638806[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:\n",
    ">     [1,0]<stdout>:**** EPOCH 009 ****\n",
    ">     [1,0]<stdout>:loaded 151332 events\n",
    ">     [1,0]<stdout>:2021-01-04 17:48:48.844865\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 1.98952\n",
    ">     [1,0]<stderr>:global_step/sec: 1.98952\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 1.9895\n",
    ">     [1,1]<stderr>:global_step/sec: 1.9895\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85433\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85433\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.8543\n",
    ">     [1,1]<stderr>:global_step/sec: 2.8543\n",
    ">     [1,0]<stderr>:INFO:tensorflow:global_step/sec: 2.85624\n",
    ">     [1,1]<stderr>:INFO:tensorflow:global_step/sec: 2.85631\n",
    ">     [1,1]<stderr>:global_step/sec: 2.85631\n",
    ">     [1,0]<stderr>:global_step/sec: 2.85624\n",
    ">     [1,1]<stdout>:learning rate: 0.001000\n",
    ">     [1,1]<stdout>:train mean loss: 0.017083\n",
    ">     [1,1]<stdout>:train clustering accuracy: 0.566671\n",
    ">     [1,0]<stdout>:learning rate: 0.001000[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:train mean loss: 0.017304\n",
    ">     [1,0]<stdout>:train clustering accuracy: 0.599682\n",
    ">     [1,0]<stdout>:loaded 37833 events\n",
    ">     [1,1]<stdout>:loaded 37833 events\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2950...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners before saving checkpoint 2950...\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,0]<stderr>:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2950...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners before saving checkpoint 2950...\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,1]<stderr>:Saving checkpoints for 2950 into /dbfs/databricks/driver/06_LHC/logs/train/1609781294.4809902/model.ckpt.\n",
    ">     [1,0]<stderr>:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
    ">     [1,0]<stderr>:Instructions for updating:\n",
    ">     [1,0]<stderr>:Use standard file APIs to delete files with this prefix.\n",
    ">     [1,0]<stderr>:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
    ">     [1,0]<stderr>:Instructions for updating:\n",
    ">     [1,0]<stderr>:Use standard file APIs to delete files with this prefix.\n",
    ">     [1,0]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2950...\n",
    ">     [1,0]<stderr>:Calling checkpoint listeners after saving checkpoint 2950...\n",
    ">     [1,1]<stderr>:WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
    ">     [1,1]<stderr>:Instructions for updating:\n",
    ">     [1,1]<stderr>:Use standard file APIs to delete files with this prefix.\n",
    ">     [1,1]<stderr>:From /databricks/python/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
    ">     [1,1]<stderr>:Instructions for updating:\n",
    ">     [1,1]<stderr>:Use standard file APIs to delete files with this prefix.\n",
    ">     [1,1]<stderr>:INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2950...\n",
    ">     [1,1]<stderr>:Calling checkpoint listeners after saving checkpoint 2950...\n",
    ">     [1,1]<stdout>:test mean loss: 0.015524\n",
    ">     [1,1]<stdout>:testing clustering accuracy: 0.553644\n",
    ">     [1,0]<stdout>:test mean loss: 0.018224[1,0]<stdout>:\n",
    ">     [1,0]<stdout>:testing clustering accuracy: 0.600920[1,0]<stdout>:\n",
    "\n",
    "  \n",
    "\n",
    "Results: - Execution of the command for np=2 GPUs takes 3.39 hours. -\n",
    "Plot below show the validation accuracy vs epoch. - Note that we switch\n",
    "to the full loss after n=10 epochs. - We observe an improvement in the\n",
    "cluster validation set accuracy after around 50 epochs. - Highest\n",
    "cluster validation set accuracy lies at about 68%. - Output of the\n",
    "algorithm is the stored model.\n",
    "\n",
    "![The Standard\n",
    "Model](https://raw.githubusercontent.com/Tarnekar/bitstarter/master/validation_accuracy.png)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
