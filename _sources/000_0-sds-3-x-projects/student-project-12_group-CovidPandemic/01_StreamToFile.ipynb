{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream to parquet file\n",
    "======================\n",
    "\n",
    "This notebook allows for setup and execution of the data streaming and\n",
    "querying into a parquet file. The idea is thereafter to perform analysis\n",
    "on the parquet file.\n",
    "\n",
    "Note that this notebooks assumes one has already has downloaded several\n",
    "\"Our World in Data\" dataset csv files. This can be done by first running\n",
    "\"DownloadFilesPeriodicallyScript\" at least once.\n",
    "\n",
    "Content is based on \"038\\_StructuredStreamingProgGuide\" by Raazesh\n",
    "Sainudiin.\n",
    "\n",
    "start by copying latest downloaded csv data to data analysis folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\"file:///databricks/driver/projects/group12/logsEveryXSecs/\",\"/datasets/group12/\",true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res0: Boolean = true\n",
    "\n",
    "  \n",
    "\n",
    "check that data is in the group12 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/datasets/group12/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "check the schema for the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/datasets/group12/21_01_07_09_05_33.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     df_csv: org.apache.spark.sql.DataFrame = [iso_code: string, continent: string ... 52 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     root\n",
    ">      |-- iso_code: string (nullable = true)\n",
    ">      |-- continent: string (nullable = true)\n",
    ">      |-- location: string (nullable = true)\n",
    ">      |-- date: string (nullable = true)\n",
    ">      |-- total_cases: double (nullable = true)\n",
    ">      |-- new_cases: double (nullable = true)\n",
    ">      |-- new_cases_smoothed: double (nullable = true)\n",
    ">      |-- total_deaths: double (nullable = true)\n",
    ">      |-- new_deaths: double (nullable = true)\n",
    ">      |-- new_deaths_smoothed: double (nullable = true)\n",
    ">      |-- total_cases_per_million: double (nullable = true)\n",
    ">      |-- new_cases_per_million: double (nullable = true)\n",
    ">      |-- new_cases_smoothed_per_million: double (nullable = true)\n",
    ">      |-- total_deaths_per_million: double (nullable = true)\n",
    ">      |-- new_deaths_per_million: double (nullable = true)\n",
    ">      |-- new_deaths_smoothed_per_million: double (nullable = true)\n",
    ">      |-- reproduction_rate: double (nullable = true)\n",
    ">      |-- icu_patients: double (nullable = true)\n",
    ">      |-- icu_patients_per_million: double (nullable = true)\n",
    ">      |-- hosp_patients: double (nullable = true)\n",
    ">      |-- hosp_patients_per_million: double (nullable = true)\n",
    ">      |-- weekly_icu_admissions: double (nullable = true)\n",
    ">      |-- weekly_icu_admissions_per_million: double (nullable = true)\n",
    ">      |-- weekly_hosp_admissions: double (nullable = true)\n",
    ">      |-- weekly_hosp_admissions_per_million: double (nullable = true)\n",
    ">      |-- new_tests: double (nullable = true)\n",
    ">      |-- total_tests: double (nullable = true)\n",
    ">      |-- total_tests_per_thousand: double (nullable = true)\n",
    ">      |-- new_tests_per_thousand: double (nullable = true)\n",
    ">      |-- new_tests_smoothed: double (nullable = true)\n",
    ">      |-- new_tests_smoothed_per_thousand: double (nullable = true)\n",
    ">      |-- positive_rate: double (nullable = true)\n",
    ">      |-- tests_per_case: double (nullable = true)\n",
    ">      |-- tests_units: string (nullable = true)\n",
    ">      |-- total_vaccinations: double (nullable = true)\n",
    ">      |-- new_vaccinations: double (nullable = true)\n",
    ">      |-- total_vaccinations_per_hundred: double (nullable = true)\n",
    ">      |-- new_vaccinations_per_million: double (nullable = true)\n",
    ">      |-- stringency_index: double (nullable = true)\n",
    ">      |-- population: double (nullable = true)\n",
    ">      |-- population_density: double (nullable = true)\n",
    ">      |-- median_age: double (nullable = true)\n",
    ">      |-- aged_65_older: double (nullable = true)\n",
    ">      |-- aged_70_older: double (nullable = true)\n",
    ">      |-- gdp_per_capita: double (nullable = true)\n",
    ">      |-- extreme_poverty: double (nullable = true)\n",
    ">      |-- cardiovasc_death_rate: double (nullable = true)\n",
    ">      |-- diabetes_prevalence: double (nullable = true)\n",
    ">      |-- female_smokers: double (nullable = true)\n",
    ">      |-- male_smokers: double (nullable = true)\n",
    ">      |-- handwashing_facilities: double (nullable = true)\n",
    ">      |-- hospital_beds_per_thousand: double (nullable = true)\n",
    ">      |-- life_expectancy: double (nullable = true)\n",
    ">      |-- human_development_index: double (nullable = true)\n",
    "\n",
    "  \n",
    "\n",
    "The stream requires a user defined schema. Note that the January 2021\n",
    "schema is different compared to the December 2020 schema. Below, the\n",
    "user defined schemas are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val OurWorldinDataSchema2021 = new StructType()                      \n",
    "                      .add(\"iso_code\", \"string\")\n",
    "                      .add(\"continent\", \"string\")\n",
    "                      .add(\"location\", \"string\")\n",
    "                      .add(\"date\", \"string\")\n",
    "                      .add(\"total_cases\",\"double\")\n",
    "                      .add(\"new_cases\",\"double\")\n",
    "                      .add(\"new_cases_smoothed\",\"double\")\n",
    "                      .add(\"total_deaths\",\"double\")\n",
    "                      .add(\"new_deaths\",\"double\")\n",
    "                      .add(\"new_deaths_smoothed\",\"double\")\n",
    "                      .add(\"total_cases_per_million\",\"double\")\n",
    "                      .add(\"new_cases_per_million\",\"double\")\n",
    "                      .add(\"new_cases_smoothed_per_million\",\"double\")\n",
    "                      .add(\"total_deaths_per_million\",\"double\")\n",
    "                      .add(\"new_deaths_per_million\",\"double\")\n",
    "                      .add(\"new_deaths_smoothed_per_million\",\"double\")\n",
    "                      .add(\"reproduction_rate\", \"double\")\n",
    "                      .add(\"icu_patients\", \"double\")\n",
    "                      .add(\"icu_patients_per_million\", \"double\")\n",
    "                      .add(\"hosp_patients\", \"double\")\n",
    "                      .add(\"hosp_patients_per_million\", \"double\")\n",
    "                      .add(\"weekly_icu_admissions\", \"double\")\n",
    "                      .add(\"weekly_icu_admissions_per_million\", \"double\")\n",
    "                      .add(\"weekly_hosp_admissions\", \"double\")\n",
    "                      .add(\"weekly_hosp_admissions_per_million\", \"double\")\n",
    "                      .add(\"new_tests\", \"double\")\n",
    "                      .add(\"total_tests\", \"double\")\n",
    "                      .add(\"total_tests_per_thousand\", \"double\")\n",
    "                      .add(\"new_tests_per_thousand\", \"double\")\n",
    "                      .add(\"new_tests_smoothed\", \"double\")\n",
    "                      .add(\"new_tests_smoothed_per_thousand\", \"double\")\n",
    "                      .add(\"positive_rate\", \"double\")\n",
    "                      .add(\"tests_per_case\", \"double\")\n",
    "                      .add(\"tests_units\", \"double\")\n",
    "                      .add(\"total_vaccinations\", \"double\")\n",
    "                      .add(\"new_vaccinations\", \"double\")\n",
    "                      .add(\"stringency_index\",\"double\")\n",
    "                      .add(\"population\",\"double\")\n",
    "                      .add(\"population_density\",\"double\")\n",
    "                      .add(\"median_age\", \"double\")\n",
    "                      .add(\"aged_65_older\", \"double\")\n",
    "                      .add(\"aged_70_older\", \"double\")\n",
    "                      .add(\"gdp_per_capita\",\"double\")\n",
    "                      .add(\"extreme_poverty\",\"double\")\n",
    "                      .add(\"cardiovasc_death_rate\",\"double\")\n",
    "                      .add(\"diabetes_prevalence\",\"double\")\n",
    "                      .add(\"female_smokers\", \"double\")\n",
    "                      .add(\"male_smokers\", \"double\")\n",
    "                      .add(\"handwashing_facilities\", \"double\")\n",
    "                      .add(\"hospital_beds_per_thousand\", \"double\")\n",
    "                      .add(\"life_expectancy\",\"double\")\n",
    "                      .add(\"human_development_index\",\"double\")\n",
    "\n",
    "val OurWorldinDataSchema2020 = new StructType()                      \n",
    "                      .add(\"iso_code\", \"string\")\n",
    "                      .add(\"continent\", \"string\")\n",
    "                      .add(\"location\", \"string\")\n",
    "                      .add(\"date\", \"string\")\n",
    "                      .add(\"total_cases\",\"double\")\n",
    "                      .add(\"new_cases\",\"double\")\n",
    "                      .add(\"new_cases_smoothed\",\"double\")\n",
    "                      .add(\"total_deaths\",\"double\")\n",
    "                      .add(\"new_deaths\",\"double\")\n",
    "                      .add(\"new_deaths_smoothed\",\"double\")\n",
    "                      .add(\"total_cases_per_million\",\"double\")\n",
    "                      .add(\"new_cases_per_million\",\"double\")\n",
    "                      .add(\"new_cases_smoothed_per_million\",\"double\")\n",
    "                      .add(\"total_deaths_per_million\",\"double\")\n",
    "                      .add(\"new_deaths_per_million\",\"double\")\n",
    "                      .add(\"new_deaths_smoothed_per_million\",\"double\")\n",
    "                      .add(\"reproduction_rate\", \"double\")\n",
    "                      .add(\"icu_patients\", \"double\")\n",
    "                      .add(\"icu_patients_per_million\", \"double\")\n",
    "                      .add(\"hosp_patients\", \"double\")\n",
    "                      .add(\"hosp_patients_per_million\", \"double\")\n",
    "                      .add(\"weekly_icu_admissions\", \"double\")\n",
    "                      .add(\"weekly_icu_admissions_per_million\", \"double\")\n",
    "                      .add(\"weekly_hosp_admissions\", \"double\")\n",
    "                      .add(\"weekly_hosp_admissions_per_million\", \"double\")\n",
    "                      .add(\"total_tests\", \"double\")\n",
    "                      .add(\"new_tests\", \"double\")\n",
    "                      .add(\"total_tests_per_thousand\", \"double\")\n",
    "                      .add(\"new_tests_per_thousand\", \"double\")\n",
    "                      .add(\"new_tests_smoothed\", \"double\")\n",
    "                      .add(\"new_tests_smoothed_per_thousand\", \"double\")\n",
    "                      .add(\"tests_per_case\", \"double\")\n",
    "                      .add(\"positive_rate\", \"double\")\n",
    "                      .add(\"tests_units\", \"double\")\n",
    "                      .add(\"stringency_index\",\"double\")\n",
    "                      .add(\"population\",\"double\")\n",
    "                      .add(\"population_density\",\"double\")\n",
    "                      .add(\"median_age\", \"double\")\n",
    "                      .add(\"aged_65_older\", \"double\")\n",
    "                      .add(\"aged_70_older\", \"double\")\n",
    "                      .add(\"gdp_per_capita\",\"double\")\n",
    "                      .add(\"extreme_poverty\",\"double\")\n",
    "                      .add(\"cardiovasc_death_rate\",\"double\")\n",
    "                      .add(\"diabetes_prevalence\",\"double\")\n",
    "                      .add(\"female_smokers\", \"double\")\n",
    "                      .add(\"male_smokers\", \"double\")\n",
    "                      .add(\"handwashing_facilities\", \"double\")\n",
    "                      .add(\"hospital_beds_per_thousand\", \"double\")\n",
    "                      .add(\"life_expectancy\",\"double\")\n",
    "                      .add(\"human_development_index\",\"double\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.sql.types._\n",
    ">     OurWorldinDataSchema2021: org.apache.spark.sql.types.StructType = StructType(StructField(iso_code,StringType,true), StructField(continent,StringType,true), StructField(location,StringType,true), StructField(date,StringType,true), StructField(total_cases,DoubleType,true), StructField(new_cases,DoubleType,true), StructField(new_cases_smoothed,DoubleType,true), StructField(total_deaths,DoubleType,true), StructField(new_deaths,DoubleType,true), StructField(new_deaths_smoothed,DoubleType,true), StructField(total_cases_per_million,DoubleType,true), StructField(new_cases_per_million,DoubleType,true), StructField(new_cases_smoothed_per_million,DoubleType,true), StructField(total_deaths_per_million,DoubleType,true), StructField(new_deaths_per_million,DoubleType,true), StructField(new_deaths_smoothed_per_million,DoubleType,true), StructField(reproduction_rate,DoubleType,true), StructField(icu_patients,DoubleType,true), StructField(icu_patients_per_million,DoubleType,true), StructField(hosp_patients,DoubleType,true), StructField(hosp_patients_per_million,DoubleType,true), StructField(weekly_icu_admissions,DoubleType,true), StructField(weekly_icu_admissions_per_million,DoubleType,true), StructField(weekly_hosp_admissions,DoubleType,true), StructField(weekly_hosp_admissions_per_million,DoubleType,true), StructField(new_tests,DoubleType,true), StructField(total_tests,DoubleType,true), StructField(total_tests_per_thousand,DoubleType,true), StructField(new_tests_per_thousand,DoubleType,true), StructField(new_tests_smoothed,DoubleType,true), StructField(new_tests_smoothed_per_thousand,DoubleType,true), StructField(positive_rate,DoubleType,true), StructField(tests_per_case,DoubleType,true), StructField(tests_units,DoubleType,true), StructField(total_vaccinations,DoubleType,true), StructField(new_vaccinations,DoubleType,true), StructField(stringency_index,DoubleType,true), StructField(population,DoubleType,true), StructField(population_density,DoubleType,true), StructField(median_age,DoubleType,true), StructField(aged_65_older,DoubleType,true), StructField(aged_70_older,DoubleType,true), StructField(gdp_per_capita,DoubleType,true), StructField(extreme_poverty,DoubleType,true), StructField(cardiovasc_death_rate,DoubleType,true), StructField(diabetes_prevalence,DoubleType,true), StructField(female_smokers,DoubleType,true), StructField(male_smokers,DoubleType,true), StructField(handwashing_facilities,DoubleType,true), StructField(hospital_beds_per_thousand,DoubleType,true), StructField(life_expectancy,DoubleType,true), StructField(human_development_index,DoubleType,true))\n",
    ">     OurWorldinDataSchema2020: org.apache.spark.sql.types.StructType = StructType(StructField(iso_code,StringType,true), StructField(continent,StringType,true), StructField(location,StringType,true), StructField(date,StringType,true), StructField(total_cases,DoubleType,true), StructField(new_cases,DoubleType,true), StructField(new_cases_smoothed,DoubleType,true), StructField(total_deaths,DoubleType,true), StructField(new_deaths,DoubleType,true), StructField(new_deaths_smoothed,DoubleType,true), StructField(total_cases_per_million,DoubleType,true), StructField(new_cases_per_million,DoubleType,true), StructField(new_cases_smoothed_per_million,DoubleType,true), StructField(total_deaths_per_million,DoubleType,true), StructField(new_deaths_per_million,DoubleType,true), StructField(new_deaths_smoothed_per_million,DoubleType,true), StructField(reproduction_rate,DoubleType,true), StructField(icu_patients,DoubleType,true), StructField(icu_patients_per_million,DoubleType,true), StructField(hosp_patients,DoubleType,true), StructField(hosp_patients_per_million,DoubleType,true), StructField(weekly_icu_admissions,DoubleType,true), StructField(weekly_icu_admissions_per_million,DoubleType,true), StructField(weekly_hosp_admissions,DoubleType,true), StructField(weekly_hosp_admissions_per_million,DoubleType,true), StructField(total_tests,DoubleType,true), StructField(new_tests,DoubleType,true), StructField(total_tests_per_thousand,DoubleType,true), StructField(new_tests_per_thousand,DoubleType,true), StructField(new_tests_smoothed,DoubleType,true), StructField(new_tests_smoothed_per_thousand,DoubleType,true), StructField(tests_per_case,DoubleType,true), StructField(positive_rate,DoubleType,true), StructField(tests_units,DoubleType,true), StructField(stringency_index,DoubleType,true), StructField(population,DoubleType,true), StructField(population_density,DoubleType,true), StructField(median_age,DoubleType,true), StructField(aged_65_older,DoubleType,true), StructField(aged_70_older,DoubleType,true), StructField(gdp_per_capita,DoubleType,true), StructField(extreme_poverty,DoubleType,true), StructField(cardiovasc_death_rate,DoubleType,true), StructField(diabetes_prevalence,DoubleType,true), StructField(female_smokers,DoubleType,true), StructField(male_smokers,DoubleType,true), StructField(handwashing_facilities,DoubleType,true), StructField(hospital_beds_per_thousand,DoubleType,true), StructField(life_expectancy,DoubleType,true), StructField(human_development_index,DoubleType,true))\n",
    "\n",
    "  \n",
    "\n",
    "### Start stream\n",
    "\n",
    "In January 2021, the schema was updated compared to the schema in\n",
    "December 2020. Below, one can choose which type of csv files to stream\n",
    "below.\n",
    "\n",
    "Stream for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val OurWorldinDataStream = spark\n",
    "  .readStream\n",
    "  .schema(OurWorldinDataSchema2020) \n",
    "  .option(\"MaxFilesPerTrigger\", 1)\n",
    "  .option(\"latestFirst\", \"true\")\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"/datasets/group12/20*.csv\")\n",
    "  .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.sql.types._\n",
    ">     OurWorldinDataStream: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [iso_code: string, continent: string ... 48 more fields]\n",
    "\n",
    "  \n",
    "\n",
    "Stream for 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val OurWorldinDataStream2021 = spark\n",
    "  .readStream\n",
    "  .schema(OurWorldinDataSchema2021) \n",
    "  .option(\"MaxFilesPerTrigger\", 1)\n",
    "  .option(\"latestFirst\", \"true\")\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"/datasets/group12/21*.csv\")\n",
    "  .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.sql.types._\n",
    ">     OurWorldinDataStream2021: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [iso_code: string, continent: string ... 50 more fields]\n",
    "\n",
    "  \n",
    "\n",
    "display stream 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OurWorldinDataStream.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res81: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(OurWorldinDataStream) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "### Query to File (2020)\n",
    "\n",
    "query that saves file into a parquet file at periodic intervalls.\n",
    "Analysis will thereafter be performed on the parquet file\n",
    "\n",
    "create folders for parquet file and checkpoint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// remove any previous folders if exists\n",
    "dbutils.fs.rm(\"datasets/group12/chkpoint\",recurse=true)\n",
    "dbutils.fs.rm(\"datasets/group12/analysis\",recurse=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res14: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"datasets/group12/chkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res15: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/datasets/group12/analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res16: Boolean = true\n",
    "\n",
    "  \n",
    "\n",
    "initialize query to store data in parquet files based on column\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "\n",
    "val query = OurWorldinDataStream\n",
    "                 .select($\"iso_code\", $\"continent\", $\"location\", $\"date\", $\"total_cases\", $\"new_cases\", $\"new_cases_smoothed\", $\"total_deaths\", $\"new_deaths\",$\"new_deaths_smoothed\", $\"total_cases_per_million\", $\"new_cases_per_million\", $\"new_cases_smoothed_per_million\", $\"total_deaths_per_million\", $\"new_deaths_per_million\", $\"new_deaths_smoothed_per_million\", $\"reproduction_rate\", $\"icu_patients\", $\"icu_patients_per_million\", $\"hosp_patients\", $\"hosp_patients_per_million\", $\"weekly_icu_admissions\", $\"weekly_icu_admissions_per_million\", $\"weekly_hosp_admissions\", $\"weekly_hosp_admissions_per_million\", $\"total_tests\",$\"new_tests\", $\"total_tests_per_thousand\", $\"new_tests_per_thousand\", $\"new_tests_smoothed\",$\"new_tests_smoothed_per_thousand\", $\"tests_per_case\", $\"positive_rate\", $\"tests_units\", $\"stringency_index\", $\"population\", $\"population_density\", $\"median_age\", $\"aged_65_older\", $\"aged_70_older\", $\"gdp_per_capita\", $\"extreme_poverty\", $\"cardiovasc_death_rate\", $\"diabetes_prevalence\", $\"female_smokers\", $\"male_smokers\", $\"handwashing_facilities\", $\"hospital_beds_per_thousand\", $\"life_expectancy\", $\"human_development_index\")\n",
    "                 .writeStream\n",
    "                 //.trigger(Trigger.ProcessingTime(\"20 seconds\")) // debugging\n",
    "                 .trigger(Trigger.ProcessingTime(\"216000 seconds\")) // for each day\n",
    "                 .option(\"checkpointLocation\", \"/datasets/group12/chkpoint\")\n",
    "                 .format(\"parquet\")  \n",
    "                 .option(\"path\", \"/datasets/group12/analysis\")\n",
    "                 .start()\n",
    "                 \n",
    "query.awaitTermination() // hit cancel to terminate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "check saved parquet file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/datasets/group12/analysis\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val parquetFileDF = spark.read.parquet(\"dbfs:/datasets/group12/analysis/*.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     parquetFileDF: org.apache.spark.sql.DataFrame = [iso_code: string, continent: string ... 48 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(parquetFileDF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 12 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(parquetFileDF.orderBy($\"date\".desc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows\n",
    "\n",
    "Truncated to 12 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetFileDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res5: Long = 62500\n",
    "\n",
    "  \n",
    "\n",
    "### Query to File (2021)\n",
    "\n",
    "query that saves file into a parquet file at periodic intervalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// remove any previous folders if exists\n",
    "dbutils.fs.rm(\"datasets/group12/chkpoint2021\",recurse=true)\n",
    "dbutils.fs.rm(\"datasets/group12/analysis2021\",recurse=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"datasets/group12/chkpoint2021\")\n",
    "dbutils.fs.mkdirs(\"datasets/group12/analysis2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res18: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "\n",
    "val query = OurWorldinDataStream2021\n",
    "                 .select($\"iso_code\", $\"continent\", $\"location\", $\"date\", $\"total_cases\", $\"new_cases\", $\"new_cases_smoothed\", $\"total_deaths\", $\"new_deaths\",$\"new_deaths_smoothed\", $\"total_cases_per_million\", $\"new_cases_per_million\", $\"new_cases_smoothed_per_million\", $\"total_deaths_per_million\", $\"new_deaths_per_million\", $\"new_deaths_smoothed_per_million\", $\"reproduction_rate\", $\"icu_patients\", $\"icu_patients_per_million\", $\"hosp_patients\", $\"hosp_patients_per_million\", $\"weekly_icu_admissions\", $\"weekly_icu_admissions_per_million\", $\"weekly_hosp_admissions\", $\"weekly_hosp_admissions_per_million\", $\"total_tests\",$\"new_tests\", $\"total_tests_per_thousand\", $\"new_tests_per_thousand\", $\"new_tests_smoothed\",$\"new_tests_smoothed_per_thousand\", $\"tests_per_case\", $\"positive_rate\", $\"tests_units\", $\"stringency_index\", $\"population\", $\"population_density\", $\"median_age\", $\"aged_65_older\", $\"aged_70_older\", $\"gdp_per_capita\", $\"extreme_poverty\", $\"cardiovasc_death_rate\", $\"diabetes_prevalence\", $\"female_smokers\", $\"male_smokers\", $\"handwashing_facilities\", $\"hospital_beds_per_thousand\", $\"life_expectancy\", $\"human_development_index\")\n",
    "                 .writeStream\n",
    "                 //.trigger(Trigger.ProcessingTime(\"20 seconds\")) // debugging\n",
    "                 .trigger(Trigger.ProcessingTime(\"216000 seconds\")) // each day\n",
    "                 .option(\"checkpointLocation\", \"/datasets/group12/chkpoint2021\")\n",
    "                 .format(\"parquet\")  \n",
    "                 .option(\"path\", \"/datasets/group12/analysis2021\")\n",
    "                 .start()\n",
    "                 \n",
    "query.awaitTermination() // hit cancel to terminate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val parquetFile2021DF = spark.read.parquet(\"dbfs:/datasets/group12/analysis2021/*.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     parquetFile2021DF: org.apache.spark.sql.DataFrame = [iso_code: string, continent: string ... 48 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(parquetFile2021DF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 12 cols"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
