{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis\n",
    "======================================================================\n",
    "\n",
    "### Georg Bökman & Rasmus Kjær Høier\n",
    "\n",
    "  \n",
    "\n",
    "In this project we have used Spark Streaming and the twitter4j library\n",
    "to perform filtered streaming of tweets. As we were interested in\n",
    "combining location and sentiment information, we filtered for location\n",
    "tagged tweets. This was necessary as only around 1% of tweets coming\n",
    "straight from the twitter hose has information on the country of origin.\n",
    "\n",
    "In particular we hoped to explore the following ideas/questions: \\*\n",
    "Sentiment analysis of text can be difficult across different languages.\n",
    "However, the same emojis are used on twitter all over the world\n",
    "(although some emojis are more popular in some regions). Could this be\n",
    "used to compare sentiment across borders? \\* From the filtered stream we\n",
    "get tweets containing information on country of origin and timestamps.\n",
    "What insight can we get by visualizing tweets as a function of time and\n",
    "space?\n",
    "\n",
    "We saw this project as an opportunity to learn more about twitter and\n",
    "streaming in general as none of us had any prior experience with this.\n",
    "\n",
    "Contents\n",
    "--------\n",
    "\n",
    "Our project consists of 8 notebooks. We recommend you read through the\n",
    "first four, and if you are curious about some of the functions we use or\n",
    "how the data was collected, then have a look in the appendix notebooks\n",
    "as well. The appendices are not quite as tidy as the first four\n",
    "notebooks.\n",
    "\n",
    "-   01 Introduction\n",
    "-   02 Clustering emoticons based on tweets\n",
    "-   03 Dynamic Tweet Maps\n",
    "-   04 Conclusion\n",
    "-   05 Appendix get cc data\n",
    "-   06 Appendix Tweet carto functions\n",
    "-   07a Appendix ExtendedTwitterUtils2run\n",
    "-   07b Appendix TTTDFfunctions\n",
    "\n",
    "Notes on data collection\n",
    "------------------------\n",
    "\n",
    "Tweets were collected using functions from the course notebooks\n",
    "`07_a_appendix_extendedTwitterUtils` and `07_b_appendix_TTTDFfunctions`\n",
    "(originally numbered 025). Some minor changes were made in order to\n",
    "perform filtered streaming only of countries with a known country of\n",
    "origin.\n",
    "\n",
    "In notebook `05_appendix_get-cc-data` we run the function\n",
    "`streamFuncWithProcessing()`. This function creates a new twitter stream\n",
    "by calling the createStream methods from the `ExtendedTwitterUtils`\n",
    "object in notebook 07\\_a. One of the arguments to this method is a\n",
    "filterquery, which has been set to require that the tweet must have\n",
    "registered coordinates. Longitudes range from -180 to 180 degrees and\n",
    "latitudes range from -90 to 90 degrees, covering the entire globe.\n",
    "\n",
    "\\`\\`\\` // Create filter\n",
    "\n",
    "val locationsQuery = new FilterQuery().locations(Array(-180.0, -90.0),\n",
    "Array(180.0, 90.0)) // all locations\n",
    "\n",
    "// Create a Twitter Stream for the input source.\n",
    "\n",
    "val twitterStream = ExtendedTwitterUtils.createStream(ssc, auth,\n",
    "Some(locationsQuery)) \\`\\`\\`\n",
    "\n",
    "We used the databricks jobs feature to automatically run the data\n",
    "acquisition for 3 minutes every hour from December 22nd 2020 until\n",
    "January 2nd 2021. We also acquired data continuously on the 22nd. In\n",
    "total this yielded around 2 million tweets."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
