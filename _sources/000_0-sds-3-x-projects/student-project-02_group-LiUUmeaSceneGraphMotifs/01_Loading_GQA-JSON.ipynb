{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading GQA JSON files\n",
    "\n",
    "This is the old code attempt at reading the JSON files. The original\n",
    "JSON files are probably not formatted properly/not proper JSON files,\n",
    "which makes Spark fail in reading them when trying to figure out the\n",
    "schema during reading time. We need to read the files using the pythonic\n",
    "approach and writing them back to files, as the resulting files might be\n",
    "well-formated (hopefully). However, this is not necessary at the moment,\n",
    "as the pythonic way works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/shared_uploads/scenegraph_motifs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data:\n",
    "######## throws an error:\n",
    "# Reload the page and try again. If the error persists, contact support. Reference error code: 73f0fdda29f9485aaa2ec67c7e881e68\n",
    "train_scene_data = spark.read.text(\"dbfs:/FileStore/shared_uploads/dali@cs.umu.se/train_sceneGraphs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tr_sc = sc.textFile(\"dbfs:/FileStore/shared_uploads/dali@cs.umu.se/train_sceneGraphs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scene_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val val_scene_data = spark.read.json(\"dbfs:/FileStore/shared_uploads/scenegraph_motifs/val_sceneGraphs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still takes too long and fails\n",
    "val_scene_data = sqlContext.read.json(\"dbfs:/FileStore/shared_uploads/scenegraph_motifs/val_sceneGraphs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scene_data.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scene_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
