{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.mllib.recommendation.ALS\n",
    "import org.apache.spark.mllib.recommendation.MatrixFactorizationModel\n",
    "import org.apache.spark.mllib.recommendation.Rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import spark.implicits._\n",
    ">     import org.apache.spark.sql.functions._\n",
    ">     import org.apache.spark.mllib.recommendation.ALS\n",
    ">     import org.apache.spark.mllib.recommendation.MatrixFactorizationModel\n",
    ">     import org.apache.spark.mllib.recommendation.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fileName=\"dbfs:/FileStore/tables/project4/hetrec2011-lastfm-2k/user_artists.dat\"\n",
    "val df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").option(\"inferSchema\",\"true\").load(fileName).withColumnRenamed(\"weight\",\"play_count\").withColumnRenamed(\"userID\", \"listenerID\")\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     fileName: String = dbfs:/FileStore/tables/project4/hetrec2011-lastfm-2k/user_artists.dat\n",
    ">     df: org.apache.spark.sql.DataFrame = [listenerID: int, artistID: int ... 1 more field]\n",
    ">     res7: df.type = [listenerID: int, artistID: int ... 1 more field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(desc(\"play_count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fileName=\"dbfs:/FileStore/tables/project4/hetrec2011-lastfm-2k/artists.dat\"\n",
    "val artist_names = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").option(\"inferSchema\",\"true\").load(fileName).withColumnRenamed(\"id\",\"artistID\").select(\"artistID\",\"name\")\n",
    "artist_names.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     fileName: String = dbfs:/FileStore/tables/project4/hetrec2011-lastfm-2k/artists.dat\n",
    ">     artist_names: org.apache.spark.sql.DataFrame = [artistID: int, name: string]\n",
    ">     res9: artist_names.type = [artistID: int, name: string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Number of data points: \" + df.count())\n",
    "df.agg(countDistinct(\"listenerID\") as \"Number of listeners\").show()\n",
    "df.agg(countDistinct(\"artistID\") as \"Number of artists\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Number of data points: 92834\n",
    ">     +-------------------+\n",
    ">     |Number of listeners|\n",
    ">     +-------------------+\n",
    ">     |               1892|\n",
    ">     +-------------------+\n",
    ">\n",
    ">     +-----------------+\n",
    ">     |Number of artists|\n",
    ">     +-----------------+\n",
    ">     |            17632|\n",
    ">     +-----------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Sparsity\n",
    "println((17632.0*1892.0-92834.0)/(17632.0*1892.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     0.9972171848800758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.select(\"play_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val artist_data = df.groupBy(\"artistID\").agg(count(\"artistID\") as \"unique_listeners\",\n",
    "                                                      sum(\"play_count\") as \"total_plays_artist\")\n",
    "artist_data.sort(desc(\"total_plays_artist\")).show(5)\n",
    "artist_data.sort(desc(\"unique_listeners\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Most popular artists with respect to total plays\n",
    "artist_names.filter($\"artistID\"===289 || $\"artistID\"===72 || $\"artistID\"===89 || $\"artistID\"===292 || $\"artistID\"===498).show()\n",
    "\n",
    "//Most popular artists with respect to unique listeners\n",
    "artist_names.filter($\"artistID\"===89 || $\"artistID\"===289 || $\"artistID\"===288 || $\"artistID\"===227 || $\"artistID\"===300).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +--------+------------------+\n",
    ">     |artistID|              name|\n",
    ">     +--------+------------------+\n",
    ">     |      72|      Depeche Mode|\n",
    ">     |      89|         Lady Gaga|\n",
    ">     |     289|    Britney Spears|\n",
    ">     |     292|Christina Aguilera|\n",
    ">     |     498|          Paramore|\n",
    ">     +--------+------------------+\n",
    ">\n",
    ">     +--------+--------------+\n",
    ">     |artistID|          name|\n",
    ">     +--------+--------------+\n",
    ">     |      89|     Lady Gaga|\n",
    ">     |     227|   The Beatles|\n",
    ">     |     288|       Rihanna|\n",
    ">     |     289|Britney Spears|\n",
    ">     |     300|    Katy Perry|\n",
    ">     +--------+--------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(artist_data.select(\"unique_listeners\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(artist_data.select(\"total_plays_artist\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(artist_data.select(\"total_plays_artist\", \"unique_listeners\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val user_data = df.groupBy(\"listenerID\").agg(count(\"listenerID\") as \"unique_artists\",\n",
    "                                                  sum(\"play_count\") as \"total_plays_listener\")\n",
    "user_data.sort(desc(\"total_plays_listener\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +----------+--------------+--------------------+\n",
    ">     |listenerID|unique_artists|total_plays_listener|\n",
    ">     +----------+--------------+--------------------+\n",
    ">     |       757|            50|              480039|\n",
    ">     |      2000|            50|              468409|\n",
    ">     |      1418|            50|              416349|\n",
    ">     |      1642|            50|              388251|\n",
    ">     |      1094|            50|              379125|\n",
    ">     +----------+--------------+--------------------+\n",
    ">     only showing top 5 rows\n",
    ">\n",
    ">     user_data: org.apache.spark.sql.DataFrame = [listenerID: int, unique_artists: bigint ... 1 more field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(user_data.sort(desc(\"total_plays_listener\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df_joined = df.join(artist_data, \"artistID\").join(user_data, \"listenerID\").join(artists,\"artistID\").select(\"listenerID\", \"artistID\",\"play_count\", \"name\", \"unique_artists\",\"unique_listeners\", \"total_plays_listener\",\"total_plays_artist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     df_joined: org.apache.spark.sql.DataFrame = [listenerID: int, artistID: int ... 6 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df_joined_filtered = df_joined.filter($\"unique_artists\">4 && $\"unique_listeners\">4)\n",
    "df_joined_filtered.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     df_joined_filtered: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [listenerID: int, artistID: int ... 6 more fields]\n",
    ">     res462: df_joined_filtered.type = [listenerID: int, artistID: int ... 6 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_filtered.sort(desc(\"play_count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val user_artist=df_joined_filtered.select(\"listenerID\", \"artistID\", \"play_count\") //Change DFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\n",
    "user_artist.show(10)\n",
    "println(\"Number of data points: \" + user_artist.count())\n",
    "user_artist.agg(countDistinct(\"listenerID\") as \"Number of listeners\").show()\n",
    "user_artist.agg(countDistinct(\"artistID\") as \"Number of artists\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +----------+--------+----------+\n",
    ">     |listenerID|artistID|play_count|\n",
    ">     +----------+--------+----------+\n",
    ">     |         2|      51|     13883|\n",
    ">     |         2|      52|     11690|\n",
    ">     |         2|      53|     11351|\n",
    ">     |         2|      54|     10300|\n",
    ">     |         2|      55|      8983|\n",
    ">     |         2|      56|      6152|\n",
    ">     |         2|      57|      5955|\n",
    ">     |         2|      58|      4616|\n",
    ">     |         2|      59|      4337|\n",
    ">     |         2|      61|      3923|\n",
    ">     +----------+--------+----------+\n",
    ">     only showing top 10 rows\n",
    ">\n",
    ">     Number of data points: 70652\n",
    ">     +-------------------+\n",
    ">     |Number of listeners|\n",
    ">     +-------------------+\n",
    ">     |               1858|\n",
    ">     +-------------------+\n",
    ">\n",
    ">     +-----------------+\n",
    ">     |Number of artists|\n",
    ">     +-----------------+\n",
    ">     |             2799|\n",
    ">     +-----------------+\n",
    ">\n",
    ">     user_artist: org.apache.spark.sql.DataFrame = [listenerID: int, artistID: int ... 1 more field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val user_artistRDD = user_artist.rdd.map(row => Rating(row.getInt(0),row.getInt(1), row.getInt(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     user_artistRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[744814] at map at command-2294440354339338:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val Array(trainingRDD, validationRDD, testRDD) = user_artistRDD.randomSplit(Array(0.8, 0.2, 0.0), 0L)\n",
    "trainingRDD.cache()\n",
    "validationRDD.cache()\n",
    "testRDD.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     trainingRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[744880] at randomSplit at command-3103574048361401:1\n",
    ">     validationRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[744881] at randomSplit at command-3103574048361401:1\n",
    ">     testRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[744882] at randomSplit at command-3103574048361401:1\n",
    ">     res450: testRDD.type = MapPartitionsRDD[744882] at randomSplit at command-3103574048361401:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rank = 15\n",
    "val numIterations = 10\n",
    "val lambda=0.25\n",
    "val alpha=1.0\n",
    "val model = ALS.trainImplicit(trainingRDD, rank, numIterations, lambda, alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     rank: Int = 15\n",
    ">     numIterations: Int = 10\n",
    ">     lambda: Double = 0.25\n",
    ">     alpha: Double = 1.0\n",
    ">     model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@556d74d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_filtered.filter($\"listenerID\"===1810).sort(desc(\"play_count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +----------+--------+----------+--------------+--------------+----------------+--------------------+------------------+\n",
    ">     |listenerID|artistID|play_count|          name|unique_artists|unique_listeners|total_plays_listener|total_plays_artist|\n",
    ">     +----------+--------+----------+--------------+--------------+----------------+--------------------+------------------+\n",
    ">     |      1810|     288|     27486|       Rihanna|             9|             478|               30179|            905417|\n",
    ">     |      1810|     300|      1850|    Katy Perry|             9|             471|               30179|            532541|\n",
    ">     |      1810|     475|       358|        Eminem|             9|             202|               30179|            321009|\n",
    ">     |      1810|     701|       162|       Shakira|             9|             319|               30179|            688529|\n",
    ">     |      1810|      89|       160|     Lady Gaga|             9|             610|               30179|           1291386|\n",
    ">     |      1810|     891|       136|         Jewel|             9|              18|               30179|              9412|\n",
    ">     |      1810|    1760|        12|  Renato Russo|             9|               7|               30179|              3184|\n",
    ">     |      1810|     466|         8|         Ke$ha|             9|             361|               30179|            384404|\n",
    ">     |      1810|     289|         7|Britney Spears|             9|             521|               30179|           2393139|\n",
    ">     +----------+--------+----------+--------------+--------------+----------------+--------------------+------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingRDD.filter{case Rating(listener,artist,plays) => listener==1810}.map{case Rating(listener,artist,plays) =>(artist,plays)}.sortBy(_._2, ascending = false).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res457: Array[(Int, Double)] = Array((300,1850.0), (701,162.0), (891,136.0), (1760,12.0), (466,8.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationRDD.filter{case Rating(listener,artist,plays) => listener==1611}.map{case Rating(listener,artist,plays) =>(artist,plays)}.sortBy(_._2,  ascending = false).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res441: Array[(Int, Double)] = Array((2500,651.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val predicted = model.recommendProducts(1810, 10)\n",
    "\n",
    "//predicted.map{case Rating(user, artist, score) => artist}.zipWithIndex.filter(p => p._1 == 229).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     predicted: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(1810,333,0.9459016710075482), Rating(1810,89,0.9437156291908422), Rating(1810,679,0.9303599122893169), Rating(1810,300,0.9231183336384853), Rating(1810,331,0.9190269807771281), Rating(1810,298,0.908096096885354), Rating(1810,466,0.9011996354190186), Rating(1810,306,0.8986075315150057), Rating(1810,288,0.892545317423586), Rating(1810,289,0.8892359575673122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.filter($\"artistID\"===333 || $\"artistID\"===89 || $\"artistID\"===679 || $\"artistID\"===300).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +--------+-------------+\n",
    ">     |artistID|         name|\n",
    ">     +--------+-------------+\n",
    ">     |      89|    Lady Gaga|\n",
    ">     |     300|   Katy Perry|\n",
    ">     |     333|Avril Lavigne|\n",
    ">     |     679|    Glee Cast|\n",
    ">     +--------+-------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist.filter($\"listenerID\"===100 && $\"artistID\"===424 ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +----------+--------+----------+\n",
    ">     |listenerID|artistID|play_count|\n",
    ">     +----------+--------+----------+\n",
    ">     +----------+--------+----------+"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
