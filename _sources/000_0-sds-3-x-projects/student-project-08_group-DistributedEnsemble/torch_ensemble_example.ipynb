{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data creation\n",
    "num_samples = 500\n",
    "means = torch.tensor([-2, 2], dtype=float)\n",
    "stds = torch.tensor([1, 1], dtype=float)\n",
    "x1 = torch.normal(mean=means[0], std=stds[0], size=(num_samples, 1))\n",
    "x2 = torch.normal(mean=means[1], std=stds[1], size=(num_samples, 1))\n",
    "X = torch.cat((x1, x2), dim=0)\n",
    "\n",
    "y1 = torch.zeros((num_samples, 1))\n",
    "y2 = torch.ones((num_samples, 1))\n",
    "Y = torch.cat((y1, y2), dim=0)\n",
    "\n",
    "print(X.size())\n",
    "print(Y.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "inds = torch.randperm(X.size(0))\n",
    "X = X[inds, :]\n",
    "Y = Y[inds, :]\n",
    "\n",
    "num_train = 800\n",
    "train_X = X[:num_train, :]\n",
    "train_Y = Y[:num_train, :]\n",
    "\n",
    "test_X = X[num_train:, :]\n",
    "test_Y = Y[num_train:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple linear model\n",
    "class SimpleModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleModel, self).__init__()\n",
    "  \n",
    "    input_dim = 1\n",
    "    num_classes = 2\n",
    "    self.fc = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "  def forward(self,x):\n",
    "      return self.fc(x)\n",
    "      \n",
    "  def predict(self,x):\n",
    "    return torch.argmax(nn.Softmax(dim=-1)(self.forward(x)), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, test_X, num_epochs=10):\n",
    "  model = SimpleModel()\n",
    "  loss_func = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(model.parameters(),lr = 0.1)\n",
    "  model.train()\n",
    "  inputs, labels = data\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    output = model(inputs)\n",
    "    loss = loss_func(output,labels[:, 0].long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "  \n",
    "  print(\"Epoch: {} \\tRunning Loss: {:.6f}\".format(epoch+1, running_loss))\n",
    "  \n",
    "  return model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sequential test (note: won't work now that train_model returns model.state_dict, but we could send state_dict to the predict function and use model.load_state_dict())\n",
    "M1 = SimpleModel()\n",
    "M2 = SimpleModel()\n",
    "M3 = SimpleModel()\n",
    "\n",
    "ensemble_list = [M1, M2, M3]\n",
    "\n",
    "# Sequential training and testing\n",
    "trained_ensemble = [train_model(ensemble_member, (train_X, train_Y)) for ensemble_member in ensemble_list]\n",
    "predicted_labels = [ensemble_member.predict(test_X) for ensemble_member in trained_ensemble]\n",
    "test_acc = [np.mean(p.data.numpy() == test_Y.data.numpy()) for p in predicted_labels]\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt at parallel training\n",
    "#ensemble_data_list = [(M1, (train_X, train_Y)), (M2, (train_X, train_Y)), (M3, (train_X, train_Y))]\n",
    "ensemble_data_list = [(train_X, train_Y), (train_X, train_Y), (train_X, train_Y)]\n",
    "par_ensemble_data = sc.parallelize(ensemble_data_list)\n",
    "trained_ensemble = par_ensemble_data.map(lambda ensemble_member: train_model(ensemble_member, test_X)).collect()\n",
    "print(trained_ensemble)\n",
    "#output_ens = trained_ensemble.map(lambda ensemble_member: next(ensemble_member[0].parameters()))\n",
    "\n",
    "#predicted_labels = trained_ensemble.map(lambda ensemble_member: ensemble_member.predict(test_X))\n",
    "#test_acc = predicted_labels.map(lambda p: np.mean(p.data.numpy() == test_Y.data.numpy())).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
