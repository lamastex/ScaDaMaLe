{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val k_mers_df_train = spark.read.parquet(\"dbfs:/FileStore/shared_uploads/caylak@kth.se/data_train\").cache()\n",
    "val k_mers_df_test = spark.read.parquet(\"dbfs:/FileStore/shared_uploads/caylak@kth.se/data_test\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     k_mers_df_train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [genome: string, label: string ... 1 more field]\n",
    ">     k_mers_df_test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [genome: string, label: string ... 1 more field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val k_mers_df_train = spark.read.parquet(\"dbfs:/FileStore/shared_uploads/caylak@kth.se/data_train_nonoverlapping\").cache()\n",
    "val k_mers_df_test = spark.read.parquet(\"dbfs:/FileStore/shared_uploads/caylak@kth.se/data_test_nonoverlapping\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     k_mers_df_train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [genome: string, label: string ... 1 more field]\n",
    ">     k_mers_df_test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [genome: string, label: string ... 1 more field]\n",
    "\n",
    "  \n",
    "\n",
    "#### Format data\n",
    "\n",
    "Generate word count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.RegexTokenizer\n",
    "\n",
    "// Set params for RegexTokenizer\n",
    "val tokenizer = new RegexTokenizer()\n",
    ".setPattern(\"[\\\\W_]+\") // break by white space character(s)  - try to remove emails and other patterns\n",
    ".setInputCol(\"genome\") // name of the input column\n",
    ".setOutputCol(\"tokens\") // name of the output column\n",
    "\n",
    "// Tokenize document\n",
    "val tokenized_df_train = tokenizer.transform(k_mers_df_train)\n",
    "val tokenized_df_test = tokenizer.transform(k_mers_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.ml.feature.RegexTokenizer\n",
    ">     tokenizer: org.apache.spark.ml.feature.RegexTokenizer = RegexTokenizer: uid=regexTok_5df744efa843, minTokenLength=1, gaps=true, pattern=[\\W_]+, toLowercase=true\n",
    ">     tokenized_df_train: org.apache.spark.sql.DataFrame = [genome: string, label: string ... 2 more fields]\n",
    ">     tokenized_df_test: org.apache.spark.sql.DataFrame = [genome: string, label: string ... 2 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tokenized_df_train.select(\"tokens\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.CountVectorizer\n",
    "val vectorizer = new CountVectorizer()\n",
    "      .setInputCol(\"tokens\")\n",
    "      .setOutputCol(\"features\")\n",
    "      .setMinDF(10)\n",
    "      .fit(tokenized_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.ml.feature.CountVectorizer\n",
    ">     vectorizer: org.apache.spark.ml.feature.CountVectorizerModel = CountVectorizerModel: uid=cntVec_9226a16a835f, vocabularySize=241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val vocabList = vectorizer.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     vocabList: Array[String] = Array(ttt, tgt, aaa, tta, aca, ttg, taa, att, aat, ctt, caa, tga, gtt, atg, act, aga, tat, tac, aac, tgg, tgc, aag, tca, cta, ttc, tct, gtg, agt, gaa, cat, gct, ctg, cac, gta, ata, tag, gat, ggt, cag, acc, gca, cca, atc, agg, gac, cct, agc, gag, gga, ctc, gtc, ggc, tcc, gcc, acg, cgt, ggg, ccc, tcg, cgc, cga, gcg, cgg, ccg, nnn, nna, naa, ntt, tnn, cnn, gnn, ann, nnt, nng, nnc, agn, ttn, aan, acn, tan, nat, tcn, ngt, nct, can, gtn, ctn, nta, atn, tgn, ana, nca, ggn, nga, tna, nac, ntg, gcn, gan, tgk, ngc, ccn, ncc, ngg, tnt, ntc, nag, agk, yta, cnt, ktt, aya, gkt, kta, gnt, nan, ytt, ktg, gkc, tty, ayt, tay, yaa, acy, gsc, aay, tgy, ggk, ant, tyt, yac, tya, yat, anc, ang, cay, tkt, cak, cna, cng, rcc, akt, ggw, aty, cgn, gyt, tng, acw, aak, cyt, ytg, raa, yca, ntn, gay, gna, kat, kct, gnc, ngn, cty, tkg, tnc, yag, ayc, kca, aka, tyg, gka, ygt, cnc, cya, ttk, ayg, tka, gng, maa, tth, yga, ncn, ama, aar, kag, ytc, gtk, cch, ncg, kaa, ctk, gty, yct, ara, rtg, ckt, tar, gya, kac, tgr, crc, ccy, tkc, tak, akg, tyc, grt, gcy, trt, ggr, ygg, gak, gcr, kgt, ygc, cgk, wga, wtc, tma, tck, atr, waa, vcc, cwt, tcy, tgs, rgc, rac, agy, kgc, gam, haa, agr, rgt, tha, cyc, atk, gtr, tra, nam, gkg, gwg, cra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabList.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res17: Int = 241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create vector of token counts\n",
    "val countVectors_train = vectorizer.transform(tokenized_df_train).select(\"id\", \"features\")\n",
    "val countVectors_test = vectorizer.transform(tokenized_df_test).select(\"id\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     countVectors_train: org.apache.spark.sql.DataFrame = [id: bigint, features: vector]\n",
    ">     countVectors_test: org.apache.spark.sql.DataFrame = [id: bigint, features: vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.linalg.{Vector => MLVector}\n",
    "import org.apache.spark.mllib.{linalg => mllib}\n",
    "import org.apache.spark.ml.{linalg => ml}\n",
    "\n",
    "val lda_countVector_train = countVectors_train.map { case Row(id: Long, countVector: MLVector) => (id, mllib.Vectors.fromML(countVector)) }.cache()\n",
    "val lda_countVector_test = countVectors_test.map { case Row(id: Long, countVector: MLVector) => (id, mllib.Vectors.fromML(countVector)) }.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.ml.linalg.{Vector=>MLVector}\n",
    ">     import org.apache.spark.mllib.{linalg=>mllib}\n",
    ">     import org.apache.spark.ml.{linalg=>ml}\n",
    ">     lda_countVector_train: org.apache.spark.sql.Dataset[(Long, org.apache.spark.mllib.linalg.Vector)] = [_1: bigint, _2: vector]\n",
    ">     lda_countVector_test: org.apache.spark.sql.Dataset[(Long, org.apache.spark.mllib.linalg.Vector)] = [_1: bigint, _2: vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n",
    "import org.apache.spark.ml.linalg.{Vectors => NewVectors}\n",
    "\n",
    "\n",
    "val lda_countVector_train_1 = lda_countVector_train.map({case (a,b) =>(a,b.asML)})\n",
    "val lda_countVector_test_1 = lda_countVector_test.map({case (a,b) =>(a,b.asML)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.mllib.linalg.{Vectors=>OldVectors}\n",
    ">     import org.apache.spark.ml.linalg.{Vectors=>NewVectors}\n",
    ">     lda_countVector_train_1: org.apache.spark.sql.Dataset[(Long, org.apache.spark.ml.linalg.Vector)] = [_1: bigint, _2: vector]\n",
    ">     lda_countVector_test_1: org.apache.spark.sql.Dataset[(Long, org.apache.spark.ml.linalg.Vector)] = [_1: bigint, _2: vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainDF = lda_countVector_train_1.toDF()\n",
    "val testDF = lda_countVector_test_1.toDF()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     trainDF: org.apache.spark.sql.DataFrame = [_1: bigint, _2: vector]\n",
    ">     testDF: org.apache.spark.sql.DataFrame = [_1: bigint, _2: vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "\n",
    "val mergedTrainingData = trainDF.join(k_mers_df_train,trainDF(\"_1\") === k_mers_df_train(\"id\"),\"inner\").withColumnRenamed(\"_2\",\"features\").drop(\"_1\")\n",
    "val mergedTestData = testDF.join(k_mers_df_test,testDF(\"_1\") === k_mers_df_test(\"id\"),\"inner\").withColumnRenamed(\"_2\",\"features\").drop(\"_1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     mergedTrainingData: org.apache.spark.sql.DataFrame = [features: vector, genome: string ... 2 more fields]\n",
    ">     mergedTestData: org.apache.spark.sql.DataFrame = [features: vector, genome: string ... 2 more fields]\n",
    "\n",
    "  \n",
    "\n",
    "### Classification\n",
    "\n",
    "The count vectors are used as features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.{StringIndexer,VectorAssembler}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.feature.LabeledPoint\n",
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "\n",
    "val transformers = Array(\n",
    "              new StringIndexer().setInputCol(\"label\").setOutputCol(\"label_id\"))\n",
    "\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier() \n",
    "              .setLabelCol(\"label_id\")\n",
    "              .setFeaturesCol(\"features\")\n",
    "              .setNumTrees(500)\n",
    "              .setFeatureSubsetStrategy(\"auto\")\n",
    "              .setImpurity(\"gini\")\n",
    "              .setMaxDepth(20)\n",
    "              .setMaxBins(32)\n",
    "              .setSeed(12345)\n",
    "\n",
    "val model = new Pipeline().setStages(transformers :+ rf).fit(mergedTrainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.ml.feature.{StringIndexer, VectorAssembler}\n",
    ">     import org.apache.spark.ml.Pipeline\n",
    ">     import org.apache.spark.ml.feature.LabeledPoint\n",
    ">     import org.apache.spark.ml.classification.RandomForestClassifier\n",
    ">     import org.apache.spark.ml.linalg.Vector\n",
    ">     transformers: Array[org.apache.spark.ml.feature.StringIndexer] = Array(strIdx_e8cf65204547)\n",
    ">     rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_0a45a46b7366\n",
    ">     model: org.apache.spark.ml.PipelineModel = pipeline_14ad91398432\n",
    "\n",
    "  \n",
    "\n",
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "def evaluateModel(model: org.apache.spark.ml.PipelineModel, df: org.apache.spark.sql.DataFrame){\n",
    "  val predictionsOnData = model.transform(df)\n",
    "  val predictionAndLabelsRdd = predictionsOnData.select(\"prediction\", \"label_id\").as[(Double,Double)].rdd\n",
    "\n",
    "  val metricsMulti = new MulticlassMetrics(predictionAndLabelsRdd)\n",
    "  val accuracy = metricsMulti.accuracy\n",
    "  \n",
    "  val fm0 = metricsMulti.fMeasure(0)\n",
    "  val fm1 = metricsMulti.fMeasure(1)\n",
    "  val fm2 = metricsMulti.fMeasure(2)\n",
    "  val fm3 = metricsMulti.fMeasure(3)\n",
    "  val fm4 = metricsMulti.fMeasure(4)\n",
    "  val fm5 = metricsMulti.fMeasure(5)\n",
    "  \n",
    "  println(\"Confusion matrix:\")\n",
    "  println(metricsMulti.confusionMatrix)\n",
    "  \n",
    "  println(\"Summary Statistics\")\n",
    "  println(s\"Accuracy = $accuracy\")\n",
    "  \n",
    "  println(s\"fm0 = $fm0\")\n",
    "  println(s\"fm1 = $fm1\")\n",
    "  println(s\"fm2 = $fm2\")\n",
    "  println(s\"fm3 = $fm3\")\n",
    "  println(s\"fm4 = $fm4\")\n",
    "  println(s\"fm5 = $fm5\")\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "###### Evaluation Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel(model, mergedTrainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Confusion matrix:\n",
    ">     12776.0  0.0     0.0     0.0    0.0    0.0   \n",
    ">     70.0     6955.0  3.0     0.0    0.0    0.0   \n",
    ">     139.0    1.0     1002.0  1.0    0.0    0.0   \n",
    ">     133.0    0.0     4.0     756.0  0.0    0.0   \n",
    ">     36.0     0.0     0.0     0.0    175.0  0.0   \n",
    ">     33.0     0.0     0.0     0.0    0.0    71.0  \n",
    ">     Summary Statistics\n",
    ">     Accuracy = 0.981042654028436\n",
    ">     fm0 = 0.9841697800716405\n",
    ">     fm1 = 0.99470823798627\n",
    ">     fm2 = 0.9312267657992566\n",
    ">     fm3 = 0.9163636363636364\n",
    ">     fm4 = 0.9067357512953368\n",
    ">     fm5 = 0.8114285714285714\n",
    "\n",
    "  \n",
    "\n",
    "##### Evaluation Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel(model, mergedTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Confusion matrix:\n",
    ">     5450.0  8.0     6.0    4.0    0.0   0.0   \n",
    ">     140.0   2743.0  8.0    0.0    0.0   0.0   \n",
    ">     189.0   7.0     314.0  6.0    0.0   0.0   \n",
    ">     116.0   1.0     7.0    269.0  0.0   0.0   \n",
    ">     44.0    2.0     1.0    3.0    46.0  0.0   \n",
    ">     9.0     0.0     0.0    0.0    0.0   22.0  \n",
    ">     Summary Statistics\n",
    ">     Accuracy = 0.9413517828632251\n",
    ">     fm0 = 0.9548002803083393\n",
    ">     fm1 = 0.9706298655343242\n",
    ">     fm2 = 0.7370892018779341\n",
    ">     fm3 = 0.7970370370370371\n",
    ">     fm4 = 0.647887323943662\n",
    ">     fm5 = 0.8301886792452831"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
