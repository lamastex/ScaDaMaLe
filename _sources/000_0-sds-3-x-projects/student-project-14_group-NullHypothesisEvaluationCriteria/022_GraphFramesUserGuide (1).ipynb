{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ScaDaMaLe, Scalable Data Science and Distributed Machine Learning](https://lamastex.github.io/scalable-data-science/sds/3/x/)\n",
    "==============================================================================================================================\n",
    "\n",
    "Distributed Vertex Programming using GraphX\n",
    "-------------------------------------------\n",
    "\n",
    "This is an augmentation of\n",
    "<http://go.databricks.com/hubfs/notebooks/3-GraphFrames-User-Guide-scala.html>\n",
    "that was last retrieved in 2019.\n",
    "\n",
    "See:\n",
    "\n",
    "-   <https://amplab.cs.berkeley.edu/wp-content/uploads/2014/09/graphx.pdf>\n",
    "-   <https://amplab.github.io/graphx/>\n",
    "-   <https://spark.apache.org/docs/latest/graphx-programming-guide.html>\n",
    "-   <https://databricks.com/blog/2016/03/03/introducing-graphframes.html>\n",
    "-   <https://databricks.com/blog/2016/03/16/on-time-flight-performance-with-spark-graphframes.html>\n",
    "-   <http://ampcamp.berkeley.edu/big-data-mini-course/graph-analytics-with-graphx.html>\n",
    "\n",
    "And of course the databricks guide: \\*\n",
    "<https://docs.databricks.com/spark/latest/graph-analysis/index.html>\n",
    "\n",
    "*Use the source, Luke/Lea!*\n",
    "\n",
    "-   <https://github.com/graphframes/graphframes>\n",
    "\n",
    "Community Packages in Spark - more generally\n",
    "--------------------------------------------\n",
    "\n",
    "Let us recall the following quoate in Chapter 10 of *High Performance\n",
    "Spark* book (needs access to Orielly publishers via your\n",
    "library/subscription): -\n",
    "https://learning.oreilly.com/library/view/high-performance-spark/9781491943199/ch10.html\\#components\n",
    "\n",
    "> Beyond the integrated components, the community packages can add\n",
    "> important functionality to Spark, sometimes even superseding built-in\n",
    "> functionalityâ€”like with GraphFrames.\n",
    "\n",
    "Here we introduce you to GraphFrames quickly so you don't need to drop\n",
    "down to the GraphX library that requires more understanding of caching\n",
    "and checkpointing to keep the vertex program's DAG from exploding or\n",
    "becoming inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//This allows easy embedding of publicly available information into any other notebook\n",
    "//when viewing in git-book just ignore this block - you may have to manually chase the URL in frameIt(\"URL\").\n",
    "//Example usage:\n",
    "// displayHTML(frameIt(\"https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation#Topics_in_LDA\",250))\n",
    "def frameIt( u:String, h:Int ) : String = {\n",
    "      \"\"\"<iframe \n",
    " src=\"\"\"\"+ u+\"\"\"\"\n",
    " width=\"95%\" height=\"\"\"\" + h + \"\"\"\"\n",
    " sandbox>\n",
    "  <p>\n",
    "    <a href=\"http://spark.apache.org/docs/latest/index.html\">\n",
    "      Fallback link for browsers that, unlikely, don't support frames\n",
    "    </a>\n",
    "  </p>\n",
    "</iframe>\"\"\"\n",
    "   }\n",
    "displayHTML(frameIt(\"https://amplab.github.io/graphx/\",700))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayHTML(frameIt(\"https://spark.apache.org/docs/latest/graphx-programming-guide.html#optimized-representation\",800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "GraphFrames User Guide (Scala)\n",
    "==============================\n",
    "\n",
    "GraphFrames is a package for Apache Spark which provides DataFrame-based\n",
    "Graphs. It provides high-level APIs in Scala, Java, and Python. It aims\n",
    "to provide both the functionality of GraphX and extended functionality\n",
    "taking advantage of Spark DataFrames. This extended functionality\n",
    "includes motif finding, DataFrame-based serialization, and highly\n",
    "expressive graph queries.\n",
    "\n",
    "The GraphFrames package is available from [Spark\n",
    "Packages](http://spark-packages.org/package/graphframes/graphframes).\n",
    "\n",
    "This notebook demonstrates examples from the GraphFrames User Guide:\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.version // link the right library depending on Spark version of the cluster that's running\n",
    "// spark version 2.3.0 works with graphframes:graphframes:0.7.0-spark2.3-s_2.11\n",
    "// spark version 3.0.1 works with graphframes:graphframes:0.8.1-spark3.0-s_2.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res2: String = 3.0.1\n",
    "\n",
    "  \n",
    "\n",
    "Since databricks.com stopped allowing IFrame embeds we have to open it\n",
    "in a separate window now. The blog is insightful and worth a perusal:\n",
    "\n",
    "-   https://databricks.com/blog/2016/03/03/introducing-graphframes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// we first need to install the library - graphframes as a Spark package - and attach it to our cluster - see note two cells above!\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.graphframes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.sql._\n",
    ">     import org.apache.spark.sql.functions._\n",
    ">     import org.graphframes._\n",
    "\n",
    "  \n",
    "\n",
    "Creating GraphFrames\n",
    "--------------------\n",
    "\n",
    "Let us try to create an example social network from the blog: \\*\n",
    "<https://databricks.com/blog/2016/03/03/introducing-graphframes.html>.\n",
    "\n",
    "![](https://databricks.com/wp-content/uploads/2016/03/social-network-graph-diagram.png)\n",
    "\n",
    "Users can create GraphFrames from vertex and edge DataFrames.\n",
    "\n",
    "-   **Vertex DataFrame:** A vertex DataFrame should contain a special\n",
    "    column named `id` which specifies unique IDs for each vertex in the\n",
    "    graph.\n",
    "-   **Edge DataFrame:** An edge DataFrame should contain two special\n",
    "    columns: `src` (source vertex ID of edge) and `dst` (destination\n",
    "    vertex ID of edge).\n",
    "\n",
    "Both DataFrames can have arbitrary other columns. Those columns can\n",
    "represent vertex and edge attributes.\n",
    "\n",
    "In our example, we can use a GraphFrame can store data or properties\n",
    "associated with each vertex and edge.\n",
    "\n",
    "In our social network, each user might have an age and name, and each\n",
    "connection might have a relationship type.\n",
    "\n",
    "Create the vertices and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Vertex DataFrame\n",
    "val v = sqlContext.createDataFrame(List(\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 30),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 36),\n",
    "  (\"g\", \"Gabby\", 60)\n",
    ")).toDF(\"id\", \"name\", \"age\")\n",
    "\n",
    "// Edge DataFrame\n",
    "val e = sqlContext.createDataFrame(List(\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\")\n",
    ")).toDF(\"src\", \"dst\", \"relationship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     v: org.apache.spark.sql.DataFrame = [id: string, name: string ... 1 more field]\n",
    ">     e: org.apache.spark.sql.DataFrame = [src: string, dst: string ... 1 more field]\n",
    "\n",
    "  \n",
    "\n",
    "Let's create a graph from these vertices and these edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     g: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])\n",
    "\n",
    "  \n",
    "\n",
    "Let's use the d3.graphs to visualise graphs (recall the D3 graphs in\n",
    "wiki-click example). You need the `Run Cell` below using that cell's\n",
    "*Play* button's drop-down menu.\n",
    "\n",
    ">     Warning: classes defined within packages cannot be redefined without a cluster restart.\n",
    ">     Compilation successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3._\n",
    "d3.graphs.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.lit // import the lit function in sql\n",
    "val gE= g.edges.select($\"src\", $\"dst\".as(\"dest\"), lit(1L).as(\"count\")) // for us the column count is just an edge incidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.apache.spark.sql.functions.lit\n",
    ">     gE: org.apache.spark.sql.DataFrame = [src: string, dest: string ... 1 more field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3.graphs.force(\n",
    "  height = 500,\n",
    "  width = 500,\n",
    "  clicks = gE.as[d3.Edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This example graph also comes with the GraphFrames package.\n",
    "val g0 = examples.Graphs.friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     g0: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3.graphs.force( // let us see g0 now in one cell\n",
    "  height = 500,\n",
    "  width = 500,\n",
    "  clicks = g0.edges.select($\"src\", $\"dst\".as(\"dest\"), lit(1L).as(\"count\")).as[d3.Edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Basic graph and DataFrame queries\n",
    "---------------------------------\n",
    "\n",
    "GraphFrames provide several simple graph queries, such as node degree.\n",
    "\n",
    "Also, since GraphFrames represent graphs as pairs of vertex and edge\n",
    "DataFrames, it is easy to make powerful queries directly on the vertex\n",
    "and edge DataFrames. Those DataFrames are made available as vertices and\n",
    "edges fields in the GraphFrame.\n",
    "\n",
    "### Simple queries are simple\n",
    "\n",
    "GraphFrames make it easy to express queries over graphs. Since\n",
    "GraphFrame vertices and edges are stored as DataFrames, many queries are\n",
    "just DataFrame (or SQL) queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g0.vertices) // this is the same query on the graph loaded as an example from GraphFrame package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "The incoming degree of the vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g.inDegrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "The outgoing degree of the vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g.outDegrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "The degree of the vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g.degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "You can run queries directly on the vertices DataFrame. For example, we\n",
    "can find the age of the youngest person in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val youngest = g.vertices.groupBy().min(\"age\")\n",
    "display(youngest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "Likewise, you can run queries on the edges DataFrame.\n",
    "\n",
    "For example, let us count the number of 'follow' relationships in the\n",
    "graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val numFollows = g.edges.filter(\"relationship = 'follow'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     numFollows: Long = 4\n",
    "\n",
    "  \n",
    "\n",
    "Motif finding\n",
    "-------------\n",
    "\n",
    "More complex relationships involving edges and vertices can be built\n",
    "using motifs.\n",
    "\n",
    "The following cell finds the pairs of vertices with edges in both\n",
    "directions between them.\n",
    "\n",
    "The result is a dataframe, in which the column names are given by the\n",
    "motif keys.\n",
    "\n",
    "Check out the GraphFrame User Guide at\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html>\n",
    "for more details on the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Search for pairs of vertices with edges in both directions between them, i.e., find undirected or bidirected edges.\n",
    "val motifs = g.find(\"(a)-[e1]->(b); (b)-[e2]->(a)\")\n",
    "display(motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Since the result is a DataFrame, more complex queries can be built on\n",
    "top of the motif.\n",
    "\n",
    "Let us find all the reciprocal relationships in which one person is\n",
    "older than 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filtered = motifs.filter(\"b.age > 30\")\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "**You Try!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Search for all \"directed triangles\" or triplets of vertices: a,b,c with edges: a->b, b->c and c->a\n",
    "//uncomment the next 2 lines and replace the \"XXX\" below\n",
    "//val motifs3 = g.find(\"(a)-[e1]->(b); (b)-[e2]->(c); (c)-[e3]->(XXX)\")\n",
    "//display(motifs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "**Stateful queries**\n",
    "\n",
    "Many motif queries are stateless and simple to express, as in the\n",
    "examples above. The next examples demonstrate more complex queries which\n",
    "carry state along a path in the motif. These queries can be expressed by\n",
    "combining GraphFrame motif finding with filters on the result, where the\n",
    "filters use sequence operations to construct a series of DataFrame\n",
    "Columns.\n",
    "\n",
    "For example, suppose one wishes to identify a chain of 4 vertices with\n",
    "some property defined by a sequence of functions. That is, among chains\n",
    "of 4 vertices `a->b->c->d`, identify the subset of chains matching this\n",
    "complex filter:\n",
    "\n",
    "-   Initialize state on path.\n",
    "-   Update state based on vertex a.\n",
    "-   Update state based on vertex b.\n",
    "-   Etc. for c and d.\n",
    "-   If final state matches some condition, then the chain is accepted by\n",
    "    the filter.\n",
    "\n",
    "The below code snippets demonstrate this process, where we identify\n",
    "chains of 4 vertices such that at least 2 of the 3 edges are `friend`\n",
    "relationships. In this example, the state is the current count of\n",
    "`friend` edges; in general, it could be any DataFrame Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Find chains of 4 vertices.\n",
    "val chain4 = g.find(\"(a)-[ab]->(b); (b)-[bc]->(c); (c)-[cd]->(d)\")\n",
    "\n",
    "// Query on sequence, with state (cnt)\n",
    "//  (a) Define method for updating state given the next element of the motif.\n",
    "def sumFriends(cnt: Column, relationship: Column): Column = {\n",
    "  when(relationship === \"friend\", cnt + 1).otherwise(cnt)\n",
    "}\n",
    "//  (b) Use sequence operation to apply method to sequence of elements in motif.\n",
    "//      In this case, the elements are the 3 edges.\n",
    "val condition = Seq(\"ab\", \"bc\", \"cd\").\n",
    "  foldLeft(lit(0))((cnt, e) => sumFriends(cnt, col(e)(\"relationship\")))\n",
    "//  (c) Apply filter to DataFrame.\n",
    "val chainWith2Friends2 = chain4.where(condition >= 2)\n",
    "display(chainWith2Friends2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res22: org.apache.spark.sql.DataFrame = [a: struct<id: string, name: string ... 1 more field>, ab: struct<src: string, dst: string ... 1 more field> ... 5 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain4.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     root\n",
    ">      |-- a: struct (nullable = false)\n",
    ">      |    |-- id: string (nullable = true)\n",
    ">      |    |-- name: string (nullable = true)\n",
    ">      |    |-- age: integer (nullable = false)\n",
    ">      |-- ab: struct (nullable = false)\n",
    ">      |    |-- src: string (nullable = true)\n",
    ">      |    |-- dst: string (nullable = true)\n",
    ">      |    |-- relationship: string (nullable = true)\n",
    ">      |-- b: struct (nullable = false)\n",
    ">      |    |-- id: string (nullable = true)\n",
    ">      |    |-- name: string (nullable = true)\n",
    ">      |    |-- age: integer (nullable = false)\n",
    ">      |-- bc: struct (nullable = false)\n",
    ">      |    |-- src: string (nullable = true)\n",
    ">      |    |-- dst: string (nullable = true)\n",
    ">      |    |-- relationship: string (nullable = true)\n",
    ">      |-- c: struct (nullable = false)\n",
    ">      |    |-- id: string (nullable = true)\n",
    ">      |    |-- name: string (nullable = true)\n",
    ">      |    |-- age: integer (nullable = false)\n",
    ">      |-- cd: struct (nullable = false)\n",
    ">      |    |-- src: string (nullable = true)\n",
    ">      |    |-- dst: string (nullable = true)\n",
    ">      |    |-- relationship: string (nullable = true)\n",
    ">      |-- d: struct (nullable = false)\n",
    ">      |    |-- id: string (nullable = true)\n",
    ">      |    |-- name: string (nullable = true)\n",
    ">      |    |-- age: integer (nullable = false)\n",
    "\n",
    "  \n",
    "\n",
    "### An idea -- a diatribe into an AI security product.\n",
    "\n",
    "Can you think of a way to use stateful queries in social media networks\n",
    "to find perpetrators of hate-speech online who are possibly worthy of an\n",
    "investigation by domain experts, say in the intelligence or security\n",
    "domain, for potential prosecution on charges of having incited another\n",
    "person to cause physical violence... This is a real problem today as\n",
    "Swedish law effectively prohibits certain forms of online hate-speech.\n",
    "\n",
    "An idea for a product that can be used by Swedish security agencies?\n",
    "\n",
    "See [https://nÃ¤thatsgranskaren.se/](https://nÃ¤thatsgranskaren.se/) for\n",
    "details of a non-profit in Sweden doing such operaitons mostly manually\n",
    "as of early 2020.\n",
    "\n",
    "### Subgraphs\n",
    "\n",
    "Subgraphs are built by filtering a subset of edges and vertices. For\n",
    "example, the following subgraph only contains people who are friends and\n",
    "who are more than 30 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Select subgraph of users older than 30, and edges of type \"friend\"\n",
    "val v2 = g.vertices.filter(\"age > 30\")\n",
    "val e2 = g.edges.filter(\"relationship = 'friend'\")\n",
    "val g2 = GraphFrame(v2, e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     v2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, name: string ... 1 more field]\n",
    ">     e2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [src: string, dst: string ... 1 more field]\n",
    ">     g2: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g2.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g2.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3.graphs.force( // let us see g2 now in one cell\n",
    "  height = 500,\n",
    "  width = 500,\n",
    "  clicks = g2.edges.select($\"src\", $\"dst\".as(\"dest\"), lit(1L).as(\"count\")).as[d3.Edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "**Complex triplet filters**\n",
    "\n",
    "The following example shows how to select a subgraph based upon triplet\n",
    "filters which operate on:\n",
    "\n",
    "-   an edge and\n",
    "-   its src and\n",
    "-   dst vertices.\n",
    "\n",
    "This example could be extended to go beyond triplets by using more\n",
    "complex motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Select subgraph based on edges \"e\" of type \"follow\"\n",
    "// pointing from a younger user \"a\" to an older user \"b\".\n",
    "val paths = g.find(\"(a)-[e]->(b)\")\n",
    "  .filter(\"e.relationship = 'follow'\")\n",
    "  .filter(\"a.age < b.age\")\n",
    "// \"paths\" contains vertex info. Extract the edges.\n",
    "val e2 = paths.select(\"e.src\", \"e.dst\", \"e.relationship\")\n",
    "// In Spark 1.5+, the user may simplify this call:\n",
    "//  val e2 = paths.select(\"e.*\")\n",
    "\n",
    "// Construct the subgraph\n",
    "val g2 = GraphFrame(g.vertices, e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     paths: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [a: struct<id: string, name: string ... 1 more field>, e: struct<src: string, dst: string ... 1 more field> ... 1 more field]\n",
    ">     e2: org.apache.spark.sql.DataFrame = [src: string, dst: string ... 1 more field]\n",
    ">     g2: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g2.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(g2.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "Standard graph algorithms in GraphX conveniently via GraphFrames\n",
    "----------------------------------------------------------------\n",
    "\n",
    "GraphFrames comes with a number of standard graph algorithms built in:\n",
    "\n",
    "-   Breadth-first search (BFS)\n",
    "-   Connected components\n",
    "-   Strongly connected components\n",
    "-   Label Propagation Algorithm (LPA)\n",
    "-   PageRank\n",
    "-   Shortest paths\n",
    "-   Triangle count\n",
    "\n",
    "### Breadth-first search (BFS)\n",
    "\n",
    "Read\n",
    "\n",
    "https://graphframes.github.io/graphframes/docs/\\_site/user-guide.html\n",
    "\n",
    "-   [graphframes user-guide\n",
    "    breadth-first-search-bfs](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#breadth-first-search-bfs).\n",
    "\n",
    "  \n",
    "\n",
    "Search from \"Esther\" for users of age &lt; 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Search from \"Esther\" for users of age <= 32.\n",
    "val paths: DataFrame = g.bfs.fromExpr(\"name = 'Esther'\").toExpr(\"age < 32\").run()\n",
    "display(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val paths: DataFrame = g.bfs.fromExpr(\"name = 'Esther' OR name = 'Bob'\").toExpr(\"age < 32\").run()\n",
    "display(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "The search may also be limited by edge filters and maximum path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filteredPaths = g.bfs.fromExpr(\"name = 'Esther'\").toExpr(\"age < 32\")\n",
    "  .edgeFilter(\"relationship != 'friend'\")\n",
    "  .maxPathLength(3)\n",
    "  .run()\n",
    "display(filteredPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "### Connected components\n",
    "\n",
    "Compute the connected component membership of each vertex and return a\n",
    "graph with each vertex assigned a component ID.\n",
    "\n",
    "READ\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#connected-components>.\n",
    "\n",
    "  \n",
    "\n",
    "From\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#connected-components>:-\n",
    "\n",
    "NOTE: With GraphFrames 0.3.0 and later releases, the default Connected\n",
    "Components algorithm requires setting a Spark checkpoint directory.\n",
    "Users can revert to the old algorithm using `.setAlgorithm(\"graphx\")`.\n",
    "\n",
    "Recall the following quote from [Chapter 5 on *Effective\n",
    "Transformations* of the *High Performance Spark*\n",
    "Book](https://learning.oreilly.com/library/view/high-performance-spark/9781491943199/ch05.html)\n",
    "why one needs to check-point to keep the RDD lineage DAGs from growing\n",
    "too large.\n",
    "\n",
    "> **Types of Reuse: Cache, Persist, Checkpoint, Shuffle Files** If you\n",
    "> decide that you need to reuse your RDD, Spark provides a multitude of\n",
    "> options for how to store the RDD. Thus it is important to understand\n",
    "> when to use the various types of persistence.There are three primary\n",
    "> operations that you can use to store your RDD: cache, persist, and\n",
    "> checkpoint. In general, caching (equivalent to persisting with the\n",
    "> in-memory storage) and persisting are most useful to avoid\n",
    "> recomputation during one Spark job or to break RDDs with long\n",
    "> lineages, since they keep an RDD on the executors during a Spark job.\n",
    "> **Checkpointing is most useful to prevent failures and a high cost of\n",
    "> recomputation by saving intermediate results. Like persisting,\n",
    "> checkpointing helps avoid computation, thus minimizing the cost of\n",
    "> failure, and avoids recomputation by breaking the lineage graph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setCheckpointDir(\"/_checkpoint\") // just a directory in distributed file system\n",
    "val result = g.connectedComponents.run() \n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "Fun Exercise: Try to modify the d3.graph function to allow a\n",
    "visualisation of a given Sequence of `component` ids in the above\n",
    "`result`.\n",
    "\n",
    "Strongly connected components\n",
    "-----------------------------\n",
    "\n",
    "Compute the strongly connected component (SCC) of each vertex and return\n",
    "a graph with each vertex assigned to the SCC containing that vertex.\n",
    "\n",
    "READ\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#strongly-connected-components>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val result = g.stronglyConnectedComponents.maxIter(10).run()\n",
    "display(result.orderBy(\"component\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "Label propagation\n",
    "-----------------\n",
    "\n",
    "Run static Label Propagation Algorithm for detecting communities in\n",
    "networks.\n",
    "\n",
    "Each node in the network is initially assigned to its own community. At\n",
    "every superstep, nodes send their community affiliation to all neighbors\n",
    "and update their state to the mode community affiliation of incoming\n",
    "messages.\n",
    "\n",
    "LPA is a standard community detection algorithm for graphs. It is very\n",
    "inexpensive computationally, although\n",
    "\n",
    "-   \\(1\\) convergence is not guaranteed and\n",
    "-   \\(2\\) one can end up with trivial solutions (all nodes are\n",
    "    identified into a single community).\n",
    "\n",
    "READ:\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#label-propagation-algorithm-lpa>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val result = g.labelPropagation.maxIter(5).run()\n",
    "display(result.orderBy(\"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "PageRank\n",
    "--------\n",
    "\n",
    "Identify important vertices in a graph based on connections.\n",
    "\n",
    "READ:\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#pagerank>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run PageRank until convergence to tolerance \"tol\".\n",
    "val results = g.pageRank.resetProbability(0.15).tol(0.01).run()\n",
    "display(results.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run PageRank for a fixed number of iterations.\n",
    "val results2 = g.pageRank.resetProbability(0.15).maxIter(10).run()\n",
    "display(results2.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run PageRank personalized for vertex \"a\"\n",
    "val results3 = g.pageRank.resetProbability(0.15).maxIter(10).sourceId(\"a\").run()\n",
    "display(results3.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "Shortest paths\n",
    "--------------\n",
    "\n",
    "Computes shortest paths to the given set of landmark vertices, where\n",
    "landmarks are specified by vertex ID.\n",
    "\n",
    "READ\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#shortest-paths>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val paths = g.shortestPaths.landmarks(Seq(\"a\", \"d\")).run()\n",
    "display(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +---+---+------------+\n",
    ">     |src|dst|relationship|\n",
    ">     +---+---+------------+\n",
    ">     |  a|  b|      friend|\n",
    ">     |  b|  c|      follow|\n",
    ">     |  c|  b|      follow|\n",
    ">     |  f|  c|      follow|\n",
    ">     |  e|  f|      follow|\n",
    ">     |  e|  d|      friend|\n",
    ">     |  d|  a|      friend|\n",
    ">     |  a|  e|      friend|\n",
    ">     +---+---+------------+\n",
    "\n",
    "  \n",
    "\n",
    "### Triangle count\n",
    "\n",
    "Computes the number of triangles passing through each vertex.\n",
    "\n",
    "See\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#triangle-count>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val results = g.triangleCount.run()\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "  \n",
    "\n",
    "YouTry\n",
    "------\n",
    "\n",
    "Read about\n",
    "<https://graphframes.github.io/graphframes/docs/_site/user-guide.html#message-passing-via-aggregatemessages>\n",
    "\n",
    "and undestand how the below code snippet shows how to use\n",
    "aggregateMessages to compute the sum of the ages of adjacent users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.graphframes.{examples,GraphFrame}\n",
    "import org.graphframes.lib.AggregateMessages\n",
    "val g: GraphFrame = examples.Graphs.friends  // get example graph\n",
    "\n",
    "// We will use AggregateMessages utilities later, so name it \"AM\" for short.\n",
    "val AM = AggregateMessages\n",
    "\n",
    "// For each user, sum the ages of the adjacent users.\n",
    "val msgToSrc = AM.dst(\"age\")\n",
    "val msgToDst = AM.src(\"age\")\n",
    "val agg = { g.aggregateMessages\n",
    "  .sendToSrc(msgToSrc)  // send destination user's age to source\n",
    "  .sendToDst(msgToDst)  // send source user's age to destination\n",
    "  .agg(sum(AM.msg).as(\"summedAges\")) } // sum up ages, stored in AM.msg column\n",
    "agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     +---+----------+\n",
    ">     | id|summedAges|\n",
    ">     +---+----------+\n",
    ">     |  a|        97|\n",
    ">     |  c|       108|\n",
    ">     |  e|        99|\n",
    ">     |  d|        66|\n",
    ">     |  b|        94|\n",
    ">     |  f|        62|\n",
    ">     +---+----------+\n",
    ">\n",
    ">     import org.graphframes.{examples, GraphFrame}\n",
    ">     import org.graphframes.lib.AggregateMessages\n",
    ">     g: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])\n",
    ">     AM: org.graphframes.lib.AggregateMessages.type = org.graphframes.lib.AggregateMessages$@706833c8\n",
    ">     msgToSrc: org.apache.spark.sql.Column = dst[age]\n",
    ">     msgToDst: org.apache.spark.sql.Column = src[age]\n",
    ">     agg: org.apache.spark.sql.DataFrame = [id: string, summedAges: bigint]\n",
    "\n",
    "  \n",
    "\n",
    "There is a lot more that can be done with aggregate messaging - let's\n",
    "get into belief propogation algorithm for a more complex example!\n",
    "\n",
    "Belief propogation is a powerful computational framework for Graphical\n",
    "Models.\n",
    "\n",
    "-   let's dive here:\n",
    "    -   <https://github.com/graphframes/graphframes/blob/master/src/main/scala/org/graphframes/examples/BeliefPropagation.scala>\n",
    "\n",
    "as\n",
    "\n",
    "> This provides a template for building customized BP algorithms for\n",
    "> different types of graphical models.\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "Project Idea\n",
    "------------\n",
    "\n",
    "Understand *parallel belief propagation using colored fields* in the\n",
    "Scala code linked above and also pasted below in one cell (for you to\n",
    "modify if you want to do it in a databricks or jupyter or zeppelin\n",
    "notebook) unless you want to fork and extend the github repo directly\n",
    "with your own example.\n",
    "\n",
    "Then use it with necessary adaptations to be able to model your favorite\n",
    "interacting particle system. Don't just redo the Ising model done there!\n",
    "\n",
    "This can be used to gain intuition for various real-world scenarios,\n",
    "including the mathematics in your head:\n",
    "\n",
    "-   Make a graph for contact network of a set of hosts\n",
    "-   A simple model of COVID spreading in an SI or SIS or SIR or other\n",
    "    epidemic models\n",
    "    -   this can be abstract and simply show your skills in programming,\n",
    "        say create a random network\n",
    "    -   or be more explicit with some assumptions about the contact\n",
    "        process (population sampled, in one or two cities, with some\n",
    "        assumptions on contacts during transportation, school, work,\n",
    "        etc)\n",
    "    -   show that you have a fully scalable simulation model that can\n",
    "        theoretically scale to billions of hosts\n",
    "\n",
    "The project does not have to be a recommendation to Swedish authorities!\n",
    "Just a start in the right direction, for instance.\n",
    "\n",
    "Some readings that can help here include the following and references\n",
    "therein:\n",
    "\n",
    "-   The Transmission Process: A Combinatorial Stochastic Process for the\n",
    "    Evolution of Transmission Trees over Networks, Raazesh Sainudiin and\n",
    "    David Welch, Journal of Theoretical Biology, Volume 410, Pages\n",
    "    137â€“170,\n",
    "    [10.1016/j.jtbi.2016.07.038](http://dx.doi.org/10.1016/j.jtbi.2016.07.038), 2016.\n",
    "\n",
    "Other Project Ideas\n",
    "-------------------\n",
    "\n",
    "-   try to do a scalable inference algorithm for one of the graphical\n",
    "    models that you already know...\n",
    "-   make a large simulaiton of your favourite *Finite Markov Information\n",
    "    Exchange (FMIE)* process defined by Aldous (see reference in the\n",
    "    above linked paper)\n",
    "-   anything else that fancies you or your research\n",
    "    orientation/interests and can benefit from adapting the template for\n",
    "    the *parallel belief propagation* algorithm here.\n",
    "\n",
    "If you want to do this project in databricks (or other) notebook then\n",
    "start by modifying the following code from the example and making it\n",
    "run... Then adapt... start in small steps... make a team with fellow\n",
    "students with complementary skills..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    " * Licensed to the Apache Software Foundation (ASF) under one or more\n",
    " * contributor license agreements.  See the NOTICE file distributed with\n",
    " * this work for additional information regarding copyright ownership.\n",
    " * The ASF licenses this file to You under the Apache License, Version 2.0\n",
    " * (the \"License\"); you may not use this file except in compliance with\n",
    " * the License.  You may obtain a copy of the License at\n",
    " *\n",
    " *    http://www.apache.org/licenses/LICENSE-2.0\n",
    " *\n",
    " * Unless required by applicable law or agreed to in writing, software\n",
    " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " * See the License for the specific language governing permissions and\n",
    " * limitations under the License.\n",
    " */\n",
    "\n",
    "package org.graphframes.examples\n",
    "\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.graphx.{Graph, VertexRDD, Edge => GXEdge}\n",
    "import org.apache.spark.sql.{Column, Row, SparkSession, SQLContext}\n",
    "import org.apache.spark.sql.functions.{col, lit, sum, udf, when}\n",
    "\n",
    "import org.graphframes.GraphFrame\n",
    "import org.graphframes.examples.Graphs.gridIsingModel\n",
    "import org.graphframes.lib.AggregateMessages\n",
    "\n",
    "\n",
    "/**\n",
    " * Example code for Belief Propagation (BP)\n",
    " *\n",
    " * This provides a template for building customized BP algorithms for different types of\n",
    " * graphical models.\n",
    " *\n",
    " * This example:\n",
    " *  - Ising model on a grid\n",
    " *  - Parallel Belief Propagation using colored fields\n",
    " *\n",
    " * Ising models are probabilistic graphical models over binary variables x,,i,,.\n",
    " * Each binary variable x,,i,, corresponds to one vertex, and it may take values -1 or +1.\n",
    " * The probability distribution P(X) (over all x,,i,,) is parameterized by vertex factors a,,i,,\n",
    " * and edge factors b,,ij,,:\n",
    " * {{{\n",
    " *  P(X) = (1/Z) * exp[ \\sum_i a_i x_i + \\sum_{ij} b_{ij} x_i x_j ]\n",
    " * }}}\n",
    " * where Z is the normalization constant (partition function).\n",
    " * See [[https://en.wikipedia.org/wiki/Ising_model Wikipedia]] for more information on Ising models.\n",
    " *\n",
    " * Belief Propagation (BP) provides marginal probabilities of the values of the variables x,,i,,,\n",
    " * i.e., P(x,,i,,) for each i.  This allows a user to understand likely values of variables.\n",
    " * See [[https://en.wikipedia.org/wiki/Belief_propagation Wikipedia]] for more information on BP.\n",
    " *\n",
    " * We use a batch synchronous BP algorithm, where batches of vertices are updated synchronously.\n",
    " * We follow the mean field update algorithm in Slide 13 of the\n",
    " * [[http://www.eecs.berkeley.edu/~wainwrig/Talks/A_GraphModel_Tutorial  talk slides]] from:\n",
    " *  Wainwright. \"Graphical models, message-passing algorithms, and convex optimization.\"\n",
    " *\n",
    " * The batches are chosen according to a coloring.  For background on graph colorings for inference,\n",
    " * see for example:\n",
    " *  Gonzalez et al. \"Parallel Gibbs Sampling: From Colored Fields to Thin Junction Trees.\"\n",
    " *  AISTATS, 2011.\n",
    " *\n",
    " * The BP algorithm works by:\n",
    " *  - Coloring the graph by assigning a color to each vertex such that no neighboring vertices\n",
    " *    share the same color.\n",
    " *  - In each step of BP, update all vertices of a single color.  Alternate colors.\n",
    " */\n",
    "object BeliefPropagation {\n",
    "\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    val spark = SparkSession\n",
    "      .builder()\n",
    "      .appName(\"BeliefPropagation example\")\n",
    "      .getOrCreate()\n",
    "\n",
    "    val sql = spark.sqlContext\n",
    "\n",
    "    // Create graphical model g of size 3 x 3.\n",
    "    val g = gridIsingModel(sql, 3)\n",
    "\n",
    "    println(\"Original Ising model:\")\n",
    "    g.vertices.show()\n",
    "    g.edges.show()\n",
    "\n",
    "    // Run BP for 5 iterations.\n",
    "    val numIter = 5\n",
    "    val results = runBPwithGraphX(g, numIter)\n",
    "\n",
    "    // Display beliefs.\n",
    "    val beliefs = results.vertices.select(\"id\", \"belief\")\n",
    "    println(s\"Done with BP. Final beliefs after $numIter iterations:\")\n",
    "    beliefs.show()\n",
    "\n",
    "    spark.stop()\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * Given a GraphFrame, choose colors for each vertex.  No neighboring vertices will share the\n",
    "   * same color.  The number of colors is minimized.\n",
    "   *\n",
    "   * This is written specifically for grid graphs. For non-grid graphs, it should be generalized,\n",
    "   * such as by using a greedy coloring scheme.\n",
    "   *\n",
    "   * @param g  Grid graph generated by [[org.graphframes.examples.Graphs.gridIsingModel()]]\n",
    "   * @return  Same graph, but with a new vertex column \"color\" of type Int (0 or 1)\n",
    "   */\n",
    "  private def colorGraph(g: GraphFrame): GraphFrame = {\n",
    "    val colorUDF = udf { (i: Int, j: Int) => (i + j) % 2 }\n",
    "    val v = g.vertices.withColumn(\"color\", colorUDF(col(\"i\"), col(\"j\")))\n",
    "    GraphFrame(v, g.edges)\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * Run Belief Propagation.\n",
    "   *\n",
    "   * This implementation of BP shows how to use GraphX's aggregateMessages method.\n",
    "   * It is simple to convert to and from GraphX format.  This method does the following:\n",
    "   *  - Color GraphFrame vertices for BP scheduling.\n",
    "   *  - Convert GraphFrame to GraphX format.\n",
    "   *  - Run BP using GraphX's aggregateMessages API.\n",
    "   *  - Augment the original GraphFrame with the BP results (vertex beliefs).\n",
    "   *\n",
    "   * @param g  Graphical model created by `org.graphframes.examples.Graphs.gridIsingModel()`\n",
    "   * @param numIter  Number of iterations of BP to run.  One iteration includes updating each\n",
    "   *                 vertex's belief once.\n",
    "   * @return  Same graphical model, but with [[GraphFrame.vertices]] augmented with a new column\n",
    "   *          \"belief\" containing P(x,,i,, = +1), the marginal probability of vertex i taking\n",
    "   *          value +1 instead of -1.\n",
    "   */\n",
    "  def runBPwithGraphX(g: GraphFrame, numIter: Int): GraphFrame = {\n",
    "    // Choose colors for vertices for BP scheduling.\n",
    "    val colorG = colorGraph(g)\n",
    "    val numColors: Int = colorG.vertices.select(\"color\").distinct.count().toInt\n",
    "\n",
    "    // Convert GraphFrame to GraphX, and initialize beliefs.\n",
    "    val gx0 = colorG.toGraphX\n",
    "    // Schema maps for extracting attributes\n",
    "    val vColsMap = colorG.vertexColumnMap\n",
    "    val eColsMap = colorG.edgeColumnMap\n",
    "    // Convert vertex attributes to nice case classes.\n",
    "    val gx1: Graph[VertexAttr, Row] = gx0.mapVertices { case (_, attr) =>\n",
    "      // Initialize belief at 0.0\n",
    "      VertexAttr(attr.getDouble(vColsMap(\"a\")), 0.0, attr.getInt(vColsMap(\"color\")))\n",
    "    }\n",
    "    // Convert edge attributes to nice case classes.\n",
    "    val extractEdgeAttr: (GXEdge[Row] => EdgeAttr) = { e =>\n",
    "      EdgeAttr(e.attr.getDouble(eColsMap(\"b\")))\n",
    "    }\n",
    "    var gx: Graph[VertexAttr, EdgeAttr] = gx1.mapEdges(extractEdgeAttr)\n",
    "\n",
    "    // Run BP for numIter iterations.\n",
    "    for (iter <- Range(0, numIter)) {\n",
    "      // For each color, have that color receive messages from neighbors.\n",
    "      for (color <- Range(0, numColors)) {\n",
    "        // Send messages to vertices of the current color.\n",
    "        val msgs: VertexRDD[Double] = gx.aggregateMessages(\n",
    "          ctx =>\n",
    "            // Can send to source or destination since edges are treated as undirected.\n",
    "            if (ctx.dstAttr.color == color) {\n",
    "              val msg = ctx.attr.b * ctx.srcAttr.belief\n",
    "              // Only send message if non-zero.\n",
    "              if (msg != 0) ctx.sendToDst(msg)\n",
    "            } else if (ctx.srcAttr.color == color) {\n",
    "              val msg = ctx.attr.b * ctx.dstAttr.belief\n",
    "              // Only send message if non-zero.\n",
    "              if (msg != 0) ctx.sendToSrc(msg)\n",
    "            },\n",
    "          _ + _)\n",
    "        // Receive messages, and update beliefs for vertices of the current color.\n",
    "        gx = gx.outerJoinVertices(msgs) {\n",
    "          case (vID, vAttr, optMsg) =>\n",
    "            if (vAttr.color == color) {\n",
    "              val x = vAttr.a + optMsg.getOrElse(0.0)\n",
    "              val newBelief = math.exp(-log1pExp(-x))\n",
    "              VertexAttr(vAttr.a, newBelief, color)\n",
    "            } else {\n",
    "              vAttr\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    // Convert back to GraphFrame with a new column \"belief\" for vertices DataFrame.\n",
    "    val gxFinal: Graph[Double, Unit] = gx.mapVertices((_, attr) => attr.belief).mapEdges(_ => ())\n",
    "    GraphFrame.fromGraphX(colorG, gxFinal, vertexNames = Seq(\"belief\"))\n",
    "  }\n",
    "\n",
    "  case class VertexAttr(a: Double, belief: Double, color: Int)\n",
    "\n",
    "  case class EdgeAttr(b: Double)\n",
    "\n",
    "  /**\n",
    "   * Run Belief Propagation.\n",
    "   *\n",
    "   * This implementation of BP shows how to use GraphFrame's aggregateMessages method.\n",
    "   *  - Color GraphFrame vertices for BP scheduling.\n",
    "   *  - Run BP using GraphFrame's aggregateMessages API.\n",
    "   *  - Augment the original GraphFrame with the BP results (vertex beliefs).\n",
    "   *\n",
    "   * @param g  Graphical model created by `org.graphframes.examples.Graphs.gridIsingModel()`\n",
    "   * @param numIter  Number of iterations of BP to run.  One iteration includes updating each\n",
    "   *                 vertex's belief once.\n",
    "   * @return  Same graphical model, but with [[GraphFrame.vertices]] augmented with a new column\n",
    "   *          \"belief\" containing P(x,,i,, = +1), the marginal probability of vertex i taking\n",
    "   *          value +1 instead of -1.\n",
    "   */\n",
    "  def runBPwithGraphFrames(g: GraphFrame, numIter: Int): GraphFrame = {\n",
    "    // Choose colors for vertices for BP scheduling.\n",
    "    val colorG = colorGraph(g)\n",
    "    val numColors: Int = colorG.vertices.select(\"color\").distinct.count().toInt\n",
    "\n",
    "    // TODO: Handle vertices without any edges.\n",
    "\n",
    "    // Initialize vertex beliefs at 0.0.\n",
    "    var gx = GraphFrame(colorG.vertices.withColumn(\"belief\", lit(0.0)), colorG.edges)\n",
    "\n",
    "    // Run BP for numIter iterations.\n",
    "    for (iter <- Range(0, numIter)) {\n",
    "      // For each color, have that color receive messages from neighbors.\n",
    "      for (color <- Range(0, numColors)) {\n",
    "        // Define \"AM\" for shorthand for referring to the src, dst, edge, and msg fields.\n",
    "        // (See usage below.)\n",
    "        val AM = AggregateMessages\n",
    "        // Send messages to vertices of the current color.\n",
    "        // We may send to source or destination since edges are treated as undirected.\n",
    "        val msgForSrc: Column = when(AM.src(\"color\") === color, AM.edge(\"b\") * AM.dst(\"belief\"))\n",
    "        val msgForDst: Column = when(AM.dst(\"color\") === color, AM.edge(\"b\") * AM.src(\"belief\"))\n",
    "        val logistic = udf { (x: Double) => math.exp(-log1pExp(-x)) }\n",
    "        val aggregates = gx.aggregateMessages\n",
    "          .sendToSrc(msgForSrc)\n",
    "          .sendToDst(msgForDst)\n",
    "          .agg(sum(AM.msg).as(\"aggMess\"))\n",
    "        val v = gx.vertices\n",
    "        // Receive messages, and update beliefs for vertices of the current color.\n",
    "        val newBeliefCol = when(v(\"color\") === color && aggregates(\"aggMess\").isNotNull,\n",
    "          logistic(aggregates(\"aggMess\") + v(\"a\")))\n",
    "          .otherwise(v(\"belief\"))  // keep old beliefs for other colors\n",
    "        val newVertices = v\n",
    "          .join(aggregates, v(\"id\") === aggregates(\"id\"), \"left_outer\")  // join messages, vertices\n",
    "          .drop(aggregates(\"id\"))  // drop duplicate ID column (from outer join)\n",
    "          .withColumn(\"newBelief\", newBeliefCol)  // compute new beliefs\n",
    "          .drop(\"aggMess\")  // drop messages\n",
    "          .drop(\"belief\")  // drop old beliefs\n",
    "          .withColumnRenamed(\"newBelief\", \"belief\")\n",
    "        // Cache new vertices using workaround for SPARK-13346\n",
    "        val cachedNewVertices = AM.getCachedDataFrame(newVertices)\n",
    "        gx = GraphFrame(cachedNewVertices, gx.edges)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    // Drop the \"color\" column from vertices\n",
    "    GraphFrame(gx.vertices.drop(\"color\"), gx.edges)\n",
    "  }\n",
    "\n",
    "  /** More numerically stable `log(1 + exp(x))` */\n",
    "  private def log1pExp(x: Double): Double = {\n",
    "    if (x > 0) {\n",
    "      x + math.log1p(math.exp(-x))\n",
    "    } else {\n",
    "      math.log1p(math.exp(x))\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
