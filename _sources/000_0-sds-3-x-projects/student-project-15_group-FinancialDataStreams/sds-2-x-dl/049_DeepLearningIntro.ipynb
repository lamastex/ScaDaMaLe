{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SDS-2.x, Scalable Data Engineering Science](https://lamastex.github.io/scalable-data-science/sds/2/x/)\n",
    "=======================================================================================================\n",
    "\n",
    "This is Raaz's update of Siva's whirl-wind compression of the free\n",
    "Google's DL course in Udacity\n",
    "<https://www.youtube.com/watch?v=iDyeK3GvFpo> for Adam Briendel's DL\n",
    "modules that will follow.\n",
    "\n",
    "Deep learning: A Crash Introduction\n",
    "===================================\n",
    "\n",
    "This notebook provides an introduction to Deep Learning. It is meant to\n",
    "help you descend more fully into these learning resources and\n",
    "references:\n",
    "\n",
    "-   Udacity's course on Deep Learning\n",
    "    <https://www.udacity.com/course/deep-learning--ud730> by Google\n",
    "    engineers: Arpan Chakraborty and Vincent Vanhoucke and their full\n",
    "    video playlist:\n",
    "    -   [https://www.youtube.com/watch?v=X*B9NADf2wk&index=2&list=PLAwxTw4SYaPn*OWPFT9ulXLuQrImzHfOV](https://www.youtube.com/watch?v=X_B9NADf2wk&index=2&list=PLAwxTw4SYaPn_OWPFT9ulXLuQrImzHfOV)\n",
    "-   Neural networks and deep learning\n",
    "    <http://neuralnetworksanddeeplearning.com/> by Michael Nielsen\n",
    "-   Deep learning book <http://www.deeplearningbook.org/> by Ian\n",
    "    Goodfellow, Yoshua Bengio and Aaron Courville\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "-   Deep learning - buzzword for Artifical Neural Networks\n",
    "-   What is it?\n",
    "    -   Supervised learning model - Classifier\n",
    "    -   Unsupervised model - Anomaly detection (say via auto-encoders)\n",
    "-   Needs lots of data\n",
    "-   Online learning model - backpropogation\n",
    "-   Optimization - Stochastic gradient descent  \n",
    "-   Regularization - L1, L2, Dropout\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "-   Supervised\n",
    "    -   Fully connected network\n",
    "    -   Convolutional neural network - Eg: For classifying images\n",
    "    -   Recurrent neural networks - Eg: For use on text, speech\n",
    "-   Unsupervised\n",
    "    -   Autoencoder\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### A quick recap of logistic regression / linear models\n",
    "\n",
    "**(watch now 46 seconds from 4 to 50)**:\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Training a logistic\n",
    "classifier](http://img.youtube.com/vi/G8eNWzxOgqE/0.jpg)](https://www.youtube.com/watch?v=G8eNWzxOgqE?rel=0&autoplay=1&modestbranding=1&start=4&end=50)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "-- Video Credit: Udacity's deep learning by Arpan Chakraborthy and\n",
    "Vincent Vanhoucke\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "#### Regression\n",
    "\n",
    "![Regression](https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg)  \n",
    "y = mx + c\n",
    "\n",
    "**Another way to look at a linear model**\n",
    "\n",
    "![Another way to look at a linear\n",
    "model](http://neuralnetworksanddeeplearning.com/images/tikz0.png)\n",
    "\n",
    "-- Image Credit: Michael Nielsen\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### Recap - Gradient descent\n",
    "\n",
    "**(1:54 seconds)**:\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Gradient\n",
    "descent](http://img.youtube.com/vi/x449QQDhMDE/0.jpg)](https://www.youtube.com/watch?v=x449QQDhMDE)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "-- Video Credit: Udacity's deep learning by Arpan Chakraborthy and\n",
    "Vincent Vanhoucke\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### Recap - Stochastic Gradient descent\n",
    "\n",
    "**(2:25 seconds)**:\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Stochastic Gradient\n",
    "descent\n",
    "(SGD)](http://img.youtube.com/vi/hMLUgM6kTp8/0.jpg)](https://www.youtube.com/watch?v=hMLUgM6kTp8)\n",
    "\n",
    "**(1:28 seconds)**:\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Momentum and learning\n",
    "rate decay in\n",
    "SGD](http://img.youtube.com/vi/s6jC7Wc9iMI/0.jpg)](https://www.youtube.com/watch?v=s6jC7Wc9iMI)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "-- Video Credit: Udacity's deep learning by Arpan Chakraborthy and\n",
    "Vincent Vanhoucke\n",
    "\n",
    "HOGWILD! Parallel SGD without locks\n",
    "<http://i.stanford.edu/hazy/papers/hogwild-nips.pdf>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### Why deep learning? - Linear model\n",
    "\n",
    "**(24 seconds - 15 to 39)**:\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Linear\n",
    "model](http://img.youtube.com/vi/PfNfY1xmkLs/0.jpg)](https://www.youtube.com/watch?v=PfNfY1xmkLs)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "-- Video Credit: Udacity's deep learning by Arpan Chakraborthy and\n",
    "Vincent Vanhoucke\n",
    "\n",
    "**ReLU - Rectified linear unit or Rectifier** - max(0, x)\n",
    "\n",
    "![ReLU](https://upload.wikimedia.org/wikipedia/commons/6/6c/Rectifier_and_softplus_functions.svg)\n",
    "\n",
    "-- Image Credit: Wikipedia\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "**Neural Network**\n",
    "\n",
    "Watch now (45 seconds, 0-45)\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Neural\n",
    "network](http://img.youtube.com/vi/Opg63pan_YQ/0.jpg)](https://www.youtube.com/watch?v=Opg63pan_YQ)\n",
    "\\*\\*\\* -- Video Credit: Udacity's deep learning by Arpan Chakraborthy\n",
    "and Vincent Vanhoucke\n",
    "\n",
    "Is decision tree a linear model?  \n",
    "<http://datascience.stackexchange.com/questions/6787/is-decision-tree-algorithm-a-linear-or-nonlinear-algorithm>\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "**Neural Network** \\*\\*\\* ![Neural\n",
    "network](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/500px-Colored_neural_network.svg.png)\n",
    "\\*\\*\\* -- Image credit: Wikipedia\n",
    "\n",
    "**Multiple hidden layers**\n",
    "\n",
    "![Many hidden\n",
    "layers](http://neuralnetworksanddeeplearning.com/images/tikz36.png)\n",
    "\\*\\*\\* -- Image credit: Michael Nielsen\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "**What does it mean to go deep? What do each of the hidden layers\n",
    "learn?**\n",
    "\n",
    "Watch now (1:13 seconds)\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Neural\n",
    "network](http://img.youtube.com/vi/_TcMRoWFppo/0.jpg)](https://www.youtube.com/watch?v=_TcMRoWFppo)\n",
    "\\*\\*\\* -- Video Credit: Udacity's deep learning by Arpan Chakraborthy\n",
    "and Vincent Vanhoucke\n",
    "\n",
    "### Chain rule\n",
    "\n",
    "$$ (f \\\\circ g)\\\\prime = (f\\\\prime \\\\circ g) \\\\cdot g\\\\prime $$ *** ***\n",
    "\n",
    "**Chain rule in neural networks**\n",
    "\n",
    "Watch later (55 seconds)\n",
    "\n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Neural\n",
    "network](http://img.youtube.com/vi/fDeAJspBEnM/0.jpg)](https://www.youtube.com/watch?v=fDeAJspBEnM)\n",
    "\\*\\*\\* -- Video Credit: Udacity's deep learning by Arpan Chakraborthy\n",
    "and Vincent Vanhoucke\n",
    "\n",
    "### Backpropogation\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "To properly understand this you are going to minimally need 20 minutes\n",
    "or so, depending on how rusty your maths is now.\n",
    "\n",
    "First go through this carefully: \\*\n",
    "<https://stats.stackexchange.com/questions/224140/step-by-step-example-of-reverse-mode-automatic-differentiation>\n",
    "\n",
    "Watch **later** (9:55 seconds)\n",
    "\n",
    "[![Backpropogation](http://img.youtube.com/vi/mgceQli6ZKQ/0.jpg)](https://www.youtube.com/watch?v=mgceQli6ZKQ)\n",
    "*** ***\n",
    "\n",
    "Watch now (1: 54 seconds)  \n",
    "[![Backpropogation](http://img.youtube.com/vi/83bMCcPmFvE/0.jpg)](https://www.youtube.com/watch?v=83bMCcPmFvE)\n",
    "\\*\\*\\*\n",
    "\n",
    "#### How do you set the learning rate? - Step size in SGD?\n",
    "\n",
    "-   [ADADELTA: Adaptive learning\n",
    "    rate](http://arxiv.org/pdf/1212.5701v1.pdf)\n",
    "-   [ADAGRAD](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
    "\n",
    "there is a lot more... including newer frameworks for automating these\n",
    "knows using probabilistic programs (but in non-distributed settings as\n",
    "of Dec 2017).\n",
    "\n",
    "So far we have only seen fully connected neural networks, now let's move\n",
    "into more interesting ones that exploit spatial locality and nearness\n",
    "patterns inherent in certain classes of data, such as image data.\n",
    "\n",
    "#### Convolutional Neural Networks\n",
    "\n",
    "&lt;img\n",
    "src=\"http://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-9x5-Conv2Conv2.png\"\n",
    "width=800&gt;  \n",
    "*** Watch now (3:55)  \n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Convolutional Neural\n",
    "network](http://img.youtube.com/vi/jajksuQW4mc/0.jpg)](https://www.youtube.com/watch?v=jajksuQW4mc)  \n",
    "***\n",
    "\n",
    "-   Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton -\n",
    "    <https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf>  \n",
    "-   Convolutional Neural networks blog -\n",
    "    <http://colah.github.io/posts/2014-07-Conv-Nets-Modular/>\n",
    "\n",
    "#### Recurrent neural network\n",
    "\n",
    "![Recurrent neural\n",
    "network](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)  \n",
    "<http://colah.github.io/posts/2015-08-Understanding-LSTMs/>\n",
    "\n",
    "<http://karpathy.github.io/2015/05/21/rnn-effectiveness/>  \n",
    "*** Watch (3:55)  \n",
    "[![Udacity: Deep Learning by Vincent Vanhoucke - Recurrent Neural\n",
    "network](http://img.youtube.com/vi/H3ciJF2eCJI/0.jpg)](https://www.youtube.com/watch?v=H3ciJF2eCJI?rel=0&autoplay=1&modestbranding=1&start=0)  \n",
    "***\n",
    "\n",
    "##### LSTM - Long short term memory\n",
    "\n",
    "![LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### GRU - Gated recurrent unit\n",
    "\n",
    "![Gated Recurrent\n",
    "unit](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png)\n",
    "<http://arxiv.org/pdf/1406.1078v3.pdf>\n",
    "\n",
    "### Autoencoder\n",
    "\n",
    "![Autoencoder](http://deeplearning4j.org/img/deep_autoencoder.png) ***\n",
    "Watch now (3:51)  \n",
    "[![Autoencoder](http://img.youtube.com/vi/s96mYcicbpE/0.jpg)](https://www.youtube.com/watch?v=s96mYcicbpE)  \n",
    "***\n",
    "\n",
    "The more recent improvement over CNNs are called capsule networks by\n",
    "Hinton. Check them out here if you want to prepare for your future\n",
    "interview question in 2017/2018 or so...:\n",
    "\n",
    "-   <https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b>"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
