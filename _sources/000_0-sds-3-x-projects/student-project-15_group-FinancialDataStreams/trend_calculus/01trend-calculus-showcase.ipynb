{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding trend in oil price data.\n",
    "================================\n",
    "\n",
    "Johannes Graner, Albert Nilsson and Raazesh Sainudiin\n",
    "\n",
    "2020, Uppsala, Sweden\n",
    "\n",
    "This project was supported by Combient Mix AB through summer internships\n",
    "at:\n",
    "\n",
    "Combient Competence Centre for Data Engineering Sciences, Department of\n",
    "Mathematics, Uppsala University, Uppsala, Sweden\n",
    "\n",
    "Resources\n",
    "---------\n",
    "\n",
    "This builds on the following library and its antecedents therein:\n",
    "\n",
    "-   <https://github.com/lamastex/spark-trend-calculus>\n",
    "\n",
    "This work was inspired by:\n",
    "--------------------------\n",
    "\n",
    "-   Antoine Aamennd's\n",
    "    [texata-2017](https://github.com/aamend/texata-r2-2017)\n",
    "-   Andrew Morgan's [Trend Calculus\n",
    "    Library](https://github.com/ByteSumoLtd/TrendCalculus-lua)\n",
    "\n",
    "When dealing with time series, it can be difficult to find a good way to\n",
    "find and analyze trends in the data.\n",
    "\n",
    "One approach is by using the Trend Calculus algorithm invented by Andrew\n",
    "Morgan. More information about Trend Calculus can be found at\n",
    "[this](https://lamastex.github.io/spark-trend-calculus-examples/)\n",
    "github.io page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.lamastex.spark.trendcalculus._\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.lamastex.spark.trendcalculus._\n",
    ">     import spark.implicits._\n",
    ">     import org.apache.spark.sql._\n",
    ">     import org.apache.spark.sql.functions._\n",
    ">     import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /dbfs/FileStore/shared_uploads/fabiansi@kth.se/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     DAT_ASCII_BCOUSD_M1_2010_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2011_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2012_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2013_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2014_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2015_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2016_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2017_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2018_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201901_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201902_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201903_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201904_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201905_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201906_csv.gz\n",
    ">     joinedDSWithMaxRev\n",
    "\n",
    "  \n",
    "\n",
    "The input to the algorithm is data in the format (ticker, time, value).\n",
    "In this example, ticker is `\"BCOUSD\"` (Brent Crude Oil), time is given\n",
    "in minutes and value is the closing price for Brent Crude Oil during\n",
    "that minute.\n",
    "\n",
    "This data is historical data from 2010 to 2019 taken from\n",
    "https://www.histdata.com/ using methods from\n",
    "[FX-1-Minute-Data](https://github.com/philipperemy/FX-1-Minute-Data) by\n",
    "Philippe Remy. In this notebook, everything is done on static\n",
    "dataframes. See **02streamable-trend-calculus** for examples on\n",
    "streaming dataframes.\n",
    "\n",
    "There are gaps in the data, notably during the weekends when no trading\n",
    "takes place, but this does not affect the algorithm as it is does not\n",
    "place any assumptions on the data other than that time is monotonically\n",
    "increasing.\n",
    "\n",
    "The window size is set to 2, which is minimal, beacuse we want to retain\n",
    "as much information as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res0: Seq[com.databricks.backend.daemon.dbutils.FileInfo] = WrappedArray(FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2010_csv.gz, DAT_ASCII_BCOUSD_M1_2010_csv.gz, 284384), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2011_csv.gz, DAT_ASCII_BCOUSD_M1_2011_csv.gz, 2479115), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2012_csv.gz, DAT_ASCII_BCOUSD_M1_2012_csv.gz, 2327511), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2013_csv.gz, DAT_ASCII_BCOUSD_M1_2013_csv.gz, 2109500), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2014_csv.gz, DAT_ASCII_BCOUSD_M1_2014_csv.gz, 1961172), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2015_csv.gz, DAT_ASCII_BCOUSD_M1_2015_csv.gz, 2205678), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2016_csv.gz, DAT_ASCII_BCOUSD_M1_2016_csv.gz, 2131659), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2017_csv.gz, DAT_ASCII_BCOUSD_M1_2017_csv.gz, 1854793), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_2018_csv.gz, DAT_ASCII_BCOUSD_M1_2018_csv.gz, 2251250), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_201901_csv.gz, DAT_ASCII_BCOUSD_M1_201901_csv.gz, 250411), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_201902_csv.gz, DAT_ASCII_BCOUSD_M1_201902_csv.gz, 213207), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_201903_csv.gz, DAT_ASCII_BCOUSD_M1_201903_csv.gz, 211928), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_201904_csv.gz, DAT_ASCII_BCOUSD_M1_201904_csv.gz, 208552), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_201905_csv.gz, DAT_ASCII_BCOUSD_M1_201905_csv.gz, 241092), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/DAT_ASCII_BCOUSD_M1_201906_csv.gz, DAT_ASCII_BCOUSD_M1_201906_csv.gz, 171191), FileInfo(dbfs:/FileStore/shared_uploads/fabiansi@kth.se/joinedDSWithMaxRev/, joinedDSWithMaxRev/, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val windowSize = 2\n",
    "val oilDS = spark.read.fx1m(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se/*csv.gz\").toDF.withColumn(\"ticker\", lit(\"BCOUSD\")).select($\"ticker\", $\"time\" as \"x\", $\"close\" as \"y\").as[TickerPoint].orderBy(\"x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     windowSize: Int = 2\n",
    ">     oilDS: org.apache.spark.sql.Dataset[org.lamastex.spark.trendcalculus.TickerPoint] = [ticker: string, x: timestamp ... 1 more field]\n",
    "\n",
    "  \n",
    "\n",
    "If we want to look at long term trends, we can use the output time\n",
    "series as input for another iteration. The output contains the points of\n",
    "the input where the trend changes (reversals). This can be repeated\n",
    "several times, resulting in longer term trends.\n",
    "\n",
    "Here, we look at (up to) 15 iterations of the algorithm. It is no\n",
    "problem if the output of some iteration is too small to find a reversal\n",
    "in the next iteration, since the output will just be an empty dataframe\n",
    "in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val numReversals = 50\n",
    "val dfWithReversals = new TrendCalculus2(oilDS, windowSize, spark).nReversalsJoinedWithMaxRev(numReversals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"trendCalculus\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def logLevel(sc):\n",
    "    # REF: https://stackoverflow.com/questions/25193488/how-to-turn-off-info-logging-in-spark\n",
    "    log4jLogger = sc._jvm.org.apache.log4j\n",
    "    log4jLogger.Logger.getLogger(\"org\").setLevel(log4jLogger.Level.ERROR)\n",
    "    log = log4jLogger.LogManager.getLogger(__name__)\n",
    "    log.warn(\"Custom WARN message\")\n",
    "\n",
    "\n",
    "logLevel(spark)\n",
    "\n",
    "print(spark.range(5000).where(\"id > 500\").selectExpr(\"sum(id)\").collect())\n",
    "\n",
    "# sc._jvm.org.lamastex.spark.trendcalculus.TrendCalculus2.FHLS(emptyPoint,emptyPoint,emptyPoint,emptyPoint)\n",
    "sc._jvm.org.lamastex.spark.trendcalculus.Point(0, 0.0)\n",
    "\n",
    "# oilDS = spark.read.fx1m(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se/*csv.gz\")\n",
    "\n",
    "# sc._jvm.org.lamastex.spark.trendcalculus.TrendCalculus2.nReversalsJoined(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfWithReversals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "The number of reversals decrease rapidly as more iterations are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithReversals.cache.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 to numReversals).map( i => println(dfWithReversals.filter(s\"reversal$i is not null\").count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Writing dataframe to parquet in order to read from python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithReversals.write.mode(SaveMode.Overwrite).parquet(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se/joinedDSWithMaxRev\")\n",
    "dfWithReversals.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Visualization\n",
    "-------------\n",
    "\n",
    "Plotly in python is used to make interactive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import plot\n",
    "from plotly.graph_objs import *\n",
    "from datetime import *\n",
    "joinedDS = spark.read.parquet(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se/joinedDSWithMaxRev\").orderBy(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Seeing how much the timeseries has to be thinned out in order to display\n",
    "locally.\n",
    "\n",
    "No information about higher order trend reversals is lost since every\n",
    "higher order reversal is also a lower order reversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDS.filter(\"maxRev > 2\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTS = joinedDS.filter(\"maxRev > 2\").select(\"x\",\"y\",\"maxRev\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Picking an interval to focus on.\n",
    "\n",
    "Start and end dates as (year, month, day, hour, minute, second). Only\n",
    "year, month and day are required. The interval from 1800 to 2200 ensures\n",
    "all data is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = datetime(1800,1,1)\n",
    "endDate= datetime(2200,12,31)\n",
    "TS = [row for row in fullTS if startDate <= row['x'] and row['x'] <= endDate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Setting up the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numReversals = 15\n",
    "startReversal = 7\n",
    "\n",
    "allData = {'x': [row['x'] for row in TS], 'y': [row['y'] for row in TS], 'maxRev': [row['maxRev'] for row in TS]}\n",
    "revTS = [row for row in TS if row[2] >= startReversal]\n",
    "colorList = ['rgba(' + str(tmp) + ',' + str(255-tmp) + ',' + str(255-tmp) + ',1)' for tmp in [int(i*255/(numReversals-startReversal+1)) for i in range(1,numReversals-startReversal+2)]]\n",
    "\n",
    "def getRevTS(tsWithRevMax, revMax):\n",
    "  x = [row[0] for row in tsWithRevMax if row[2] >= revMax]\n",
    "  y = [row[1] for row in tsWithRevMax if row[2] >= revMax]\n",
    "  return x,y,revMax\n",
    "\n",
    "reducedData = [getRevTS(revTS, i) for i in range(startReversal, numReversals+1)]\n",
    "\n",
    "markerPlots = [Scattergl(x=x, y=y, mode='markers', marker=dict(color=colorList[i-startReversal], size=i), name='Reversal ' + str(i)) for (x,y,i) in [getRevTS(revTS, i) for i in range(startReversal, numReversals+1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "### Plotting result as plotly graph\n",
    "\n",
    "The graph is interactive, one can drag to zoom in on an area\n",
    "(double-click to get back) and click on the legend to hide/show\n",
    "different series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(\n",
    "  [Scattergl(x=allData['x'], y=allData['y'], mode='lines', name='Oil Price')] + markerPlots\n",
    "  ,\n",
    "  output_type='div'\n",
    ")\n",
    "\n",
    "displayHTML(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
