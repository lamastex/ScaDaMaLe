{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.lamastex.spark.trendcalculus._\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import org.lamastex.spark.trendcalculus._\n",
    ">     import spark.implicits._\n",
    ">     import org.apache.spark.sql._\n",
    ">     import org.apache.spark.sql.functions._\n",
    ">     import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /dbfs/FileStore/shared_uploads/fabiansi@kth.se/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     DAT_ASCII_BCOUSD_M1_2010_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2011_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2012_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2013_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2014_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2015_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2016_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2017_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_2018_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201901_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201902_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201903_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201904_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201905_csv.gz\n",
    ">     DAT_ASCII_BCOUSD_M1_201906_csv.gz\n",
    ">     joinedDSWithMaxRev\n",
    "\n",
    "  \n",
    "\n",
    "#### DateTime Stamp\n",
    "\n",
    "Format: `YYYYMMDD HHMMSS`\n",
    "\n",
    "Legend: - YYYY – Year - MM – Month (01 to 12) - DD – Day of the Month -\n",
    "HH – Hour of the day (in 24h format) - MM – Minute - SS – Second, in\n",
    "this case it will be always 00\n",
    "\n",
    "TimeZone: Eastern Standard Time (EST) time-zone *WITHOUT* Day Light\n",
    "Savings adjustments\n",
    "\n",
    "*OPEN Bid Quote* - The open (first) bid quote of the 1M bin.\n",
    "\n",
    "*HIGH Bid Quote* - The highest bid quote of the 1M bin.\n",
    "\n",
    "*LOW Bid Quote* - The lowest bid quote of the 1M bin.\n",
    "\n",
    "*CLOSE Bid Quote* - The close (last) bid quote of the 1M bin.\n",
    "\n",
    "*Volume* - Number of lots. From what I saw it's always 0 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load data for BRENT CRUDE OIL in USD and process it, by getting only the timestamp and CLOSE bid quote\n",
    "val oilDS = spark.read.fx1m(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se/*csv.gz\").toDF.withColumn(\"ticker\", lit(\"BCOUSD\")).select($\"ticker\", $\"time\" as \"x\", $\"close\" as \"y\").as[TickerPoint].orderBy(\"x\")\n",
    "// Convert Dataset to Dataframe\n",
    "val oilDF = oilDS.toDF()    \n",
    "oilDF.printSchema()\n",
    "oilDF.show(10) // error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     root\n",
    ">      |-- ticker: string (nullable = false)\n",
    ">      |-- x: timestamp (nullable = true)\n",
    ">      |-- y: double (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"trendCalculus\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "def logLevel(sc):\n",
    "    # REF: https://stackoverflow.com/questions/25193488/how-to-turn-off-info-logging-in-spark\n",
    "    log4jLogger = sc._jvm.org.apache.log4j\n",
    "    log4jLogger.Logger.getLogger(\"org\").setLevel(log4jLogger.Level.ERROR)\n",
    "    log = log4jLogger.LogManager.getLogger(__name__)\n",
    "    log.warn(\"Custom WARN message\")\n",
    "\n",
    "\n",
    "logLevel(spark)\n",
    "\n",
    "print(spark.range(5000).where(\"id > 500\").selectExpr(\"sum(id)\").collect())\n",
    "\n",
    "sc._jvm.org.lamastex.spark.trendcalculus.Point(0, 0.0)\n",
    "oilDS = sc._jvm.org.lamastex.spark.trendcalculus.Finance.fx1m(\"dbfs:/FileStore/shared_uploads/fabiansi@kth.se/*csv.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
