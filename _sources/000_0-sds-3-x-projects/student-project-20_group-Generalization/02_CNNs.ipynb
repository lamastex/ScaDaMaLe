{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Image classification\n",
    "-----------------------\n",
    "\n",
    "Let us begin with a classic machine learning task: Image classification\n",
    "with Convolutional Neural Networks (CNN). The general idea is as\n",
    "follows: 1. Train a CNN on normal training data. Evaluate its\n",
    "performance on a conventional (\"unmixed\") validation set and on a MixUp\n",
    "(\"mixed\") version of the same validation set. 2. Train a CNN on MixUp\n",
    "training data. Evaluate its performance on both unmixed and mixed\n",
    "validation data.\n",
    "\n",
    "When training on MixUp training data, we compute a new MixUp of each\n",
    "batch in every epoch. As explained in the introduction, this effectively\n",
    "augments the training set and hopefully makes the network more robust.\n",
    "Evaluating the performance of both networks on unmixed and mixed\n",
    "validation data allows us to compare the generalization properties of\n",
    "both networks, the working hypothesis being that training on MixUp data\n",
    "enhances generalization. To reduce the dependence of our results on the\n",
    "specific choice of hyperparameters, we train several CNNs with varying\n",
    "numbers of convolutional and dense layers. This is done for both kinds\n",
    "of training data (unmixed, mixed) in a distributed fashion using Ray\n",
    "Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from functools import partial\n",
    "\n",
    "# Fixes the issue \"AttributeError: 'ConsoleBuffer has no attribute 'fileno'\"\n",
    "import sys\n",
    "sys.stdout.fileno = lambda: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### The data set\n",
    "\n",
    "We will use the Intel Image Classification data set \\[\\[3\\]\\]. It\n",
    "consists of 25k 150x150 RBG images from 6 different classes: buildings,\n",
    "forest, glacier, mountain, sea, or street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The global parameters for training.\n",
    "\"\"\"\n",
    "\n",
    "img_height,img_width,channels = 32,32,3\n",
    "batch_size = 32\n",
    "train_data_dir,test_data_dir = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train/\", \"dbfs/FileStore/tables/Group20/seg_test/seg_test/\"\n",
    "num_classes = 6\n",
    "alpha = 0.2 # Degree of mixup is ~ Beta(alpha,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### MixUp data generator\n",
    "\n",
    "To create MixUp data, we will define a custom data generator. It takes\n",
    "an underlying image generator as argument, and outputs convex\n",
    "combinations of two randomly selected (example,label) pairs drawn\n",
    "according to the underlying generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "def copy_data():\n",
    "  src = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train\"\n",
    "  dst = os.path.join(os.getcwd(), 'seg_train')\n",
    "  print(\"Copying data/files to local horovod folder...\")\n",
    "  shutil.copytree(src, dst)\n",
    "  print(\"Done with copying!\")\n",
    "  train_data_dir = dst\n",
    "\n",
    "  src = \"/dbfs/FileStore/tables/Group20/seg_test/seg_test\"\n",
    "  dst = os.path.join(os.getcwd(), 'seg_test')\n",
    "  print(\"Copying data/files to local horovod folder...\")\n",
    "  shutil.copytree(src, dst)\n",
    "  print(\"Done with copying!\")\n",
    "  test_data_dir = dst\n",
    "\n",
    "  return train_data_dir,test_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    ">     Out[3]: <tensorflow.python.keras.engine.sequential.Sequential at 0x7f76ea86d650>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_index = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # First iterator yielding tuples of (x, y)\n",
    "        self.generator1 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Second iterator yielding tuples of (x, y)\n",
    "        self.generator2 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Number of images across all classes in image directory.\n",
    "        self.n = self.generator1.samples\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of batches\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get a pair of inputs and outputs from two iterators.\n",
    "        X1, y1 = self.generator1.next()\n",
    "        X2, y2 = self.generator2.next()\n",
    "\n",
    "\n",
    "        # random sample the lambda value from beta distribution.\n",
    "        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])\n",
    "\n",
    "        X_l = l.reshape(X1.shape[0], 1, 1, 1)\n",
    "        y_l = l.reshape(X1.shape[0], 1)\n",
    "\n",
    "\n",
    "        # Perform the mixup.\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "        y = y1 * y_l + y2 * (1 - y_l)\n",
    "        return X, y\n",
    "\n",
    "    def reset_index(self):\n",
    "        \"\"\"Reset the generator indexes array.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A method that gives us the different dataloaders that we need for training and validation.\n",
    "\n",
    "With for_training set to True, the model gives us the dataloaders\n",
    "* train_mix_loader: Gives us mixed data for training\n",
    "* train_loader:     Gives us the unmixed training data\n",
    "* val_mix_loader:   Gives us mixed validation data\n",
    "* val_loader:       Gives us unmixed validation data\n",
    "\n",
    "By setting for_training to False, the method gives us the dataloader\n",
    "* test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.\n",
    "\"\"\"\n",
    "def get_data_loaders(train_data_dir,test_data_dir,for_training = True):\n",
    "  \n",
    "    #For training data\n",
    "    if for_training:\n",
    "        datagen_train_val = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=5,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0,\n",
    "                                shear_range=0.05,\n",
    "                                zoom_range=0,\n",
    "                                brightness_range=(1, 1.3),\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest',\n",
    "                                validation_split=0.1)\n",
    "\n",
    "        train_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,\n",
    "                                                   directory = train_data_dir,\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   img_height = img_height,\n",
    "                                                   img_width = img_width,\n",
    "                                                   alpha=alpha,\n",
    "                                                   subset=\"training\")\n",
    "        \n",
    "        val_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,\n",
    "                                                 directory = train_data_dir,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 img_height = img_height,\n",
    "                                                 img_width = img_width,\n",
    "                                                 alpha=alpha,\n",
    "                                                 subset=\"validation\")\n",
    "\n",
    "        train_loader = datagen_train_val.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=\"training\")\n",
    "\n",
    "        val_loader = datagen_train_val.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=\"validation\")\n",
    "        \n",
    "        return train_mix_loader,train_loader, val_mix_loader, val_loader\n",
    "\n",
    "    #For test data\n",
    "    else:\n",
    "        datagen_test = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0,\n",
    "                                height_shift_range=0,\n",
    "                                shear_range=0,\n",
    "                                zoom_range=0,\n",
    "                                brightness_range=(1, 1),\n",
    "                                horizontal_flip=False,\n",
    "                                fill_mode='nearest',\n",
    "                                validation_split=0)\n",
    "\n",
    "        test_loader = datagen_test.flow_from_directory(test_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=False,\n",
    "                                                        subset=None)\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "##### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creates the CNN with number_conv convolutional layers followed by number_dense dense layers. The model is compiled with a SGD optimizer and a categorical crossentropy loss.\n",
    "\"\"\"\n",
    "def create_model(number_conv,number_dense):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=\"same\", input_shape=(img_height, img_width,channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    for s in range(1,number_conv):\n",
    "        model.add(Conv2D(24+12*s,kernel_size = 3,padding=\"same\", activation = 'relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    for s in range(number_dense):\n",
    "        model.add(Dense(units=num_classes, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes,activation= \"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### Training function\n",
    "\n",
    "\\*\\*This should be replaced by Horovod training function if we manage to\n",
    "complete the installation. Now, I put the Olofs\\_implementation\n",
    "thing\\*\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config, checkpoint_dir=None):\n",
    "    # Hyperparameters\n",
    "    number_conv, number_dense = config[\"number_conv\"], config[\"number_dense\"]\n",
    "    train_with_mixed_data = config[\"train_with_mixed_data\"]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Get the different dataloaders\n",
    "    One with training data using mixing\n",
    "    One with training without mixing\n",
    "    One with validation data with mixing\n",
    "    One with validation without mixing\n",
    "    Set for_training to False to get testing data\n",
    "    \"\"\"\n",
    "    #train_data_dir,test_data_dir = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train\",\"/dbfs/FileStore/tables/Group20/seg_test/seg_test\"\n",
    "\n",
    "    #train_data_dir, test_data_dir = copy_data()\n",
    "    train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(train_data_dir, test_data_dir, for_training = True)\n",
    "\n",
    "    \"\"\"\n",
    "    Construct the model based on hyperparameters\n",
    "    \"\"\"\n",
    "    model = create_model( number_conv,number_dense )\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?\n",
    "    \"\"\"\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10,monitor=\"val_accuracy\",min_delta=0.01,restore_best_weights=True)]\n",
    "\n",
    "    \"\"\"\n",
    "    Train the model and give the training history.\n",
    "    \"\"\"\n",
    "    if train_with_mixed_data:\n",
    "      history = model.fit_generator(train_mix_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)\n",
    "    else:\n",
    "      history = model.fit_generator(train_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)\n",
    "    \n",
    "    \"\"\"\n",
    "    Logg the results\n",
    "    \"\"\"\n",
    "    #x_mix, y_mix = mixup_data( x_val, y_val)\n",
    "    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )\n",
    "    train_loss_unmix, train_acc_unmix = model.evaluate( train_dataloader )\n",
    "    val_mix_loss, val_mix_acc = model.evaluate( val_mix_dataloader )\n",
    "    ind_max = np.argmax(history.history['val_accuracy'])\n",
    "    train_mix_acc = history.history['accuracy'][ind_max]\n",
    "    train_loss = history.history['loss'][ind_max]\n",
    "    val_acc = history.history['val_accuracy'][ind_max]\n",
    "    val_loss = history.history['val_loss'][ind_max]\n",
    "    \n",
    "    tune.report(mean_loss=train_mix_loss, train_mix_accuracy = train_mix_acc, train_accuracy = train_acc_unmix, val_mix_accuracy = val_mix_acc, val_accuracy = val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(for_training = True)\n",
    "train_data_dir,test_data_dir = copy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Copying data/files to local horovod folder...\n",
    ">     Done with copying!\n",
    ">     Copying data/files to local horovod folder...\n",
    ">     Done with copying!\n",
    "\n",
    "  \n",
    "\n",
    "### Connection between MixUp performance and generalization\n",
    "\n",
    "First, we will train our neural networks using a standard procedure,\n",
    "with normal training data. We then measure their performance on a\n",
    "validation set as well as on a MixUp version of the same validation set,\n",
    "the idea being to study the connection between these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_function( config={\"number_conv\": 2, \"number_dense\": 2, \"train_with_mixed_data\": False} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of rows.\n",
    "reporter = CLIReporter(max_progress_rows=10)\n",
    "# Add a custom metric column, in addition to the default metrics.\n",
    "# Note that this must be a metric that is returned in your training results.\n",
    "reporter.add_metric_column(\"val_mix_accuracy\")\n",
    "reporter.add_metric_column(\"val_accuracy\")\n",
    "reporter.add_metric_column(\"train_accuracy\")\n",
    "reporter.add_metric_column(\"train_mix_accuracy\")\n",
    "\n",
    "#config = {\"number_conv\" : 3,\"number_dense\" : 5}\n",
    "#training_function(config)\n",
    "\n",
    "#get_data_loaders()\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"number_conv\": tune.grid_search(np.arange(2,7,2).tolist()),\n",
    "        \"number_dense\": tune.grid_search(np.arange(0,3,1).tolist()),\n",
    "        \"train_with_mixed_data\": False\n",
    "    },\n",
    "    local_dir='ray_results',\n",
    "    progress_reporter=reporter\n",
    ") \n",
    "  #resources_per_trial={'gpu': 1})\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "    metric=\"val_accuracy\", mode=\"max\"))\n",
    "\n",
    "#Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     2021-01-12 18:12:47,354\tWARNING tune.py:409 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n",
    ">     == Status ==\n",
    ">     Memory usage on this node: 8.0/10.8 GiB\n",
    ">     Using FIFO scheduling algorithm.\n",
    ">     Resources requested: 1/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)\n",
    ">     Result logdir: /databricks/driver/ray_results/training_function_2021-01-12_18-12-47\n",
    ">     Number of trials: 1/9 (1 RUNNING)\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">     | Trial name                    | status   | loc   |   number_conv |   number_dense |\n",
    ">     |-------------------------------+----------+-------+---------------+----------------|\n",
    ">     | training_function_c6336_00000 | RUNNING  |       |             2 |              0 |\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">\n",
    ">\n",
    ">     (pid=6948) 2021-01-12 18:12:49.118221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     (pid=6943) 2021-01-12 18:12:49.275935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     (pid=6945) 2021-01-12 18:12:49.365509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     (pid=6949) 2021-01-12 18:12:49.345345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
    ">     (pid=6948) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6949) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6945) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6943) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6945) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6948) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6949) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6943) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6948) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6949) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6945) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6943) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6948) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6949) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6945) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6943) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6948) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6945) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6943) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6949) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=6948) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6949) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6945) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6943) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=6948) 2021-01-12 18:13:07.019617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028237: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028400: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028438: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2\n",
    ">     (pid=6948) 2021-01-12 18:13:07.028756: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     (pid=6948) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     (pid=6948) 2021-01-12 18:13:07.038165: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     (pid=6948) 2021-01-12 18:13:07.038446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa37c3100b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     (pid=6948) 2021-01-12 18:13:07.038471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     (pid=6943) 2021-01-12 18:13:07.027957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     (pid=6943) 2021-01-12 18:13:07.036413: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    ">     (pid=6943) 2021-01-12 18:13:07.036466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6943) 2021-01-12 18:13:07.036480: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6943) 2021-01-12 18:13:07.036587: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2\n",
    ">     (pid=6943) 2021-01-12 18:13:07.036639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\n",
    ">     (pid=6943) 2021-01-12 18:13:07.036655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2\n",
    ">     (pid=6943) 2021-01-12 18:13:07.037129: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     (pid=6943) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     (pid=6943) 2021-01-12 18:13:07.048693: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     (pid=6943) 2021-01-12 18:13:07.049004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f38dc310160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     (pid=6943) 2021-01-12 18:13:07.049038: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     (pid=6945) 2021-01-12 18:13:07.017585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     (pid=6945) 2021-01-12 18:13:07.044730: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    ">     (pid=6945) 2021-01-12 18:13:07.044782: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6945) 2021-01-12 18:13:07.044798: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6945) 2021-01-12 18:13:07.044912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2\n",
    ">     (pid=6945) 2021-01-12 18:13:07.044951: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\n",
    ">     (pid=6945) 2021-01-12 18:13:07.044965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2\n",
    ">     (pid=6945) 2021-01-12 18:13:07.045332: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     (pid=6945) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     (pid=6949) 2021-01-12 18:13:07.027482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
    ">     (pid=6949) 2021-01-12 18:13:07.034677: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    ">     (pid=6949) 2021-01-12 18:13:07.034744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6949) 2021-01-12 18:13:07.034762: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1120-144117-apses921-10-149-224-88\n",
    ">     (pid=6949) 2021-01-12 18:13:07.034876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.80.2\n",
    ">     (pid=6949) 2021-01-12 18:13:07.034928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.80.2\n",
    ">     (pid=6949) 2021-01-12 18:13:07.034943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.80.2\n",
    ">     (pid=6949) 2021-01-12 18:13:07.035171: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
    ">     (pid=6949) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     (pid=6949) 2021-01-12 18:13:07.050296: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     (pid=6949) 2021-01-12 18:13:07.050606: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efeec3101d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     (pid=6949) 2021-01-12 18:13:07.050637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     (pid=6945) 2021-01-12 18:13:07.064856: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
    ">     (pid=6945) 2021-01-12 18:13:07.065243: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f93c8310320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    ">     (pid=6945) 2021-01-12 18:13:07.065279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    ">     (pid=6948) WARNING:tensorflow:From <command-685894176419834>:37: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
    ">     (pid=6948) Instructions for updating:\n",
    ">     (pid=6948) Please use Model.fit, which supports generators.\n",
    ">     (pid=6943) WARNING:tensorflow:From <command-685894176419834>:37: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
    ">     (pid=6943) Instructions for updating:\n",
    ">     (pid=6943) Please use Model.fit, which supports generators.\n",
    ">     (pid=6945) WARNING:tensorflow:From <command-685894176419834>:37: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
    ">     (pid=6945) Instructions for updating:\n",
    ">     (pid=6945) Please use Model.fit, which supports generators.\n",
    ">     (pid=6949) WARNING:tensorflow:From <command-685894176419834>:37: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
    ">     (pid=6949) Instructions for updating:\n",
    ">     (pid=6949) Please use Model.fit, which supports generators.\n",
    ">     (pid=6945) Epoch 1/200\n",
    ">     (pid=6943) Epoch 1/200\n",
    ">     (pid=6949) Epoch 1/200\n",
    ">     (pid=6948) Epoch 1/200\n",
    ">     (pid=6943)   1/395 [..............................] - ETA: 0s - loss: 2.2131 - accuracy: 0.1562\n",
    ">     (pid=6948)   1/395 [..............................] - ETA: 0s - loss: 2.3414 - accuracy: 0.1875\n",
    ">     (pid=6945)   1/395 [..............................] - ETA: 0s - loss: 2.0423 - accuracy: 0.2500\n",
    ">     (pid=6949)   1/395 [..............................] - ETA: 0s - loss: 2.2062 - accuracy: 0.1875\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  2/395 [..............................] - ETA: 4:41 - loss: 2.0237 - accuracy: 0.1875\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  2/395 [..............................] - ETA: 5:47 - loss: 2.6242 - accuracy: 0.2500\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  2/395 [..............................] - ETA: 6:03 - loss: 2.1231 - accuracy: 0.2969\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  2/395 [..............................] - ETA: 5:13 - loss: 2.6741 - accuracy: 0.2500\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  3/395 [..............................] - ETA: 6:33 - loss: 1.9714 - accuracy: 0.1771\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  3/395 [..............................] - ETA: 7:06 - loss: 2.1580 - accuracy: 0.3229\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  3/395 [..............................] - ETA: 7:45 - loss: 2.4659 - accuracy: 0.3229\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  3/395 [..............................] - ETA: 6:58 - loss: 2.9112 - accuracy: 0.2812\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  4/395 [..............................] - ETA: 7:29 - loss: 1.8858 - accuracy: 0.2344\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  4/395 [..............................] - ETA: 7:33 - loss: 2.2433 - accuracy: 0.3438\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  4/395 [..............................] - ETA: 8:22 - loss: 2.4949 - accuracy: 0.3750\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  4/395 [..............................] - ETA: 7:30 - loss: 2.7770 - accuracy: 0.3516\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  5/395 [..............................] - ETA: 7:50 - loss: 1.8617 - accuracy: 0.2375\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  5/395 [..............................] - ETA: 7:48 - loss: 2.4487 - accuracy: 0.3750\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  5/395 [..............................] - ETA: 7:48 - loss: 2.7115 - accuracy: 0.3875\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  5/395 [..............................] - ETA: 8:39 - loss: 2.7588 - accuracy: 0.3750\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  6/395 [..............................] - ETA: 8:15 - loss: 1.8445 - accuracy: 0.2396\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  6/395 [..............................] - ETA: 8:32 - loss: 2.5224 - accuracy: 0.3854\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  6/395 [..............................] - ETA: 8:10 - loss: 2.7145 - accuracy: 0.4010\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  6/395 [..............................] - ETA: 8:57 - loss: 2.8308 - accuracy: 0.3802\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  7/395 [..............................] - ETA: 8:34 - loss: 1.8105 - accuracy: 0.2545\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  7/395 [..............................] - ETA: 8:20 - loss: 2.8188 - accuracy: 0.3973\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  7/395 [..............................] - ETA: 8:51 - loss: 2.5645 - accuracy: 0.3839\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  7/395 [..............................] - ETA: 9:21 - loss: 2.9240 - accuracy: 0.3839\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  8/395 [..............................] - ETA: 8:41 - loss: 1.8109 - accuracy: 0.2656\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  8/395 [..............................] - ETA: 8:36 - loss: 2.9181 - accuracy: 0.3945\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  8/395 [..............................] - ETA: 9:09 - loss: 2.5546 - accuracy: 0.4062\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  8/395 [..............................] - ETA: 9:39 - loss: 2.9288 - accuracy: 0.3789\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  9/395 [..............................] - ETA: 8:55 - loss: 1.8119 - accuracy: 0.2674\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  9/395 [..............................] - ETA: 9:02 - loss: 2.9599 - accuracy: 0.4062\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  9/395 [..............................] - ETA: 9:24 - loss: 2.6355 - accuracy: 0.3958\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008  9/395 [..............................] - ETA: 10:00 - loss: 2.8595 - accuracy: 0.3785\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 10/395 [..............................] - ETA: 9:18 - loss: 1.8093 - accuracy: 0.2656\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 10/395 [..............................] - ETA: 9:42 - loss: 2.7097 - accuracy: 0.4031\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 10/395 [..............................] - ETA: 9:26 - loss: 2.8147 - accuracy: 0.4313\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 10/395 [..............................] - ETA: 9:58 - loss: 2.8107 - accuracy: 0.3969 \n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 11/395 [..............................] - ETA: 9:24 - loss: 1.8248 - accuracy: 0.2642\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 11/395 [..............................] - ETA: 9:15 - loss: 2.8705 - accuracy: 0.4290\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 11/395 [..............................] - ETA: 9:46 - loss: 2.6304 - accuracy: 0.4176\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 11/395 [..............................] - ETA: 10:00 - loss: 2.7871 - accuracy: 0.4176\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 12/395 [..............................] - ETA: 9:26 - loss: 1.8038 - accuracy: 0.2682\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 12/395 [..............................] - ETA: 9:17 - loss: 2.9361 - accuracy: 0.4245\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 12/395 [..............................] - ETA: 9:53 - loss: 2.5781 - accuracy: 0.4297\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 12/395 [..............................] - ETA: 10:03 - loss: 2.8041 - accuracy: 0.4089\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 13/395 [..............................] - ETA: 9:28 - loss: 1.7958 - accuracy: 0.2716\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 13/395 [..............................] - ETA: 9:23 - loss: 2.9888 - accuracy: 0.4231\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 13/395 [..............................] - ETA: 9:54 - loss: 2.6444 - accuracy: 0.4207\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 13/395 [..............................] - ETA: 10:11 - loss: 2.7499 - accuracy: 0.4111\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 14/395 [>.............................] - ETA: 9:33 - loss: 3.0002 - accuracy: 0.4263\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 14/395 [>.............................] - ETA: 9:58 - loss: 2.7610 - accuracy: 0.4174\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 14/395 [>.............................] - ETA: 10:05 - loss: 1.7887 - accuracy: 0.2835\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 14/395 [>.............................] - ETA: 10:08 - loss: 2.7568 - accuracy: 0.4107\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 15/395 [>.............................] - ETA: 9:40 - loss: 3.0620 - accuracy: 0.4208\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 15/395 [>.............................] - ETA: 9:56 - loss: 2.8249 - accuracy: 0.4083\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 15/395 [>.............................] - ETA: 10:09 - loss: 1.7787 - accuracy: 0.2833\n",
    ">     (pid=6948) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 15/395 [>.............................] - ETA: 10:11 - loss: 2.7702 - accuracy: 0.4104\n",
    ">     (pid=6949) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 16/395 [>.............................] - ETA: 9:50 - loss: 3.0118 - accuracy: 0.4258\n",
    ">     (pid=6945) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 16/395 [>.............................] - ETA: 10:02 - loss: 2.8379 - accuracy: 0.4062\n",
    ">     (pid=6943) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 16/395 [>.............................] - ETA: 10:09 - loss: 1.7643 - accuracy: 0.2871\n",
    ">\n",
    ">     *** WARNING: skipped 18076112 bytes of output ***\n",
    ">\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008377/395 [===========================>..] - ETA: 11s - loss: 1.0448 - accuracy: 0.6059\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008378/395 [===========================>..] - ETA: 10s - loss: 1.0445 - accuracy: 0.6065\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008379/395 [===========================>..] - ETA: 10s - loss: 1.0443 - accuracy: 0.6066\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008380/395 [===========================>..]\n",
    ">     (pid=14102)  - ETA: 9s - loss: 1.0445 - accuracy: 0.6066 \n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008381/395 [===========================>..] - ETA: 8s - loss: 1.0444 - accuracy: 0.6067\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008382/395 [============================>.] - ETA: 8s - loss: 1.0449 - accuracy: 0.6064\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008383/395 [============================>.] - ETA: 7s - loss: 1.0449 - accuracy: 0.6062\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008384/395 [============================>.] - ETA: 7s - loss: 1.0448 - accuracy: 0.6059\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008385/395 [============================>.] - ETA: 6s - loss: 1.0447 - accuracy: 0.6059\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008386/395 [============================>.] - ETA: 5s - loss: 1.0449 - accuracy: 0.6057\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008387/395 [============================>.] - ETA: 5s - loss: 1.0446 - accuracy: 0.6059\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008388/395 [============================>.] - ETA: 4s - loss: 1.0441 - accuracy: 0.6062\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008389/395 [============================>.] - ETA: 3s - loss: 1.0439 - accuracy: 0.6064\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008390/395 [============================>.] - ETA: 3s - loss: 1.0438 - accuracy: 0.6067\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008391/395 [============================>.] - ETA: 2s - loss: 1.0437 - accuracy: 0.6068\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008392/395 [============================>.] - ETA: 1s - loss: 1.0437 - accuracy: 0.6071\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008393/395 [============================>.] - ETA: 1s - loss: 1.0436 - accuracy: 0.6070\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008394/395 [============================>.] - ETA: 0s - loss: 1.0437 - accuracy: 0.6072\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008395/395 [==============================] - ETA: 0s - loss: 1.0434 - accuracy: 0.6077\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008395/395 [==============================] - 252s 637ms/step - loss: 1.0434 - accuracy: 0.6077\n",
    ">     (pid=14102)  1/44 [..............................] - ETA: 0s - loss: 1.3407 - accuracy: 0.5000\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 2/44 [>.............................] - ETA: 24s - loss: 1.2272 - accuracy: 0.5938\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 3/44 [=>............................] - ETA: 34s - loss: 1.2597 - accuracy: 0.5521\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 4/44 [=>............................] - ETA: 37s - loss: 1.3114 - accuracy: 0.5391\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 5/44 [==>...........................] - ETA: 37s - loss: 1.2837 - accuracy: 0.5312\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 6/44 [===>..........................] - ETA: 38s - loss: 1.2913 - accuracy: 0.5312\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 7/44 [===>..........................] - ETA: 38s - loss: 1.3062 - accuracy: 0.5402\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 8/44 [====>.........................] - ETA: 38s - loss: 1.3110 - accuracy: 0.5508\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008 9/44 [=====>........................] - ETA: 38s - loss: 1.2941 - accuracy: 0.5660\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000810/44 [=====>........................] - ETA: 37s - loss: 1.2770 - accuracy: 0.5719\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000811/44 [======>.......................] - ETA: 36s - loss: 1.2895 - accuracy: 0.5653\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000812/44 [=======>......................] - ETA: 35s - loss: 1.2831 - accuracy: 0.5547\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000813/44 [=======>......................] - ETA: 34s - loss: 1.2693 - accuracy: 0.5625\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000814/44 [========>.....................] - ETA: 34s - loss: 1.2614 - accuracy: 0.5625\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000815/44 [=========>....................] - ETA: 33s - loss: 1.2722 - accuracy: 0.5625\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000816/44 [=========>....................] - ETA: 32s - loss: 1.2561 - accuracy: 0.5625\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000817/44 [==========>...................] - ETA: 31s - loss: 1.2545 - accuracy: 0.5662\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000818/44 [===========>..................] - ETA: 30s - loss: 1.2468 - accuracy: 0.5694\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000819/44 [===========>..................] - ETA: 30s - loss: 1.2473 - accuracy: 0.5691\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000820/44 [============>.................] - ETA: 29s - loss: 1.2446 - accuracy: 0.5672\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000821/44 [=============>................] - ETA: 28s - loss: 1.2428 - accuracy: 0.5655\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000822/44 [==============>...............] - ETA: 27s - loss: 1.2506 - accuracy: 0.5611\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000823/44 [==============>...............] - ETA: 25s - loss: 1.2489 - accuracy: 0.5611\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000824/44 [===============>..............] - ETA: 24s - loss: 1.2492 - accuracy: 0.5638\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000825/44 [================>.............] - ETA: 23s - loss: 1.2480 - accuracy: 0.5663\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000826/44 [================>.............] - ETA: 22s - loss: 1.2478 - accuracy: 0.5673\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000827/44 [=================>............] - ETA: 20s - loss: 1.2499 - accuracy: 0.5671\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000828/44 [==================>...........] - ETA: 19s - loss: 1.2494 - accuracy: 0.5681\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000829/44 [==================>...........] - ETA: 18s - loss: 1.2509 - accuracy: 0.5700\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000830/44 [===================>..........] - ETA: 17s - loss: 1.2494 - accuracy: 0.5698\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000831/44 [====================>.........] - ETA: 16s - loss: 1.2489 - accuracy: 0.5685\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000832/44 [====================>.........] - ETA: 15s - loss: 1.2472 - accuracy: 0.5684\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000833/44 [=====================>........] - ETA: 13s - loss: 1.2489 - accuracy: 0.5701\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000834/44 [======================>.......] - ETA: 12s - loss: 1.2514 - accuracy: 0.5708\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000835/44 [======================>.......] - ETA: 11s - loss: 1.2525 - accuracy: 0.5679\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000836/44 [=======================>......] - ETA: 10s - loss: 1.2528 - accuracy: 0.5686\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000837/44 [========================>.....] - ETA: 8s - loss: 1.2544 - accuracy: 0.5684 \n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000838/44 [========================>.....] - ETA: 7s - loss: 1.2610 - accuracy: 0.5658\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000839/44 [=========================>....] - ETA: 6s - loss: 1.2627 - accuracy: 0.5657\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000840/44 [==========================>...] - ETA: 5s - loss: 1.2619 - accuracy: 0.5633\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000841/44 [==========================>...] - ETA: 3s - loss: 1.2618 - accuracy: 0.5648\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000842/44 [===========================>..] - ETA: 2s - loss: 1.2591 - accuracy: 0.5655\n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000843/44 [============================>.] - ETA: 1s - loss: 1.2609 - accuracy: 0.5620\n",
    ">     (pid=14102) 2021-01-13 00:53:00,732\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
    ">     (pid=14102) Traceback (most recent call last):\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
    ">     (pid=14102)     self._entrypoint()\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
    ">     (pid=14102)     self._status_reporter.get_checkpoint())\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
    ">     (pid=14102)     output = fn()\n",
    ">     (pid=14102)   File \"<command-685894176419834>\", line 52, in training_function\n",
    ">     (pid=14102) NameError: name 'train_mix_loss' is not defined\n",
    ">     (pid=14102) Exception in thread Thread-2:\n",
    ">     (pid=14102) Traceback (most recent call last):\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
    ">     (pid=14102)     self.run()\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
    ">     (pid=14102)     raise e\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
    ">     (pid=14102)     self._entrypoint()\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
    ">     (pid=14102)     self._status_reporter.get_checkpoint())\n",
    ">     (pid=14102)   File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
    ">     (pid=14102)     output = fn()\n",
    ">     (pid=14102)   File \"<command-685894176419834>\", line 52, in training_function\n",
    ">     (pid=14102) NameError: name 'train_mix_loss' is not defined\n",
    ">     (pid=14102) \n",
    ">     (pid=14102) \u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000844/44 [==============================] - ETA: 0s - loss: 1.2616 - accuracy: 0.5613\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u0008\u000844/44 [==============================] - 55s 1s/step - loss: 1.2616 - accuracy: 0.5613\n",
    ">     2021-01-13 00:53:00,926\tERROR trial_runner.py:607 -- Trial training_function_c6336_00008: Error processing event.\n",
    ">     Traceback (most recent call last):\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 519, in _process_trial\n",
    ">         result = self.trial_executor.fetch_result(trial)\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 497, in fetch_result\n",
    ">         result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/worker.py\", line 1379, in get\n",
    ">         raise value.as_instanceof_cause()\n",
    ">     ray.exceptions.RayTaskError(TuneError): ray::ImplicitFunc.train() (pid=14102, ip=10.149.224.88)\n",
    ">       File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
    ">       File \"python/ray/_raylet.pyx\", line 415, in ray._raylet.execute_task.function_executor\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/trainable.py\", line 183, in train\n",
    ">         result = self.step()\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
    ">         self._report_thread_runner_error(block=True)\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
    ">         .format(err_tb_str)))\n",
    ">     ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
    ">     ray::ImplicitFunc.train() (pid=14102, ip=10.149.224.88)\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
    ">         self._entrypoint()\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
    ">         self._status_reporter.get_checkpoint())\n",
    ">       File \"/databricks/python/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
    ">         output = fn()\n",
    ">       File \"<command-685894176419834>\", line 52, in training_function\n",
    ">     NameError: name 'train_mix_loss' is not defined\n",
    ">     Result for training_function_c6336_00008:\n",
    ">       {}\n",
    ">       \n",
    ">     == Status ==\n",
    ">     Memory usage on this node: 9.1/10.8 GiB\n",
    ">     Using FIFO scheduling algorithm.\n",
    ">     Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)\n",
    ">     Result logdir: /databricks/driver/ray_results/training_function_2021-01-12_18-12-47\n",
    ">     Number of trials: 9/9 (9 ERROR)\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">     | Trial name                    | status   | loc   |   number_conv |   number_dense |\n",
    ">     |-------------------------------+----------+-------+---------------+----------------|\n",
    ">     | training_function_c6336_00000 | ERROR    |       |             2 |              0 |\n",
    ">     | training_function_c6336_00001 | ERROR    |       |             4 |              0 |\n",
    ">     | training_function_c6336_00002 | ERROR    |       |             6 |              0 |\n",
    ">     | training_function_c6336_00003 | ERROR    |       |             2 |              1 |\n",
    ">     | training_function_c6336_00004 | ERROR    |       |             4 |              1 |\n",
    ">     | training_function_c6336_00005 | ERROR    |       |             6 |              1 |\n",
    ">     | training_function_c6336_00006 | ERROR    |       |             2 |              2 |\n",
    ">     | training_function_c6336_00007 | ERROR    |       |             4 |              2 |\n",
    ">     | training_function_c6336_00008 | ERROR    |       |             6 |              2 |\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">     Number of errored trials: 9\n",
    ">     +-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    ">     | Trial name                    |   # failures | error file                                                                                                                                                      |\n",
    ">     |-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    ">     | training_function_c6336_00000 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00000_0_number_conv=2,number_dense=0_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00001 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00001_1_number_conv=4,number_dense=0_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00002 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00002_2_number_conv=6,number_dense=0_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00003 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00003_3_number_conv=2,number_dense=1_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00004 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00004_4_number_conv=4,number_dense=1_2021-01-12_19-41-14/error.txt |\n",
    ">     | training_function_c6336_00005 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00005_5_number_conv=6,number_dense=1_2021-01-12_19-46-24/error.txt |\n",
    ">     | training_function_c6336_00006 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00006_6_number_conv=2,number_dense=2_2021-01-12_20-35-10/error.txt |\n",
    ">     | training_function_c6336_00007 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00007_7_number_conv=4,number_dense=2_2021-01-12_20-35-23/error.txt |\n",
    ">     | training_function_c6336_00008 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00008_8_number_conv=6,number_dense=2_2021-01-12_22-22-53/error.txt |\n",
    ">     +-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    ">\n",
    ">     == Status ==\n",
    ">     Memory usage on this node: 9.1/10.8 GiB\n",
    ">     Using FIFO scheduling algorithm.\n",
    ">     Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/2.49 GiB heap, 0.0/0.83 GiB objects (0/1.0 accelerator_type:T4)\n",
    ">     Result logdir: /databricks/driver/ray_results/training_function_2021-01-12_18-12-47\n",
    ">     Number of trials: 9/9 (9 ERROR)\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">     | Trial name                    | status   | loc   |   number_conv |   number_dense |\n",
    ">     |-------------------------------+----------+-------+---------------+----------------|\n",
    ">     | training_function_c6336_00000 | ERROR    |       |             2 |              0 |\n",
    ">     | training_function_c6336_00001 | ERROR    |       |             4 |              0 |\n",
    ">     | training_function_c6336_00002 | ERROR    |       |             6 |              0 |\n",
    ">     | training_function_c6336_00003 | ERROR    |       |             2 |              1 |\n",
    ">     | training_function_c6336_00004 | ERROR    |       |             4 |              1 |\n",
    ">     | training_function_c6336_00005 | ERROR    |       |             6 |              1 |\n",
    ">     | training_function_c6336_00006 | ERROR    |       |             2 |              2 |\n",
    ">     | training_function_c6336_00007 | ERROR    |       |             4 |              2 |\n",
    ">     | training_function_c6336_00008 | ERROR    |       |             6 |              2 |\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">     Number of errored trials: 9\n",
    ">     +-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    ">     | Trial name                    |   # failures | error file                                                                                                                                                      |\n",
    ">     |-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    ">     | training_function_c6336_00000 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00000_0_number_conv=2,number_dense=0_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00001 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00001_1_number_conv=4,number_dense=0_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00002 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00002_2_number_conv=6,number_dense=0_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00003 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00003_3_number_conv=2,number_dense=1_2021-01-12_18-12-47/error.txt |\n",
    ">     | training_function_c6336_00004 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00004_4_number_conv=4,number_dense=1_2021-01-12_19-41-14/error.txt |\n",
    ">     | training_function_c6336_00005 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00005_5_number_conv=6,number_dense=1_2021-01-12_19-46-24/error.txt |\n",
    ">     | training_function_c6336_00006 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00006_6_number_conv=2,number_dense=2_2021-01-12_20-35-10/error.txt |\n",
    ">     | training_function_c6336_00007 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00007_7_number_conv=4,number_dense=2_2021-01-12_20-35-23/error.txt |\n",
    ">     | training_function_c6336_00008 |            1 | /databricks/driver/ray_results/training_function_2021-01-12_18-12-47/training_function_c6336_00008_8_number_conv=6,number_dense=2_2021-01-12_22-22-53/error.txt |\n",
    ">     +-------------------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "### Directly training on MixUp data\n",
    "\n",
    "As we saw in the previous parts (**probably. my preliminary trials\n",
    "indicated this, at least**), performance on MixUp data gave a reasonably\n",
    "good indication of performance on held-out validation data. This\n",
    "indicates that performance may be improved by directly training on MixUp\n",
    "data, which we will now do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of rows.\n",
    "reporter = CLIReporter(max_progress_rows=10)\n",
    "# Add a custom metric column, in addition to the default metrics.\n",
    "# Note that this must be a metric that is returned in your training results.\n",
    "reporter.add_metric_column(\"val_mix_accuracy\")\n",
    "reporter.add_metric_column(\"val_accuracy\")\n",
    "reporter.add_metric_column(\"train_accuracy\")\n",
    "\n",
    "#config = {\"number_conv\" : 3,\"number_dense\" : 5}\n",
    "#training_function(config)\n",
    "\n",
    "#get_data_loaders()\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"number_conv\": tune.grid_search(np.arange(2,7,2).tolist()),\n",
    "        \"number_dense\": tune.grid_search(np.arange(0,3,1).tolist()),\n",
    "        \"train_with_mixed_data\": True\n",
    "    },\n",
    "    local_dir='ray_results',\n",
    "    progress_reporter=reporter)\n",
    "    \n",
    "  #resources_per_trial={'gpu': 1})\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "    metric=\"val_accuracy\", mode=\"max\"))\n",
    "\n",
    "#Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "### Conclusions\n",
    "\n",
    "**We obviously need to check if this is true...** In conclusion, we\n",
    "found some agreement between the performance of networks trained through\n",
    "a standard procedure on a MixUp version of the training set and the\n",
    "performance on a validation set, for a wide variety of hyperparameters.\n",
    "By directly utilizing MixUp data as part of the training procedure, we\n",
    "found further gains in the performance on held-out validation data,\n",
    "again for a wide variety of hyperparameters. This indicates that, at\n",
    "least for image data and convolutional neural networks, the connection\n",
    "between MixUp and generalization is strong."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
