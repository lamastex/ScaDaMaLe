{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Image classification\n",
    "-----------------------\n",
    "\n",
    "Let us begin with a classic machine learning task: Image classification\n",
    "with Convolutional Neural Networks (CNN). The general idea is as\n",
    "follows: 1. Train a CNN on normal training data. Evaluate its\n",
    "performance on a conventional (\"unmixed\") validation set and on a MixUp\n",
    "(\"mixed\") version of the same validation set. 2. Train a CNN on MixUp\n",
    "training data. Evaluate its performance on both unmixed and mixed\n",
    "validation data.\n",
    "\n",
    "When training on MixUp training data, we compute a new MixUp of each\n",
    "batch in every epoch. As explained in the introduction, this effectively\n",
    "augments the training set and hopefully makes the network more robust.\n",
    "Evaluating the performance of both networks on unmixed and mixed\n",
    "validation data allows us to compare the generalization properties of\n",
    "both networks, the working hypothesis being that training on MixUp data\n",
    "enhances generalization. To reduce the dependence of our results on the\n",
    "specific choice of hyperparameters, we train several CNNs with varying\n",
    "numbers of convolutional and dense layers. This is done for both kinds\n",
    "of training data (unmixed, mixed) in a distributed fashion using Ray\n",
    "Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from functools import partial\n",
    "\n",
    "# Fixes the issue \"AttributeError: 'ConsoleBuffer has no attribute 'fileno'\"\n",
    "import sys\n",
    "sys.stdout.fileno = lambda: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### The data set\n",
    "\n",
    "We will use the Intel Image Classification data set \\[\\[3\\]\\]. It\n",
    "consists of 25k 150x150 RBG images from 6 different classes: buildings,\n",
    "forest, glacier, mountain, sea, or street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The global parameters for training.\n",
    "\"\"\"\n",
    "\n",
    "img_height,img_width,channels = 32,32,3\n",
    "batch_size = 32\n",
    "train_data_dir,test_data_dir = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train/\", \"dbfs/FileStore/tables/Group20/seg_test/seg_test/\"\n",
    "num_classes = 6\n",
    "alpha = 0.2 # Degree of mixup is ~ Beta(alpha,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### MixUp data generator\n",
    "\n",
    "To create MixUp data, we will define a custom data generator. It takes\n",
    "an underlying image generator as argument, and outputs convex\n",
    "combinations of two randomly selected (example,label) pairs drawn\n",
    "according to the underlying generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "def copy_data():\n",
    "  src = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train\"\n",
    "  dst = os.path.join(os.getcwd(), 'seg_train')\n",
    "  print(\"Copying data/files to local horovod folder...\")\n",
    "  shutil.copytree(src, dst)\n",
    "  print(\"Done with copying!\")\n",
    "  train_data_dir = dst\n",
    "\n",
    "  src = \"/dbfs/FileStore/tables/Group20/seg_test/seg_test\"\n",
    "  dst = os.path.join(os.getcwd(), 'seg_test')\n",
    "  print(\"Copying data/files to local horovod folder...\")\n",
    "  shutil.copytree(src, dst)\n",
    "  print(\"Done with copying!\")\n",
    "  test_data_dir = dst\n",
    "\n",
    "  return train_data_dir,test_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    ">     Out[3]: <tensorflow.python.keras.engine.sequential.Sequential at 0x7f76ea86d650>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_index = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # First iterator yielding tuples of (x, y)\n",
    "        self.generator1 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Second iterator yielding tuples of (x, y)\n",
    "        self.generator2 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Number of images across all classes in image directory.\n",
    "        self.n = self.generator1.samples\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of batches\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get a pair of inputs and outputs from two iterators.\n",
    "        X1, y1 = self.generator1.next()\n",
    "        X2, y2 = self.generator2.next()\n",
    "\n",
    "\n",
    "        # random sample the lambda value from beta distribution.\n",
    "        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])\n",
    "\n",
    "        X_l = l.reshape(X1.shape[0], 1, 1, 1)\n",
    "        y_l = l.reshape(X1.shape[0], 1)\n",
    "\n",
    "\n",
    "        # Perform the mixup.\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "        y = y1 * y_l + y2 * (1 - y_l)\n",
    "        return X, y\n",
    "\n",
    "    def reset_index(self):\n",
    "        \"\"\"Reset the generator indexes array.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A method that gives us the different dataloaders that we need for training and validation.\n",
    "\n",
    "With for_training set to True, the model gives us the dataloaders\n",
    "* train_mix_loader: Gives us mixed data for training\n",
    "* train_loader:     Gives us the unmixed training data\n",
    "* val_mix_loader:   Gives us mixed validation data\n",
    "* val_loader:       Gives us unmixed validation data\n",
    "\n",
    "By setting for_training to False, the method gives us the dataloader\n",
    "* test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.\n",
    "\"\"\"\n",
    "def get_data_loaders(train_data_dir,test_data_dir,for_training = True):\n",
    "  \n",
    "    #For training data\n",
    "    if for_training:\n",
    "        datagen_train_val = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=5,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0,\n",
    "                                shear_range=0.05,\n",
    "                                zoom_range=0,\n",
    "                                brightness_range=(1, 1.3),\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest',\n",
    "                                validation_split=0.1)\n",
    "\n",
    "        train_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,\n",
    "                                                   directory = train_data_dir,\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   img_height = img_height,\n",
    "                                                   img_width = img_width,\n",
    "                                                   alpha=alpha,\n",
    "                                                   subset=\"training\")\n",
    "        \n",
    "        val_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,\n",
    "                                                 directory = train_data_dir,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 img_height = img_height,\n",
    "                                                 img_width = img_width,\n",
    "                                                 alpha=alpha,\n",
    "                                                 subset=\"validation\")\n",
    "\n",
    "        train_loader = datagen_train_val.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=\"training\")\n",
    "\n",
    "        val_loader = datagen_train_val.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=\"validation\")\n",
    "        \n",
    "        return train_mix_loader,train_loader, val_mix_loader, val_loader\n",
    "\n",
    "    #For test data\n",
    "    else:\n",
    "        datagen_test = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0,\n",
    "                                height_shift_range=0,\n",
    "                                shear_range=0,\n",
    "                                zoom_range=0,\n",
    "                                brightness_range=(1, 1),\n",
    "                                horizontal_flip=False,\n",
    "                                fill_mode='nearest',\n",
    "                                validation_split=0)\n",
    "\n",
    "        test_loader = datagen_test.flow_from_directory(test_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=False,\n",
    "                                                        subset=None)\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "##### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creates the CNN with number_conv convolutional layers followed by number_dense dense layers. The model is compiled with a SGD optimizer and a categorical crossentropy loss.\n",
    "\"\"\"\n",
    "def create_model(number_conv,number_dense):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=\"same\", input_shape=(img_height, img_width,channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    for s in range(1,number_conv):\n",
    "        model.add(Conv2D(24+12*s,kernel_size = 3,padding=\"same\", activation = 'relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    for s in range(number_dense):\n",
    "        model.add(Dense(units=num_classes, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes,activation= \"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### Training function\n",
    "\n",
    "\\*\\*This should be replaced by Horovod training function if we manage to\n",
    "complete the installation. Now, I put the Olofs\\_implementation\n",
    "thing\\*\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config, checkpoint_dir=None):\n",
    "    # Hyperparameters\n",
    "    number_conv, number_dense = config[\"number_conv\"], config[\"number_dense\"]\n",
    "    train_with_mixed_data = config[\"train_with_mixed_data\"]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Get the different dataloaders\n",
    "    One with training data using mixing\n",
    "    One with training without mixing\n",
    "    One with validation data with mixing\n",
    "    One with validation without mixing\n",
    "    Set for_training to False to get testing data\n",
    "    \"\"\"\n",
    "    #train_data_dir,test_data_dir = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train\",\"/dbfs/FileStore/tables/Group20/seg_test/seg_test\"\n",
    "\n",
    "    #train_data_dir, test_data_dir = copy_data()\n",
    "    train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(train_data_dir, test_data_dir, for_training = True)\n",
    "\n",
    "    \"\"\"\n",
    "    Construct the model based on hyperparameters\n",
    "    \"\"\"\n",
    "    model = create_model( number_conv,number_dense )\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?\n",
    "    \"\"\"\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10,monitor=\"val_accuracy\",min_delta=0.01,restore_best_weights=True)]\n",
    "\n",
    "    \"\"\"\n",
    "    Train the model and give the training history.\n",
    "    \"\"\"\n",
    "    if train_with_mixed_data:\n",
    "      history = model.fit_generator(train_mix_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)\n",
    "    else:\n",
    "      history = model.fit_generator(train_dataloader, validation_data = val_dataloader,callbacks = callbacks,verbose = True,epochs = 200)\n",
    "    \n",
    "    \"\"\"\n",
    "    Logg the results\n",
    "    \"\"\"\n",
    "    #x_mix, y_mix = mixup_data( x_val, y_val)\n",
    "    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )\n",
    "    train_loss_unmix, train_acc_unmix = model.evaluate( train_dataloader )\n",
    "    val_mix_loss, val_mix_acc = model.evaluate( val_mix_dataloader )\n",
    "    ind_max = np.argmax(history.history['val_accuracy'])\n",
    "    train_mix_acc = history.history['accuracy'][ind_max]\n",
    "    train_mix_loss = history.history[\"loss\"][ind_max]\n",
    "    train_loss = history.history['loss'][ind_max]\n",
    "    val_acc = history.history['val_accuracy'][ind_max]\n",
    "    val_loss = history.history['val_loss'][ind_max]\n",
    "    \n",
    "    tune.report(mean_loss=train_mix_loss, train_mix_accuracy = train_mix_acc, train_accuracy = train_acc_unmix, val_mix_accuracy = val_mix_acc, val_accuracy = val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(for_training = True)\n",
    "train_data_dir,test_data_dir = copy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Copying data/files to local horovod folder...\n",
    ">     Done with copying!\n",
    ">     Copying data/files to local horovod folder...\n",
    ">     Done with copying!\n",
    "\n",
    "  \n",
    "\n",
    "### Connection between MixUp performance and generalization\n",
    "\n",
    "First, we will train our neural networks using a standard procedure,\n",
    "with normal training data. We then measure their performance on a\n",
    "validation set as well as on a MixUp version of the same validation set,\n",
    "the idea being to study the connection between these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_function( config={\"number_conv\": 2, \"number_dense\": 2, \"train_with_mixed_data\": False} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of rows.\n",
    "reporter = CLIReporter(max_progress_rows=10)\n",
    "# Add a custom metric column, in addition to the default metrics.\n",
    "# Note that this must be a metric that is returned in your training results.\n",
    "reporter.add_metric_column(\"val_mix_accuracy\")\n",
    "reporter.add_metric_column(\"val_accuracy\")\n",
    "reporter.add_metric_column(\"train_accuracy\")\n",
    "reporter.add_metric_column(\"train_mix_accuracy\")\n",
    "\n",
    "#config = {\"number_conv\" : 3,\"number_dense\" : 5}\n",
    "#training_function(config)\n",
    "\n",
    "#get_data_loaders()\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"number_conv\": tune.grid_search(np.arange(2,7,3).tolist()),\n",
    "        \"number_dense\": tune.grid_search(np.arange(0,3,2).tolist()),\n",
    "        \"train_with_mixed_data\": False\n",
    "    },\n",
    "    local_dir='ray_results',\n",
    "    progress_reporter=reporter\n",
    ") \n",
    "  #resources_per_trial={'gpu': 1})\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "    metric=\"val_accuracy\", mode=\"max\"))\n",
    "\n",
    "#Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "### Directly training on MixUp data\n",
    "\n",
    "As we saw in the previous parts (**probably. my preliminary trials\n",
    "indicated this, at least**), performance on MixUp data gave a reasonably\n",
    "good indication of performance on held-out validation data. This\n",
    "indicates that performance may be improved by directly training on MixUp\n",
    "data, which we will now do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of rows.\n",
    "reporter = CLIReporter(max_progress_rows=10)\n",
    "# Add a custom metric column, in addition to the default metrics.\n",
    "# Note that this must be a metric that is returned in your training results.\n",
    "reporter.add_metric_column(\"val_mix_accuracy\")\n",
    "reporter.add_metric_column(\"val_accuracy\")\n",
    "reporter.add_metric_column(\"train_accuracy\")\n",
    "\n",
    "#config = {\"number_conv\" : 3,\"number_dense\" : 5}\n",
    "#training_function(config)\n",
    "\n",
    "#get_data_loaders()\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"number_conv\": tune.grid_search(np.arange(2,7,3).tolist()),\n",
    "        \"number_dense\": tune.grid_search(np.arange(0,3,2).tolist()),\n",
    "        \"train_with_mixed_data\": True\n",
    "    },\n",
    "    local_dir='ray_results',\n",
    "    progress_reporter=reporter)\n",
    "    \n",
    "  #resources_per_trial={'gpu': 1})\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "    metric=\"val_accuracy\", mode=\"max\"))\n",
    "\n",
    "#Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "### Conclusions\n",
    "\n",
    "**We obviously need to check if this is true...** In conclusion, we\n",
    "found some agreement between the performance of networks trained through\n",
    "a standard procedure on a MixUp version of the training set and the\n",
    "performance on a validation set, for a wide variety of hyperparameters.\n",
    "By directly utilizing MixUp data as part of the training procedure, we\n",
    "found further gains in the performance on held-out validation data,\n",
    "again for a wide variety of hyperparameters. This indicates that, at\n",
    "least for image data and convolutional neural networks, the connection\n",
    "between MixUp and generalization is strong."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
