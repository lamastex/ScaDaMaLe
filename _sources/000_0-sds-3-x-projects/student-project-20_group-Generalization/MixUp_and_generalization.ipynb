{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "------------\n",
    "\n",
    "A pertinent question in machine learning is to explain why a model\n",
    "generalizes and using the answer to improve learning algorithms.\n",
    "Recently, a training procedure called MixUp was proposed to address this\n",
    "\\[\\[1\\]\\]. The basic idea is that instead of feeding the raw training\n",
    "data to our supervised learning algorithm, we instead use convex\n",
    "combinations of two randomly selected data points. The benefit of this\n",
    "is two-fold. First, it plays the role of data augmentation: the network\n",
    "will never see two completely identical training samples, since we\n",
    "constantly produce new random combinations. Second, the network is\n",
    "encouraged to behave nicely in-between training samples, which has the\n",
    "potential to reduce overfitting. A connection between performance on\n",
    "MixUp data and generalization abilities of networks trained without the\n",
    "MixUp procedure was also studied in \\[\\[2\\]\\].\n",
    "\n",
    "In this project, we will investigate these connections at a large scale\n",
    "by performing a distributed hyperparameter search. First, we will train\n",
    "neural networks without MixUp, and study the connection between MixUp\n",
    "performance and test error. Then, we will train on MixUp data, and see\n",
    "whether directly optimizing MixUp performance will yield more beneficial\n",
    "test errors.\n",
    "\n",
    "To make the hyperparameter search distributed and scalable, we will use\n",
    "the Ray Tune package \\[\\[3\\]\\]. Furthermore, we will use Horovod to\n",
    "enable the individual networks to handle data in a distributed fashion\n",
    "as well \\[\\[4\\]\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from functools import partial\n",
    "\n",
    "# Fixes the issue \"AttributeError: 'ConsoleBuffer has no attribute 'fileno'\"\n",
    "import sys\n",
    "sys.stdout.fileno = lambda: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### The data set\n",
    "\n",
    "We will use the Intel Image Classification data set \\[\\[5\\]\\]. It\n",
    "consists of 25k 150x150 RBG images from 6 different classes: buildings,\n",
    "forest, glacier, mountain, sea, or street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The global parameters for training.\n",
    "\"\"\"\n",
    "\n",
    "img_height,img_width,channels = 32*2,32*2,3\n",
    "batch_size = 32\n",
    "train_data_dir,test_data_dir = \"/dbfs/FileStore/tables/Group20/seg_train/seg_train/\", \"dbfs/FileStore/tables/Group20/seg_test/seg_test/\"\n",
    "num_classes = 6\n",
    "alpha = 0.2 # Degree of mixup is ~ Beta(alpha,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### MixUp data generator\n",
    "\n",
    "To create MixUp data, we will define a custom data generator. It takes\n",
    "an underlying image generator as argument, and outputs convex\n",
    "combinations of two randomly selected (example,label) pairs drawn\n",
    "according to the underlying generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_index = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # First iterator yielding tuples of (x, y)\n",
    "        self.generator1 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Second iterator yielding tuples of (x, y)\n",
    "        self.generator2 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Number of images across all classes in image directory.\n",
    "        self.n = self.generator1.samples\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of batches\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get a pair of inputs and outputs from two iterators.\n",
    "        X1, y1 = self.generator1.next()\n",
    "        X2, y2 = self.generator2.next()\n",
    "\n",
    "\n",
    "        # random sample the lambda value from beta distribution.\n",
    "        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])\n",
    "\n",
    "        X_l = l.reshape(X1.shape[0], 1, 1, 1)\n",
    "        y_l = l.reshape(X1.shape[0], 1)\n",
    "\n",
    "\n",
    "        # Perform the mixup.\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "        y = y1 * y_l + y2 * (1 - y_l)\n",
    "        return X, y\n",
    "\n",
    "    def reset_index(self):\n",
    "        \"\"\"Reset the generator indexes array.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A method that gives us the different dataloaders that we need for training and validation.\n",
    "\n",
    "With for_training set to True, the model gives us the dataloaders\n",
    "* train_mix_loader: A data loader that gives us mixed data for training\n",
    "* train_loader: A data loader that gives us the unmixed training data\n",
    "* val_mixed_loader: A data loader that gives us mixed validation data\n",
    "* val_loader: A data loader with the unmixed validation data\n",
    "\n",
    "By setting for_training to False, the method gives us the dataloader\n",
    "* test_loader: Unmixed and unshuffled dataloader for the testing data. The reason for not shuffeling the data is in order to simplify the validation process.\n",
    "\"\"\"\n",
    "def get_data_loaders(for_training = True):\n",
    "  \n",
    "    #For training data\n",
    "    if for_training:\n",
    "        datagen_train_val = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=5,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0,\n",
    "                                shear_range=0.05,\n",
    "                                zoom_range=0,\n",
    "                                brightness_range=(1, 1.3),\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest',\n",
    "                                validation_split=0.1)\n",
    "\n",
    "        train_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,\n",
    "                                                   directory = train_data_dir,\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   img_height = img_height,\n",
    "                                                   img_width = img_width,\n",
    "                                                   alpha=alpha,\n",
    "                                                   subset=\"training\")\n",
    "        \n",
    "        val_mix_loader = MixupImageDataGenerator(generator = datagen_train_val,\n",
    "                                                 directory = train_data_dir,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 img_height = img_height,\n",
    "                                                 img_width = img_width,\n",
    "                                                 alpha=alpha,\n",
    "                                                 subset=\"validation\")\n",
    "\n",
    "        train_loader = datagen_train_val.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=\"training\")\n",
    "\n",
    "        val_loader = datagen_train_val.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=\"validation\")\n",
    "        \n",
    "        return train_mix_loader,train_loader, val_mix_loader, val_loader\n",
    "\n",
    "    #For test data\n",
    "    else:\n",
    "        datagen_test = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0,\n",
    "                                height_shift_range=0,\n",
    "                                shear_range=0,\n",
    "                                zoom_range=0,\n",
    "                                brightness_range=(1, 1),\n",
    "                                horizontal_flip=False,\n",
    "                                fill_mode='nearest',\n",
    "                                validation_split=0)\n",
    "\n",
    "        test_loader = datagen_test.flow_from_directory(test_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=False,\n",
    "                                                        subset=None)\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "##### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creates the CNN with number_conv convolutional layers followed by number_dense dense layers. THe model is compiled with a SGD optimizer and a categorical crossentropy loss.\n",
    "\"\"\"\n",
    "def create_model(number_conv,number_dense):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(24,kernel_size = 3, activation='relu',padding=\"same\", input_shape=(img_height, img_width,channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    for s in range(1,number_conv):\n",
    "        model.add(Conv2D(24+12*s,kernel_size = 3,padding=\"same\", activation = 'relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    for s in range(number_dense):\n",
    "        model.add(Dense(units=num_classes, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes,activation= \"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "  \n",
    "\n",
    "#### Training function\n",
    "\n",
    "\\*\\*This should be replaced by Horovod training function if we manage to\n",
    "complete the installation. Now, I put the Olofs\\_implementation\n",
    "thing\\*\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config, checkpoint_dir=None):\n",
    "    # Hyperparameters\n",
    "    number_conv, number_dense = config[\"number_conv\"], config[\"number_dense\"]\n",
    "    train_with_mixed_data = config[\"train_with_mixed_data\"]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Get the different dataloaders\n",
    "    One with training data using mixing\n",
    "    One with training without mixing\n",
    "    One with validation data with mixing\n",
    "    One with validation without mixing\n",
    "    Set for_training to False to get testing data\n",
    "    \"\"\"\n",
    "    train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(for_training = True)\n",
    "\n",
    "    \"\"\"\n",
    "    Construct the model based on hyperparameters\n",
    "    \"\"\"\n",
    "    model = create_model( number_conv,number_dense )\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Adds earlystopping to training. This is based on the performance accuracy on the validation dataset. Chould we have validation loss here?\n",
    "    \"\"\"\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10,monitor=\"val_accuracy\",min_delta=0.01,restore_best_weights=True)]\n",
    "\n",
    "    \"\"\"\n",
    "    Train the model and give the training history.\n",
    "    \"\"\"\n",
    "    if train_with_mixed_data:\n",
    "      history = model.fit_generator(train_mix_dataloader, validation_data = val_mix_dataloader,callbacks = callbacks,verbose = False,epochs = 200)\n",
    "    else:\n",
    "      history = model.fit_generator(train_dataloader, validation_data = val_mix_dataloader,callbacks = callbacks,verbose = False,epochs = 200)\n",
    "    \n",
    "    \"\"\"\n",
    "    Logg the results\n",
    "    \"\"\"\n",
    "    #x_mix, y_mix = mixup_data( x_val, y_val)\n",
    "    #mix_loss, mix_acc = model.evaluate( x_mix, y_mix )\n",
    "    train_loss_unmix, train_acc_unmix = model.evaluate( train_dataloader )\n",
    "    val_loss, val_acc = model.evaluate( val_dataloader )\n",
    "    ind_max = np.argmax(history.history['val_accuracy'])\n",
    "    train_acc = history.history['accuracy'][ind_max]\n",
    "    val_mix_acc = history.history['val_accuracy'][ind_max]\n",
    "    \n",
    "    tune.report(mean_loss=train_acc, train_accuracy = train_acc_unmix, val_mix_accuracy = val_mix_acc, val_accuracy = val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix_dataloader,train_dataloader,val_mix_dataloader,val_dataloader = get_data_loaders(for_training = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    ">     Found 12632 images belonging to 6 classes.\n",
    ">     Found 1402 images belonging to 6 classes.\n",
    "\n",
    "  \n",
    "\n",
    "### Connection between MixUp performance and generalization\n",
    "\n",
    "First, we will train our neural networks using a standard procedure,\n",
    "with normal training data. We then measure their performance on a MixUp\n",
    "version of the training set as well as on a validation set to study the\n",
    "connection between these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of rows.\n",
    "reporter = CLIReporter(max_progress_rows=10)\n",
    "# Add a custom metric column, in addition to the default metrics.\n",
    "# Note that this must be a metric that is returned in your training results.\n",
    "reporter.add_metric_column(\"val_mix_accuracy\")\n",
    "reporter.add_metric_column(\"val_accuracy\")\n",
    "reporter.add_metric_column(\"train_accuracy\")\n",
    "\n",
    "#config = {\"number_conv\" : 3,\"number_dense\" : 5}\n",
    "#training_function(config)\n",
    "\n",
    "#get_data_loaders()\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"number_conv\": tune.grid_search(np.arange(2,3,3).tolist()),\n",
    "        \"number_dense\": tune.grid_search(np.arange(2,3,1).tolist()),\n",
    "        \"train_with_mixed_data\": False\n",
    "    },\n",
    "    local_dir='ray_results',\n",
    "    progress_reporter=reporter,\n",
    "    resources_per_trial={'gpu': 1})\n",
    "\n",
    "print(\"Best config: \", analysis.get_best_config(\n",
    "    metric=\"val_accuracy\", mode=\"max\"))\n",
    "\n",
    "#Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     2021-01-10 13:49:58,077\tINFO services.py:1173 -- View the Ray dashboard at http://127.0.0.1:8265\n",
    ">     == Status ==\n",
    ">     Memory usage on this node: 5.1/10.8 GiB\n",
    ">     Using FIFO scheduling algorithm.\n",
    ">     Resources requested: 1/4 CPUs, 1/1 GPUs, 0.0/3.66 GiB heap, 0.0/1.27 GiB objects (0/1.0 accelerator_type:T4)\n",
    ">     Result logdir: /databricks/driver/ray_results/training_function_2021-01-10_13-49-59\n",
    ">     Number of trials: 1/1 (1 RUNNING)\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">     | Trial name                    | status   | loc   |   number_conv |   number_dense |\n",
    ">     |-------------------------------+----------+-------+---------------+----------------|\n",
    ">     | training_function_baf52_00000 | RUNNING  |       |             2 |              2 |\n",
    ">     +-------------------------------+----------+-------+---------------+----------------+\n",
    ">\n",
    ">\n",
    ">     (pid=2962) 2021-01-10 13:50:00.038310: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
    ">     (pid=2962) 2021-01-10 13:50:00.038359: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
    ">     (pid=2962) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=2962) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=2962) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=2962) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=2962) Found 12632 images belonging to 6 classes.\n",
    ">     (pid=2962) Found 1402 images belonging to 6 classes.\n",
    ">     (pid=2962) 2021-01-10 13:50:06.218881: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
    ">     (pid=2962) 2021-01-10 13:50:06.219867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
    ">     (pid=2962) 2021-01-10 13:50:06.245830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    ">     (pid=2962) 2021-01-10 13:50:06.246687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
    ">     (pid=2962) pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
    ">     (pid=2962) coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
    ">     (pid=2962) 2021-01-10 13:50:06.246797: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
    ">     (pid=2962) 2021-01-10 13:50:06.246861: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
    ">     (pid=2962) 2021-01-10 13:50:06.246913: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
    ">     (pid=2962) 2021-01-10 13:50:06.248674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
    ">     (pid=2962) 2021-01-10 13:50:06.248985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
    ">     (pid=2962) 2021-01-10 13:50:06.251099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
    ">     (pid=2962) 2021-01-10 13:50:06.251210: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
    ">     (pid=2962) 2021-01-10 13:50:06.251298: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
    ">     (pid=2962) 2021-01-10 13:50:06.251319: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
    ">     (pid=2962) Skipping registering GPU devices...\n",
    ">     (pid=2962) 2021-01-10 13:50:06.252511: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
    ">     (pid=2962) To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    ">     (pid=2962) 2021-01-10 13:50:06.252728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    ">     (pid=2962) 2021-01-10 13:50:06.252748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
    ">     (pid=2962) 2021-01-10 13:50:06.252760: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
    ">     (pid=2962) /databricks/python/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
    ">     (pid=2962)   warnings.warn('`Model.fit_generator` is deprecated and '\n",
    "\n",
    "  \n",
    "\n",
    "### Directly training on MixUp data\n",
    "\n",
    "As we saw in the previous parts (**probably. my preliminary trials\n",
    "indicated this, at least**)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
