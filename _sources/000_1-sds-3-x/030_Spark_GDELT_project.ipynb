{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ScaDaMaLe, Scalable Data Science and Distributed Machine Learning](https://lamastex.github.io/scalable-data-science/sds/3/x/)\n",
    "==============================================================================================================================\n",
    "\n",
    "Johannes Graner, Albert Nilsson and Raazesh Sainudiin\n",
    "\n",
    "Plugging into GDELT Streams - TODO - IN PROGRESS\n",
    "================================================\n",
    "\n",
    "This is just a brief teaser into the world of the GDELT-project: \\*\n",
    "<https://www.gdeltproject.org/>\n",
    "\n",
    "This exposition was originally from [Mastering Spark for Data\n",
    "Science](https://books.google.se/books/about/Mastering_Spark_for_Data_Science.html?id=prkrDwAAQBAJ&source=kp_cover&redir_esc=y)\n",
    "which we will try to dive into in the geospatial modules.\n",
    "\n",
    "We will use a spark-gdelt library for Spark 3.0.1:\n",
    "\n",
    "-   <https://github.com/aamend/spark-gdelt>\n",
    "\n",
    "SEE:\n",
    "\n",
    "-   https://github.com/lamastex/spark-gdelt-examples\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.aamend.spark.gdelt._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import com.aamend.spark.gdelt._\n",
    "\n",
    "  \n",
    "\n",
    "This is just dipping our pinky toe in this ocean of information!\n",
    "================================================================\n",
    "\n",
    "Download from gdelt-project\n",
    "==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -al "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     total 32\n",
    ">     drwxr-xr-x 1 root root 4096 Dec 18 09:00 .\n",
    ">     drwxr-xr-x 1 root root 4096 Dec 18 08:54 ..\n",
    ">     drwxr-xr-x 2 root root 4096 Jan  1  1970 conf\n",
    ">     -rw-r--r-- 1 root root  733 Dec 18 08:55 derby.log\n",
    ">     drwxr-xr-x 3 root root 4096 Dec 18 08:55 eventlogs\n",
    ">     drwxr-xr-x 2 root root 4096 Dec 18 09:30 ganglia\n",
    ">     drwxr-xr-x 2 root root 4096 Dec 18 09:00 logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -O http://data.gdeltproject.org/gdeltv2/20190517121500.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">       % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    ">                                      Dload  Upload   Total   Spent    Left  Speed\n",
    ">\n",
    ">       0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
    ">       0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
    ">     100 7966k  100 7966k    0     0  10.0M      0 --:--:-- --:--:-- --:--:-- 10.0M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -O http://data.gdeltproject.org/gdeltv2/20190523121500.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">       % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    ">                                      Dload  Upload   Total   Spent    Left  Speed\n",
    ">\n",
    ">       0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
    ">      44 9167k   44 4112k    0     0  8566k      0  0:00:01 --:--:--  0:00:01 8548k\n",
    ">     100 9167k  100 9167k    0     0  17.1M      0 --:--:-- --:--:-- --:--:-- 17.1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip 20190517121500.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Archive:  20190517121500.gkg.csv.zip\n",
    ">       inflating: 20190517121500.gkg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip 20190523121500.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Archive:  20190523121500.gkg.csv.zip\n",
    ">       inflating: 20190523121500.gkg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -O http://data.gdeltproject.org/gdeltv2/20180416121500.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">       % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    ">                                      Dload  Upload   Total   Spent    Left  Speed\n",
    ">\n",
    ">       0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
    ">       0 10.3M    0 13493    0     0  37068      0  0:04:52 --:--:--  0:04:52 36967\n",
    ">      34 10.3M   34 3596k    0     0  2812k      0  0:00:03  0:00:01  0:00:02 2810k\n",
    ">      71 10.3M   71 7610k    0     0  3339k      0  0:00:03  0:00:02  0:00:01 3337k\n",
    ">     100 10.3M  100 10.3M    0     0  3502k      0  0:00:03  0:00:03 --:--:-- 3502k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip 20180416121500.gkg.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     Archive:  20180416121500.gkg.csv.zip\n",
    ">       inflating: 20180416121500.gkg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     total 115348\n",
    ">     drwxr-xr-x 1 root root     4096 Dec 18 09:43 .\n",
    ">     drwxr-xr-x 1 root root     4096 Dec 18 08:54 ..\n",
    ">     -rw-r--r-- 1 root root 34277858 Apr 16  2018 20180416121500.gkg.csv\n",
    ">     -rw-r--r-- 1 root root 10827477 Dec 18 09:43 20180416121500.gkg.csv.zip\n",
    ">     -rw-r--r-- 1 root root 25728991 May 17  2019 20190517121500.gkg.csv\n",
    ">     -rw-r--r-- 1 root root  8157895 Dec 18 09:43 20190517121500.gkg.csv.zip\n",
    ">     -rw-r--r-- 1 root root 29695688 May 23  2019 20190523121500.gkg.csv\n",
    ">     -rw-r--r-- 1 root root  9387721 Dec 18 09:43 20190523121500.gkg.csv.zip\n",
    ">     drwxr-xr-x 2 root root     4096 Jan  1  1970 conf\n",
    ">     -rw-r--r-- 1 root root      733 Dec 18 08:55 derby.log\n",
    ">     drwxr-xr-x 3 root root     4096 Dec 18 08:55 eventlogs\n",
    ">     drwxr-xr-x 2 root root     4096 Dec 18 09:30 ganglia\n",
    ">     drwxr-xr-x 2 root root     4096 Dec 18 09:00 logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /datasets/ScaDaMaLe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp \"file:///databricks/driver/20180416121500.gkg.csv\" \"dbfs:///datasets/ScaDaMaLe/GDELT/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res5: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /datasets/ScaDaMaLe/GDELT/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp \"file:///databricks/driver/20190523121500.gkg.csv\" \"dbfs:///datasets/ScaDaMaLe/GDELT/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res7: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp \"file:///databricks/driver/20190517121500.gkg.csv\" \"dbfs:///datasets/ScaDaMaLe/GDELT/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res8: Boolean = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls \"dbfs:///datasets/ScaDaMaLe/GDELT/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.aamend.spark.gdelt._\n",
    "// For implicit conversions like converting RDDs to DataFrames\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.Dataset\n",
    "//val gdeltEventDS: Dataset[Event] = spark.read.gdeltEvent(\"/path/to/event.csv\")\n",
    "//val gdeltGkgDS: Dataset[GKGEventV1] = spark.read.gdeltGkg(\"dbfs:/datasets/20190523121500.gkg.csv\")\n",
    "val gdeltGkgDS = spark.read.format(\"text\").load(\"dbfs:/datasets/ScaDaMaLe/GDELT/20190523121500.gkg.csv\")//.as[GKGEventV1]\n",
    "//val gdeltMention: Dataset[Mention] = spark.read.gdeltMention(\"/path/to/mention.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     import com.aamend.spark.gdelt._\n",
    ">     import spark.implicits._\n",
    ">     import org.apache.spark.sql.Dataset\n",
    ">     gdeltGkgDS: org.apache.spark.sql.DataFrame = [value: string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdeltGkgDS.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     root\n",
    ">      |-- value: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gdeltGkgDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdeltGkgDS.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val gdeltGkgDS = spark.read.format(\"text\").load(\"dbfs:/datasets/ScaDaMaLe/GDELT/20190523121500.gkg.csv\").as[GKGEventV2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Let's look a the locations field.\n",
    "\n",
    "We want to be able to filter by a country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gdeltGkgDS.select($\"locations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val USgdeltGkgDS = gdeltGkgDS.withColumn(\"loc\",$\"locations\"(0))\n",
    "          .filter($\"loc.countryCode\" contains \"US\").drop(\"loc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     USgdeltGkgDS: org.apache.spark.sql.DataFrame = [gkgRecordId: struct<publishDate: timestamp, translingual: boolean ... 1 more field>, publishDate: timestamp ... 25 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val IEgdeltGkgDS = gdeltGkgDS.withColumn(\"loc\",$\"locations\"(0))\n",
    "          .filter($\"loc.countryCode\" contains \"IE\").drop(\"loc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     IEgdeltGkgDS: org.apache.spark.sql.DataFrame = [gkgRecordId: struct<publishDate: timestamp, translingual: boolean ... 1 more field>, publishDate: timestamp ... 25 more fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IEgdeltGkgDS.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res54: Long = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USgdeltGkgDS.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     res51: Long = 682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(USgdeltGkgDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "GDELT Reference data\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val countryCodes: Dataset[CountryCode] = spark.loadCountryCodes\n",
    "val gcam: Dataset[GcamCode] = spark.loadGcams\n",
    "val cameoEvent: Dataset[CameoCode] = spark.loadCameoEventCodes\n",
    "val cameoType: Dataset[CameoCode] = spark.loadCameoTypeCodes\n",
    "val cameoGroup: Dataset[CameoCode] = spark.loadCameoGroupCodes\n",
    "val cameoEthnic: Dataset[CameoCode] = spark.loadCameoEthnicCodes\n",
    "val cameoReligion: Dataset[CameoCode] = spark.loadCameoReligionCodes\n",
    "val cameoCountry: Dataset[CameoCode] = spark.loadCameoCountryCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    ">     countryCodes: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CountryCode] = [iso: string, iso3: string ... 3 more fields]\n",
    ">     gcam: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.GcamCode] = [gcamCode: string, dictionaryId: string ... 6 more fields]\n",
    ">     cameoEvent: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CameoCode] = [cameoCode: string, cameoValue: string]\n",
    ">     cameoType: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CameoCode] = [cameoCode: string, cameoValue: string]\n",
    ">     cameoGroup: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CameoCode] = [cameoCode: string, cameoValue: string]\n",
    ">     cameoEthnic: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CameoCode] = [cameoCode: string, cameoValue: string]\n",
    ">     cameoReligion: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CameoCode] = [cameoCode: string, cameoValue: string]\n",
    ">     cameoCountry: org.apache.spark.sql.Dataset[com.aamend.spark.gdelt.CameoCode] = [cameoCode: string, cameoValue: string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(countryCodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cameoEvent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "[TABLE]\n",
    "\n",
    "Truncated to 30 rows"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
