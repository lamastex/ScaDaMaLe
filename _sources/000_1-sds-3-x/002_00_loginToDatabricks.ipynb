{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ScaDaMaLe, Scalable Data Science and Distributed Machine Learning](https://lamastex.github.io/scalable-data-science/sds/3/x/)\n",
    "==============================================================================================================================\n",
    "\n",
    "databricks community edition\n",
    "----------------------------\n",
    "\n",
    "1.  First obtain a free Obtain a databricks community edition account\n",
    "    at:\n",
    "\n",
    "-   <https://community.cloud.databricks.com>\n",
    "\n",
    "1.  Let's get an overview of the databricks managed cloud for processing\n",
    "    big data with Apache Spark\n",
    "\n",
    "Essentials of Databricks Cloud (DBC) in a Big Hurry\n",
    "---------------------------------------------------\n",
    "\n",
    "Please go here for a relaxed and detailed-enough tour (later):\n",
    "\n",
    "-   <https://docs.databricks.com/index.html>\n",
    "\n",
    "DBC Essentials: What is Databricks Cloud?\n",
    "-----------------------------------------\n",
    "\n",
    "![DB workspace, spark,\n",
    "platform](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/week1/dbTrImg_WorkspaceSparkPlatform700x.png)\n",
    "\n",
    "DBC Essentials: Shard, Cluster, Notebook and Dashboard\n",
    "------------------------------------------------------\n",
    "\n",
    "![DB workspace, spark,\n",
    "platform](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/week1/dbTrImg_ShardClusterNotebookDashboard700x.png)\n",
    "\n",
    "DBC Essentials: Team, State, Collaboration, Elastic Resources\n",
    "-------------------------------------------------------------\n",
    "\n",
    "![DB workspace, spark,\n",
    "platform](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/week1/dbTrImg_TeamStateCollaborationElasticResources700x.png)\n",
    "\n",
    "You Should All Have databricks community edition account by now!\n",
    "================================================================\n",
    "\n",
    "Import Course Content Now!\n",
    "==========================\n",
    "\n",
    "Two Steps:\n",
    "\n",
    "1.  Create a folder named `scalable-data-science` in your `Workspace`\n",
    "    (NO Typos due to hard-coding of paths!)\n",
    "\n",
    "-   Import the following dbc archive from the following URL:\n",
    "    -   <https://github.com/lamastex/scalable-data-science/raw/master/dbcArchives/2020/ScaDaMaLe-module-01-day-01-part-01.dbc>\n",
    "\n",
    "Cloud-free Computing Environment (Optional but recommended)\n",
    "===========================================================\n",
    "\n",
    "Before we dive into Scala crash course in a notebook, let's take a look\n",
    "at TASK 2 of the first step in the\n",
    "[instructions](https://lamastex.github.io/scalable-data-science/sds/basics/instructions/)\n",
    "to set up a local and \"cloud-free\" computing environment, say on your\n",
    "laptop computer here:\n",
    "\n",
    "-   TASK 2 at\n",
    "    <https://lamastex.github.io/scalable-data-science/sds/basics/instructions/prep/>.\n",
    "\n",
    "This can be handy for prototyping quickly and may even be necessary due\n",
    "to sensitivity of data in certain projects that mandate the data to be\n",
    "confined to some on-premise cluster, etc.\n",
    "\n",
    "**NOTE:** This can be done as an optional exercise as it heavily depends\n",
    "on your local computing environment and your software skills or\n",
    "willingness to acquire them.\n",
    "\n",
    "**CAVEAT:** The docker-compose prepared for your local environment uses\n",
    "Spark 2.x instead of 3.x, but most of the contents here would run in\n",
    "either version of Spark. - Feel free to make PR with latest versions of\n",
    "Spark :)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
