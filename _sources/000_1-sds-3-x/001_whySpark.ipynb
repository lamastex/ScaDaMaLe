{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ScaDaMaLe Course\n",
    "[site](https://lamastex.github.io/scalable-data-science/sds/3/x/) and\n",
    "[book](https://lamastex.github.io/ScaDaMaLe/index.html)\n",
    "\n",
    "Why Apache Spark?\n",
    "=================\n",
    "\n",
    "-   [Apache Spark: A Unified Engine for Big Data\n",
    "    Processing](https://cacm.acm.org/magazines/2016/11/209116-apache-spark/fulltext)\n",
    "    By Matei Zaharia, Reynold S. Xin, Patrick Wendell, Tathagata Das,\n",
    "    Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen, Shivaram\n",
    "    Venkataraman, Michael J. Franklin, Ali Ghodsi, Joseph Gonzalez,\n",
    "    Scott Shenker, Ion Stoica Communications of the ACM, Vol. 59 No. 11,\n",
    "    Pages 56-65 10.1145/2934664\n",
    "\n",
    "[![Apache Spark ACM\n",
    "Video](https://i.vimeocdn.com/video/597494216_640.jpg)](https://player.vimeo.com/video/185645796)\n",
    "\n",
    "Right-click the above image-link, open in a new tab and watch the video\n",
    "(4 minutes) or read about it in the Communications of the ACM in the\n",
    "frame below or from the link above.\n",
    "\n",
    "**Key Insights from [Apache Spark: A Unified Engine for Big Data\n",
    "Processing](https://cacm.acm.org/magazines/2016/11/209116-apache-spark/fulltext)\n",
    "**\n",
    "\n",
    "-   A simple programming model can capture streaming, batch, and\n",
    "    interactive workloads and enable new applications that combine them.\n",
    "-   Apache Spark applications range from finance to scientific data\n",
    "    processing and combine libraries for SQL, machine learning, and\n",
    "    graphs.\n",
    "-   In six years, Apache Spark has grown to 1,000 contributors and\n",
    "    thousands of deployments.\n",
    "\n",
    "![Key\n",
    "Insights](https://dl.acm.org/cms/attachment/6f54b222-fe96-497a-8bfc-0e6ea250b05d/ins01.gif)\n",
    "\n",
    "  \n",
    "\n",
    "Spark 3.0 is the latest version now (20200918) and it should be seen as\n",
    "the latest step in the evolution of tools in the big data ecosystem as\n",
    "summarized in\n",
    "<https://towardsdatascience.com/what-is-big-data-understanding-the-history-32078f3b53ce>:\n",
    "\n",
    "![Spark in\n",
    "context](https://miro.medium.com/max/1200/1*0bWwqlOfjRqoUDqrH62GbQ.png)\n",
    "\n",
    "The big data problem\n",
    "--------------------\n",
    "\n",
    "**Hardware, distributing work, handling failed and slow machines**\n",
    "\n",
    "The following content was created by Anthony Joseph and used in\n",
    "BerkeleyX/CS100.1x from 2015.\n",
    "\n",
    "-   **(watch now 1:48)**: The Big Data Problem\n",
    "    -   [![The Big Data Problem by Anthony Joseph in\n",
    "        BerkeleyX/CS100.1x](http://img.youtube.com/vi/0JdJe5iehhw/0.jpg)](https://www.youtube.com/watch?v=0JdJe5iehhw&modestbranding=1&start=1)\n",
    "-   **(watch now 1:43)**: Hardware for Big Data\n",
    "-   [![Hardware for Big Data by Anthony Joseph in\n",
    "    BerkeleyX/CS100.1x](http://img.youtube.com/vi/KmIIMdsXGzc/0.jpg)](https://www.youtube.com/watch?v=KmIIMdsXGzc&rel=0&autoplay=1&modestbranding=1&start=1)\n",
    "-   **(watch now 1:17)**: How to distribute work across a cluster of\n",
    "    commodity machines?\n",
    "    -   [![How to distribute work across a cluster of commodity\n",
    "        machines? by Anthony Joseph in\n",
    "        BerkeleyX/CS100.1x](http://img.youtube.com/vi/Euk1v3VtNcM/0.jpg)](https://www.youtube.com/watch?v=Euk1v3VtNcM&rel=0&autoplay=1&modestbranding=1&start=1)\n",
    "-   **(watch now 0:36)**: How to deal with failures or slow machines?\n",
    "    -   [![How to deal with failures or slow machines? by Anthony Joseph\n",
    "        in\n",
    "        BerkeleyX/CS100.1x](http://img.youtube.com/vi/NaHNsPEK3KA/0.jpg)](https://www.youtube.com/watch?v=NaHNsPEK3KA&rel=0&autoplay=1&modestbranding=1&start=1)\n",
    "\n",
    "MapReduce and Apache Spark.\n",
    "---------------------------\n",
    "\n",
    "The following content was created by Anthony Joseph and used in\n",
    "BerkeleyX/CS100.1x from 2015.\n",
    "\n",
    "-   **(watch now 1:48)**: Map Reduce (is bounded by Disk I/O)\n",
    "    -   [![The Big Data Problem by Anthony Joseph in\n",
    "        BerkeleyX/CS100.1x](http://img.youtube.com/vi/NqG_hYAKjYk/0.jpg)](https://www.youtube.com/watch?v=NqG_hYAKjYk&rel=0&autoplay=1&modestbranding=1&start=1)\n",
    "-   **(watch now 2:49)**: Apache Spark (uses Memory instead of Disk)\n",
    "-   [![Apache Spark by Anthony Joseph in\n",
    "    BerkeleyX/CS100.1x](http://img.youtube.com/vi/vat5Jki1lbI/0.jpg)](https://www.youtube.com/watch?v=vat5Jki1lbI&rel=0&autoplay=1&modestbranding=1&start=1)\n",
    "-   **(watch now 3:00)**: Spark Versus MapReduce\n",
    "    -   [![Spark Versus MapReduce by Anthony Joseph in\n",
    "        BerkeleyX/CS100.1x](http://img.youtube.com/vi/Ddq3Gua2QFg/0.jpg)](https://www.youtube.com/watch?v=Ddq3Gua2QFg&rel=0&autoplay=1&modestbranding=1&start=1)\n",
    "-   SUMMARY\n",
    "    -   uses memory instead of disk alone and is thus fater than Hadoop\n",
    "        MapReduce\n",
    "    -   resilience abstraction is by RDD (resilient distributed dataset)\n",
    "    -   RDDs can be recovered upon failures from their *lineage graphs*,\n",
    "        the recipes to make them starting from raw data\n",
    "    -   Spark supports a lot more than MapReduce, including streaming,\n",
    "        interactive in-memory querying, etc.\n",
    "    -   Spark demonstrated an unprecedented sort of 1 petabyte (1,000\n",
    "        terabytes) worth of data in 234 minutes running on 190 Amazon\n",
    "        EC2 instances (in 2015).\n",
    "    -   Spark expertise corresponds to the highest Median Salary in the\n",
    "        US (~ 150K)\n",
    "\n",
    "Key Papers\n",
    "----------\n",
    "\n",
    "-   Key Historical Milestones\n",
    "\n",
    "    -   1956-1979: [Stanford, MIT, CMU, and other universities develop\n",
    "        set/list operations in LISP, Prolog, and other languages for\n",
    "        parallel\n",
    "        processing](http://www-formal.stanford.edu/jmc/history/lisp/lisp.html)\n",
    "    -   2004: **READ**: [Google's MapReduce: Simplified Data Processing\n",
    "        on Large Clusters, by Jeffrey Dean and Sanjay\n",
    "        Ghemawat](http://research.google.com/archive/mapreduce.html)\n",
    "    -   2006: [Yahoo!'s Apache Hadoop, originating from the Yahoo!â€™s\n",
    "        Nutch Project, Doug Cutting -\n",
    "        wikipedia](https://en.wikipedia.org/wiki/Apache_Hadoop)\n",
    "    -   2009: [Cloud computing with Amazon Web Services Elastic\n",
    "        MapReduce](http://aws.amazon.com/elasticmapreduce/), a Hadoop\n",
    "        version modified for Amazon Elastic Cloud Computing (EC2) and\n",
    "        Amazon Simple Storage System (S3), including support for Apache\n",
    "        Hive and Pig.\n",
    "    -   2010: **READ**: [The Hadoop Distributed File System, by\n",
    "        Konstantin Shvachko, Hairong Kuang, Sanjay Radia, and Robert\n",
    "        Chansler. IEEE\n",
    "        MSST](http://dx.doi.org/10.1109/MSST.2010.5496972)\n",
    "\n",
    "-   Apache Spark Core Papers\n",
    "\n",
    "    -   2010: [Spark: Cluster Computing with Working Sets, Matei\n",
    "        Zaharia, Mosharaf Chowdhury, Michael J. Franklin, Scott Shenker,\n",
    "        Ion Stoica. USENIX\n",
    "        HotCloud](http://people.csail.mit.edu/matei/papers/2010/hotcloud_spark.pdf).\n",
    "    -   2012: **READ**: [Resilient Distributed Datasets: A\n",
    "        Fault-Tolerant Abstraction for In-Memory Cluster Computing,\n",
    "        Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave,\n",
    "        Justin Ma, Murphy McCauley, Michael J. Franklin, Scott Shenker\n",
    "        and Ion Stoica.\n",
    "        NSDI](http://usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf)\n",
    "    -   2016: [Apache Spark: A Unified Engine for Big Data\n",
    "        Processing](https://cacm.acm.org/magazines/2016/11/209116-apache-spark/fulltext)\n",
    "        By Matei Zaharia, Reynold S. Xin, Patrick Wendell, Tathagata\n",
    "        Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen,\n",
    "        Shivaram Venkataraman, Michael J. Franklin, Ali Ghodsi, Joseph\n",
    "        Gonzalez, Scott Shenker, Ion Stoica , Communications of the ACM,\n",
    "        Vol. 59 No. 11, Pages 56-65, 10.1145/2934664\n",
    "\n",
    "    ![brief history of functional programming and big data by\n",
    "    SparkCamp](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/week1/dbTrImg_BriefHistoryFuncProgBigData700x.png)\n",
    "\n",
    "-   Here are some directions the creators of Apache Spark at Berkeley\n",
    "    and Stanford are currently (2018) taking:\n",
    "\n",
    "    -   [Stanford's Dawn Lab](http://dawn.cs.stanford.edu/)\n",
    "    -   [Berkeley's RISE lab](https://rise.cs.berkeley.edu/)\n",
    "\n",
    "-   More research papers on Spark are available from here:\n",
    "\n",
    "    -   [https://databricks.com/resources?*sft*resource\\_type=research-papers](https://databricks.com/resources?_sft_resource_type=research-papers)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "**Next let us get everyone to login to databricks** (or another Spark\n",
    "platform) to get our hands dirty with some Spark code!\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
