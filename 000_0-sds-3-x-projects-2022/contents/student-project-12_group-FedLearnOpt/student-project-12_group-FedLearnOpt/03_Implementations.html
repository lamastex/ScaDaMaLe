<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>03_Implementations - sds-3.x/ScaDaMaLe</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../../favicon.svg">
        <link rel="shortcut icon" href="../../../favicon.png">
        <link rel="stylesheet" href="../../../css/variables.css">
        <link rel="stylesheet" href="../../../css/general.css">
        <link rel="stylesheet" href="../../../css/chrome.css">
        <link rel="stylesheet" href="../../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../../highlight.css">
        <link rel="stylesheet" href="../../../tomorrow-night.css">
        <link rel="stylesheet" href="../../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../../scroll-mdbook-outputs.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../../introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Projects</li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/00_Introduction.html"><strong aria-hidden="true">1.</strong> student-project-01_group-GraphOfWiki_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/01_DataLoading_redirectsTable.html"><strong aria-hidden="true">1.1.</strong> 01_DataLoading_redirectsTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/02_DataLoading_pagesTable.html"><strong aria-hidden="true">1.2.</strong> 02_DataLoading_pagesTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/03_DataLoading_pagelinksTable.html"><strong aria-hidden="true">1.3.</strong> 03_DataLoading_pagelinksTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/04_DataLoading_categorylinksTable.html"><strong aria-hidden="true">1.4.</strong> 04_DataLoading_categorylinksTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/05_DataLoading_categoryTable.html"><strong aria-hidden="true">1.5.</strong> 05_DataLoading_categoryTable</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/06_redirectRemoval.html"><strong aria-hidden="true">1.6.</strong> 06_redirectRemoval</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/07_createArticleGraph.html"><strong aria-hidden="true">1.7.</strong> 07_createArticleGraph</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/08_explorationArticleGraph.html"><strong aria-hidden="true">1.8.</strong> 08_explorationArticleGraph</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/09_fullGraphAnalysis.html"><strong aria-hidden="true">1.9.</strong> 09_fullGraphAnalysis</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/10_explorativeMotifs.html"><strong aria-hidden="true">1.10.</strong> 10_explorativeMotifs</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/11_conclusionDiscussionAndFutureWork.html"><strong aria-hidden="true">1.11.</strong> 11_conclusionDiscussionAndFutureWork</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/12_gameNotebookSetup.html"><strong aria-hidden="true">1.12.</strong> 12_gameNotebookSetup</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-01_group-GraphOfWiki/student-project-01_group-GraphOfWiki/13_gameNotebook.html"><strong aria-hidden="true">1.13.</strong> 13_gameNotebook</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/00_vqa_introduction.html"><strong aria-hidden="true">2.</strong> student-project-02_group-DDLOfVision_00_vqa_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/01_vqa_model_training.html"><strong aria-hidden="true">2.1.</strong> 01_vqa_model_training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-02_group-DDLOfVision/student-project-02_group-DDLOfVision/02_vqa_model_inference.html"><strong aria-hidden="true">2.2.</strong> 02_vqa_model_inference</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/00_ingest_data.html"><strong aria-hidden="true">3.</strong> student-project-03_group-WikiKG2_00_ingest_data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/01_fetch_descriptions.html"><strong aria-hidden="true">3.1.</strong> 01_fetch_descriptions</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/02_load_data.html"><strong aria-hidden="true">3.2.</strong> 02_load_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/03_data_exploration.html"><strong aria-hidden="true">3.3.</strong> 03_data_exploration</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/04_analysing_relation_types.html"><strong aria-hidden="true">3.4.</strong> 04_analysing_relation_types</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/05_motif_search.html"><strong aria-hidden="true">3.5.</strong> 05_motif_search</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/06_produce_pagerank_vectors.html"><strong aria-hidden="true">3.6.</strong> 06_produce_pagerank_vectors</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-03_group-WikiKG2/student-project-03_group-WikiKG2/07_pagerank_for_classification.html"><strong aria-hidden="true">3.7.</strong> 07_pagerank_for_classification</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/00_Notebook_Presentation.html"><strong aria-hidden="true">4.</strong> student-project-04_group-FedMLMedicalApp_00_Notebook_Presentation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/01_BrainTumorSegmentation_Centralized_Training.html"><strong aria-hidden="true">4.1.</strong> 01_BrainTumorSegmentation_Centralized_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/02_Federated_Learning_BrainTumorSegmentation.html"><strong aria-hidden="true">4.2.</strong> 02_Federated_Learning_BrainTumorSegmentation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-04_group-FedMLMedicalApp/student-project-04_group-FedMLMedicalApp/data_upload_test.html"><strong aria-hidden="true">4.3.</strong> data_upload_test</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/00_introduction.html"><strong aria-hidden="true">5.</strong> student-project-05_group-DistOpt_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/01_Bayesian_optimization.html"><strong aria-hidden="true">5.1.</strong> 01_Bayesian_optimization</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/02_Gaussian_processes.html"><strong aria-hidden="true">5.2.</strong> 02_Gaussian_processes</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/03_acquisition_functions.html"><strong aria-hidden="true">5.3.</strong> 03_acquisition_functions</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/04_scalable_Bayesian_optimization.html"><strong aria-hidden="true">5.4.</strong> 04_scalable_Bayesian_optimization</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/05_implementation_documentation.html"><strong aria-hidden="true">5.5.</strong> 05_implementation_documentation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/06_our_implementation.html"><strong aria-hidden="true">5.6.</strong> 06_our_implementation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-05_group-DistOpt/student-project-05_group-DistOpt/07_additional_code.html"><strong aria-hidden="true">5.7.</strong> 07_additional_code</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/00_introduction_resnet.html"><strong aria-hidden="true">6.</strong> student-project-07_group-ExpsZerOInit_00_introduction_resnet</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/01_transformer.html"><strong aria-hidden="true">6.1.</strong> 01_transformer</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-07_group-ExpsZerOInit/student-project-07_group-ExpsZerOInit/02_ddpm.html"><strong aria-hidden="true">6.2.</strong> 02_ddpm</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/00_Introduction.html"><strong aria-hidden="true">7.</strong> student-project-08_group-WikiSearch_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/01_InputParsing.html"><strong aria-hidden="true">7.1.</strong> 01_InputParsing</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/02_PageRank.html"><strong aria-hidden="true">7.2.</strong> 02_PageRank</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-08_group-WikiSearch/student-project-08_group-WikiSearch/03_QuerySearch.html"><strong aria-hidden="true">7.3.</strong> 03_QuerySearch</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/00_Introduction.html"><strong aria-hidden="true">8.</strong> student-project-09_group-DistEnsembles_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/01_Human_Pose_Data.html"><strong aria-hidden="true">8.1.</strong> 01_Human_Pose_Data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/02_Ensemble_Training.html"><strong aria-hidden="true">8.2.</strong> 02_Ensemble_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/03_Ensemble_Evaluation.html"><strong aria-hidden="true">8.3.</strong> 03_Ensemble_Evaluation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-09_group-DistEnsembles/student-project-09_group-DistEnsembles/099_extra_Ensemble.html"><strong aria-hidden="true">8.4.</strong> 099_extra_Ensemble</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/00_introduction.html"><strong aria-hidden="true">9.</strong> student-project-10_group-RDI_00_introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/01_prepare_data.html"><strong aria-hidden="true">9.1.</strong> 01_prepare_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/02_baseline.html"><strong aria-hidden="true">9.2.</strong> 02_baseline</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/03_single_machine.html"><strong aria-hidden="true">9.3.</strong> 03_single_machine</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-10_group-RDI/student-project-10_group-RDI/04_distributed_learning.html"><strong aria-hidden="true">9.4.</strong> 04_distributed_learning</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/01_Introduction.html"><strong aria-hidden="true">10.</strong> student-project-11_group-CollaborativeFiltering_01_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/02_AlgorithmsBeyondALS.html"><strong aria-hidden="true">10.1.</strong> 02_AlgorithmsBeyondALS</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-11_group-CollaborativeFiltering/student-project-11_group-CollaborativeFiltering/03_Implementation.html"><strong aria-hidden="true">10.2.</strong> 03_Implementation</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/01_Federated_Learning_Introduction.html"><strong aria-hidden="true">11.</strong> student-project-12_group-FedLearnOpt_01_Federated_Learning_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/02_Horovod_Introduction.html"><strong aria-hidden="true">11.1.</strong> 02_Horovod_Introduction</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/03_Implementations.html" class="active"><strong aria-hidden="true">11.2.</strong> 03_Implementations</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-project-13_group-DRL/student-project-13_group-DRL/00_DistributedRL.html"><strong aria-hidden="true">12.</strong> student-project-13_group-DRL_00_DistributedRL</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/00_Introduction.html"><strong aria-hidden="true">13.</strong> student-project-14_group-EarthObs_00_Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/01_Download_data.html"><strong aria-hidden="true">13.1.</strong> 01_Download_data</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/02_Image_preprocessing.html"><strong aria-hidden="true">13.2.</strong> 02_Image_preprocessing</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/03_Model_Architecture_and_Training.html"><strong aria-hidden="true">13.3.</strong> 03_Model_Architecture_and_Training</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/04_Prediction_And_Visualisation.html"><strong aria-hidden="true">13.4.</strong> 04_Prediction_And_Visualisation</a></li><li class="chapter-item expanded "><a href="../../../contents/student-project-14_group-EarthObs/student-project-14_group-EarthObs/05_Conclusions.html"><strong aria-hidden="true">13.5.</strong> 05_Conclusions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../../../contents/student-projects-BrIntSuSvConclusion/student-projects-BrIntSuSvConclusion/BrIntSuSv.html"><strong aria-hidden="true">14.</strong> student-projects-BrIntSuSvConclusion_BrIntSuSv</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="../../../editors.html"><strong aria-hidden="true">15.</strong> Editors</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">sds-3.x/ScaDaMaLe</h1>

                    <div class="right-buttons">
                        <a href="../../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="cell markdown">
<h2 id="federated-deep-learning-training-using-pytorch-with-horovodrunner-for-cifar10"><a class="header" href="#federated-deep-learning-training-using-pytorch-with-horovodrunner-for-cifar10">Federated deep learning training using PyTorch with HorovodRunner for CIFAR10</a></h2>
<p>This notebook illustrates the use of HorovodRunner for Federated training using PyTorch. It first shows how to train a model on a single node, and then shows how to adapt the code using HorovodRunner for federated training. The notebook runs on CPU and GPU clusters.</p>
<h3 id="requirements"><a class="header" href="#requirements">Requirements</a></h3>
<p>Databricks Runtime 9.1 ML or above with long term support.
HorovodRunner is designed to improve model training performance on clusters with multiple processors.</p>
<p>Workers according to the number of resources. Here we used up to 8 workers for parallel computation in CPU cluster and 2 workers in our GPU cluster.</p>
<p>CPU: Databricks 9.1x-cpu-ml-scala2.12 (max 9 workers 72GB-18 cores)</p>
<p>GPU: Databricks 11.3.x-gpu-ml-scala2.12 (max 3 workers 48GB-12 cores)</p>
</div>
<div class="cell markdown">
<h3 id="set-up-checkpoint-location"><a class="header" href="#set-up-checkpoint-location">Set up checkpoint location</a></h3>
<p>The next cell creates a directory for saved checkpoint models. Databricks recommends saving training data under <code>dbfs:/ml</code>, which maps to <code>file:/dbfs/ml</code> on driver and worker nodes.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">PYTORCH_DIR = '/dbfs/ml/horovod_pytorch'
</code></pre>
</div>
<div class="cell markdown">
<h3 id="prepare-single-node-code"><a class="header" href="#prepare-single-node-code">Prepare single node code</a></h3>
<p>First, create single-node PyTorch code. This is modified from the <a href="https://github.com/horovod/horovod/blob/master/examples/pytorch/pytorch_mnist.py">Horovod PyTorch MNIST Example</a>.</p>
</div>
<div class="cell markdown">
<h3 id="define-a-simple-convolutional-network"><a class="header" href="#define-a-simple-convolutional-network">Define a simple convolutional network</a></h3>
<p>Here below a vanilla CCN architecture in order to illustrate our problem. First, we will study federated learning for one node.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from time import time
import os
import matplotlib.pyplot as plt
import numpy as np
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">import horovod.torch as hvd
from sparkdl import HorovodRunner
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">      
#CIFAR10[100, 3, 32, 32]
class Net_CIFAR10(nn.Module):
    def __init__(self):
        super(Net_CIFAR10, self).__init__()
        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) #convolutional layer 1
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # convolutional layer 2
        self.conv2_drop = nn.Dropout2d() # dropout - layer 3
        self.fc1 = nn.Linear(500, 50) # fully connected layer 4
        self.fc2 = nn.Linear(50, 10) # fully connected layer 5
    def forward(self, x):
        #convolution + max pool + activation function with Relu function for layer 1
        x = F.relu(F.max_pool2d(self.conv1(x), 2))#dimout=15*15
        # convolution + max pool + activation function with Relu function for layer 2
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))#dimout=5*5
        # Returns a new tensor with the same data as the self tensor but of a different shape
        x = x.view(-1, 500)#25*20=500
        # conv + activation function with Relu function for layer 3
        x = F.relu(self.fc1(x))
        # dropout
        x = F.dropout(x, training=self.training)
        # final fully connected layer
        x = self.fc2(x)
        return F.log_softmax(x) # activation function with logarithmic soft max function for layer 5
      
</code></pre>
</div>
<div class="cell markdown">
<h3 id="configure-single-node-training"><a class="header" href="#configure-single-node-training">Configure single node training</a></h3>
<p>Elocal si the number of local updates. If Elocal = 1 it is equivalent to distributate learning.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Specify training parameters
batch_size = 100 
num_epochs = 3 # number of global epoch
momentum = 0.5 # used for the optimizer
log_interval = 100 # used to print the parameters every 100 samples
Elocal = 5 # number of local epoch
</code></pre>
</div>
<div class="cell markdown">
<p>Here below the inner loop training for one node.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">def train_one_epoch(model, device, data_loader, optimizer, epoch,Elocal):
    model.train()
    for batch_idx, (data, target) in enumerate(data_loader):
        for idx in range(Elocal):
          data, target = data.to(device), target.to(device)
          optimizer.zero_grad()
          output = model(data)
          loss = F.nll_loss(output, target) # The negative log likelihood loss, used for classification problem
          loss.backward()
          optimizer.step()
          
        # Printing the training
        if batch_idx % log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(data_loader) * len(data),
                100. * batch_idx / len(data_loader), loss.item()))
</code></pre>
</div>
<div class="cell markdown">
<h3 id="create-methods-for-saving-and-loading-model-checkpoints"><a class="header" href="#create-methods-for-saving-and-loading-model-checkpoints">Create methods for saving and loading model checkpoints</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># Save checkpoint in a filed
def save_checkpoint(log_dir, model, optimizer, epoch):
  filepath = log_dir+ '/checkpoint-{epoch}.pth.tar'.format(epoch=epoch)
  state = {
    'model': model.state_dict(),
    'optimizer': optimizer.state_dict(),
  }
  torch.save(state, filepath)

# Load checkpoint saved from the filed 
def load_checkpoint(log_dir, epoch=num_epochs):
  filepath = log_dir+ '/checkpoint-{epoch}.pth.tar'.format(epoch=epoch)
  return torch.load(filepath)

# Creating the directory for saving the checkpoint
def create_log_dir():
  log_dir = os.path.join(PYTORCH_DIR, str(time()), 'CIFAR10')
  os.makedirs(log_dir)
  return log_dir
</code></pre>
</div>
<div class="cell markdown">
<h3 id="run-single-node-training-with-pytorch"><a class="header" href="#run-single-node-training-with-pytorch">Run single node training with PyTorch</a></h3>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">
# Creation of the directory to save the parameters
single_node_log_dir = create_log_dir()
print(&quot;Log directory:&quot;, single_node_log_dir)

def train(learning_rate, Elocal, model1):
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  # Downloading + preparation of the dataset
  train_dataset = datasets.CIFAR10(
    'CIFAR10', 
    train=True,
    download=True,
    # Normalization + conversion of the dataset to tensor since we use pytorch the input has to be a tensor
    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))
  
  data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
  
  # architecture importation
  model = model1.to(device)
  #stochatic gradient descent optimizer
  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum) 
  # Evaluation of the training time
  time_start=time()
  # Training
  for epoch in range(1, num_epochs + 1):
    train_one_epoch(model, device, data_loader, optimizer, epoch,Elocal)
    save_checkpoint(single_node_log_dir, model, optimizer, epoch)
  print(&quot;---It took %s seconds ---&quot; % (time() - time_start))
  
# Test phase  
def test(log_dir,model1):
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  loaded_model = model1.to(device) # architecture importation
  checkpoint = load_checkpoint(log_dir) # checkpoint importation
  #Loading model for Inference
  loaded_model.load_state_dict(checkpoint['model']) # state_dict is a Python dictionary object that maps each layer to its parameter tensor
  loaded_model.eval() # set dropout and batch normalization layers to evaluation mode
  # loading + preparing the dataset test
  test_dataset = datasets.CIFAR10(
    'CIFAR10', 
    train=False,
    download=True,
    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))
  data_loader = torch.utils.data.DataLoader(test_dataset)
  
  test_loss = 0
  for data, target in data_loader:
      data, target = data.to(device), target.to(device)
      output = loaded_model(data)
      test_loss += F.nll_loss(output, target)
  
  test_loss /= len(data_loader.dataset)
  print(&quot;Average test loss: {}&quot;.format(test_loss.item()))
</code></pre>
</div>
<div class="cell markdown">
<p>Run the <code>train</code> function you just created to train a model on the driver node. For comparison, we train both on WASP Cluster 2 and the 11.3 LSTML gpu cluster.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">#I (Hoomaan) mistakenly removed the output and then the gpu clusters were unavailable. The good news is that I saved the execution time :).(remove the previous 'dot' to see my lips) It was 60.721 s.
#GPU tiny-debug-cluster-gpu
train(learning_rate=0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">#CPU WASP Cluster 3-current log is for another cluster thus the executed time is different from previous result.
train(learning_rate=0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell markdown">
<p>Load and use the model</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">test(single_node_log_dir,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell markdown">
<h5 id="thus-our-gpu-cluster-is-much-faster-than-our-cpu-cluster"><a class="header" href="#thus-our-gpu-cluster-is-much-faster-than-our-cpu-cluster">Thus our GPU cluster is much faster than our CPU cluster.</a></h5>
<p>Note that in these simulations we are not concentrating on average loss and only scalability is of our interest.</p>
</div>
<div class="cell markdown">
<h2 id="migrate-to-horovodrunner"><a class="header" href="#migrate-to-horovodrunner">Migrate to HorovodRunner</a></h2>
<p>HorovodRunner takes a Python method that contains deep learning training code with Horovod hooks. HorovodRunner pickles the method on the driver and distributes it to Spark workers. A <a href="https://horovod.readthedocs.io/en/stable/mpi_include.html">Horovod MPI</a> job is embedded as a Spark job using <a href="https://blog.madhukaraphatak.com/barrier-execution-mode-part-1">barrier execution mode</a>.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">hvd_log_dir = create_log_dir()
print(&quot;Log directory:&quot;, hvd_log_dir)

def train_hvd(learning_rate,Elocal,model1):
  
  # Initialize Horovod
  hvd.init()  
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
 
  if device.type == 'cuda':
    # Pin GPU to local rank
    torch.cuda.set_device(hvd.local_rank())

  train_dataset = datasets.CIFAR10(
  # Use different root directory for each worker to avoid conflicts
  root='data-%d'% hvd.rank(),  
  train=True, 
  download=True,
  transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
  )


  from torch.utils.data.distributed import DistributedSampler
  
  # Configure the sampler so that each worker gets a distinct sample of the input dataset
  train_sampler = DistributedSampler(train_dataset, num_replicas=hvd.size(), rank=hvd.rank())
  # Use train_sampler to load a different sample of data on each worker
  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)

  model = model1.to(device)
  
  # The effective batch size in synchronous distributed training is scaled by the number of workers
  # Increase learning_rate to compensate for the increased batch size
  optimizer = optim.SGD(model.parameters(), lr=learning_rate * hvd.size(), momentum=momentum)

  # Wrap the local optimizer with hvd.DistributedOptimizer so that Horovod handles the distributed optimization
  optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters(), op=hvd.Adasum)
  
  
  #1- op=hvd.Adasum not  op=hvd.AdaSum.  
  
  #2- hvd.Adasum works with powers of 2 number of processors. For other numbers hvd.Sum is implementable.
  
  #3- Horovod can have multiple optimizers for different clients and different number of processors:
  # Run on a single client with 4 GPUs: horovodrun -np 4 python train.py
  # Run on 4 clients with 4 GPUs each: horovodrun -np 16 -H server1:4,server2:4,server3:4,server4:4 python train.py 
  
  # Broadcast initial parameters so all workers start with the same parameters
  hvd.broadcast_parameters(model.state_dict(), root_rank=0)
  time_start=time()
  for epoch in range(1, num_epochs + 1):
    train_one_epoch(model, device, train_loader, optimizer, epoch,Elocal)
    # Save checkpoints only on worker 0 to prevent conflicts between workers
    if hvd.rank() == 0:
      save_checkpoint(hvd_log_dir, model, optimizer, epoch)
  exe_time = time() - time_start    
  print(&quot;---It took %s seconds ---&quot; % (exe_time))
</code></pre>
</div>
<div class="cell markdown">
<h2 id="note-on-learning-rate-update"><a class="header" href="#note-on-learning-rate-update">Note on Learning rate update</a></h2>
<p>Consider a network at iteration \(t\) with weights \(w_t\), and a sequence of \(k\) minibatches \(B_j\) for \(0 ≤ j &lt; k\) each of size \(n\). In <a href="https://arxiv.org/pdf/1706.02677.pdf">this paper</a> they compare the effect of executing \(k\) SGD iterations with small minibatches \(B_j\) and learning rate \(\eta\) versus a single iteration with a large minibatch \(\cup_j B_j\) of size \(kn\) and learning rate \(\widehat{\eta}\). For the SGD update</p>
<p>\[ w_{t+1}=w_t - \eta \frac{1}{n}\sum_{x\in \mathcal{B_j}}\nabla l(x,w_t) \]</p>
<p>after \(k\) iteration we have</p>
<p>\[ w_{t+k}=w_t - \eta \frac{1}{n}\sum_{j&lt;k}\sum_{x\in \mathcal{B_j}}\nabla l(x,w_{j+k}) \]</p>
<p>and for the single step with the large minibatch of sie \(kn\) we have</p>
<p>\[ \widehat{w}<em>{t+1}=w_t - \widehat{\eta} \frac{1}{kn}\sum</em>{j&lt;k}\sum_{x\in \mathcal{B_j}}\nabla l(x,w_t) \]</p>
<p>Now, if we can have \(w_{t+k} \approx \widehat{w_{t+1}}\) if we have \(\nabla l(x,w_{j+k})\approx \nabla l(x,w_t)\) and \(\widehat{\eta}=k\eta\). Though this assumption is strict, but they show in the paper that it does not affect the final result.</p>
</div>
<div class="cell markdown">
<p>Now that you have defined a training function with Horovod, you can use HorovodRunner to distribute the work of training the model.</p>
<p>The HorovodRunner parameter <code>np</code> sets the number of processes. This example uses a cluster with two workers, each with a single GPU, so set <code>np=2</code> (If you use <code>np=-1</code>, HorovodRunner trains using a single process on the driver node). We will perform the training for single worker CPU and GPU and compare the results. Then the number of workers are increased. Also note that</p>
<p>1- AdaSum is not correct and Adasum works. This is in contrast to what is written on Horovod Website,\ 2- Adasum works with power of 2 workers only.</p>
<p>In what follows, we will train our network on CPU processors.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">#CPU -  WASP Cluster 3
hr = HorovodRunner(np=1,driver_log_verbosity='all')
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">test(hvd_log_dir,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">#CPU -  WASP Cluster 3
hr = HorovodRunner(np=2,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">test(hvd_log_dir,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">#CPU -  WASP Cluster 3
hr = HorovodRunner(np=4,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">test(hvd_log_dir,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># CPU - WASP Cluster 3
hr = HorovodRunner(np=8,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">test(hvd_log_dir,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell markdown">
<p>Note that the accuracy heavily depends on the heterogeneity of the data and not the number of clients. Therefore, if the dissipated data does not contain evetry aspect of the whole dataset, the final learning loss will rise.</p>
</div>
<div class="cell markdown">
<h2 id="summary-on-cpu-execution-time"><a class="header" href="#summary-on-cpu-execution-time">Summary on CPU Execution Time</a></h2>
<p>Execution time of \(i\)'th worker case is \((E_i)\) and therefore the execution time is \(\max(E_i)\). | Number of Workers | Execution Time(s) | | ----------- | ----------- | | 1 | 336.105 | | 2 | 207.549 | | 4 | 115.372 | | 8 | 75.987 |</p>
<p>Next, GPU processors are considered. Due to unavailability of 4 and 8 worker GPU clusters we skip those cases.</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># GPU - 11.3 LSTML - Debug Cluster 
hr = HorovodRunner(np=1,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># GPU - 11.3 LSTML - Debug Cluster 
hr = HorovodRunner(np=2,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># GPU - 11.3 LSTML - Debug Cluster Current run cancelled due to unavailability of workers.
hr = HorovodRunner(np=3,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python"># GPU - 11.3 LSTML - Debug Cluster Current run cancelled due to unavailability of workers.
hr = HorovodRunner(np=8,driver_log_verbosity='all') 
hr.run(train_hvd, learning_rate = 0.001,Elocal=5,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">test(hvd_log_dir,model1=Net_CIFAR10())
</code></pre>
</div>
<div class="cell markdown">
<h2 id="summary-on-gpu-execution-time"><a class="header" href="#summary-on-gpu-execution-time">Summary on GPU Execution Time</a></h2>
<p>Execution time of \(i\)'th worker is \((E_i)\) and therefore the execution time is \(\max(E_i)\). | Number of Workers | Execution Time(s) | | ----------- | ----------- | | 1 | 52.84 | | 2 | 41.27 | | 4 | NA | | 8 | NA |</p>
</div>
<div class="cell code" execution_count="1" scrolled="false">
<pre><code class="language-python">Execution_time=[336.105,207.549,115.372, 75.987]
Execution_time2=[52.84,41.27,0,0]
num_workers=[1,2,4,8]
plt.figure(figsize=(8, 6), dpi=120)
colors=[1,1,1,1]
plt.plot(num_workers,Execution_time,'--o',linewidth=4,markersize=8,label=&quot;CPU&quot;)
plt.xlabel(&quot;Number of Workers&quot;)
plt.ylabel(&quot;Execution Time&quot;)
plt.plot(num_workers,Execution_time2,'--*',alpha=0.5,linewidth=4,markersize=10,label=&quot;GPU&quot;) # c=colors
plt.legend()
</code></pre>
</div>
<div class="cell markdown">
<h2 id="final-notes"><a class="header" href="#final-notes">Final Notes</a></h2>
<ol>
<li>It is obvious that GPU clusters easily outperform CPU clusters in our case.</li>
<li>In case of data changes (specifically increase of data) we need to update our optimizer's learning rate. This scenario is already considered by Horovod and the solution is to use elastic Horovod which gives you the possibility to update hvd.size() based on the state of the network. For more information see <a href="https://horovod.readthedocs.io/en/stable/elastic_include.html">here</a></li>
</ol>
</div>
<div class="cell markdown">
<p>Under the hood, HorovodRunner takes a Python method that contains deep learning training code with Horovod hooks. HorovodRunner pickles the method on the driver and distributes it to Spark workers. A Horovod MPI job is embedded as a Spark job using the barrier execution mode. The first executor collects the IP addresses of all task executors using BarrierTaskContext and triggers a Horovod job using <code>mpirun</code>. Each Python MPI process loads the pickled user program, deserializes it, and runs it.</p>
<p>For more information, see <a href="https://databricks.github.io/spark-deep-learning/#api-documentation">HorovodRunner API documentation</a>.</p>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/02_Horovod_Introduction.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../../../contents/student-project-13_group-DRL/student-project-13_group-DRL/00_DistributedRL.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../../contents/student-project-12_group-FedLearnOpt/student-project-12_group-FedLearnOpt/02_Horovod_Introduction.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../../../contents/student-project-13_group-DRL/student-project-13_group-DRL/00_DistributedRL.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
