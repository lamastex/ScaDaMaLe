
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ScaDaMaLe, Scalable Data Science and Distributed Machine Learning &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="007c_SparkSQLProgGuide_HW.html" />
    <link rel="prev" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="007a_SparkSQLProgGuide_HW.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="001_whySpark.html">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#notebooks">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Let’s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Let’s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html#introduction-to-spark">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html#homework-notebook-rdds-transformations-and-actions">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#piped-rdds-and-bayesian-ab-testing">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html#word-count-on-us-state-of-the-union-sou-addresses">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html#spark-sql-programming-guide">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#getting-started">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html#getting-started-exercise">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#data-sources">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html#performance-tuning">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#distributed-sql-engine">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#introduction-to-spark-sql">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wiki-clickstream-analysis">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#plugging-into-gdelt-streams-todo-in-progress">
   Plugging into GDELT Streams - TODO - IN PROGRESS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#old-bailey-online-data-analysis-in-apache-spark">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html#topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/000_1-sds-3-x/007b_SparkSQLProgGuide_HW.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_1-sds-3-x/007b_SparkSQLProgGuide_HW.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-started">
   Getting Started
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spark-sql-programming-guide">
     Spark Sql Programming Guide
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Getting Started
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#starting-point-sparksession">
     Starting Point: SparkSession
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-dataframes">
     Creating DataFrames
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#untyped-dataset-operations-aka-dataframe-operations">
     Untyped Dataset Operations (aka DataFrame Operations)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-sql-queries-programmatically">
     Running SQL Queries Programmatically
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-temporary-view">
     Global Temporary View
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-datasets">
     Creating Datasets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interoperating-with-rdds">
     Interoperating with RDDs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inferring-the-schema-using-reflection">
       Inferring the Schema Using Reflection
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#programmatically-specifying-the-schema">
       Programmatically Specifying the Schema
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scalar-functions">
     Scalar Functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aggregate-functions">
     Aggregate Functions
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="scadamale-scalable-data-science-and-distributed-machine-learning">
<h1><a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/3/x/">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a><a class="headerlink" href="#scadamale-scalable-data-science-and-distributed-machine-learning" title="Permalink to this headline">¶</a></h1>
<p>This is an elaboration of the
<a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html">http://spark.apache.org/docs/latest/sql-programming-guide.html</a> by Ivan
Sadikov and Raazesh Sainudiin.</p>
</div>
<div class="section" id="getting-started">
<h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h1>
<div class="section" id="spark-sql-programming-guide">
<h2>Spark Sql Programming Guide<a class="headerlink" href="#spark-sql-programming-guide" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Starting Point: SparkSession</p></li>
<li><p>Creating DataFrames</p></li>
<li><p>Untyped Dataset Operations (aka DataFrame Operations)</p></li>
<li><p>Running SQL Queries Programmatically</p></li>
<li><p>Global Temporary View</p></li>
<li><p>Creating Datasets</p></li>
<li><p>Interoperating with RDDs</p>
<ul>
<li><p>Inferring the Schema Using Reflection</p></li>
<li><p>Programmatically Specifying the Schema</p></li>
</ul>
</li>
<li><p>Scalar Functions</p></li>
<li><p>Aggregate Functions</p></li>
</ul>
</div>
</div>
<div class="section" id="id1">
<h1>Getting Started<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="starting-point-sparksession">
<h2>Starting Point: SparkSession<a class="headerlink" href="#starting-point-sparksession" title="Permalink to this headline">¶</a></h2>
<p>The entry point into all functionality in Spark is the
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/SparkSession.html"><code class="docutils literal notranslate"><span class="pre">SparkSession</span></code></a>
class and/or <code class="docutils literal notranslate"><span class="pre">SQLContext</span></code>/<code class="docutils literal notranslate"><span class="pre">HiveContext</span></code>. <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> is created for
you as <code class="docutils literal notranslate"><span class="pre">spark</span></code> when you start <strong>spark-shell</strong> on command-line REPL or
through a notebook server (databricks, zeppelin, jupyter, etc.). You
will need to create <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> usually when building an application
for submission to a Spark cluster. To create a basic <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code>,
just use <code class="docutils literal notranslate"><span class="pre">SparkSession.builder()</span></code>:</p>
<p>``` import org.apache.spark.sql.SparkSession</p>
<p>val spark = SparkSession .builder() .appName(“Spark SQL basic example”)
.config(“spark.some.config.option”, “some-value”) .getOrCreate()</p>
<p>// For implicit conversions like converting RDDs to DataFrames import
spark.implicits._ ```</p>
<p>Find full example code in the Spark repo at:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala">https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala</a></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> in Spark 2.0 provides builtin support for Hive features
including the ability to write queries using HiveQL, access to Hive
UDFs, and the ability to read data from Hive tables. To use these
features, you do not need to have an existing Hive setup.</p>
<p><code class="docutils literal notranslate"><span class="pre">//</span> <span class="pre">You</span> <span class="pre">could</span> <span class="pre">get</span> <span class="pre">SparkContext</span> <span class="pre">and</span> <span class="pre">SQLContext</span> <span class="pre">from</span> <span class="pre">SparkSession</span> <span class="pre">val</span> <span class="pre">sc</span> <span class="pre">=</span> <span class="pre">spark.sparkContext</span> <span class="pre">val</span> <span class="pre">sqlContext</span> <span class="pre">=</span> <span class="pre">spark.sqlContext</span></code></p>
<p>But in Databricks notebook (similar to <code class="docutils literal notranslate"><span class="pre">spark-shell</span></code>) <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> is
already created for you and is available as <code class="docutils literal notranslate"><span class="pre">spark</span></code> (similarly, <code class="docutils literal notranslate"><span class="pre">sc</span></code> and
<code class="docutils literal notranslate"><span class="pre">sqlContext</span></code> are also available).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Evaluation</span> <span class="n">of</span> <span class="n">the</span> <span class="n">cell</span> <span class="n">by</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">will</span> <span class="nb">print</span> <span class="n">spark</span> <span class="n">session</span> <span class="n">available</span> <span class="ow">in</span> <span class="n">notebook</span>
<span class="n">spark</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5a289bf5
</pre></div>
</div>
</div></blockquote>
<p>After evaluation you should see something like this, i.e., a reference
to the <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> you just created:</p>
<p><code class="docutils literal notranslate"><span class="pre">res0:</span> <span class="pre">org.apache.spark.sql.SparkSession</span> <span class="pre">=</span> <span class="pre">org.apache.spark.sql.SparkSession&#64;5a289bf5</span></code></p>
</div>
<div class="section" id="creating-dataframes">
<h2>Creating DataFrames<a class="headerlink" href="#creating-dataframes" title="Permalink to this headline">¶</a></h2>
<p>With a <code class="docutils literal notranslate"><span class="pre">SparkSessions</span></code>, applications can create
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">Dataset</a>
or
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame"><code class="docutils literal notranslate"><span class="pre">DataFrame</span></code></a>
from an <a class="reference external" href="https://spark.apache.org/docs/latest/sql-getting-started.html#interoperating-with-rdds">existing
<code class="docutils literal notranslate"><span class="pre">RDD</span></code></a>,
from a Hive table, or from various
<a class="reference external" href="https://spark.apache.org/docs/latest/sql-data-sources.html">datasources</a>.</p>
<p>Just to recap, a DataFrame is a distributed collection of data organized
into named columns. You can think of it as an organized into table RDD
of case class <code class="docutils literal notranslate"><span class="pre">Row</span></code> (which is not exactly true). DataFrames, in
comparison to RDDs, are backed by rich optimizations, including tracking
their own schema, adaptive query execution, code generation including
whole stage codegen, extensible Catalyst optimizer, and project
<a class="reference external" href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html">Tungsten</a>.</p>
<p>Dataset provides type-safety when working with SQL, since <code class="docutils literal notranslate"><span class="pre">Row</span></code> is
mapped to a case class, so that each column can be referenced by
property of that class.</p>
<blockquote>
<div><p>Note that performance for Dataset/DataFrames is the same across
languages Scala, Java, Python, and R. This is due to the fact that the
planning phase is just language-specific, only logical plan is
constructed in Python, and all the physical execution is compiled and
executed as JVM bytecode.</p>
</div></blockquote>
<p>As an example, the following creates a DataFrame based on the content of
a JSON file:</p>
<p>``` val df =
spark.read.json(“examples/src/main/resources/people.json”)</p>
<p>// Displays the content of the DataFrame to stdout df.show() //
+—-+——-+ // | age| name| // +—-+——-+ // |null|Michael| // |
30| Andy| // | 19| Justin| // +—-+——-+ ```</p>
<p>Find full example code at -
https://raw.githubusercontent.com/apache/spark/master/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala
in the Spark repo.</p>
<p>To be able to try this example in databricks we need to load the
<code class="docutils literal notranslate"><span class="pre">people.json</span></code> file into <code class="docutils literal notranslate"><span class="pre">dbfs</span></code>. Let us do this programmatically next.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">the</span> <span class="n">following</span> <span class="n">lines</span> <span class="n">merely</span> <span class="n">fetch</span> <span class="n">the</span> <span class="n">file</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">URL</span> <span class="ow">and</span> <span class="n">load</span> <span class="n">it</span> <span class="n">into</span> <span class="n">the</span> <span class="n">dbfs</span> <span class="k">for</span> <span class="n">us</span> <span class="n">to</span> <span class="k">try</span> <span class="ow">in</span> <span class="n">databricks</span>
<span class="o">//</span> <span class="n">getLines</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">file</span> <span class="n">at</span> <span class="n">the</span> <span class="n">URL</span>
<span class="n">val</span> <span class="n">peopleJsonLinesFromURL</span> <span class="o">=</span> <span class="n">scala</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">Source</span><span class="o">.</span><span class="n">fromURL</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/apache/spark/master/examples/src/main/resources/people.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getLines</span>
<span class="o">//</span> <span class="n">remove</span> <span class="nb">any</span> <span class="n">pre</span><span class="o">-</span><span class="n">existing</span> <span class="n">file</span> <span class="n">at</span> <span class="n">the</span> <span class="n">dbfs</span> <span class="n">location</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.json&quot;</span><span class="p">,</span><span class="n">recurse</span><span class="o">=</span><span class="n">true</span><span class="p">)</span>
<span class="o">//</span> <span class="n">convert</span> <span class="n">the</span> <span class="n">lines</span> <span class="n">fetched</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">URL</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Seq</span><span class="p">,</span> <span class="n">then</span> <span class="n">make</span> <span class="n">it</span> <span class="n">a</span> <span class="n">RDD</span> <span class="n">of</span> <span class="n">String</span> <span class="ow">and</span> <span class="k">finally</span> <span class="n">save</span> <span class="n">it</span> <span class="k">as</span> <span class="n">textfile</span> <span class="n">to</span> <span class="n">dbfs</span>
<span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">peopleJsonLinesFromURL</span><span class="o">.</span><span class="n">toSeq</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.json&quot;</span><span class="p">)</span>
<span class="o">//</span> <span class="n">read</span> <span class="n">the</span> <span class="n">text</span> <span class="n">file</span> <span class="n">we</span> <span class="n">just</span> <span class="n">saved</span> <span class="ow">and</span> <span class="n">see</span> <span class="n">what</span> <span class="n">it</span> <span class="n">has</span>
<span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>peopleJsonLinesFromURL: Iterator[String] = &lt;iterator&gt;
res1: String =
{&quot;name&quot;:&quot;Michael&quot;}
{&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30}
{&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19}
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.json&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>df: org.apache.spark.sql.DataFrame = [age: bigint, name: string]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">you</span> <span class="n">can</span> <span class="n">also</span> <span class="n">read</span> <span class="n">into</span> <span class="n">df</span> <span class="n">like</span> <span class="n">this</span>
<span class="n">val</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.json&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>df: org.apache.spark.sql.DataFrame = [age: bigint, name: string]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+-------+
| age|   name|
+----+-------+
|  19| Justin|
|  30|   Andy|
|null|Michael|
+----+-------+
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="untyped-dataset-operations-aka-dataframe-operations">
<h2>Untyped Dataset Operations (aka DataFrame Operations)<a class="headerlink" href="#untyped-dataset-operations-aka-dataframe-operations" title="Permalink to this headline">¶</a></h2>
<p>DataFrames provide a domain-specific language for structured data
manipulation in
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">Scala</a>,
<a class="reference external" href="https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html">Java</a>,
<a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame">Python</a>
and <a class="reference external" href="https://spark.apache.org/docs/latest/api/R/SparkDataFrame.html">R</a>.</p>
<p>As mentioned above, in Spark 2.0, DataFrames are just Dataset of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s
in Scala and Java API. These operations are also referred as “untyped
transformations” in contrast to “typed transformations” come with
strongly typed Scala/Java Datasets.</p>
<p>Here we include some basic examples of structured data processing using
Datasets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// This import is needed to use the $-notation
import spark.implicits._
// Print the schema in a tree format
df.printSchema()
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>root
 |-- age: long (nullable = true)
 |-- name: string (nullable = true)

import spark.implicits._
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Select</span> <span class="n">only</span> <span class="n">the</span> <span class="s2">&quot;name&quot;</span> <span class="n">column</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+
|   name|
+-------+
| Justin|
|   Andy|
|Michael|
+-------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Select everybody, but increment the age by 1
df.select($&quot;name&quot;, $&quot;age&quot; + 1).show()
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+---------+
|   name|(age + 1)|
+-------+---------+
| Justin|       20|
|   Andy|       31|
|Michael|     null|
+-------+---------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Select people older than 21
df.filter($&quot;age&quot; &gt; 21).show()
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+---+----+
|age|name|
+---+----+
| 30|Andy|
+---+----+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Count</span> <span class="n">people</span> <span class="n">by</span> <span class="n">age</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;age&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+-----+
| age|count|
+----+-----+
|  19|    1|
|null|    1|
|  30|    1|
+----+-----+
</pre></div>
</div>
</div></blockquote>
<p>Find full example code at -
https://raw.githubusercontent.com/apache/spark/master/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala
in the Spark repo.</p>
<p>For a complete list of the types of operations that can be performed on
a Dataset, refer to the <a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">API
Documentation</a>.</p>
<p>In addition to simple column references and expressions, Datasets also
have a rich library of functions including string manipulation, date
arithmetic, common math operations and more. The complete list is
available in the <a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions%24.html">DataFrame Function
Reference</a>.</p>
</div>
<div class="section" id="running-sql-queries-programmatically">
<h2>Running SQL Queries Programmatically<a class="headerlink" href="#running-sql-queries-programmatically" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">sql</span></code> function on a <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> enables applications to run SQL
queries programmatically and returns the result as a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Register</span> <span class="n">the</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">a</span> <span class="n">SQL</span> <span class="n">temporary</span> <span class="n">view</span>
<span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">sqlDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM people&quot;</span><span class="p">)</span>
<span class="n">sqlDF</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+-------+
| age|   name|
+----+-------+
|  19| Justin|
|  30|   Andy|
|null|Michael|
+----+-------+

sqlDF: org.apache.spark.sql.DataFrame = [age: bigint, name: string]
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="global-temporary-view">
<h2>Global Temporary View<a class="headerlink" href="#global-temporary-view" title="Permalink to this headline">¶</a></h2>
<p>Temporary views in Spark SQL are session-scoped and will disappear if
the session that creates it terminates. If you want to have a temporary
view that is shared among all sessions and keep alive until the Spark
application terminates, you can create a global temporary view. Global
temporary view is tied to a system preserved database <code class="docutils literal notranslate"><span class="pre">global_temp</span></code>, and
we must use the qualified name to refer it, e.g.
<code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span> <span class="pre">FROM</span> <span class="pre">global_temp.view1</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Register</span> <span class="n">the</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">a</span> <span class="k">global</span> <span class="n">temporary</span> <span class="n">view</span>
<span class="n">df</span><span class="o">.</span><span class="n">createGlobalTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Global temporary view is tied to a system preserved database `global_temp`
spark.sql(&quot;SELECT * FROM global_temp.people&quot;).show()
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+-------+
| age|   name|
+----+-------+
|  19| Justin|
|  30|   Andy|
|null|Michael|
+----+-------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Global</span> <span class="n">temporary</span> <span class="n">view</span> <span class="ow">is</span> <span class="n">cross</span><span class="o">-</span><span class="n">session</span>
<span class="n">spark</span><span class="o">.</span><span class="n">newSession</span><span class="p">()</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM global_temp.people&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+-------+
| age|   name|
+----+-------+
|  19| Justin|
|  30|   Andy|
|null|Michael|
+----+-------+
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="creating-datasets">
<h2>Creating Datasets<a class="headerlink" href="#creating-datasets" title="Permalink to this headline">¶</a></h2>
<p>Datasets are similar to RDDs, however, instead of using Java
serialization or Kryo they use a specialized
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Encoder.html">Encoder</a>
to serialize the objects for processing or transmitting over the
network. While both encoders and standard serialization are responsible
for turning an object into bytes, encoders are code generated
dynamically and use a format that allows Spark to perform many
operations like filtering, sorting and hashing without deserializing the
bytes back into an object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">age</span><span class="p">:</span> <span class="n">Long</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Encoders</span> <span class="n">are</span> <span class="n">created</span> <span class="k">for</span> <span class="n">case</span> <span class="n">classes</span>
<span class="n">val</span> <span class="n">caseClassDS</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="n">Person</span><span class="p">(</span><span class="s2">&quot;Andy&quot;</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span><span class="o">.</span><span class="n">toDS</span><span class="p">()</span>
<span class="n">caseClassDS</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+---+
|name|age|
+----+---+
|Andy| 32|
+----+---+

defined class Person
caseClassDS: org.apache.spark.sql.Dataset[Person] = [name: string, age: bigint]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Encoders</span> <span class="k">for</span> <span class="n">most</span> <span class="n">common</span> <span class="n">types</span> <span class="n">are</span> <span class="n">automatically</span> <span class="n">provided</span> <span class="n">by</span> <span class="n">importing</span> <span class="n">spark</span><span class="o">.</span><span class="n">implicits</span><span class="o">.</span><span class="n">_</span>
<span class="n">val</span> <span class="n">primitiveDS</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">toDS</span><span class="p">()</span>
<span class="n">primitiveDS</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">Returns</span><span class="p">:</span> <span class="n">Array</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>primitiveDS: org.apache.spark.sql.Dataset[Int] = [value: int]
res18: Array[Int] = Array(2, 3, 4)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">DataFrames</span> <span class="n">can</span> <span class="n">be</span> <span class="n">converted</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Dataset</span> <span class="n">by</span> <span class="n">providing</span> <span class="n">a</span> <span class="n">class</span><span class="o">.</span> <span class="n">Mapping</span> <span class="n">will</span> <span class="n">be</span> <span class="n">done</span> <span class="n">by</span> <span class="n">name</span>
<span class="n">val</span> <span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;dbfs:///datasets/spark-examples/people.json&quot;</span>
<span class="n">val</span> <span class="n">peopleDS</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="k">as</span><span class="p">[</span><span class="n">Person</span><span class="p">]</span>
<span class="n">peopleDS</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----+-------+
| age|   name|
+----+-------+
|  19| Justin|
|  30|   Andy|
|null|Michael|
+----+-------+

path: String = dbfs:///datasets/spark-examples/people.json
peopleDS: org.apache.spark.sql.Dataset[Person] = [age: bigint, name: string]
</pre></div>
</div>
</div></blockquote>
<p><strong>Dataset is not available directly in PySpark or SparkR</strong>.</p>
</div>
<div class="section" id="interoperating-with-rdds">
<h2>Interoperating with RDDs<a class="headerlink" href="#interoperating-with-rdds" title="Permalink to this headline">¶</a></h2>
<p>Spark SQL supports two different methods for converting existing RDDs
into Datasets. The first method uses reflection to infer the schema of
an RDD that contains specific types of objects. This reflection-based
approach leads to more concise code and works well when you already know
the schema while writing your Spark application.</p>
<p>The second method for creating Datasets is through a programmatic
interface that allows you to construct a schema and then apply it to an
existing RDD. While this method is more verbose, it allows you to
construct Datasets when the columns and their types are not known until
runtime.</p>
<div class="section" id="inferring-the-schema-using-reflection">
<h3>Inferring the Schema Using Reflection<a class="headerlink" href="#inferring-the-schema-using-reflection" title="Permalink to this headline">¶</a></h3>
<p>The Scala interface for Spark SQL supports automatically converting an
RDD containing case classes to a DataFrame. The case class defines the
schema of the table. The names of the arguments to the case class are
read using reflection and become the names of the columns. Case classes
can also be nested or contain complex types such as <code class="docutils literal notranslate"><span class="pre">Seq</span></code>s or <code class="docutils literal notranslate"><span class="pre">Array</span></code>s.
This RDD can be implicitly converted to a DataFrame and then be
registered as a table. Tables can be used in subsequent SQL statements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">the</span> <span class="n">following</span> <span class="n">lines</span> <span class="n">merely</span> <span class="n">fetch</span> <span class="n">the</span> <span class="n">file</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">URL</span> <span class="ow">and</span> <span class="n">load</span> <span class="n">it</span> <span class="n">into</span> <span class="n">the</span> <span class="n">dbfs</span> <span class="k">for</span> <span class="n">us</span> <span class="n">to</span> <span class="k">try</span> <span class="ow">in</span> <span class="n">databricks</span>
<span class="o">//</span> <span class="n">getLines</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">file</span> <span class="n">at</span> <span class="n">the</span> <span class="n">URL</span>
<span class="n">val</span> <span class="n">peopleTxtLinesFromURL</span> <span class="o">=</span> <span class="n">scala</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">Source</span><span class="o">.</span><span class="n">fromURL</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/apache/spark/master/examples/src/main/resources/people.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getLines</span>
<span class="o">//</span> <span class="n">remove</span> <span class="nb">any</span> <span class="n">pre</span><span class="o">-</span><span class="n">existing</span> <span class="n">file</span> <span class="n">at</span> <span class="n">the</span> <span class="n">dbfs</span> <span class="n">location</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.txt&quot;</span><span class="p">,</span><span class="n">recurse</span><span class="o">=</span><span class="n">true</span><span class="p">)</span>
<span class="o">//</span> <span class="n">convert</span> <span class="n">the</span> <span class="n">lines</span> <span class="n">fetched</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">URL</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Seq</span><span class="p">,</span> <span class="n">then</span> <span class="n">make</span> <span class="n">it</span> <span class="n">a</span> <span class="n">RDD</span> <span class="n">of</span> <span class="n">String</span> <span class="ow">and</span> <span class="k">finally</span> <span class="n">save</span> <span class="n">it</span> <span class="k">as</span> <span class="n">textfile</span> <span class="n">to</span> <span class="n">dbfs</span>
<span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">peopleTxtLinesFromURL</span><span class="o">.</span><span class="n">toSeq</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.txt&quot;</span><span class="p">)</span>
<span class="o">//</span> <span class="n">read</span> <span class="n">the</span> <span class="n">text</span> <span class="n">file</span> <span class="n">we</span> <span class="n">just</span> <span class="n">saved</span> <span class="ow">and</span> <span class="n">see</span> <span class="n">what</span> <span class="n">it</span> <span class="n">has</span>
<span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>peopleTxtLinesFromURL: Iterator[String] = &lt;iterator&gt;
res26: String =
Michael, 29
Andy, 30
Justin, 19
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res32: String =
Michael, 29
Andy, 30
Justin, 19
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">For</span> <span class="n">implicit</span> <span class="n">conversions</span> <span class="kn">from</span> <span class="nn">RDDs</span> <span class="n">to</span> <span class="n">DataFrames</span>
<span class="kn">import</span> <span class="nn">spark.implicits._</span>

<span class="o">//</span> <span class="n">make</span> <span class="n">a</span> <span class="n">case</span> <span class="k">class</span>
<span class="nc">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">age</span><span class="p">:</span> <span class="n">Long</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">an</span> <span class="n">RDD</span> <span class="n">of</span> <span class="n">Person</span> <span class="n">objects</span> <span class="kn">from</span> <span class="nn">a</span> <span class="n">text</span> <span class="n">file</span><span class="p">,</span> <span class="n">convert</span> <span class="n">it</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Dataframe</span>
<span class="n">val</span> <span class="n">peopleDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
  <span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.txt&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">))</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">attributes</span> <span class="o">=&gt;</span> <span class="n">Person</span><span class="p">(</span><span class="n">attributes</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">attributes</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">trim</span><span class="o">.</span><span class="n">toLong</span><span class="p">))</span>
  <span class="o">//.</span><span class="n">map</span><span class="p">(</span><span class="n">attributes</span> <span class="o">=&gt;</span> <span class="n">Person</span><span class="p">(</span><span class="n">attributes</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">attributes</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">trim</span><span class="o">.</span><span class="n">toLong</span><span class="p">))</span>
  <span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import spark.implicits._
defined class Person
peopleDF: org.apache.spark.sql.DataFrame = [name: string, age: bigint]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">peopleDF</span><span class="o">.</span><span class="n">show</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+---+
|   name|age|
+-------+---+
|Michael| 29|
|   Andy| 30|
| Justin| 19|
+-------+---+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Register</span> <span class="n">the</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">a</span> <span class="n">temporary</span> <span class="n">view</span>
<span class="n">peopleDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">SQL</span> <span class="n">statements</span> <span class="n">can</span> <span class="n">be</span> <span class="n">run</span> <span class="n">by</span> <span class="n">using</span> <span class="n">the</span> <span class="n">sql</span> <span class="n">methods</span> <span class="n">provided</span> <span class="n">by</span> <span class="n">Spark</span>
<span class="n">val</span> <span class="n">teenagersDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name, age FROM people WHERE age BETWEEN 13 AND 19&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>teenagersDF: org.apache.spark.sql.DataFrame = [name: string, age: bigint]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">teenagersDF</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------+---+
|  name|age|
+------+---+
|Justin| 19|
+------+---+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">The</span> <span class="n">columns</span> <span class="n">of</span> <span class="n">a</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">result</span> <span class="n">can</span> <span class="n">be</span> <span class="n">accessed</span> <span class="n">by</span> <span class="n">field</span> <span class="n">index</span>
<span class="n">teenagersDF</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">teenager</span> <span class="o">=&gt;</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">teenager</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------------+
|       value|
+------------+
|Name: Justin|
+------------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="ow">or</span> <span class="n">by</span> <span class="n">field</span> <span class="n">name</span>
<span class="n">teenagersDF</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">teenager</span> <span class="o">=&gt;</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">teenager</span><span class="o">.</span><span class="n">getAs</span><span class="p">[</span><span class="n">String</span><span class="p">](</span><span class="s2">&quot;name&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------------+
|       value|
+------------+
|Name: Justin|
+------------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">No</span> <span class="n">pre</span><span class="o">-</span><span class="n">defined</span> <span class="n">encoders</span> <span class="k">for</span> <span class="n">Dataset</span><span class="p">[</span><span class="n">Map</span><span class="p">[</span><span class="n">K</span><span class="p">,</span><span class="n">V</span><span class="p">]],</span> <span class="n">define</span> <span class="n">explicitly</span>
<span class="n">implicit</span> <span class="n">val</span> <span class="n">mapEncoder</span> <span class="o">=</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">Encoders</span><span class="o">.</span><span class="n">kryo</span><span class="p">[</span><span class="n">Map</span><span class="p">[</span><span class="n">String</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mapEncoder: org.apache.spark.sql.Encoder[Map[String,Any]] = class[value[0]: binary]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Primitive</span> <span class="n">types</span> <span class="ow">and</span> <span class="n">case</span> <span class="n">classes</span> <span class="n">can</span> <span class="n">be</span> <span class="n">also</span> <span class="n">defined</span> <span class="k">as</span>
<span class="o">//</span> <span class="kn">import</span> <span class="nn">more</span> <span class="n">classes</span> <span class="n">here</span><span class="o">...</span>
<span class="o">//</span><span class="n">implicit</span> <span class="n">val</span> <span class="n">stringIntMapEncoder</span><span class="p">:</span> <span class="n">Encoder</span><span class="p">[</span><span class="n">Map</span><span class="p">[</span><span class="n">String</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">ExpressionEncoder</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">row</span><span class="o">.</span><span class="n">getValuesMap</span><span class="p">[</span><span class="n">T</span><span class="p">]</span> <span class="n">retrieves</span> <span class="n">multiple</span> <span class="n">columns</span> <span class="n">at</span> <span class="n">once</span> <span class="n">into</span> <span class="n">a</span> <span class="n">Map</span><span class="p">[</span><span class="n">String</span><span class="p">,</span> <span class="n">T</span><span class="p">]</span>
<span class="n">teenagersDF</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">teenager</span> <span class="o">=&gt;</span> <span class="n">teenager</span><span class="o">.</span><span class="n">getValuesMap</span><span class="p">[</span><span class="n">Any</span><span class="p">](</span><span class="n">List</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res49: Array[Map[String,Any]] = Array(Map(name -&gt; Justin, age -&gt; 19))
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="programmatically-specifying-the-schema">
<h3>Programmatically Specifying the Schema<a class="headerlink" href="#programmatically-specifying-the-schema" title="Permalink to this headline">¶</a></h3>
<p>When case classes cannot be defined ahead of time (for example, the
structure of records is encoded in a string, or a text dataset will be
parsed and fields will be projected differently for different users), a
<code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> can be created programmatically with three steps.</p>
<ol class="simple">
<li><p>Create an RDD of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s from the original RDD;</p></li>
<li><p>Create the schema represented by a <code class="docutils literal notranslate"><span class="pre">StructType</span></code> matching the
structure of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s in the RDD created in Step 1.</p></li>
<li><p>Apply the schema to the RDD of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s via <code class="docutils literal notranslate"><span class="pre">createDataFrame</span></code> method
provided by <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code>.</p></li>
</ol>
<p>For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types._</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">an</span> <span class="n">RDD</span>
<span class="n">val</span> <span class="n">peopleRDD</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:///datasets/spark-examples/people.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.sql.Row
import org.apache.spark.sql.types._
peopleRDD: org.apache.spark.rdd.RDD[String] = dbfs:///datasets/spark-examples/people.txt MapPartitionsRDD[1] at textFile at command-1380089306925986:6
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">The</span> <span class="n">schema</span> <span class="ow">is</span> <span class="n">encoded</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">string</span>
<span class="n">val</span> <span class="n">schemaString</span> <span class="o">=</span> <span class="s2">&quot;name age&quot;</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>schemaString: String = name age
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Generate</span> <span class="n">the</span> <span class="n">schema</span> <span class="n">based</span> <span class="n">on</span> <span class="n">the</span> <span class="n">string</span> <span class="n">of</span> <span class="n">schema</span>
<span class="n">val</span> <span class="n">fields</span> <span class="o">=</span> <span class="n">schemaString</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">fieldName</span> <span class="o">=&gt;</span> <span class="n">StructField</span><span class="p">(</span><span class="n">fieldName</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fields: Array[org.apache.spark.sql.types.StructField] = Array(StructField(name,StringType,true), StructField(age,StringType,true))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>schema: org.apache.spark.sql.types.StructType = StructType(StructField(name,StringType,true), StructField(age,StringType,true))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Convert</span> <span class="n">records</span> <span class="n">of</span> <span class="n">the</span> <span class="n">RDD</span> <span class="p">(</span><span class="n">people</span><span class="p">)</span> <span class="n">to</span> <span class="n">Rows</span>
<span class="n">val</span> <span class="n">rowRDD</span> <span class="o">=</span> <span class="n">peopleRDD</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">))</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">attributes</span> <span class="o">=&gt;</span> <span class="n">Row</span><span class="p">(</span><span class="n">attributes</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">attributes</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">trim</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rowRDD: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[3] at map at command-1581229708952934:4
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Apply</span> <span class="n">the</span> <span class="n">schema</span> <span class="n">to</span> <span class="n">the</span> <span class="n">RDD</span>
<span class="n">val</span> <span class="n">peopleDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rowRDD</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>peopleDF: org.apache.spark.sql.DataFrame = [name: string, age: string]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">peopleDF</span><span class="o">.</span><span class="n">show</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+---+
|   name|age|
+-------+---+
|Michael| 29|
|   Andy| 30|
| Justin| 19|
+-------+---+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Creates</span> <span class="n">a</span> <span class="n">temporary</span> <span class="n">view</span> <span class="n">using</span> <span class="n">the</span> <span class="n">DataFrame</span>
<span class="n">peopleDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">SQL</span> <span class="n">can</span> <span class="n">be</span> <span class="n">run</span> <span class="n">over</span> <span class="n">a</span> <span class="n">temporary</span> <span class="n">view</span> <span class="n">created</span> <span class="n">using</span> <span class="n">DataFrames</span>
<span class="n">val</span> <span class="n">results</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>results: org.apache.spark.sql.DataFrame = [name: string]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">show</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+
|   name|
+-------+
|Michael|
|   Andy|
| Justin|
+-------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">The</span> <span class="n">results</span> <span class="n">of</span> <span class="n">SQL</span> <span class="n">queries</span> <span class="n">are</span> <span class="n">DataFrames</span> <span class="ow">and</span> <span class="n">support</span> <span class="nb">all</span> <span class="n">the</span> <span class="n">normal</span> <span class="n">RDD</span> <span class="n">operations</span>
<span class="o">//</span> <span class="n">The</span> <span class="n">columns</span> <span class="n">of</span> <span class="n">a</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">result</span> <span class="n">can</span> <span class="n">be</span> <span class="n">accessed</span> <span class="n">by</span> <span class="n">field</span> <span class="n">index</span> <span class="ow">or</span> <span class="n">by</span> <span class="n">field</span> <span class="n">name</span>
<span class="n">results</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">attributes</span> <span class="o">=&gt;</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">attributes</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------------+
|        value|
+-------------+
|Name: Michael|
|   Name: Andy|
| Name: Justin|
+-------------+
</pre></div>
</div>
</div></blockquote>
<p>Find full example code at -
https://raw.githubusercontent.com/apache/spark/master/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala
in the Spark repo.</p>
</div>
</div>
<div class="section" id="scalar-functions">
<h2>Scalar Functions<a class="headerlink" href="#scalar-functions" title="Permalink to this headline">¶</a></h2>
<p>Scalar functions are functions that return a single value per row, as
opposed to aggregation functions, which return a value for a group of
rows. Spark SQL supports a variety of <a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-functions.html#scalar-functions">Built-in Scalar
Functions</a>.
It also supports <a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html">User Defined Scalar
Functions</a>.</p>
</div>
<div class="section" id="aggregate-functions">
<h2>Aggregate Functions<a class="headerlink" href="#aggregate-functions" title="Permalink to this headline">¶</a></h2>
<p>Aggregate functions are functions that return a single value on a group
of rows. The <a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions">Built-in Aggregation
Functions</a>
provide common aggregations such as <code class="docutils literal notranslate"><span class="pre">count()</span></code>, <code class="docutils literal notranslate"><span class="pre">countDistinct()</span></code>,
<code class="docutils literal notranslate"><span class="pre">avg()</span></code>, <code class="docutils literal notranslate"><span class="pre">max()</span></code>, <code class="docutils literal notranslate"><span class="pre">min()</span></code>, etc. Users are not limited to the predefined
aggregate functions and can create their own. For more details about
user defined aggregate functions, please refer to the documentation of
<a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-functions-udf-aggregate.html">User Defined Aggregate
Functions</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_1-sds-3-x"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="007a_SparkSQLProgGuide_HW.html" title="previous page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>
    <a class='right-next' id="next-link" href="007c_SparkSQLProgGuide_HW.html" title="next page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>