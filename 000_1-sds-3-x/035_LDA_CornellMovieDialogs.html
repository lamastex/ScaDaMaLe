
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ScaDaMaLe, Scalable Data Science and Distributed Machine Learning &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Piped RDDs and Bayesian AB Testing" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="001_whySpark.html">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#notebooks">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Let’s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Let’s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html#introduction-to-spark">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html#homework-notebook-rdds-transformations-and-actions">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#piped-rdds-and-bayesian-ab-testing">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html#word-count-on-us-state-of-the-union-sou-addresses">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html#spark-sql-programming-guide">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#getting-started">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html#getting-started-exercise">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#data-sources">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html#performance-tuning">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#distributed-sql-engine">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#introduction-to-spark-sql">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wiki-clickstream-analysis">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#plugging-into-gdelt-streams-todo-in-progress">
   Plugging into GDELT Streams - TODO - IN PROGRESS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#old-bailey-online-data-analysis-in-apache-spark">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/000_1-sds-3-x/035_LDA_CornellMovieDialogs.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_1-sds-3-x/035_LDA_CornellMovieDialogs.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-us-cluster-the-conversations-from-different-movies">
     Let us cluster the conversations from different movies!
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm-summary">
     Algorithm Summary
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#links">
     Links
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#readings-for-lda">
     Readings for LDA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probabilistic-topic-modeling-example">
     Probabilistic Topic Modeling Example
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-0-dataset-review">
     Step 0. Dataset Review
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-2-loading-the-data-and-data-cleaning">
     Step 2. Loading the Data and Data Cleaning
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conversations-data">
     Conversations Data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#movie-titles">
     Movie Titles
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lines-data">
     Lines Data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dialogs-with-lines">
     Dialogs with Lines
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-extraction-and-transformation-apis">
     Feature extraction and transformation APIs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-3-text-tokenization">
     Step 3. Text Tokenization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-4-remove-stopwords">
     Step 4. Remove Stopwords
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-5-vector-of-token-counts">
     Step 5. Vector of Token Counts
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-get-an-overview-of-lda-in-spark-s-mllib">
     Let’s get an overview of LDA in Spark’s MLLIB
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-lda-model-with-online-variational-bayes">
     Create LDA model with Online Variational Bayes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#review-topics">
     Review Topics
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-8-model-tuning-refilter-stopwords">
     Step 8. Model Tuning - Refilter Stopwords
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-to-find-what-the-default-values-are">
       How to find what the default values are?
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-9-create-lda-model-with-expectation-maximization">
     Step 9. Create LDA model with Expectation Maximization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-results">
     Visualize Results
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-1-downloading-and-loading-data-into-dbfs">
     Step 1. Downloading and Loading Data into DBFS
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="scadamale-scalable-data-science-and-distributed-machine-learning">
<h1><a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/3/x/">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a><a class="headerlink" href="#scadamale-scalable-data-science-and-distributed-machine-learning" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation">
<h1>Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation<a class="headerlink" href="#topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="let-us-cluster-the-conversations-from-different-movies">
<h2>Let us cluster the conversations from different movies!<a class="headerlink" href="#let-us-cluster-the-conversations-from-different-movies" title="Permalink to this headline">¶</a></h2>
<p>This notebook will provide a brief algorithm summary, links for further
reading, and an example of how to use LDA for Topic Modeling.</p>
<p><strong>not tested in Spark 2.2+ yet (see 034 notebook for syntactic issues,
if any)</strong></p>
</div>
<div class="section" id="algorithm-summary">
<h2>Algorithm Summary<a class="headerlink" href="#algorithm-summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><strong>Task</strong>: Identify topics from a collection of text documents</p></li>
<li><p><strong>Input</strong>: Vectors of word counts</p></li>
<li><p><strong>Optimizers</strong>:</p>
<ul>
<li><p>EMLDAOptimizer using <a class="reference external" href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">Expectation
Maximization</a></p></li>
<li><p>OnlineLDAOptimizer using Iterative Mini-Batch Sampling for
<a class="reference external" href="https://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf">Online Variational
Bayes</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="links">
<h2>Links<a class="headerlink" href="#links" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Spark API docs</p>
<ul>
<li><p>Scala:
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.LDA">LDA</a></p></li>
<li><p>Python:
<a class="reference external" href="https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.clustering.LDA">LDA</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda">MLlib Programming
Guide</a></p></li>
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/ml-features.html">ML Feature Extractors &amp;
Transformers</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Wikipedia: Latent Dirichlet
Allocation</a></p></li>
</ul>
</div>
<div class="section" id="readings-for-lda">
<h2>Readings for LDA<a class="headerlink" href="#readings-for-lda" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>A high-level introduction to the topic from Communications of the
ACM</p>
<ul>
<li><p><a class="reference external" href="http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf">http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf</a></p></li>
</ul>
</li>
<li><p>A very good high-level humanities introduction to the topic
(recommended by Chris Thomson in English Department at UC, Ilam):</p>
<ul>
<li><p><a class="reference external" href="http://journalofdigitalhumanities.org/2-1/topic-modeling-and-digital-humanities-by-david-m-blei/">http://journalofdigitalhumanities.org/2-1/topic-modeling-and-digital-humanities-by-david-m-blei/</a></p></li>
</ul>
</li>
</ul>
<p>Also read the methodological and more formal papers cited in the above
links if you want to know more.</p>
<p>Let’s get a bird’s eye view of LDA from
http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf next.</p>
<ul class="simple">
<li><p>See pictures (hopefully you read the paper last night!)</p></li>
<li><p>Algorithm of the generative model (this is unsupervised clustering)</p></li>
<li><p>For a careful introduction to the topic see Section 27.3 and 27.4
(pages 950-970) pf Murphy’s <em>Machine Learning: A Probabilistic
Perspective, MIT Press, 2012</em>.</p></li>
<li><p>We will be quite application focussed or applied here!</p></li>
</ul>
</div>
<div class="section" id="probabilistic-topic-modeling-example">
<h2>Probabilistic Topic Modeling Example<a class="headerlink" href="#probabilistic-topic-modeling-example" title="Permalink to this headline">¶</a></h2>
<p>This is an outline of our Topic Modeling workflow. Feel free to jump to
any subtopic to find out more.</p>
<ul class="simple">
<li><p>Step 0. Dataset Review</p></li>
<li><p>Step 1. Downloading and Loading Data into DBFS</p>
<ul>
<li><p>(Step 1. only needs to be done once per shard - see details at
the end of the notebook for Step 1.)</p></li>
</ul>
</li>
<li><p>Step 2. Loading the Data and Data Cleaning</p></li>
<li><p>Step 3. Text Tokenization</p></li>
<li><p>Step 4. Remove Stopwords</p></li>
<li><p>Step 5. Vector of Token Counts</p></li>
<li><p>Step 6. Create LDA model with Online Variational Bayes</p></li>
<li><p>Step 7. Review Topics</p></li>
<li><p>Step 8. Model Tuning - Refilter Stopwords</p></li>
<li><p>Step 9. Create LDA model with Expectation Maximization</p></li>
<li><p>Step 10. Visualize Results</p></li>
</ul>
</div>
<div class="section" id="step-0-dataset-review">
<h2>Step 0. Dataset Review<a class="headerlink" href="#step-0-dataset-review" title="Permalink to this headline">¶</a></h2>
<p>In this example, we will use the <a class="reference external" href="https://people.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie Dialogs
Corpus</a>.</p>
<p>Here is the <code class="docutils literal notranslate"><span class="pre">README.txt</span></code>:</p>
<hr class="docutils" />
<hr class="docutils" />
<p>Cornell Movie-Dialogs Corpus</p>
<p>Distributed together with:</p>
<p>“Chameleons in imagined conversations: A new approach to understanding
coordination of linguistic style in dialogs” Cristian
Danescu-Niculescu-Mizil and Lillian Lee Proceedings of the Workshop on
Cognitive Modeling and Computational Linguistics, ACL 2011.</p>
<p>(this paper is included in this zip file)</p>
<p>NOTE: If you have results to report on these corpora, please send email
to cristian&#64;cs.cornell.edu or llee&#64;cs.cornell.edu so we can add you to
our list of people using this data. Thanks!</p>
<p>Contents of this README:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    A) Brief description
    B) Files description
    C) Details on the collection procedure
    D) Contact
</pre></div>
</div>
<p>A) Brief description:</p>
<p>This corpus contains a metadata-rich collection of fictional
conversations extracted from raw movie scripts:</p>
<ul class="simple">
<li><p>220,579 conversational exchanges between 10,292 pairs of movie
characters</p></li>
<li><p>involves 9,035 characters from 617 movies</p></li>
<li><p>in total 304,713 utterances</p></li>
<li><p>movie metadata included: - genres - release year - IMDB rating -
number of IMDB votes - IMDB rating</p></li>
<li><p>character metadata included: - gender (for 3,774 characters) -
position on movie credits (3,321 characters)</p></li>
</ul>
<p>B) Files description:</p>
<p>In all files the field separator is ” +++$+++ “</p>
<ul class="simple">
<li><p>movie<em>titles</em>metadata.txt - contains information about each movie
title - fields: - movieID, - movie title, - movie year, - IMDB
rating, - no. IMDB votes, - genres in the format
[‘genre1’,’genre2’,…,’genreN’]</p></li>
<li><p>movie<em>characters</em>metadata.txt - contains information about each
movie character - fields: - characterID - character name - movieID -
movie title - gender (“?” for unlabeled cases) - position in credits
(“?” for unlabeled cases)</p></li>
<li><p>movie_lines.txt - contains the actual text of each utterance -
fields: - lineID - characterID (who uttered this phrase) - movieID -
character name - text of the utterance</p></li>
<li><p>movie<em>conversations.txt - the structure of the conversations -
fields - characterID of the first character involved in the
conversation - characterID of the second character involved in the
conversation - movieID of the movie in which the conversation
occurred - list of the utterances that make the conversation, in
chronological order: [‘lineID1’,’lineID2’,…,’lineIDN’] has to be
matched with movie</em>lines.txt to reconstruct the actual content</p></li>
<li><p>raw<em>script</em>urls.txt - the urls from which the raw sources were
retrieved</p></li>
</ul>
<p>C) Details on the collection procedure:</p>
<p>We started from raw publicly available movie scripts (sources
acknowledged in raw<em>script</em>urls.txt). In order to collect the metadata
necessary for this study and to distinguish between two script versions
of the same movie, we automatically matched each script with an entry in
movie database provided by IMDB (The Internet Movie Database; data
interfaces available at http://www.imdb.com/interfaces). Some amount of
manual correction was also involved. When more than one movie with the
same title was found in IMBD, the match was made with the most popular
title (the one that received most IMDB votes)</p>
<p>After discarding all movies that could not be matched or that had less
than 5 IMDB votes, we were left with 617 unique titles with metadata
including genre, release year, IMDB rating and no. of IMDB votes and
cast distribution. We then identified the pairs of characters that
interact and separated their conversations automatically using simple
data processing heuristics. After discarding all pairs that exchanged
less than 5 conversational exchanges there were 10,292 left, exchanging
220,579 conversational exchanges (304,713 utterances). After
automatically matching the names of the 9,035 involved characters to the
list of cast distribution, we used the gender of each interpreting actor
to infer the fictional gender of a subset of 3,321 movie characters (we
raised the number of gendered 3,774 characters through manual
annotation). Similarly, we collected the end credit position of a subset
of 3,321 characters as a proxy for their status.</p>
<p>D) Contact:</p>
<p>Please email any questions to: cristian&#64;cs.cornell.edu (Cristian
Danescu-Niculescu-Mizil)</p>
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="step-2-loading-the-data-and-data-cleaning">
<h2>Step 2. Loading the Data and Data Cleaning<a class="headerlink" href="#step-2-loading-the-data-and-data-cleaning" title="Permalink to this headline">¶</a></h2>
<p>We have already used the wget command to download the file, and put it
in our distributed file system (this process takes about 1 minute). To
repeat these steps or to download data from another source follow the
steps at the bottom of this worksheet on <strong>Step 1. Downloading and
Loading Data into DBFS</strong>.</p>
<p>Let’s make sure these files are in dbfs now:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// this is where the data resides in dbfs (see below to download it first, if you go to a new shard!)
display(dbutils.fs.ls(&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/&quot;)) 
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
</div>
<div class="section" id="conversations-data">
<h2>Conversations Data<a class="headerlink" href="#conversations-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_conversations.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">top</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>u999 +++$+++ u1006 +++$+++ m65 +++$+++ [&#39;L227588&#39;, &#39;L227589&#39;, &#39;L227590&#39;, &#39;L227591&#39;, &#39;L227592&#39;, &#39;L227593&#39;, &#39;L227594&#39;, &#39;L227595&#39;, &#39;L227596&#39;]
u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228159&#39;, &#39;L228160&#39;]
u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228157&#39;, &#39;L228158&#39;]
u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228130&#39;, &#39;L228131&#39;]
u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228127&#39;, &#39;L228128&#39;, &#39;L228129&#39;]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Load</span> <span class="n">text</span> <span class="n">file</span><span class="p">,</span> <span class="n">leave</span> <span class="n">out</span> <span class="n">file</span> <span class="n">paths</span><span class="p">,</span> <span class="n">convert</span> <span class="nb">all</span> <span class="n">strings</span> <span class="n">to</span> <span class="n">lowercase</span>
<span class="n">val</span> <span class="n">conversationsRaw</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_conversations.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>conversationsRaw: org.apache.spark.rdd.RDD[(String, Long)] = ZippedWithIndexRDD[3709] at zipWithIndex at command-753740454082219:2
</pre></div>
</div>
</div></blockquote>
<p>Review first 5 lines to get a sense for the data format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversationsRaw</span><span class="o">.</span><span class="n">top</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span> <span class="o">//</span> <span class="n">the</span> <span class="n">first</span> <span class="n">five</span> <span class="n">Strings</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">RDD</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(u999 +++$+++ u1006 +++$+++ m65 +++$+++ [&#39;L227588&#39;, &#39;L227589&#39;, &#39;L227590&#39;, &#39;L227591&#39;, &#39;L227592&#39;, &#39;L227593&#39;, &#39;L227594&#39;, &#39;L227595&#39;, &#39;L227596&#39;],8954)
(u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228159&#39;, &#39;L228160&#39;],8952)
(u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228157&#39;, &#39;L228158&#39;],8951)
(u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228130&#39;, &#39;L228131&#39;],8950)
(u998 +++$+++ u1005 +++$+++ m65 +++$+++ [&#39;L228127&#39;, &#39;L228128&#39;, &#39;L228129&#39;],8949)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversationsRaw</span><span class="o">.</span><span class="n">count</span> <span class="o">//</span> <span class="n">there</span> <span class="n">are</span> <span class="n">over</span> <span class="mi">83</span><span class="p">,</span><span class="mi">000</span> <span class="n">conversations</span> <span class="ow">in</span> <span class="n">total</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res1: Long = 83097
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scala.util.</span><span class="p">{</span><span class="n">Failure</span><span class="p">,</span> <span class="n">Success</span><span class="p">}</span>

<span class="n">val</span> <span class="n">regexConversation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;\s*(\w+)\s+(\+</span><span class="si">{3}</span><span class="s2">\$\+</span><span class="si">{3}</span><span class="s2">)\s*(\w+)\s+(</span><span class="se">\2</span><span class="s2">)\s*(\w+)\s+(</span><span class="se">\2</span><span class="s2">)\s*(\[.*\]\s*$)&quot;&quot;&quot;</span><span class="o">.</span><span class="n">r</span>

<span class="n">case</span> <span class="k">class</span> <span class="nc">conversationLine</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="n">String</span><span class="p">)</span>

<span class="n">val</span> <span class="n">conversationsRaw</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_conversations.txt&quot;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">zipWithIndex</span><span class="p">()</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> 
          <span class="p">{</span>
            <span class="n">val</span> <span class="nb">id</span><span class="p">:</span><span class="n">Long</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span>
            <span class="n">val</span> <span class="n">line</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span>
            <span class="n">val</span> <span class="n">pLine</span> <span class="o">=</span> <span class="n">regexConversation</span><span class="o">.</span><span class="n">findFirstMatchIn</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                               <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">m</span> <span class="o">=&gt;</span> <span class="n">conversationLine</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">7</span><span class="p">)))</span> 
                                  <span class="n">match</span> <span class="p">{</span>
                                    <span class="n">case</span> <span class="n">Some</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">Success</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
                                    <span class="n">case</span> <span class="kc">None</span> <span class="o">=&gt;</span> <span class="n">Failure</span><span class="p">(</span><span class="n">new</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;Non matching input: $line&quot;</span><span class="p">))</span>
                                  <span class="p">}</span>
              <span class="p">(</span><span class="nb">id</span><span class="p">,</span><span class="n">pLine</span><span class="p">)</span>
           <span class="p">}</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import scala.util.{Failure, Success}
regexConversation: scala.util.matching.Regex = \s*(\w+)\s+(\+{3}\$\+{3})\s*(\w+)\s+(\2)\s*(\w+)\s+(\2)\s*(\[.*\]\s*$)
defined class conversationLine
conversationsRaw: org.apache.spark.rdd.RDD[(Long, Product with Serializable with scala.util.Try[conversationLine])] = MapPartitionsRDD[3713] at map at command-753740454082223:9
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversationsRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res2: Long = 83097
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversationsRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">isFailure</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res3: Long = 0
</pre></div>
</div>
</div></blockquote>
<p>The conversation number and line numbers of each conversation are in one
line in <code class="docutils literal notranslate"><span class="pre">conversationsRaw</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversationsRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(0,Success(conversationLine(u0,u2,m0,[&#39;L194&#39;, &#39;L195&#39;, &#39;L196&#39;, &#39;L197&#39;])))
(1,Success(conversationLine(u0,u2,m0,[&#39;L198&#39;, &#39;L199&#39;])))
(2,Success(conversationLine(u0,u2,m0,[&#39;L200&#39;, &#39;L201&#39;, &#39;L202&#39;, &#39;L203&#39;])))
(3,Success(conversationLine(u0,u2,m0,[&#39;L204&#39;, &#39;L205&#39;, &#39;L206&#39;])))
(4,Success(conversationLine(u0,u2,m0,[&#39;L207&#39;, &#39;L208&#39;])))
</pre></div>
</div>
</div></blockquote>
<p>Let’s create <code class="docutils literal notranslate"><span class="pre">conversations</span></code> that have just the coversation id and
line-number with order information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">conversations</span> 
    <span class="o">=</span> <span class="n">conversationsRaw</span>
      <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span>
      <span class="o">.</span><span class="n">flatMap</span> <span class="p">{</span> 
        <span class="n">case</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span><span class="n">Success</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>  
                  <span class="o">=&gt;</span> <span class="p">{</span> <span class="n">val</span> <span class="n">conv</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">d</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;]&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                       <span class="n">val</span> <span class="n">convLinesIndexed</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">zipWithIndex</span>
                       <span class="n">convLinesIndexed</span><span class="o">.</span><span class="n">map</span><span class="p">(</span> <span class="n">cLI</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">cLI</span><span class="o">.</span><span class="n">_2</span><span class="p">,</span> <span class="n">cLI</span><span class="o">.</span><span class="n">_1</span><span class="p">))</span>
                      <span class="p">}</span>
       <span class="p">}</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;conversationID&quot;</span><span class="p">,</span><span class="s2">&quot;intraConversationID&quot;</span><span class="p">,</span><span class="s2">&quot;lineID&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>notebook:4: warning: match may not be exhaustive.
It would fail on the following input: (_, Failure(_))
      .flatMap {
               ^
conversations: org.apache.spark.sql.DataFrame = [conversationID: bigint, intraConversationID: int ... 1 more field]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversations</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+--------------+-------------------+------+
|conversationID|intraConversationID|lineID|
+--------------+-------------------+------+
|             0|                  0|  L194|
|             0|                  1|  L195|
|             0|                  2|  L196|
|             0|                  3|  L197|
|             1|                  0|  L198|
|             1|                  1|  L199|
|             2|                  0|  L200|
|             2|                  1|  L201|
|             2|                  2|  L202|
|             2|                  3|  L203|
|             3|                  0|  L204|
|             3|                  1|  L205|
|             3|                  2|  L206|
|             4|                  0|  L207|
|             4|                  1|  L208|
+--------------+-------------------+------+
only showing top 15 rows
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="movie-titles">
<h2>Movie Titles<a class="headerlink" href="#movie-titles" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">moviesMetaDataRaw</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_titles_metadata.txt&quot;</span><span class="p">)</span>
<span class="n">moviesMetaDataRaw</span><span class="o">.</span><span class="n">top</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>m99 +++$+++ indiana jones and the temple of doom +++$+++ 1984 +++$+++ 7.50 +++$+++ 112054 +++$+++ [&#39;action&#39;, &#39;adventure&#39;]
m98 +++$+++ indiana jones and the last crusade +++$+++ 1989 +++$+++ 8.30 +++$+++ 174947 +++$+++ [&#39;action&#39;, &#39;adventure&#39;, &#39;thriller&#39;, &#39;action&#39;, &#39;adventure&#39;, &#39;fantasy&#39;]
m97 +++$+++ independence day +++$+++ 1996 +++$+++ 6.60 +++$+++ 151698 +++$+++ [&#39;action&#39;, &#39;adventure&#39;, &#39;sci-fi&#39;, &#39;thriller&#39;]
m96 +++$+++ invaders from mars +++$+++ 1953 +++$+++ 6.40 +++$+++ 2115 +++$+++ [&#39;horror&#39;, &#39;sci-fi&#39;]
m95 +++$+++ i am legend +++$+++ 2007 +++$+++ 7.10 +++$+++ 156084 +++$+++ [&#39;drama&#39;, &#39;sci-fi&#39;, &#39;thriller&#39;]
moviesMetaDataRaw: org.apache.spark.rdd.RDD[String] = dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_titles_metadata.txt MapPartitionsRDD[3722] at textFile at command-753740454082232:1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">moviesMetaDataRaw</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">//</span> <span class="n">number</span> <span class="n">of</span> <span class="n">movies</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res8: Long = 617
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scala.util.</span><span class="p">{</span><span class="n">Failure</span><span class="p">,</span> <span class="n">Success</span><span class="p">}</span>

<span class="o">/*</span>  <span class="o">-</span> <span class="n">contains</span> <span class="n">information</span> <span class="n">about</span> <span class="n">each</span> <span class="n">movie</span> <span class="n">title</span>
  <span class="o">-</span> <span class="n">fields</span><span class="p">:</span>
          <span class="o">-</span> <span class="n">movieID</span><span class="p">,</span>
          <span class="o">-</span> <span class="n">movie</span> <span class="n">title</span><span class="p">,</span>
          <span class="o">-</span> <span class="n">movie</span> <span class="n">year</span><span class="p">,</span>
          <span class="o">-</span> <span class="n">IMDB</span> <span class="n">rating</span><span class="p">,</span>
          <span class="o">-</span> <span class="n">no</span><span class="o">.</span> <span class="n">IMDB</span> <span class="n">votes</span><span class="p">,</span>
          <span class="o">-</span> <span class="n">genres</span> <span class="ow">in</span> <span class="n">the</span> <span class="nb">format</span> <span class="p">[</span><span class="s1">&#39;genre1&#39;</span><span class="p">,</span><span class="s1">&#39;genre2&#39;</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="s1">&#39;genreN&#39;</span><span class="p">]</span>
          <span class="o">*/</span>
<span class="n">val</span> <span class="n">regexMovieMetaData</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;\s*(\w+)\s+(\+</span><span class="si">{3}</span><span class="s2">\$\+</span><span class="si">{3}</span><span class="s2">)\s*(.+)\s+(</span><span class="se">\2</span><span class="s2">)\s+(.+)\s+(</span><span class="se">\2</span><span class="s2">)\s+(.+)\s+(</span><span class="se">\2</span><span class="s2">)\s+(.+)\s+(</span><span class="se">\2</span><span class="s2">)\s+(\[.*\]\s*$)&quot;&quot;&quot;</span><span class="o">.</span><span class="n">r</span>

<span class="n">case</span> <span class="k">class</span> <span class="nc">lineInMovieMetaData</span><span class="p">(</span><span class="n">movieID</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">movieTitle</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">movieYear</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">IMDBRating</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">NumIMDBVotes</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">genres</span><span class="p">:</span> <span class="n">String</span><span class="p">)</span>

<span class="n">val</span> <span class="n">moviesMetaDataRaw</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_titles_metadata.txt&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">line</span> <span class="o">=&gt;</span> 
          <span class="p">{</span>
            <span class="n">val</span> <span class="n">pLine</span> <span class="o">=</span> <span class="n">regexMovieMetaData</span><span class="o">.</span><span class="n">findFirstMatchIn</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                               <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">m</span> <span class="o">=&gt;</span> <span class="n">lineInMovieMetaData</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">9</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">11</span><span class="p">)))</span> 
                                  <span class="n">match</span> <span class="p">{</span>
                                    <span class="n">case</span> <span class="n">Some</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">Success</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
                                    <span class="n">case</span> <span class="kc">None</span> <span class="o">=&gt;</span> <span class="n">Failure</span><span class="p">(</span><span class="n">new</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;Non matching input: $line&quot;</span><span class="p">))</span>
                                  <span class="p">}</span>
              <span class="n">pLine</span>
           <span class="p">}</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import scala.util.{Failure, Success}
regexMovieMetaData: scala.util.matching.Regex = \s*(\w+)\s+(\+{3}\$\+{3})\s*(.+)\s+(\2)\s+(.+)\s+(\2)\s+(.+)\s+(\2)\s+(.+)\s+(\2)\s+(\[.*\]\s*$)
defined class lineInMovieMetaData
moviesMetaDataRaw: org.apache.spark.rdd.RDD[Product with Serializable with scala.util.Try[lineInMovieMetaData]] = MapPartitionsRDD[3725] at map at command-753740454082234:17
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">moviesMetaDataRaw</span><span class="o">.</span><span class="n">count</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res9: Long = 617
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">moviesMetaDataRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res10: Long = 617
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">moviesMetaDataRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Success(lineInMovieMetaData(m0,10 things i hate about you,1999,6.90,62847,[&#39;comedy&#39;, &#39;romance&#39;]))
Success(lineInMovieMetaData(m1,1492: conquest of paradise,1992,6.20,10421,[&#39;adventure&#39;, &#39;biography&#39;, &#39;drama&#39;, &#39;history&#39;]))
Success(lineInMovieMetaData(m2,15 minutes,2001,6.10,25854,[&#39;action&#39;, &#39;crime&#39;, &#39;drama&#39;, &#39;thriller&#39;]))
Success(lineInMovieMetaData(m3,2001: a space odyssey,1968,8.40,163227,[&#39;adventure&#39;, &#39;mystery&#39;, &#39;sci-fi&#39;]))
Success(lineInMovieMetaData(m4,48 hrs.,1982,6.90,22289,[&#39;action&#39;, &#39;comedy&#39;, &#39;crime&#39;, &#39;drama&#39;, &#39;thriller&#39;]))
Success(lineInMovieMetaData(m5,the fifth element,1997,7.50,133756,[&#39;action&#39;, &#39;adventure&#39;, &#39;romance&#39;, &#39;sci-fi&#39;, &#39;thriller&#39;]))
Success(lineInMovieMetaData(m6,8mm,1999,6.30,48212,[&#39;crime&#39;, &#39;mystery&#39;, &#39;thriller&#39;]))
Success(lineInMovieMetaData(m7,a nightmare on elm street 4: the dream master,1988,5.20,13590,[&#39;fantasy&#39;, &#39;horror&#39;, &#39;thriller&#39;]))
Success(lineInMovieMetaData(m8,a nightmare on elm street: the dream child,1989,4.70,11092,[&#39;fantasy&#39;, &#39;horror&#39;, &#39;thriller&#39;]))
Success(lineInMovieMetaData(m9,the atomic submarine,1959,4.90,513,[&#39;sci-fi&#39;, &#39;thriller&#39;]))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">moviesMetaDataRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isFailure</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span> <span class="o">//</span> <span class="n">to</span> <span class="n">regex</span> <span class="n">refine</span> <span class="k">for</span> <span class="n">casting</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">moviesMetaData</span> 
    <span class="o">=</span> <span class="n">moviesMetaDataRaw</span>
      <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span>
      <span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="n">Success</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">l</span> <span class="p">}</span>
      <span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;movieID&quot;</span><span class="p">,</span><span class="s2">&quot;movieTitle&quot;</span><span class="p">,</span><span class="s2">&quot;movieYear&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>notebook:4: warning: match may not be exhaustive.
It would fail on the following input: Failure(_)
      .map { case Success(l) =&gt; l }
           ^
moviesMetaData: org.apache.spark.sql.DataFrame = [movieID: string, movieTitle: string ... 1 more field]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">moviesMetaData</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">false</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+---------------------------------------------+---------+
|movieID|movieTitle                                   |movieYear|
+-------+---------------------------------------------+---------+
|m0     |10 things i hate about you                   |1999     |
|m1     |1492: conquest of paradise                   |1992     |
|m2     |15 minutes                                   |2001     |
|m3     |2001: a space odyssey                        |1968     |
|m4     |48 hrs.                                      |1982     |
|m5     |the fifth element                            |1997     |
|m6     |8mm                                          |1999     |
|m7     |a nightmare on elm street 4: the dream master|1988     |
|m8     |a nightmare on elm street: the dream child   |1989     |
|m9     |the atomic submarine                         |1959     |
+-------+---------------------------------------------+---------+
only showing top 10 rows
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="lines-data">
<h2>Lines Data<a class="headerlink" href="#lines-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">linesRaw</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_lines.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>linesRaw: org.apache.spark.rdd.RDD[String] = dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_lines.txt MapPartitionsRDD[3733] at textFile at command-753740454082242:1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linesRaw</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">//</span> <span class="n">number</span> <span class="n">of</span> <span class="n">lines</span> <span class="n">making</span> <span class="n">up</span> <span class="n">the</span> <span class="n">conversations</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res15: Long = 304713
</pre></div>
</div>
</div></blockquote>
<p>Review first 5 lines to get a sense for the data format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linesRaw</span><span class="o">.</span><span class="n">top</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>L99999 +++$+++ u4166 +++$+++ m278 +++$+++ DULANEY +++$+++ You didn&#39;t know about it before that?
L99998 +++$+++ u4168 +++$+++ m278 +++$+++ JOANNE +++$+++ To show you this.  It&#39;s a letter from that lawyer, Koehler.  He wrote it to me the day after I saw him.  He&#39;s the one who told me I could get the money if Miss Lawson went to jail.
L99997 +++$+++ u4166 +++$+++ m278 +++$+++ DULANEY +++$+++ Why&#39;d you come here?
L99996 +++$+++ u4168 +++$+++ m278 +++$+++ JOANNE +++$+++ I&#39;m gonna go to jail.  I know they&#39;re gonna make it look like I did it. They gotta put it on someone.
L99995 +++$+++ u4168 +++$+++ m278 +++$+++ JOANNE +++$+++ What do you think I&#39;ve got?  A gun? Maybe I&#39;m gonna kill you too.  Maybe I&#39;ll blow your head off right now.
</pre></div>
</div>
</div></blockquote>
<p>To see 5 random lines in the <code class="docutils literal notranslate"><span class="pre">lines.txt</span></code> evaluate the following cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linesRaw</span><span class="o">.</span><span class="n">takeSample</span><span class="p">(</span><span class="n">false</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>L216035 +++$+++ u5302 +++$+++ m351 +++$+++ RAMBO +++$+++ Colonel.
L597568 +++$+++ u8300 +++$+++ m564 +++$+++ LOMBARD +++$+++ I don�t.
L513032 +++$+++ u7667 +++$+++ m518 +++$+++ LINDA +++$+++ He&#39;s no more an Indian than I am though. Anyhow, Doyle&#39;s gonna try and tease you and be mean to you to show off to his friends. Just like he does to Frank and me sometimes. You just ignore it. Or stay out here away from &#39;em if he&#39;ll let you. He&#39;s an okay guy till he gets drunk but tonight he&#39;ll get drunk. I guarantee it.
L35914 +++$+++ u313 +++$+++ m19 +++$+++ JESSE +++$+++ Yesss, but I was thinking, I could come by, and then take Zee out. Some place near. With other folk. Near. Here.  But out.
L426481 +++$+++ u2391 +++$+++ m153 +++$+++ COOLEY +++$+++ - and share one of your graves.
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scala.util.</span><span class="p">{</span><span class="n">Failure</span><span class="p">,</span> <span class="n">Success</span><span class="p">}</span>

<span class="o">/*</span>  <span class="n">field</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">txt</span> <span class="n">are</span><span class="p">:</span>
          <span class="o">-</span> <span class="n">lineID</span>
          <span class="o">-</span> <span class="n">characterID</span> <span class="p">(</span><span class="n">who</span> <span class="n">uttered</span> <span class="n">this</span> <span class="n">phrase</span><span class="p">)</span>
          <span class="o">-</span> <span class="n">movieID</span>
          <span class="o">-</span> <span class="n">character</span> <span class="n">name</span>
          <span class="o">-</span> <span class="n">text</span> <span class="n">of</span> <span class="n">the</span> <span class="n">utterance</span>
          <span class="o">*/</span>
<span class="n">val</span> <span class="n">regexLine</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;\s*(\w+)\s+(\+</span><span class="si">{3}</span><span class="s2">\$\+</span><span class="si">{3}</span><span class="s2">)\s*(\w+)\s+(</span><span class="se">\2</span><span class="s2">)\s*(\w+)\s+(</span><span class="se">\2</span><span class="s2">)\s*(.+)\s+(</span><span class="se">\2</span><span class="s2">)\s*(.*$)&quot;&quot;&quot;</span><span class="o">.</span><span class="n">r</span>

<span class="n">case</span> <span class="k">class</span> <span class="nc">lineInMovie</span><span class="p">(</span><span class="n">lineID</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">characterID</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">movieID</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">characterName</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="n">String</span><span class="p">)</span>

<span class="n">val</span> <span class="n">linesRaw</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_lines.txt&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">line</span> <span class="o">=&gt;</span> 
          <span class="p">{</span>
            <span class="n">val</span> <span class="n">pLine</span> <span class="o">=</span> <span class="n">regexLine</span><span class="o">.</span><span class="n">findFirstMatchIn</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                               <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">m</span> <span class="o">=&gt;</span> <span class="n">lineInMovie</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">9</span><span class="p">)))</span> 
                                  <span class="n">match</span> <span class="p">{</span>
                                    <span class="n">case</span> <span class="n">Some</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">Success</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
                                    <span class="n">case</span> <span class="kc">None</span> <span class="o">=&gt;</span> <span class="n">Failure</span><span class="p">(</span><span class="n">new</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;Non matching input: $line&quot;</span><span class="p">))</span>
                                  <span class="p">}</span>
              <span class="n">pLine</span>
           <span class="p">}</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import scala.util.{Failure, Success}
regexLine: scala.util.matching.Regex = \s*(\w+)\s+(\+{3}\$\+{3})\s*(\w+)\s+(\2)\s*(\w+)\s+(\2)\s*(.+)\s+(\2)\s*(.*$)
defined class lineInMovie
linesRaw: org.apache.spark.rdd.RDD[Product with Serializable with scala.util.Try[lineInMovie]] = MapPartitionsRDD[3737] at map at command-753740454082248:15
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linesRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res18: Long = 304713
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linesRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isFailure</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res19: Long = 0
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linesRaw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Success(lineInMovie(L1045,u0,m0,BIANCA,They do not!))
Success(lineInMovie(L1044,u2,m0,CAMERON,They do to!))
Success(lineInMovie(L985,u0,m0,BIANCA,I hope so.))
Success(lineInMovie(L984,u2,m0,CAMERON,She okay?))
Success(lineInMovie(L925,u0,m0,BIANCA,Let&#39;s go.))
</pre></div>
</div>
</div></blockquote>
<p>Let’s make a DataFrame out of the successfully parsed line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">lines</span> 
    <span class="o">=</span> <span class="n">linesRaw</span>
      <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">isSuccess</span><span class="p">)</span>
      <span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="n">Success</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">l</span> <span class="p">}</span>
      <span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
      <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">moviesMetaData</span><span class="p">,</span> <span class="s2">&quot;movieID&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="ow">and</span> <span class="n">join</span> <span class="n">it</span> <span class="n">to</span> <span class="n">get</span> <span class="n">movie</span> <span class="n">meta</span> <span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>notebook:4: warning: match may not be exhaustive.
It would fail on the following input: Failure(_)
      .map { case Success(l) =&gt; l }
           ^
lines: org.apache.spark.sql.DataFrame = [movieID: string, lineID: string ... 5 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lines</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------+-------+-----------+-------------+--------------------+-------------+---------+
|movieID| lineID|characterID|characterName|                text|   movieTitle|movieYear|
+-------+-------+-----------+-------------+--------------------+-------------+---------+
|   m203|L593445|      u3102|        HAGEN|You owe the Don a...|the godfather|     1972|
|   m203|L593444|      u3094|     BONASERA|Yes, I understand...|the godfather|     1972|
|   m203|L593443|      u3102|        HAGEN|This is Tom Hagen...|the godfather|     1972|
|   m203|L593425|      u3102|        HAGEN|               Yes. |the godfather|     1972|
|   m203|L593424|      u3094|     BONASERA|The Don himself i...|the godfather|     1972|
+-------+-------+-----------+-------------+--------------------+-------------+---------+
only showing top 5 rows
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="dialogs-with-lines">
<h2>Dialogs with Lines<a class="headerlink" href="#dialogs-with-lines" title="Permalink to this headline">¶</a></h2>
<p>Let’s join ght two DataFrames on <code class="docutils literal notranslate"><span class="pre">lineID</span></code> next.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>val convLines = conversations.join(lines, &quot;lineID&quot;).sort($&quot;conversationID&quot;, $&quot;intraConversationID&quot;)
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>convLines: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [lineID: string, conversationID: bigint ... 7 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">convLines</span><span class="o">.</span><span class="n">count</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res24: Long = 304713
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conversations</span><span class="o">.</span><span class="n">count</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res25: Long = 304713
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">convLines</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>Truncated to 30 rows</p>
<p>Let’s amalgamate the texts utered in the same conversations together.</p>
<p>By doing this we loose all the information in the order of utterance.</p>
<p>But this is fine as we are going to do LDA with just the <em>first-order
information of words uttered in each conversation</em> by anyone involved in
the dialogue.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.sql.functions.{collect_list, udf, lit, concat_ws}

val corpusDF = convLines.groupBy($&quot;conversationID&quot;,$&quot;movieID&quot;)
  .agg(concat_ws(&quot; :-()-: &quot;,collect_list($&quot;text&quot;)).alias(&quot;corpus&quot;))
  .join(moviesMetaData, &quot;movieID&quot;) // and join it to get movie meta data
  .select($&quot;conversationID&quot;.as(&quot;id&quot;),$&quot;corpus&quot;,$&quot;movieTitle&quot;,$&quot;movieYear&quot;)
  .cache()
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.sql.functions.{collect_list, udf, lit, concat_ws}
corpusDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: bigint, corpus: string ... 2 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">corpusDF</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res28: Long = 83097
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">corpusDF</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[28762,Your wife and children...you&#39;re happy with them? :-()-: Yes. :-()-: Good.,the godfather,1972]
[28815,Michael? :-()-: I&#39;m thinking about it. :-()-: Michael... :-()-: No, I would not like you better if you were Ingrid Bergman.,the godfather,1972]
[28842,What is it? :-()-: Is it all right if I go to the bathroom?,the godfather,1972]
[28766,Things went badly in Palermo? :-()-: The younger men have no respect. Things are changing; I don&#39;t know what will happen.  Michael, because of the wedding, people now know your name. :-()-: Is that why there are more men on the walls? :-()-: Even so, I don&#39;t think it is safe here anymore.  I&#39;ve made plans to move you to a villa near Siracuse. You must go right away. :-()-: What is it? :-()-: Bad news from America.  Your brother, Santino.  He has been killed.,the godfather,1972]
[28835,We can&#39;t wait.  No matter what Sollozzo say about a deal, he&#39;s figuring out how to kill Pop.  You have to get Sollozzo now. :-()-: The kid&#39;s right.,the godfather,1972]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">corpusDF</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>Truncated to 30 rows</p>
</div>
<div class="section" id="feature-extraction-and-transformation-apis">
<h2>Feature extraction and transformation APIs<a class="headerlink" href="#feature-extraction-and-transformation-apis" title="Permalink to this headline">¶</a></h2>
<p>We will use the convenient <a class="reference external" href="http://spark.apache.org/docs/latest/ml-features.html">Feature extraction and transformation
APIs</a>.</p>
</div>
<div class="section" id="step-3-text-tokenization">
<h2>Step 3. Text Tokenization<a class="headerlink" href="#step-3-text-tokenization" title="Permalink to this headline">¶</a></h2>
<p>We will use the RegexTokenizer to split each document into tokens. We
can setMinTokenLength() here to indicate a minimum token length, and
filter away all tokens that fall below the minimum. See:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/ml-features.html#tokenizer">http://spark.apache.org/docs/latest/ml-features.html#tokenizer</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RegexTokenizer</span>

<span class="o">//</span> <span class="n">Set</span> <span class="n">params</span> <span class="k">for</span> <span class="n">RegexTokenizer</span>
<span class="n">val</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">new</span> <span class="n">RegexTokenizer</span><span class="p">()</span>
<span class="o">.</span><span class="n">setPattern</span><span class="p">(</span><span class="s2">&quot;[</span><span class="se">\\</span><span class="s2">W_]+&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="k">break</span> <span class="n">by</span> <span class="n">white</span> <span class="n">space</span> <span class="n">character</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="o">.</span><span class="n">setMinTokenLength</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">//</span> <span class="n">Filter</span> <span class="n">away</span> <span class="n">tokens</span> <span class="k">with</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">4</span>
<span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;corpus&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="nb">input</span> <span class="n">column</span>
<span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">output</span> <span class="n">column</span>

<span class="o">//</span> <span class="n">Tokenize</span> <span class="n">document</span>
<span class="n">val</span> <span class="n">tokenized_df</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">corpusDF</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.ml.feature.RegexTokenizer
tokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_5380a11bc0d5
tokenized_df: org.apache.spark.sql.DataFrame = [id: bigint, corpus: string ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">tokenized_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">false</span><span class="p">,</span><span class="mf">0.001</span><span class="p">,</span><span class="mi">1234</span><span class="n">L</span><span class="p">))</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">tokenized_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">false</span><span class="p">,</span><span class="mf">0.001</span><span class="p">,</span><span class="mi">123</span><span class="n">L</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="step-4-remove-stopwords">
<h2>Step 4. Remove Stopwords<a class="headerlink" href="#step-4-remove-stopwords" title="Permalink to this headline">¶</a></h2>
<p>We can easily remove stopwords using the StopWordsRemover(). See:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/ml-features.html#stopwordsremover">http://spark.apache.org/docs/latest/ml-features.html#stopwordsremover</a>.</p></li>
</ul>
<p>If a list of stopwords is not provided, the StopWordsRemover() will use
<a class="reference external" href="http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words">this list of
stopwords</a>,
also shown below, by default.</p>
<p><code class="docutils literal notranslate"><span class="pre">a,about,above,across,after,afterwards,again,against,all,almost,alone,along,already,also,although,always,am,among,amongst,amoungst,amount,an,and,another,any,anyhow,anyone,anything,anyway,anywhere,</span> <span class="pre">are,around,as,at,back,be,became,because,become,becomes,becoming,been,before,beforehand,behind,being,below,beside,besides,between,beyond,bill,both,bottom,but,by,call,can,cannot,cant,co,computer,con,could,</span> <span class="pre">couldnt,cry,de,describe,detail,do,done,down,due,during,each,eg,eight,either,eleven,else,elsewhere,empty,enough,etc,even,ever,every,everyone,everything,everywhere,except,few,fifteen,fify,fill,find,fire,first,</span> <span class="pre">five,for,former,formerly,forty,found,four,from,front,full,further,get,give,go,had,has,hasnt,have,he,hence,her,here,hereafter,hereby,herein,hereupon,hers,herself,him,himself,his,how,however,hundred,i,ie,if,</span> <span class="pre">in,inc,indeed,interest,into,is,it,its,itself,keep,last,latter,latterly,least,less,ltd,made,many,may,me,meanwhile,might,mill,mine,more,moreover,most,mostly,move,much,must,my,myself,name,namely,neither,never,</span> <span class="pre">nevertheless,next,nine,no,nobody,none,noone,nor,not,nothing,now,nowhere,of,off,often,on,once,one,only,onto,or,other,others,otherwise,our,ours,ourselves,out,over,own,part,per,perhaps,please,put,rather,re,same,</span> <span class="pre">see,seem,seemed,seeming,seems,serious,several,she,should,show,side,since,sincere,six,sixty,so,some,somehow,someone,something,sometime,sometimes,somewhere,still,such,system,take,ten,than,that,the,their,them,</span> <span class="pre">themselves,then,thence,there,thereafter,thereby,therefore,therein,thereupon,these,they,thick,thin,third,this,those,though,three,through,throughout,thru,thus,to,together,too,top,toward,towards,twelve,twenty,two,</span> <span class="pre">un,under,until,up,upon,us,very,via,was,we,well,were,what,whatever,when,whence,whenever,where,whereafter,whereas,whereby,wherein,whereupon,wherever,whether,which,while,whither,who,whoever,whole,whom,whose,why,will,</span> <span class="pre">with,within,without,would,yet,you,your,yours,yourself,yourselves</span></code></p>
<p>You can use <code class="docutils literal notranslate"><span class="pre">getStopWords()</span></code> to see the list of stopwords that will be
used.</p>
<p>In this example, we will specify a list of stopwords for the
StopWordsRemover() to use. We do this so that we can add on to the list
later on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="s2">&quot;dbfs:/tmp/stopwords&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="n">check</span> <span class="k">if</span> <span class="n">the</span> <span class="n">file</span> <span class="n">already</span> <span class="n">exists</span> <span class="kn">from</span> <span class="nn">earlier</span> <span class="n">wget</span> <span class="ow">and</span> <span class="n">dbfs</span><span class="o">-</span><span class="n">load</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>If the file <code class="docutils literal notranslate"><span class="pre">dbfs:/tmp/stopwords</span></code> already exists then skip the next two
cells, otherwise download and load it into DBFS by uncommenting and
evaluating the next two cells.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">ir</span><span class="o">.</span><span class="n">dcs</span><span class="o">.</span><span class="n">gla</span><span class="o">.</span><span class="n">ac</span><span class="o">.</span><span class="n">uk</span><span class="o">/</span><span class="n">resources</span><span class="o">/</span><span class="n">linguistic_utils</span><span class="o">/</span><span class="n">stop_words</span> <span class="o">-</span><span class="n">O</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">stopwords</span> <span class="c1"># uncomment &#39;//&#39; at the beginning and repeat only if needed again</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>--2019-05-31 08:23:58--  http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words
Resolving ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)... 130.209.240.253
Connecting to ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)|130.209.240.253|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2237 (2.2K)
Saving to: ‘/tmp/stopwords’

     0K ..                                                    100%  320M=0s

2019-05-31 08:23:59 (320 MB/s) - ‘/tmp/stopwords’ saved [2237/2237]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cp</span> <span class="n">file</span><span class="p">:</span><span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">stopwords</span> <span class="n">dbfs</span><span class="p">:</span><span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">stopwords</span> 
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res41: Boolean = true
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">List</span> <span class="n">of</span> <span class="n">stopwords</span>
<span class="n">val</span> <span class="n">stopwords</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;/tmp/stopwords&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>stopwords: Array[String] = Array(a, about, above, across, after, afterwards, again, against, all, almost, alone, along, already, also, although, always, am, among, amongst, amoungst, amount, an, and, another, any, anyhow, anyone, anything, anyway, anywhere, are, around, as, at, back, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, below, beside, besides, between, beyond, bill, both, bottom, but, by, call, can, cannot, cant, co, computer, con, could, couldnt, cry, de, describe, detail, do, done, down, due, during, each, eg, eight, either, eleven, else, elsewhere, empty, enough, etc, even, ever, every, everyone, everything, everywhere, except, few, fifteen, fify, fill, find, fire, first, five, for, former, formerly, forty, found, four, from, front, full, further, get, give, go, had, has, hasnt, have, he, hence, her, here, hereafter, hereby, herein, hereupon, hers, herself, him, himself, his, how, however, hundred, i, ie, if, in, inc, indeed, interest, into, is, it, its, itself, keep, last, latter, latterly, least, less, ltd, made, many, may, me, meanwhile, might, mill, mine, more, moreover, most, mostly, move, much, must, my, myself, name, namely, neither, never, nevertheless, next, nine, no, nobody, none, noone, nor, not, nothing, now, nowhere, of, off, often, on, once, one, only, onto, or, other, others, otherwise, our, ours, ourselves, out, over, own, part, per, perhaps, please, put, rather, re, same, see, seem, seemed, seeming, seems, serious, several, she, should, show, side, since, sincere, six, sixty, so, some, somehow, someone, something, sometime, sometimes, somewhere, still, such, system, take, ten, than, that, the, their, them, themselves, then, thence, there, thereafter, thereby, therefore, therein, thereupon, these, they, thick, thin, third, this, those, though, three, through, throughout, thru, thus, to, together, too, top, toward, towards, twelve, twenty, two, un, under, until, up, upon, us, very, via, was, we, well, were, what, whatever, when, whence, whenever, where, whereafter, whereas, whereby, wherein, whereupon, wherever, whether, which, while, whither, who, whoever, whole, whom, whose, why, will, with, within, without, would, yet, you, your, yours, yourself, yourselves)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stopwords</span><span class="o">.</span><span class="n">length</span> <span class="o">//</span> <span class="n">find</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">stopwords</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">scala</span> <span class="n">Array</span><span class="p">[</span><span class="n">String</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res35: Int = 319
</pre></div>
</div>
</div></blockquote>
<p>Finally, we can just remove the stopwords using the <code class="docutils literal notranslate"><span class="pre">StopWordsRemover</span></code>
as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StopWordsRemover</span>

<span class="o">//</span> <span class="n">Set</span> <span class="n">params</span> <span class="k">for</span> <span class="n">StopWordsRemover</span>
<span class="n">val</span> <span class="n">remover</span> <span class="o">=</span> <span class="n">new</span> <span class="n">StopWordsRemover</span><span class="p">()</span>
<span class="o">.</span><span class="n">setStopWords</span><span class="p">(</span><span class="n">stopwords</span><span class="p">)</span> <span class="o">//</span> <span class="n">This</span> <span class="n">parameter</span> <span class="ow">is</span> <span class="n">optional</span>
<span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">new</span> <span class="n">DF</span> <span class="k">with</span> <span class="n">Stopwords</span> <span class="n">removed</span>
<span class="n">val</span> <span class="n">filtered_df</span> <span class="o">=</span> <span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">tokenized_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.ml.feature.StopWordsRemover
remover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_294e3228eba8
filtered_df: org.apache.spark.sql.DataFrame = [id: bigint, corpus: string ... 4 more fields]
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="step-5-vector-of-token-counts">
<h2>Step 5. Vector of Token Counts<a class="headerlink" href="#step-5-vector-of-token-counts" title="Permalink to this headline">¶</a></h2>
<p>LDA takes in a vector of token counts as input. We can use the
<code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> to easily convert our text documents into vectors of
token counts.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code> will return
<code class="docutils literal notranslate"><span class="pre">(VocabSize,</span> <span class="pre">Array(Indexed</span> <span class="pre">Tokens),</span> <span class="pre">Array(Token</span> <span class="pre">Frequency))</span></code>.</p>
<p>Two handy parameters to note:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">setMinDF</span></code>: Specifies the minimum number of different documents a
term must appear in to be included in the vocabulary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">setMinTF</span></code>: Specifies the minimum number of times a term has to
appear in a document to be included in the vocabulary.</p></li>
</ul>
<p>See:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/ml-features.html#countvectorizer">http://spark.apache.org/docs/latest/ml-features.html#countvectorizer</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.CountVectorizer</span>

<span class="o">//</span> <span class="n">Set</span> <span class="n">params</span> <span class="k">for</span> <span class="n">CountVectorizer</span>
<span class="n">val</span> <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">new</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">setVocabSize</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> 
<span class="o">.</span><span class="n">setMinDF</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">//</span> <span class="n">the</span> <span class="n">minimum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">different</span> <span class="n">documents</span> <span class="n">a</span> <span class="n">term</span> <span class="n">must</span> <span class="n">appear</span> <span class="ow">in</span> <span class="n">to</span> <span class="n">be</span> <span class="n">included</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">vocabulary</span><span class="o">.</span>
<span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.ml.feature.CountVectorizer
vectorizer: org.apache.spark.ml.feature.CountVectorizerModel = cntVec_48267a85f1b9
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Create</span> <span class="n">vector</span> <span class="n">of</span> <span class="n">token</span> <span class="n">counts</span>
<span class="n">val</span> <span class="n">countVectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>countVectors: org.apache.spark.sql.DataFrame = [id: bigint, features: vector]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">see</span> <span class="n">the</span> <span class="n">first</span> <span class="n">countVectors</span>
<span class="n">countVectors</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res38: Array[org.apache.spark.sql.Row] = Array([28762,(10000,[7,112,179,308],[1.0,1.0,1.0,1.0])])
</pre></div>
</div>
</div></blockquote>
<p>To use the LDA algorithm in the MLlib library, we have to convert the
DataFrame back into an RDD.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Convert</span> <span class="n">DF</span> <span class="n">to</span> <span class="n">RDD</span> <span class="o">-</span> <span class="n">ideally</span> <span class="n">we</span> <span class="n">should</span> <span class="n">use</span> <span class="n">ml</span> <span class="k">for</span> <span class="n">everything</span> <span class="n">an</span> <span class="ow">not</span> <span class="n">ml</span> <span class="ow">and</span> <span class="n">mllib</span> <span class="p">;</span> <span class="n">DAN</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="p">{</span><span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">RegexTokenizer</span><span class="p">,</span> <span class="n">StopWordsRemover</span><span class="p">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.</span><span class="p">{</span><span class="n">Vector</span> <span class="o">=&gt;</span> <span class="n">MLVector</span><span class="p">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.</span><span class="p">{</span><span class="n">LDA</span><span class="p">,</span> <span class="n">OnlineLDAOptimizer</span><span class="p">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.</span><span class="p">{</span><span class="n">Row</span><span class="p">,</span> <span class="n">SparkSession</span><span class="p">}</span>

<span class="n">val</span> <span class="n">lda_countVector</span> <span class="o">=</span> <span class="n">countVectors</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="p">:</span> <span class="n">Long</span><span class="p">,</span> <span class="n">countVector</span><span class="p">:</span> <span class="n">MLVector</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">fromML</span><span class="p">(</span><span class="n">countVector</span><span class="p">))</span> <span class="p">}</span><span class="o">.</span><span class="n">rdd</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.ml.feature.{CountVectorizer, RegexTokenizer, StopWordsRemover}
import org.apache.spark.ml.linalg.{Vector=&gt;MLVector}
import org.apache.spark.mllib.clustering.{LDA, OnlineLDAOptimizer}
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.sql.{Row, SparkSession}
lda_countVector: org.apache.spark.rdd.RDD[(Long, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[3912] at rdd at command-753740454082286:11
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="nb">format</span><span class="p">:</span> <span class="n">Array</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="p">(</span><span class="n">VocabSize</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="n">indexedTokens</span><span class="p">),</span> <span class="n">Array</span><span class="p">(</span><span class="n">Token</span> <span class="n">Frequency</span><span class="p">)))</span>
<span class="n">lda_countVector</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res42: Array[(Long, org.apache.spark.mllib.linalg.Vector)] = Array((28762,(10000,[7,112,179,308],[1.0,1.0,1.0,1.0])))
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="let-s-get-an-overview-of-lda-in-spark-s-mllib">
<h2>Let’s get an overview of LDA in Spark’s MLLIB<a class="headerlink" href="#let-s-get-an-overview-of-lda-in-spark-s-mllib" title="Permalink to this headline">¶</a></h2>
<p>See:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda">http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda</a>.</p></li>
</ul>
</div>
<div class="section" id="create-lda-model-with-online-variational-bayes">
<h2>Create LDA model with Online Variational Bayes<a class="headerlink" href="#create-lda-model-with-online-variational-bayes" title="Permalink to this headline">¶</a></h2>
<p>We will now set the parameters for LDA. We will use the
OnlineLDAOptimizer() here, which implements Online Variational Bayes.</p>
<p>Choosing the number of topics for your LDA model requires a bit of
domain knowledge. As we do not know the number of “topics”, we will set
numTopics to be 20.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">numTopics</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>numTopics: Int = 20
</pre></div>
</div>
</div></blockquote>
<p>We will set the parameters needed to build our LDA model. We can also
setMiniBatchFraction for the OnlineLDAOptimizer, which sets the fraction
of corpus sampled and used at each iteration. In this example, we will
set this to 0.8.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.</span><span class="p">{</span><span class="n">LDA</span><span class="p">,</span> <span class="n">OnlineLDAOptimizer</span><span class="p">}</span>

<span class="o">//</span> <span class="n">Set</span> <span class="n">LDA</span> <span class="n">params</span>
<span class="n">val</span> <span class="n">lda</span> <span class="o">=</span> <span class="n">new</span> <span class="n">LDA</span><span class="p">()</span>
<span class="o">.</span><span class="n">setOptimizer</span><span class="p">(</span><span class="n">new</span> <span class="n">OnlineLDAOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">setMiniBatchFraction</span><span class="p">(</span><span class="mf">0.8</span><span class="p">))</span>
<span class="o">.</span><span class="n">setK</span><span class="p">(</span><span class="n">numTopics</span><span class="p">)</span>
<span class="o">.</span><span class="n">setMaxIterations</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="o">.</span><span class="n">setDocConcentration</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">use</span> <span class="n">default</span> <span class="n">values</span>
<span class="o">.</span><span class="n">setTopicConcentration</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">use</span> <span class="n">default</span> <span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.mllib.clustering.{LDA, OnlineLDAOptimizer}
lda: org.apache.spark.mllib.clustering.LDA = org.apache.spark.mllib.clustering.LDA@3c173c8
</pre></div>
</div>
</div></blockquote>
<p>Create the LDA model with Online Variational Bayes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">ldaModel</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">lda_countVector</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ldaModel: org.apache.spark.mllib.clustering.LDAModel = org.apache.spark.mllib.clustering.LocalLDAModel@5bf00930
</pre></div>
</div>
</div></blockquote>
<p>Watch <strong>Online Learning for Latent Dirichlet Allocation</strong> in NIPS2010 by
Matt Hoffman (right click and open in new tab)</p>
<p><a class="reference external" href="http://videolectures.net/nips2010_hoffman_oll/thumb.jpg">![Matt Hoffman’s NIPS 2010 Talk Online
LDA]</a>](http://videolectures.net/nips2010<em>hoffman</em>oll/)</p>
<p>Also see the paper on <em>Online varioational Bayes</em> by Matt linked for
more details (from the above URL):
<a class="reference external" href="http://videolectures.net/site/normal_dl/tag=83534/nips2010_1291.pdf">http://videolectures.net/site/normal<em>dl/tag=83534/nips2010</em>1291.pdf</a></p>
<p>Note that using the OnlineLDAOptimizer returns us a
<a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.clustering.LocalLDAModel">LocalLDAModel</a>,
which stores the inferred topics of your corpus.</p>
</div>
<div class="section" id="review-topics">
<h2>Review Topics<a class="headerlink" href="#review-topics" title="Permalink to this headline">¶</a></h2>
<p>We can now review the results of our LDA model. We will print out all 20
topics with their corresponding term probabilities.</p>
<p>Note that you will get slightly different results every time you run an
LDA model since LDA includes some randomization.</p>
<p>Let us review results of LDA model with Online Variational Bayes, step
by step.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topicIndices</span> <span class="o">=</span> <span class="n">ldaModel</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="n">maxTermsPerTopic</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>topicIndices: Array[(Array[Int], Array[Double])] = Array((Array(1, 2, 4, 49, 0),Array(0.0014102155338741765, 0.0012758924372910556, 0.0011214448310395873, 9.238914780871355E-4, 9.047647243869576E-4)), (Array(1, 6, 2, 0, 4),Array(0.0014443699497685366, 0.0012377629724506722, 0.0011714257476524842, 0.0010861657304183027, 8.604460434628813E-4)), (Array(1, 2, 8, 0, 3),Array(0.0014926060533533697, 0.0013429026076916017, 0.0013067364965238173, 0.0011607492289313303, 0.0011400804862230437)), (Array(5, 6, 4, 1, 7),Array(0.006717314446949222, 0.006002662754297925, 0.004488111770001314, 0.004408679383982238, 0.0042465917238892655)), (Array(0, 19, 3, 8, 6),Array(0.0050059173813691085, 0.0029731088780905225, 0.0022359962463711185, 0.002193246256785973, 0.0019111384839030116)), (Array(3, 0, 10, 1, 15),Array(0.003714410612506209, 0.0017122806517390608, 0.0017073041827440282, 0.0015712232707115927, 0.0012303967042097022)), (Array(0, 1, 6, 10, 2),Array(0.00467483294478972, 0.0038641828467113268, 0.003328578440542597, 0.002867941043688811, 0.002532629878316373)), (Array(0, 2, 9, 1, 13),Array(0.00960017865043255, 0.009308573745541343, 0.005704969701604644, 0.004085042285865179, 0.004031048471919761)), (Array(0, 4, 5, 77, 16),Array(0.004550808496981245, 0.004122146617438838, 0.0019092043643137734, 0.0018255598181846045, 0.001761167250972209)), (Array(6, 2, 5, 1, 0),Array(0.0016782125889211463, 0.0012427279906039904, 0.0012197157251243875, 0.0010635502545983016, 9.50137528050953E-4)), (Array(2, 1, 3, 0, 6),Array(0.003126597598330109, 0.0027451035751362273, 0.00228759303132256, 0.0017239166326848171, 0.0017047784964894794)), (Array(2, 1, 27, 4, 3),Array(0.004734133576359814, 0.004201386287998202, 0.0036983083453854372, 0.0025414887712607768, 0.002091795015523375)), (Array(0, 5, 1, 12, 2),Array(0.0035340054254694784, 0.002387182752907053, 0.0019263993964325303, 0.001843992584617911, 0.0018065489773133325)), (Array(2, 1, 5, 14, 0),Array(0.0016017017354850733, 0.0014834097260266685, 0.0014300356385979168, 0.001294952229819751, 0.0012788947989035501)), (Array(7, 1, 10, 6, 2),Array(0.002043769246809558, 0.0013757478946969802, 0.0013208455540129331, 0.0012662647575091633, 0.0011549537488969965)), (Array(0, 1, 2, 3, 4),Array(0.022087503347588935, 0.01571524947937798, 0.012895996754133662, 0.01026452087962411, 0.009873743305368164)), (Array(0, 1, 3, 4, 9),Array(0.002204551343207476, 0.0016283414468010306, 0.0014214537687803855, 0.0012768751041210551, 0.0011525954268574248)), (Array(46, 1, 2, 16, 5),Array(0.0022031979750387655, 0.0020637622110226085, 0.0019281346187348387, 0.0015712770524161123, 0.0014183600893726285)), (Array(0, 2, 3, 5, 8),Array(0.0035729889283848504, 0.0024215014894025766, 0.0018740761967851508, 0.001838630576321126, 0.0016262171049684524)), (Array(3, 10, 30, 9, 4),Array(0.0018098267577494882, 0.0015864305565599366, 0.0015861983258874525, 0.001331260635860306, 0.0012793651558771885)))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">vocabList</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>vocabList: Array[String] = Array(know, just, like, want, think, right, going, good, yeah, tell, come, time, look, didn, mean, make, okay, really, little, sure, gonna, thing, people, said, maybe, need, sorry, love, talk, thought, doing, life, night, things, work, money, better, told, long, help, believe, years, shit, does, away, place, hell, doesn, great, home, feel, fuck, kind, remember, dead, course, wouldn, wait, kill, guess, understand, thank, girl, wrong, leave, listen, talking, real, stop, hear, nice, happened, fine, wanted, father, gotta, mind, fucking, house, wasn, getting, world, stay, mother, left, came, care, thanks, knew, room, trying, guys, went, looking, coming, heard, friend, haven, seen, best, tonight, live, used, matter, killed, pretty, business, idea, couldn, head, miss, says, wife, called, woman, morning, tomorrow, start, stuff, saying, play, hello, baby, hard, probably, minute, days, took, somebody, today, school, meet, gone, crazy, wants, damn, forget, cause, problem, deal, case, friends, point, hope, jesus, afraid, looks, knows, year, worry, exactly, aren, half, thinking, shut, hold, wanna, face, minutes, bring, read, word, doctor, everybody, makes, supposed, story, turn, true, watch, thousand, family, brother, kids, week, happen, fuckin, working, open, happy, lost, john, hurt, town, ready, alright, late, actually, married, gave, beautiful, soon, jack, times, sleep, door, having, hand, drink, easy, gets, chance, young, trouble, different, anybody, shot, rest, hate, death, second, later, asked, phone, wish, check, quite, change, police, walk, couple, question, close, taking, heart, hours, making, comes, anymore, truth, trust, dollars, important, captain, telling, funny, person, honey, goes, eyes, inside, reason, stand, break, means, number, tried, high, white, water, suppose, body, sick, game, excuse, party, women, country, waiting, christ, answer, office, send, pick, alive, sort, blood, black, daddy, line, husband, goddamn, book, fifty, thirty, fact, million, hands, died, power, stupid, started, shouldn, months, city, boys, dinner, sense, running, hour, shoot, drive, fight, speak, george, ship, living, figure, dear, street, ahead, lady, seven, free, feeling, scared, frank, able, children, outside, moment, safe, news, president, brought, write, happens, sent, bullshit, lose, light, glad, child, girls, sounds, sister, lives, promise, till, sound, weren, save, poor, cool, asking, shall, plan, bitch, king, daughter, weeks, beat, york, cold, worth, taken, harry, needs, piece, movie, fast, possible, small, goin, straight, human, hair, tired, food, company, lucky, pull, wonderful, touch, state, looked, thinks, picture, leaving, words, control, clear, known, special, buddy, luck, order, follow, expect, mary, catch, mouth, worked, mister, learn, playing, perfect, dream, calling, questions, hospital, takes, ride, coffee, miles, parents, works, secret, explain, hotel, worse, kidding, past, outta, general, unless, felt, drop, throw, interested, hang, certainly, absolutely, earth, loved, wonder, dark, accident, seeing, simple, turned, doin, clock, date, sweet, meeting, clean, sign, feet, handle, army, music, giving, report, cops, fucked, charlie, information, smart, yesterday, fall, fault, class, bank, month, blow, major, caught, swear, paul, road, talked, choice, boss, plane, david, paid, wear, american, worried, clothes, paper, goodbye, lord, ones, strange, terrible, mistake, given, hurry, blue, finish, murder, kept, apartment, sell, middle, nothin, hasn, careful, meant, walter, moving, changed, imagine, fair, difference, quiet, happening, near, quit, personal, marry, future, figured, rose, agent, kinda, michael, building, mama, early, private, trip, watching, busy, record, certain, jimmy, broke, longer, sake, store, stick, finally, boat, born, sitting, evening, bucks, chief, history, ought, lying, kiss, honor, lunch, darling, favor, fool, uncle, respect, rich, liked, killing, land, peter, tough, interesting, brain, problems, nick, welcome, completely, dick, honest, wake, radio, cash, dude, dance, james, bout, floor, weird, court, calls, jail, window, involved, drunk, johnny, officer, needed, asshole, books, spend, situation, relax, pain, service, dangerous, grand, security, letter, stopped, realize, table, offer, bastard, message, instead, killer, jake, nervous, deep, pass, somethin, evil, english, bought, short, ring, step, picked, likes, voice, eddie, machine, lived, upset, forgot, carry, afternoon, fear, quick, finished, count, forgive, wrote, named, decided, totally, space, team, doubt, pleasure, lawyer, suit, station, gotten, bother, prove, return, pictures, slow, bunch, strong, wearing, driving, list, join, christmas, tape, attack, church, appreciate, force, hungry, standing, college, dying, present, charge, prison, missing, truck, public, board, calm, staying, gold, ball, hardly, hadn, lead, missed, island, government, horse, cover, reach, french, joke, star, fish, mike, moved, america, surprise, soul, seconds, club, self, movies, putting, dress, cost, listening, lots, price, saved, smell, mark, peace, gives, crime, dreams, entire, single, usually, department, beer, holy, west, wall, stuck, nose, protect, ways, teach, awful, forever, type, grow, train, detective, billy, rock, planet, walking, beginning, dumb, papers, folks, park, attention, hide, card, birthday, reading, test, share, master, lieutenant, starting, field, partner, twice, enjoy, dollar, blame, film, mess, bomb, round, girlfriend, south, loves, plenty, using, gentlemen, especially, records, evidence, experience, silly, admit, normal, fired, talkin, lock, louis, fighting, mission, notice, memory, promised, crap, wedding, orders, ground, guns, glass, marriage, idiot, heaven, impossible, knock, green, wondering, spent, animal, hole, neck, drugs, press, nuts, names, broken, position, asleep, jerry, visit, boyfriend, acting, plans, feels, tells, paris, smoke, wind, sheriff, cross, holding, gimme, mention, walked, judge, code, double, brothers, writing, pardon, keeps, fellow, fell, closed, angry, lovely, cute, surprised, percent, charles, correct, agree, bathroom, address, andy, ridiculous, summer, tommy, rules, note, account, group, sleeping, learned, sing, pulled, colonel, proud, laugh, river, area, upstairs, jump, built, difficult, breakfast, bobby, bridge, dirty, betty, amazing, locked, north, definitely, alex, feelings, plus, worst, accept, kick, file, wild, seriously, grace, stories, steal, gettin, nature, advice, relationship, contact, waste, places, spot, beach, stole, apart, favorite, knowing, level, song, faith, risk, loose, patient, foot, eating, played, action, witness, washington, turns, build, obviously, begin, split, games, command, crew, decide, nurse, keeping, tight, bird, form, runs, copy, arrest, complete, scene, consider, jeffrey, insane, taste, teeth, shoes, monster, devil, henry, career, sooner, innocent, hall, showed, gift, weekend, heavy, study, greatest, comin, danger, keys, raise, destroy, track, carl, california, concerned, bruce, program, blind, suddenly, hanging, apologize, seventy, chicken, medical, forward, drinking, sweetheart, willing, guard, legs, admiral, shop, professor, suspect, tree, camp, data, ticket, goodnight, possibly, dunno, burn, paying, television, trick, murdered, losing, senator, credit, extra, dropped, sold, warm, meaning, stone, starts, hiding, lately, cheap, marty, taught, science, lookin, simply, majesty, harold, corner, jeff, queen, following, duty, training, seat, heads, cars, discuss, bear, noticed, enemy, helped, screw, richard, flight)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">topicIndices</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">termWeights</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">terms</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vocabList</span><span class="p">(</span><span class="n">_</span><span class="p">))</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">termWeights</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>topics: Array[Array[(String, Double)]] = Array(Array((just,0.0014102155338741765), (like,0.0012758924372910556), (think,0.0011214448310395873), (home,9.238914780871355E-4), (know,9.047647243869576E-4)), Array((just,0.0014443699497685366), (going,0.0012377629724506722), (like,0.0011714257476524842), (know,0.0010861657304183027), (think,8.604460434628813E-4)), Array((just,0.0014926060533533697), (like,0.0013429026076916017), (yeah,0.0013067364965238173), (know,0.0011607492289313303), (want,0.0011400804862230437)), Array((right,0.006717314446949222), (going,0.006002662754297925), (think,0.004488111770001314), (just,0.004408679383982238), (good,0.0042465917238892655)), Array((know,0.0050059173813691085), (sure,0.0029731088780905225), (want,0.0022359962463711185), (yeah,0.002193246256785973), (going,0.0019111384839030116)), Array((want,0.003714410612506209), (know,0.0017122806517390608), (come,0.0017073041827440282), (just,0.0015712232707115927), (make,0.0012303967042097022)), Array((know,0.00467483294478972), (just,0.0038641828467113268), (going,0.003328578440542597), (come,0.002867941043688811), (like,0.002532629878316373)), Array((know,0.00960017865043255), (like,0.009308573745541343), (tell,0.005704969701604644), (just,0.004085042285865179), (didn,0.004031048471919761)), Array((know,0.004550808496981245), (think,0.004122146617438838), (right,0.0019092043643137734), (fucking,0.0018255598181846045), (okay,0.001761167250972209)), Array((going,0.0016782125889211463), (like,0.0012427279906039904), (right,0.0012197157251243875), (just,0.0010635502545983016), (know,9.50137528050953E-4)), Array((like,0.003126597598330109), (just,0.0027451035751362273), (want,0.00228759303132256), (know,0.0017239166326848171), (going,0.0017047784964894794)), Array((like,0.004734133576359814), (just,0.004201386287998202), (love,0.0036983083453854372), (think,0.0025414887712607768), (want,0.002091795015523375)), Array((know,0.0035340054254694784), (right,0.002387182752907053), (just,0.0019263993964325303), (look,0.001843992584617911), (like,0.0018065489773133325)), Array((like,0.0016017017354850733), (just,0.0014834097260266685), (right,0.0014300356385979168), (mean,0.001294952229819751), (know,0.0012788947989035501)), Array((good,0.002043769246809558), (just,0.0013757478946969802), (come,0.0013208455540129331), (going,0.0012662647575091633), (like,0.0011549537488969965)), Array((know,0.022087503347588935), (just,0.01571524947937798), (like,0.012895996754133662), (want,0.01026452087962411), (think,0.009873743305368164)), Array((know,0.002204551343207476), (just,0.0016283414468010306), (want,0.0014214537687803855), (think,0.0012768751041210551), (tell,0.0011525954268574248)), Array((hell,0.0022031979750387655), (just,0.0020637622110226085), (like,0.0019281346187348387), (okay,0.0015712770524161123), (right,0.0014183600893726285)), Array((know,0.0035729889283848504), (like,0.0024215014894025766), (want,0.0018740761967851508), (right,0.001838630576321126), (yeah,0.0016262171049684524)), Array((want,0.0018098267577494882), (come,0.0015864305565599366), (doing,0.0015861983258874525), (tell,0.001331260635860306), (think,0.0012793651558771885)))
</pre></div>
</div>
</div></blockquote>
<p>Feel free to take things apart to understand!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">topicIndices</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res43: (Array[Int], Array[Double]) = (Array(1, 2, 4, 49, 0),Array(0.0014102155338741765, 0.0012758924372910556, 0.0011214448310395873, 9.238914780871355E-4, 9.047647243869576E-4))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">topicIndices</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res44: Array[Int] = Array(1, 2, 4, 49, 0)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">topicIndices</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res45: Int = 1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vocabList</span><span class="p">(</span><span class="n">topicIndices</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res46: String = just
</pre></div>
</div>
</div></blockquote>
<p>Review Results of LDA model with Online Variational Bayes - Doing all
four steps earlier at once.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topicIndices</span> <span class="o">=</span> <span class="n">ldaModel</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="n">maxTermsPerTopic</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">val</span> <span class="n">vocabList</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">val</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">topicIndices</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">termWeights</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">terms</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vocabList</span><span class="p">(</span><span class="n">_</span><span class="p">))</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">termWeights</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;$numTopics topics:&quot;</span><span class="p">)</span>
<span class="n">topics</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">foreach</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;TOPIC $i&quot;</span><span class="p">)</span>
  <span class="n">topic</span><span class="o">.</span><span class="n">foreach</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;$term</span><span class="se">\t</span><span class="s2">$weight&quot;</span><span class="p">)</span> <span class="p">}</span>
  <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;==========&quot;</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>20 topics:
TOPIC 0
just	0.0014102155338741765
like	0.0012758924372910556
think	0.0011214448310395873
home	9.238914780871355E-4
know	9.047647243869576E-4
==========
TOPIC 1
just	0.0014443699497685366
going	0.0012377629724506722
like	0.0011714257476524842
know	0.0010861657304183027
think	8.604460434628813E-4
==========
TOPIC 2
just	0.0014926060533533697
like	0.0013429026076916017
yeah	0.0013067364965238173
know	0.0011607492289313303
want	0.0011400804862230437
==========
TOPIC 3
right	0.006717314446949222
going	0.006002662754297925
think	0.004488111770001314
just	0.004408679383982238
good	0.0042465917238892655
==========
TOPIC 4
know	0.0050059173813691085
sure	0.0029731088780905225
want	0.0022359962463711185
yeah	0.002193246256785973
going	0.0019111384839030116
==========
TOPIC 5
want	0.003714410612506209
know	0.0017122806517390608
come	0.0017073041827440282
just	0.0015712232707115927
make	0.0012303967042097022
==========
TOPIC 6
know	0.00467483294478972
just	0.0038641828467113268
going	0.003328578440542597
come	0.002867941043688811
like	0.002532629878316373
==========
TOPIC 7
know	0.00960017865043255
like	0.009308573745541343
tell	0.005704969701604644
just	0.004085042285865179
didn	0.004031048471919761
==========
TOPIC 8
know	0.004550808496981245
think	0.004122146617438838
right	0.0019092043643137734
fucking	0.0018255598181846045
okay	0.001761167250972209
==========
TOPIC 9
going	0.0016782125889211463
like	0.0012427279906039904
right	0.0012197157251243875
just	0.0010635502545983016
know	9.50137528050953E-4
==========
TOPIC 10
like	0.003126597598330109
just	0.0027451035751362273
want	0.00228759303132256
know	0.0017239166326848171
going	0.0017047784964894794
==========
TOPIC 11
like	0.004734133576359814
just	0.004201386287998202
love	0.0036983083453854372
think	0.0025414887712607768
want	0.002091795015523375
==========
TOPIC 12
know	0.0035340054254694784
right	0.002387182752907053
just	0.0019263993964325303
look	0.001843992584617911
like	0.0018065489773133325
==========
TOPIC 13
like	0.0016017017354850733
just	0.0014834097260266685
right	0.0014300356385979168
mean	0.001294952229819751
know	0.0012788947989035501
==========
TOPIC 14
good	0.002043769246809558
just	0.0013757478946969802
come	0.0013208455540129331
going	0.0012662647575091633
like	0.0011549537488969965
==========
TOPIC 15
know	0.022087503347588935
just	0.01571524947937798
like	0.012895996754133662
want	0.01026452087962411
think	0.009873743305368164
==========
TOPIC 16
know	0.002204551343207476
just	0.0016283414468010306
want	0.0014214537687803855
think	0.0012768751041210551
tell	0.0011525954268574248
==========
TOPIC 17
hell	0.0022031979750387655
just	0.0020637622110226085
like	0.0019281346187348387
okay	0.0015712770524161123
right	0.0014183600893726285
==========
TOPIC 18
know	0.0035729889283848504
like	0.0024215014894025766
want	0.0018740761967851508
right	0.001838630576321126
yeah	0.0016262171049684524
==========
TOPIC 19
want	0.0018098267577494882
come	0.0015864305565599366
doing	0.0015861983258874525
tell	0.001331260635860306
think	0.0012793651558771885
==========
topicIndices: Array[(Array[Int], Array[Double])] = Array((Array(1, 2, 4, 49, 0),Array(0.0014102155338741765, 0.0012758924372910556, 0.0011214448310395873, 9.238914780871355E-4, 9.047647243869576E-4)), (Array(1, 6, 2, 0, 4),Array(0.0014443699497685366, 0.0012377629724506722, 0.0011714257476524842, 0.0010861657304183027, 8.604460434628813E-4)), (Array(1, 2, 8, 0, 3),Array(0.0014926060533533697, 0.0013429026076916017, 0.0013067364965238173, 0.0011607492289313303, 0.0011400804862230437)), (Array(5, 6, 4, 1, 7),Array(0.006717314446949222, 0.006002662754297925, 0.004488111770001314, 0.004408679383982238, 0.0042465917238892655)), (Array(0, 19, 3, 8, 6),Array(0.0050059173813691085, 0.0029731088780905225, 0.0022359962463711185, 0.002193246256785973, 0.0019111384839030116)), (Array(3, 0, 10, 1, 15),Array(0.003714410612506209, 0.0017122806517390608, 0.0017073041827440282, 0.0015712232707115927, 0.0012303967042097022)), (Array(0, 1, 6, 10, 2),Array(0.00467483294478972, 0.0038641828467113268, 0.003328578440542597, 0.002867941043688811, 0.002532629878316373)), (Array(0, 2, 9, 1, 13),Array(0.00960017865043255, 0.009308573745541343, 0.005704969701604644, 0.004085042285865179, 0.004031048471919761)), (Array(0, 4, 5, 77, 16),Array(0.004550808496981245, 0.004122146617438838, 0.0019092043643137734, 0.0018255598181846045, 0.001761167250972209)), (Array(6, 2, 5, 1, 0),Array(0.0016782125889211463, 0.0012427279906039904, 0.0012197157251243875, 0.0010635502545983016, 9.50137528050953E-4)), (Array(2, 1, 3, 0, 6),Array(0.003126597598330109, 0.0027451035751362273, 0.00228759303132256, 0.0017239166326848171, 0.0017047784964894794)), (Array(2, 1, 27, 4, 3),Array(0.004734133576359814, 0.004201386287998202, 0.0036983083453854372, 0.0025414887712607768, 0.002091795015523375)), (Array(0, 5, 1, 12, 2),Array(0.0035340054254694784, 0.002387182752907053, 0.0019263993964325303, 0.001843992584617911, 0.0018065489773133325)), (Array(2, 1, 5, 14, 0),Array(0.0016017017354850733, 0.0014834097260266685, 0.0014300356385979168, 0.001294952229819751, 0.0012788947989035501)), (Array(7, 1, 10, 6, 2),Array(0.002043769246809558, 0.0013757478946969802, 0.0013208455540129331, 0.0012662647575091633, 0.0011549537488969965)), (Array(0, 1, 2, 3, 4),Array(0.022087503347588935, 0.01571524947937798, 0.012895996754133662, 0.01026452087962411, 0.009873743305368164)), (Array(0, 1, 3, 4, 9),Array(0.002204551343207476, 0.0016283414468010306, 0.0014214537687803855, 0.0012768751041210551, 0.0011525954268574248)), (Array(46, 1, 2, 16, 5),Array(0.0022031979750387655, 0.0020637622110226085, 0.0019281346187348387, 0.0015712770524161123, 0.0014183600893726285)), (Array(0, 2, 3, 5, 8),Array(0.0035729889283848504, 0.0024215014894025766, 0.0018740761967851508, 0.001838630576321126, 0.0016262171049684524)), (Array(3, 10, 30, 9, 4),Array(0.0018098267577494882, 0.0015864305565599366, 0.0015861983258874525, 0.001331260635860306, 0.0012793651558771885)))
vocabList: Array[String] = Array(know, just, like, want, think, right, going, good, yeah, tell, come, time, look, didn, mean, make, okay, really, little, sure, gonna, thing, people, said, maybe, need, sorry, love, talk, thought, doing, life, night, things, work, money, better, told, long, help, believe, years, shit, does, away, place, hell, doesn, great, home, feel, fuck, kind, remember, dead, course, wouldn, wait, kill, guess, understand, thank, girl, wrong, leave, listen, talking, real, stop, hear, nice, happened, fine, wanted, father, gotta, mind, fucking, house, wasn, getting, world, stay, mother, left, came, care, thanks, knew, room, trying, guys, went, looking, coming, heard, friend, haven, seen, best, tonight, live, used, matter, killed, pretty, business, idea, couldn, head, miss, says, wife, called, woman, morning, tomorrow, start, stuff, saying, play, hello, baby, hard, probably, minute, days, took, somebody, today, school, meet, gone, crazy, wants, damn, forget, cause, problem, deal, case, friends, point, hope, jesus, afraid, looks, knows, year, worry, exactly, aren, half, thinking, shut, hold, wanna, face, minutes, bring, read, word, doctor, everybody, makes, supposed, story, turn, true, watch, thousand, family, brother, kids, week, happen, fuckin, working, open, happy, lost, john, hurt, town, ready, alright, late, actually, married, gave, beautiful, soon, jack, times, sleep, door, having, hand, drink, easy, gets, chance, young, trouble, different, anybody, shot, rest, hate, death, second, later, asked, phone, wish, check, quite, change, police, walk, couple, question, close, taking, heart, hours, making, comes, anymore, truth, trust, dollars, important, captain, telling, funny, person, honey, goes, eyes, inside, reason, stand, break, means, number, tried, high, white, water, suppose, body, sick, game, excuse, party, women, country, waiting, christ, answer, office, send, pick, alive, sort, blood, black, daddy, line, husband, goddamn, book, fifty, thirty, fact, million, hands, died, power, stupid, started, shouldn, months, city, boys, dinner, sense, running, hour, shoot, drive, fight, speak, george, ship, living, figure, dear, street, ahead, lady, seven, free, feeling, scared, frank, able, children, outside, moment, safe, news, president, brought, write, happens, sent, bullshit, lose, light, glad, child, girls, sounds, sister, lives, promise, till, sound, weren, save, poor, cool, asking, shall, plan, bitch, king, daughter, weeks, beat, york, cold, worth, taken, harry, needs, piece, movie, fast, possible, small, goin, straight, human, hair, tired, food, company, lucky, pull, wonderful, touch, state, looked, thinks, picture, leaving, words, control, clear, known, special, buddy, luck, order, follow, expect, mary, catch, mouth, worked, mister, learn, playing, perfect, dream, calling, questions, hospital, takes, ride, coffee, miles, parents, works, secret, explain, hotel, worse, kidding, past, outta, general, unless, felt, drop, throw, interested, hang, certainly, absolutely, earth, loved, wonder, dark, accident, seeing, simple, turned, doin, clock, date, sweet, meeting, clean, sign, feet, handle, army, music, giving, report, cops, fucked, charlie, information, smart, yesterday, fall, fault, class, bank, month, blow, major, caught, swear, paul, road, talked, choice, boss, plane, david, paid, wear, american, worried, clothes, paper, goodbye, lord, ones, strange, terrible, mistake, given, hurry, blue, finish, murder, kept, apartment, sell, middle, nothin, hasn, careful, meant, walter, moving, changed, imagine, fair, difference, quiet, happening, near, quit, personal, marry, future, figured, rose, agent, kinda, michael, building, mama, early, private, trip, watching, busy, record, certain, jimmy, broke, longer, sake, store, stick, finally, boat, born, sitting, evening, bucks, chief, history, ought, lying, kiss, honor, lunch, darling, favor, fool, uncle, respect, rich, liked, killing, land, peter, tough, interesting, brain, problems, nick, welcome, completely, dick, honest, wake, radio, cash, dude, dance, james, bout, floor, weird, court, calls, jail, window, involved, drunk, johnny, officer, needed, asshole, books, spend, situation, relax, pain, service, dangerous, grand, security, letter, stopped, realize, table, offer, bastard, message, instead, killer, jake, nervous, deep, pass, somethin, evil, english, bought, short, ring, step, picked, likes, voice, eddie, machine, lived, upset, forgot, carry, afternoon, fear, quick, finished, count, forgive, wrote, named, decided, totally, space, team, doubt, pleasure, lawyer, suit, station, gotten, bother, prove, return, pictures, slow, bunch, strong, wearing, driving, list, join, christmas, tape, attack, church, appreciate, force, hungry, standing, college, dying, present, charge, prison, missing, truck, public, board, calm, staying, gold, ball, hardly, hadn, lead, missed, island, government, horse, cover, reach, french, joke, star, fish, mike, moved, america, surprise, soul, seconds, club, self, movies, putting, dress, cost, listening, lots, price, saved, smell, mark, peace, gives, crime, dreams, entire, single, usually, department, beer, holy, west, wall, stuck, nose, protect, ways, teach, awful, forever, type, grow, train, detective, billy, rock, planet, walking, beginning, dumb, papers, folks, park, attention, hide, card, birthday, reading, test, share, master, lieutenant, starting, field, partner, twice, enjoy, dollar, blame, film, mess, bomb, round, girlfriend, south, loves, plenty, using, gentlemen, especially, records, evidence, experience, silly, admit, normal, fired, talkin, lock, louis, fighting, mission, notice, memory, promised, crap, wedding, orders, ground, guns, glass, marriage, idiot, heaven, impossible, knock, green, wondering, spent, animal, hole, neck, drugs, press, nuts, names, broken, position, asleep, jerry, visit, boyfriend, acting, plans, feels, tells, paris, smoke, wind, sheriff, cross, holding, gimme, mention, walked, judge, code, double, brothers, writing, pardon, keeps, fellow, fell, closed, angry, lovely, cute, surprised, percent, charles, correct, agree, bathroom, address, andy, ridiculous, summer, tommy, rules, note, account, group, sleeping, learned, sing, pulled, colonel, proud, laugh, river, area, upstairs, jump, built, difficult, breakfast, bobby, bridge, dirty, betty, amazing, locked, north, definitely, alex, feelings, plus, worst, accept, kick, file, wild, seriously, grace, stories, steal, gettin, nature, advice, relationship, contact, waste, places, spot, beach, stole, apart, favorite, knowing, level, song, faith, risk, loose, patient, foot, eating, played, action, witness, washington, turns, build, obviously, begin, split, games, command, crew, decide, nurse, keeping, tight, bird, form, runs, copy, arrest, complete, scene, consider, jeffrey, insane, taste, teeth, shoes, monster, devil, henry, career, sooner, innocent, hall, showed, gift, weekend, heavy, study, greatest, comin, danger, keys, raise, destroy, track, carl, california, concerned, bruce, program, blind, suddenly, hanging, apologize, seventy, chicken, medical, forward, drinking, sweetheart, willing, guard, legs, admiral, shop, professor, suspect, tree, camp, data, ticket, goodnight, possibly, dunno, burn, paying, television, trick, murdered, losing, senator, credit, extra, dropped, sold, warm, meaning, stone, starts, hiding, lately, cheap, marty, taught, science, lookin, simply, majesty, harold, corner, jeff, queen, following, duty, training, seat, heads, cars, discuss, bear, noticed, enemy, helped, screw, richard, flight)
topics: Array[Array[(String, Double)]] = Array(Array((just,0.0014102155338741765), (like,0.0012758924372910556), (think,0.0011214448310395873), (home,9.238914780871355E-4), (know,9.047647243869576E-4)), Array((just,0.0014443699497685366), (going,0.0012377629724506722), (like,0.0011714257476524842), (know,0.0010861657304183027), (think,8.604460434628813E-4)), Array((just,0.0014926060533533697), (like,0.0013429026076916017), (yeah,0.0013067364965238173), (know,0.0011607492289313303), (want,0.0011400804862230437)), Array((right,0.006717314446949222), (going,0.006002662754297925), (think,0.004488111770001314), (just,0.004408679383982238), (good,0.0042465917238892655)), Array((know,0.0050059173813691085), (sure,0.0029731088780905225), (want,0.0022359962463711185), (yeah,0.002193246256785973), (going,0.0019111384839030116)), Array((want,0.003714410612506209), (know,0.0017122806517390608), (come,0.0017073041827440282), (just,0.0015712232707115927), (make,0.0012303967042097022)), Array((know,0.00467483294478972), (just,0.0038641828467113268), (going,0.003328578440542597), (come,0.002867941043688811), (like,0.002532629878316373)), Array((know,0.00960017865043255), (like,0.009308573745541343), (tell,0.005704969701604644), (just,0.004085042285865179), (didn,0.004031048471919761)), Array((know,0.004550808496981245), (think,0.004122146617438838), (right,0.0019092043643137734), (fucking,0.0018255598181846045), (okay,0.001761167250972209)), Array((going,0.0016782125889211463), (like,0.0012427279906039904), (right,0.0012197157251243875), (just,0.0010635502545983016), (know,9.50137528050953E-4)), Array((like,0.003126597598330109), (just,0.0027451035751362273), (want,0.00228759303132256), (know,0.0017239166326848171), (going,0.0017047784964894794)), Array((like,0.004734133576359814), (just,0.004201386287998202), (love,0.0036983083453854372), (think,0.0025414887712607768), (want,0.002091795015523375)), Array((know,0.0035340054254694784), (right,0.002387182752907053), (just,0.0019263993964325303), (look,0.001843992584617911), (like,0.0018065489773133325)), Array((like,0.0016017017354850733), (just,0.0014834097260266685), (right,0.0014300356385979168), (mean,0.001294952229819751), (know,0.0012788947989035501)), Array((good,0.002043769246809558), (just,0.0013757478946969802), (come,0.0013208455540129331), (going,0.0012662647575091633), (like,0.0011549537488969965)), Array((know,0.022087503347588935), (just,0.01571524947937798), (like,0.012895996754133662), (want,0.01026452087962411), (think,0.009873743305368164)), Array((know,0.002204551343207476), (just,0.0016283414468010306), (want,0.0014214537687803855), (think,0.0012768751041210551), (tell,0.0011525954268574248)), Array((hell,0.0022031979750387655), (just,0.0020637622110226085), (like,0.0019281346187348387), (okay,0.0015712770524161123), (right,0.0014183600893726285)), Array((know,0.0035729889283848504), (like,0.0024215014894025766), (want,0.0018740761967851508), (right,0.001838630576321126), (yeah,0.0016262171049684524)), Array((want,0.0018098267577494882), (come,0.0015864305565599366), (doing,0.0015861983258874525), (tell,0.001331260635860306), (think,0.0012793651558771885)))
</pre></div>
</div>
</div></blockquote>
<p>Going through the results, you may notice that some of the topic words
returned are actually stopwords that are specific to our dataset (for
eg: “writes”, “article”…). Let’s try improving our model.</p>
</div>
<div class="section" id="step-8-model-tuning-refilter-stopwords">
<h2>Step 8. Model Tuning - Refilter Stopwords<a class="headerlink" href="#step-8-model-tuning-refilter-stopwords" title="Permalink to this headline">¶</a></h2>
<p>We will try to improve the results of our model by identifying some
stopwords that are specific to our dataset. We will filter these
stopwords out and rerun our LDA model to see if we get better results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>val add_stopwords = Array(&quot;whatever&quot;) // add  more stop-words like the name of your company!
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>add_stopwords: Array[String] = Array(whatever)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Combine</span> <span class="n">newly</span> <span class="n">identified</span> <span class="n">stopwords</span> <span class="n">to</span> <span class="n">our</span> <span class="n">exising</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">stopwords</span>
<span class="n">val</span> <span class="n">new_stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">add_stopwords</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>new_stopwords: Array[String] = Array(a, about, above, across, after, afterwards, again, against, all, almost, alone, along, already, also, although, always, am, among, amongst, amoungst, amount, an, and, another, any, anyhow, anyone, anything, anyway, anywhere, are, around, as, at, back, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, below, beside, besides, between, beyond, bill, both, bottom, but, by, call, can, cannot, cant, co, computer, con, could, couldnt, cry, de, describe, detail, do, done, down, due, during, each, eg, eight, either, eleven, else, elsewhere, empty, enough, etc, even, ever, every, everyone, everything, everywhere, except, few, fifteen, fify, fill, find, fire, first, five, for, former, formerly, forty, found, four, from, front, full, further, get, give, go, had, has, hasnt, have, he, hence, her, here, hereafter, hereby, herein, hereupon, hers, herself, him, himself, his, how, however, hundred, i, ie, if, in, inc, indeed, interest, into, is, it, its, itself, keep, last, latter, latterly, least, less, ltd, made, many, may, me, meanwhile, might, mill, mine, more, moreover, most, mostly, move, much, must, my, myself, name, namely, neither, never, nevertheless, next, nine, no, nobody, none, noone, nor, not, nothing, now, nowhere, of, off, often, on, once, one, only, onto, or, other, others, otherwise, our, ours, ourselves, out, over, own, part, per, perhaps, please, put, rather, re, same, see, seem, seemed, seeming, seems, serious, several, she, should, show, side, since, sincere, six, sixty, so, some, somehow, someone, something, sometime, sometimes, somewhere, still, such, system, take, ten, than, that, the, their, them, themselves, then, thence, there, thereafter, thereby, therefore, therein, thereupon, these, they, thick, thin, third, this, those, though, three, through, throughout, thru, thus, to, together, too, top, toward, towards, twelve, twenty, two, un, under, until, up, upon, us, very, via, was, we, well, were, what, whatever, when, whence, whenever, where, whereafter, whereas, whereby, wherein, whereupon, wherever, whether, which, while, whither, who, whoever, whole, whom, whose, why, will, with, within, without, would, yet, you, your, yours, yourself, yourselves, whatever)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StopWordsRemover</span>

<span class="o">//</span> <span class="n">Set</span> <span class="n">Params</span> <span class="k">for</span> <span class="n">StopWordsRemover</span> <span class="k">with</span> <span class="n">new_stopwords</span>
<span class="n">val</span> <span class="n">remover</span> <span class="o">=</span> <span class="n">new</span> <span class="n">StopWordsRemover</span><span class="p">()</span>
<span class="o">.</span><span class="n">setStopWords</span><span class="p">(</span><span class="n">new_stopwords</span><span class="p">)</span>
<span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">new</span> <span class="n">df</span> <span class="k">with</span> <span class="n">new</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">stopwords</span> <span class="n">removed</span>
<span class="n">val</span> <span class="n">new_filtered_df</span> <span class="o">=</span> <span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">tokenized_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.ml.feature.StopWordsRemover
remover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_3d7dc1a9b2ef
new_filtered_df: org.apache.spark.sql.DataFrame = [id: bigint, corpus: string ... 4 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Set</span> <span class="n">Params</span> <span class="k">for</span> <span class="n">CountVectorizer</span>
<span class="n">val</span> <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">new</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">setVocabSize</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="o">.</span><span class="n">setMinDF</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">new_filtered_df</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">new</span> <span class="n">df</span> <span class="n">of</span> <span class="n">countVectors</span>
<span class="n">val</span> <span class="n">new_countVectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">new_filtered_df</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>vectorizer: org.apache.spark.ml.feature.CountVectorizerModel = cntVec_2fcb7a8b0dc8
new_countVectors: org.apache.spark.sql.DataFrame = [id: bigint, features: vector]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Convert</span> <span class="n">DF</span> <span class="n">to</span> <span class="n">RDD</span>
<span class="n">val</span> <span class="n">new_lda_countVector</span> <span class="o">=</span> <span class="n">new_countVectors</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="p">:</span> <span class="n">Long</span><span class="p">,</span> <span class="n">countVector</span><span class="p">:</span> <span class="n">MLVector</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">fromML</span><span class="p">(</span><span class="n">countVector</span><span class="p">))</span> <span class="p">}</span><span class="o">.</span><span class="n">rdd</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>new_lda_countVector: org.apache.spark.rdd.RDD[(Long, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[3955] at rdd at command-753740454082314:2
</pre></div>
</div>
</div></blockquote>
<p>We will also increase MaxIterations to 10 to see if we get better
results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Set</span> <span class="n">LDA</span> <span class="n">parameters</span>
<span class="n">val</span> <span class="n">new_lda</span> <span class="o">=</span> <span class="n">new</span> <span class="n">LDA</span><span class="p">()</span>
<span class="o">.</span><span class="n">setOptimizer</span><span class="p">(</span><span class="n">new</span> <span class="n">OnlineLDAOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">setMiniBatchFraction</span><span class="p">(</span><span class="mf">0.8</span><span class="p">))</span>
<span class="o">.</span><span class="n">setK</span><span class="p">(</span><span class="n">numTopics</span><span class="p">)</span>
<span class="o">.</span><span class="n">setMaxIterations</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="o">.</span><span class="n">setDocConcentration</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">use</span> <span class="n">default</span> <span class="n">values</span>
<span class="o">.</span><span class="n">setTopicConcentration</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">use</span> <span class="n">default</span> <span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>new_lda: org.apache.spark.mllib.clustering.LDA = org.apache.spark.mllib.clustering.LDA@5fca2e4f
</pre></div>
</div>
</div></blockquote>
<div class="section" id="how-to-find-what-the-default-values-are">
<h3>How to find what the default values are?<a class="headerlink" href="#how-to-find-what-the-default-values-are" title="Permalink to this headline">¶</a></h3>
<p>Dive into the source!!!</p>
<ol class="simple">
<li><p>Let’s find the default value for <code class="docutils literal notranslate"><span class="pre">docConcentration</span></code> now.</p></li>
<li><p>Got to Apache Spark package Root:
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/#package">https://spark.apache.org/docs/latest/api/scala/#package</a></p></li>
</ol>
<ul>
<li><p>search for ‘ml’ in the search box on the top left (ml is for ml
library)</p></li>
<li><p>Then find the <code class="docutils literal notranslate"><span class="pre">LDA</span></code> by scrolling below on the left to mllib’s
<code class="docutils literal notranslate"><span class="pre">clustering</span></code> methods and click on <code class="docutils literal notranslate"><span class="pre">LDA</span></code></p></li>
<li><p>Then click on the source code link which should take you here:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/apache/spark/blob/v1.6.1/mllib/src/main/scala/org/apache/spark/ml/clustering/LDA.scala">https://github.com/apache/spark/blob/v1.6.1/mllib/src/main/scala/org/apache/spark/ml/clustering/LDA.scala</a></p></li>
<li><p>Now, simply go to the right function and see the following
comment block:</p></li>
</ul>
<p>``` /**</p>
<ul>
<li><p>Concentration parameter (commonly named “alpha”) for the prior
placed on documents’</p></li>
<li><p>distributions over topics (“theta”).</p></li>
<li></li>
<li><p>This is the parameter to a Dirichlet distribution, where larger
values mean more smoothing</p></li>
<li><p>(more regularization).</p></li>
<li></li>
<li><p>If not set by the user, then docConcentration is set
automatically. If set to</p></li>
<li><p>singleton vector [alpha], then alpha is replicated to a vector
of length k in fitting.</p></li>
<li><p>Otherwise, the [[docConcentration]] vector must be length k.</p></li>
<li><p>(default = automatic)</p></li>
<li></li>
<li><p>Optimizer-specific parameter settings:</p></li>
<li><ul class="simple">
<li><p>EM</p></li>
</ul>
</li>
<li><ul class="simple">
<li><p>Currently only supports symmetric distributions, so all values in the vector should be</p></li>
</ul>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>the same.
</pre></div>
</div>
</li>
<li><ul class="simple">
<li><p>Values should be &gt; 1.0</p></li>
</ul>
</li>
<li><ul class="simple">
<li><p>default = uniformly (50 / k) + 1, where 50/k is common in LDA libraries and +1 follows</p></li>
</ul>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from Asuncion et al. (2009), who recommend a +1 adjustment for EM.
</pre></div>
</div>
</li>
<li><ul class="simple">
<li><p>Online</p></li>
</ul>
</li>
<li><ul class="simple">
<li><p>Values should be &gt;= 0</p></li>
</ul>
</li>
<li><ul class="simple">
<li><p>default = uniformly (1.0 / k), following the implementation from</p></li>
</ul>
</li>
<li><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[[https://github.com/Blei-Lab/onlineldavb]].
</pre></div>
</div>
</li>
<li><p>&#64;group param */ ```</p></li>
</ul>
</li>
</ul>
<p><strong>HOMEWORK:</strong> Try to find the default value for <code class="docutils literal notranslate"><span class="pre">TopicConcentration</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Create</span> <span class="n">LDA</span> <span class="n">model</span> <span class="k">with</span> <span class="n">stopwords</span> <span class="n">refiltered</span>
<span class="n">val</span> <span class="n">new_ldaModel</span> <span class="o">=</span> <span class="n">new_lda</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">new_lda_countVector</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>new_ldaModel: org.apache.spark.mllib.clustering.LDAModel = org.apache.spark.mllib.clustering.LocalLDAModel@3f1301a7
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topicIndices</span> <span class="o">=</span> <span class="n">new_ldaModel</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="n">maxTermsPerTopic</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">val</span> <span class="n">vocabList</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">val</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">topicIndices</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">termWeights</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">terms</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vocabList</span><span class="p">(</span><span class="n">_</span><span class="p">))</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">termWeights</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;$numTopics topics:&quot;</span><span class="p">)</span>
<span class="n">topics</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">foreach</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;TOPIC $i&quot;</span><span class="p">)</span>
  <span class="n">topic</span><span class="o">.</span><span class="n">foreach</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;$term</span><span class="se">\t</span><span class="s2">$weight&quot;</span><span class="p">)</span> <span class="p">}</span>
  <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;==========&quot;</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>20 topics:
TOPIC 0
right	0.002368539995607174
love	0.0019026093436816463
just	0.001739005396343051
okay	0.001493567868602809
know	0.0011919944841106388
==========
TOPIC 1
like	0.012255569993473736
just	0.007532527227834193
come	0.007114873840600518
know	0.006960825682483897
think	0.006460380113586568
==========
TOPIC 2
know	0.017593342399778864
yeah	0.01729763439457538
gonna	0.014297985209693677
just	0.009395640487800467
tell	0.007112117826339655
==========
TOPIC 3
just	0.002310885836348927
know	0.0020049203493508585
better	0.001839601963450054
like	0.0016545385663972387
right	0.001505081787498549
==========
TOPIC 4
know	0.012396058201765845
didn	0.004786910731106122
like	0.004783067030382327
right	0.003733205551673614
just	0.0028592628116592403
==========
TOPIC 5
just	0.0028236500929191208
know	0.0026011344347436015
going	0.0015951009390631876
didn	0.001385667983895007
wait	0.001275555813151892
==========
TOPIC 6
going	0.00275337137203844
right	0.001685679960504387
just	0.0015380845174617235
know	0.0014818062892167352
captain	0.0013896743515293423
==========
TOPIC 7
going	0.011956735401221285
just	0.006541063462593452
know	0.005428932374204778
think	0.004308569608730405
believe	0.003696595226603709
==========
TOPIC 8
think	0.0019959039820595533
sorry	0.00198077299794292
know	0.0016723315231586236
shit	0.0015606901977245095
right	0.0013015271817698212
==========
TOPIC 9
know	0.003615862714921936
said	0.001961114693915351
sorry	0.0018595382287745752
like	0.0017819242854891695
think	0.0016468683030306027
==========
TOPIC 10
time	0.008784671423019166
want	0.00282365356227211
sure	0.0024833597381016476
know	0.0019777615447230884
right	0.0016576304456760946
==========
TOPIC 11
just	0.0021068918389201634
like	0.0020497480766035994
know	0.002022347553873645
want	0.0019500819941038825
said	0.001503771370040063
==========
TOPIC 12
look	0.00433587608823225
think	0.0025833796049907604
know	0.002007970741805987
going	0.0016840410422251017
just	0.0010661551551733228
==========
TOPIC 13
know	0.0020279945673448915
come	0.0019980250335794405
think	0.0012733121858788797
going	0.001192108885417234
okay	0.001186180285931844
==========
TOPIC 14
like	0.004262090436242644
right	0.0021537790725358777
just	0.0013683197398457016
know	0.0010911699327713488
look	0.0010869000557749361
==========
TOPIC 15
come	0.004769396664496132
know	0.0026229974920448534
like	0.0021612642420959253
just	0.0013228057897488347
right	0.001171812635848879
==========
TOPIC 16
know	0.025323543461007635
just	0.018361261941348715
like	0.01574431601713426
want	0.014855701536091734
think	0.011957607420818889
==========
TOPIC 17
like	0.004346004035796333
know	0.0022903208899377127
just	0.002008680613491114
little	0.0019547134832950414
maybe	0.0017287784612649724
==========
TOPIC 18
know	0.003217184151682409
think	0.003063734585623867
just	0.0018328245079520728
want	0.0017709019452594528
like	0.0016903614729120188
==========
TOPIC 19
hello	0.008911727886543675
stop	0.0025143616929346174
just	0.0023958078165974795
like	0.00184251815055585
come	0.0018199130672157007
==========
topicIndices: Array[(Array[Int], Array[Double])] = Array((Array(5, 27, 1, 16, 0),Array(0.002368539995607174, 0.0019026093436816463, 0.001739005396343051, 0.001493567868602809, 0.0011919944841106388)), (Array(2, 1, 10, 0, 4),Array(0.012255569993473736, 0.007532527227834193, 0.007114873840600518, 0.006960825682483897, 0.006460380113586568)), (Array(0, 8, 20, 1, 9),Array(0.017593342399778864, 0.01729763439457538, 0.014297985209693677, 0.009395640487800467, 0.007112117826339655)), (Array(1, 0, 36, 2, 5),Array(0.002310885836348927, 0.0020049203493508585, 0.001839601963450054, 0.0016545385663972387, 0.001505081787498549)), (Array(0, 13, 2, 5, 1),Array(0.012396058201765845, 0.004786910731106122, 0.004783067030382327, 0.003733205551673614, 0.0028592628116592403)), (Array(1, 0, 6, 13, 57),Array(0.0028236500929191208, 0.0026011344347436015, 0.0015951009390631876, 0.001385667983895007, 0.001275555813151892)), (Array(6, 5, 1, 0, 233),Array(0.00275337137203844, 0.001685679960504387, 0.0015380845174617235, 0.0014818062892167352, 0.0013896743515293423)), (Array(6, 1, 0, 4, 40),Array(0.011956735401221285, 0.006541063462593452, 0.005428932374204778, 0.004308569608730405, 0.003696595226603709)), (Array(4, 26, 0, 42, 5),Array(0.0019959039820595533, 0.00198077299794292, 0.0016723315231586236, 0.0015606901977245095, 0.0013015271817698212)), (Array(0, 23, 26, 2, 4),Array(0.003615862714921936, 0.001961114693915351, 0.0018595382287745752, 0.0017819242854891695, 0.0016468683030306027)), (Array(11, 3, 19, 0, 5),Array(0.008784671423019166, 0.00282365356227211, 0.0024833597381016476, 0.0019777615447230884, 0.0016576304456760946)), (Array(1, 2, 0, 3, 23),Array(0.0021068918389201634, 0.0020497480766035994, 0.002022347553873645, 0.0019500819941038825, 0.001503771370040063)), (Array(12, 4, 0, 6, 1),Array(0.00433587608823225, 0.0025833796049907604, 0.002007970741805987, 0.0016840410422251017, 0.0010661551551733228)), (Array(0, 10, 4, 6, 16),Array(0.0020279945673448915, 0.0019980250335794405, 0.0012733121858788797, 0.001192108885417234, 0.001186180285931844)), (Array(2, 5, 1, 0, 12),Array(0.004262090436242644, 0.0021537790725358777, 0.0013683197398457016, 0.0010911699327713488, 0.0010869000557749361)), (Array(10, 0, 2, 1, 5),Array(0.004769396664496132, 0.0026229974920448534, 0.0021612642420959253, 0.0013228057897488347, 0.001171812635848879)), (Array(0, 1, 2, 3, 4),Array(0.025323543461007635, 0.018361261941348715, 0.01574431601713426, 0.014855701536091734, 0.011957607420818889)), (Array(2, 0, 1, 18, 24),Array(0.004346004035796333, 0.0022903208899377127, 0.002008680613491114, 0.0019547134832950414, 0.0017287784612649724)), (Array(0, 4, 1, 3, 2),Array(0.003217184151682409, 0.003063734585623867, 0.0018328245079520728, 0.0017709019452594528, 0.0016903614729120188)), (Array(121, 68, 1, 2, 10),Array(0.008911727886543675, 0.0025143616929346174, 0.0023958078165974795, 0.00184251815055585, 0.0018199130672157007)))
vocabList: Array[String] = Array(know, just, like, want, think, right, going, good, yeah, tell, come, time, look, didn, mean, make, okay, really, little, sure, gonna, thing, people, said, maybe, need, sorry, love, talk, thought, doing, life, night, things, work, money, better, told, long, help, believe, years, shit, does, away, place, hell, doesn, great, home, feel, fuck, kind, remember, dead, course, wouldn, wait, kill, guess, understand, thank, girl, wrong, leave, listen, talking, real, stop, hear, nice, happened, fine, wanted, father, gotta, mind, fucking, house, wasn, getting, world, stay, mother, left, came, care, thanks, knew, room, trying, guys, went, looking, coming, heard, friend, haven, seen, best, tonight, live, used, matter, killed, pretty, business, idea, couldn, head, miss, says, wife, called, woman, morning, tomorrow, start, stuff, saying, play, hello, baby, hard, probably, minute, days, took, somebody, school, today, meet, gone, crazy, wants, damn, forget, cause, problem, deal, case, friends, point, hope, jesus, afraid, looks, knows, year, worry, exactly, aren, half, thinking, shut, hold, wanna, face, minutes, bring, word, read, doctor, everybody, makes, supposed, story, turn, true, watch, thousand, family, brother, kids, week, happen, fuckin, working, happy, open, lost, john, hurt, town, ready, alright, late, actually, gave, married, beautiful, soon, jack, times, sleep, door, having, drink, hand, easy, gets, chance, young, trouble, different, anybody, shot, rest, hate, death, second, later, asked, phone, wish, check, quite, walk, change, police, couple, question, close, taking, heart, hours, making, comes, anymore, truth, trust, dollars, important, captain, telling, funny, person, honey, goes, eyes, reason, inside, stand, break, number, tried, means, high, white, water, suppose, body, sick, game, excuse, party, women, country, answer, waiting, christ, office, send, pick, alive, sort, blood, black, daddy, line, husband, goddamn, book, fifty, thirty, million, fact, hands, died, power, started, stupid, shouldn, months, boys, city, sense, dinner, running, hour, shoot, drive, fight, speak, george, living, ship, figure, dear, street, ahead, lady, seven, scared, free, feeling, frank, able, children, outside, safe, moment, news, president, brought, write, happens, sent, bullshit, lose, light, glad, child, girls, sister, sounds, lives, till, promise, sound, weren, save, poor, cool, asking, shall, plan, king, bitch, daughter, beat, weeks, york, cold, worth, taken, harry, needs, piece, movie, fast, possible, small, goin, straight, human, hair, food, tired, company, lucky, pull, wonderful, touch, looked, state, thinks, picture, words, leaving, control, clear, known, special, buddy, luck, follow, order, expect, mary, catch, mouth, worked, mister, learn, playing, perfect, dream, calling, questions, hospital, coffee, takes, ride, parents, miles, works, secret, hotel, explain, worse, kidding, past, outta, general, unless, felt, drop, throw, hang, interested, certainly, absolutely, earth, loved, wonder, dark, accident, seeing, doin, turned, simple, clock, date, sweet, meeting, clean, sign, feet, handle, army, music, giving, report, cops, fucked, charlie, information, yesterday, smart, fall, fault, class, bank, month, blow, swear, caught, major, paul, road, talked, choice, boss, plane, david, paid, wear, american, worried, clothes, ones, lord, goodbye, paper, terrible, strange, mistake, given, kept, finish, blue, murder, hurry, apartment, sell, middle, nothin, careful, hasn, meant, walter, moving, changed, fair, imagine, difference, quiet, happening, near, quit, personal, marry, figured, rose, future, building, kinda, agent, early, mama, michael, watching, trip, private, busy, record, certain, jimmy, broke, longer, sake, store, finally, boat, stick, born, sitting, evening, bucks, history, chief, lying, ought, honor, kiss, darling, lunch, uncle, fool, favor, respect, rich, land, liked, killing, peter, tough, brain, interesting, completely, welcome, nick, problems, wake, radio, dick, honest, cash, dance, dude, james, bout, floor, weird, court, jail, calls, window, involved, drunk, johnny, officer, needed, asshole, spend, situation, books, relax, pain, grand, dangerous, service, letter, stopped, security, realize, offer, table, message, bastard, killer, instead, jake, deep, nervous, pass, somethin, evil, english, bought, short, step, ring, picked, likes, machine, voice, eddie, upset, carry, forgot, lived, afternoon, fear, finished, quick, count, forgive, wrote, named, decided, totally, space, team, lawyer, pleasure, doubt, suit, station, gotten, bother, return, prove, slow, pictures, bunch, strong, list, wearing, driving, join, tape, christmas, force, church, attack, appreciate, college, standing, hungry, present, dying, charge, prison, missing, truck, board, public, staying, calm, gold, ball, hardly, hadn, lead, missed, island, government, cover, horse, reach, joke, french, fish, star, america, moved, soul, surprise, mike, putting, seconds, club, self, movies, dress, cost, lots, price, listening, saved, smell, mark, peace, dreams, crime, gives, entire, department, usually, single, holy, west, beer, nose, wall, stuck, protect, ways, teach, train, grow, awful, type, forever, rock, detective, billy, dumb, papers, walking, beginning, planet, folks, park, attention, card, hide, birthday, master, share, lieutenant, starting, test, reading, field, partner, twice, enjoy, film, bomb, mess, blame, dollar, loves, girlfriend, south, round, records, especially, using, plenty, gentlemen, evidence, silly, admit, experience, fired, normal, talkin, lock, mission, memory, louis, fighting, notice, crap, wedding, promised, ground, idiot, orders, marriage, guns, glass, impossible, heaven, knock, spent, neck, wondering, green, animal, hole, press, drugs, nuts, position, broken, names, asleep, jerry, acting, feels, visit, plans, boyfriend, smoke, paris, wind, tells, gimme, holding, cross, sheriff, walked, mention, judge, code, writing, double, brothers, keeps, pardon, fellow, fell, closed, lovely, angry, cute, percent, surprised, charles, agree, bathroom, correct, address, ridiculous, summer, andy, rules, tommy, group, account, note, learned, colonel, pulled, sing, laugh, proud, sleeping, area, built, jump, upstairs, difficult, river, bobby, dirty, breakfast, bridge, betty, locked, amazing, north, alex, definitely, plus, feelings, accept, kick, worst, grace, gettin, wild, stories, steal, seriously, file, relationship, advice, nature, places, waste, contact, spot, apart, knowing, stole, beach, favorite, loose, level, song, faith, risk, played, eating, foot, patient, witness, turns, washington, action, build, obviously, begin, split, crew, command, games, decide, tight, nurse, keeping, bird, form, runs, copy, scene, jeffrey, arrest, complete, taste, consider, insane, teeth, shoes, henry, career, sooner, monster, devil, hall, innocent, showed, study, gift, weekend, heavy, keys, greatest, comin, destroy, danger, track, raise, suddenly, hanging, bruce, carl, california, apologize, concerned, blind, program, medical, chicken, sweetheart, drinking, forward, seventy, willing, shop, guard, legs, suspect, professor, admiral, data, ticket, camp, tree, goodnight, paying, burn, losing, possibly, dunno, television, senator, trick, murdered, dropped, extra, credit, starts, warm, stone, sold, hiding, meaning, taught, marty, cheap, lately, simply, science, lookin, following, harold, queen, majesty, jeff, corner, cars, heads, training, seat, duty, noticed, helped, bear, enemy, discuss, responsible, trial, dave)
topics: Array[Array[(String, Double)]] = Array(Array((right,0.002368539995607174), (love,0.0019026093436816463), (just,0.001739005396343051), (okay,0.001493567868602809), (know,0.0011919944841106388)), Array((like,0.012255569993473736), (just,0.007532527227834193), (come,0.007114873840600518), (know,0.006960825682483897), (think,0.006460380113586568)), Array((know,0.017593342399778864), (yeah,0.01729763439457538), (gonna,0.014297985209693677), (just,0.009395640487800467), (tell,0.007112117826339655)), Array((just,0.002310885836348927), (know,0.0020049203493508585), (better,0.001839601963450054), (like,0.0016545385663972387), (right,0.001505081787498549)), Array((know,0.012396058201765845), (didn,0.004786910731106122), (like,0.004783067030382327), (right,0.003733205551673614), (just,0.0028592628116592403)), Array((just,0.0028236500929191208), (know,0.0026011344347436015), (going,0.0015951009390631876), (didn,0.001385667983895007), (wait,0.001275555813151892)), Array((going,0.00275337137203844), (right,0.001685679960504387), (just,0.0015380845174617235), (know,0.0014818062892167352), (captain,0.0013896743515293423)), Array((going,0.011956735401221285), (just,0.006541063462593452), (know,0.005428932374204778), (think,0.004308569608730405), (believe,0.003696595226603709)), Array((think,0.0019959039820595533), (sorry,0.00198077299794292), (know,0.0016723315231586236), (shit,0.0015606901977245095), (right,0.0013015271817698212)), Array((know,0.003615862714921936), (said,0.001961114693915351), (sorry,0.0018595382287745752), (like,0.0017819242854891695), (think,0.0016468683030306027)), Array((time,0.008784671423019166), (want,0.00282365356227211), (sure,0.0024833597381016476), (know,0.0019777615447230884), (right,0.0016576304456760946)), Array((just,0.0021068918389201634), (like,0.0020497480766035994), (know,0.002022347553873645), (want,0.0019500819941038825), (said,0.001503771370040063)), Array((look,0.00433587608823225), (think,0.0025833796049907604), (know,0.002007970741805987), (going,0.0016840410422251017), (just,0.0010661551551733228)), Array((know,0.0020279945673448915), (come,0.0019980250335794405), (think,0.0012733121858788797), (going,0.001192108885417234), (okay,0.001186180285931844)), Array((like,0.004262090436242644), (right,0.0021537790725358777), (just,0.0013683197398457016), (know,0.0010911699327713488), (look,0.0010869000557749361)), Array((come,0.004769396664496132), (know,0.0026229974920448534), (like,0.0021612642420959253), (just,0.0013228057897488347), (right,0.001171812635848879)), Array((know,0.025323543461007635), (just,0.018361261941348715), (like,0.01574431601713426), (want,0.014855701536091734), (think,0.011957607420818889)), Array((like,0.004346004035796333), (know,0.0022903208899377127), (just,0.002008680613491114), (little,0.0019547134832950414), (maybe,0.0017287784612649724)), Array((know,0.003217184151682409), (think,0.003063734585623867), (just,0.0018328245079520728), (want,0.0017709019452594528), (like,0.0016903614729120188)), Array((hello,0.008911727886543675), (stop,0.0025143616929346174), (just,0.0023958078165974795), (like,0.00184251815055585), (come,0.0018199130672157007)))
</pre></div>
</div>
</div></blockquote>
</div>
</div>
<div class="section" id="step-9-create-lda-model-with-expectation-maximization">
<h2>Step 9. Create LDA model with Expectation Maximization<a class="headerlink" href="#step-9-create-lda-model-with-expectation-maximization" title="Permalink to this headline">¶</a></h2>
<p>Let’s try creating an LDA model with Expectation Maximization on the
data that has been refiltered for additional stopwords. We will also
increase MaxIterations here to 100 to see if that improves results. See:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda">http://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.EMLDAOptimizer</span>

<span class="o">//</span> <span class="n">Set</span> <span class="n">LDA</span> <span class="n">parameters</span>
<span class="n">val</span> <span class="n">em_lda</span> <span class="o">=</span> <span class="n">new</span> <span class="n">LDA</span><span class="p">()</span>
<span class="o">.</span><span class="n">setOptimizer</span><span class="p">(</span><span class="n">new</span> <span class="n">EMLDAOptimizer</span><span class="p">())</span>
<span class="o">.</span><span class="n">setK</span><span class="p">(</span><span class="n">numTopics</span><span class="p">)</span>
<span class="o">.</span><span class="n">setMaxIterations</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="o">.</span><span class="n">setDocConcentration</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">use</span> <span class="n">default</span> <span class="n">values</span>
<span class="o">.</span><span class="n">setTopicConcentration</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">use</span> <span class="n">default</span> <span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.mllib.clustering.EMLDAOptimizer
em_lda: org.apache.spark.mllib.clustering.LDA = org.apache.spark.mllib.clustering.LDA@7c84d0ae
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">em_ldaModel</span> <span class="o">=</span> <span class="n">em_lda</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">new_lda_countVector</span><span class="p">)</span> <span class="o">//</span> <span class="n">takes</span> <span class="n">a</span> <span class="n">long</span> <span class="n">long</span> <span class="n">time</span> <span class="mi">22</span> <span class="n">minutes</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>em_ldaModel: org.apache.spark.mllib.clustering.LDAModel = org.apache.spark.mllib.clustering.DistributedLDAModel@188f58bf
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.DistributedLDAModel</span><span class="p">;</span>
<span class="n">val</span> <span class="n">em_DldaModel</span> <span class="o">=</span> <span class="n">em_ldaModel</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="p">[</span><span class="n">DistributedLDAModel</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.mllib.clustering.DistributedLDAModel
em_DldaModel: org.apache.spark.mllib.clustering.DistributedLDAModel = org.apache.spark.mllib.clustering.DistributedLDAModel@188f58bf
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">top10ConversationsPerTopic</span> <span class="o">=</span> <span class="n">em_DldaModel</span><span class="o">.</span><span class="n">topDocumentsPerTopic</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>top10ConversationsPerTopic: Array[(Array[Long], Array[Double])] = Array((Array(39677, 39693, 39680, 39679, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.03185722402229515, 0.03185722402229515, 0.03185722402229515, 0.03185722402229515, 0.03185722402229515, 0.03185722402229515, 0.031196200176884056, 0.020282154018599348, 0.01099645315549, 0.01099645315549)), (Array(39677, 39693, 39680, 39679, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.035359403020952286, 0.035359403020952286, 0.035359403020952286, 0.035359403020952286, 0.035359403020952286, 0.035359403020952286, 0.03471449892991739, 0.022506359024306477, 0.0112575667750105, 0.0112575667750105)), (Array(39677, 39693, 39680, 39679, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.02454380082221751, 0.02454380082221751, 0.02454380082221751, 0.02454380082221751, 0.02454380082221751, 0.02454380082221751, 0.02390214852968437, 0.01563567947724491, 0.01037864738296468, 0.01037864738296468)), (Array(69318, 15221, 15149, 23167, 59606, 51632, 51639, 64470, 67338, 66968),Array(0.9999514001066685, 0.999945172626603, 0.9999406008121946, 0.9999406008121946, 0.9999406008121946, 0.9999406008121946, 0.9999406008121946, 0.9999406008121946, 0.9999406008121946, 0.9999406008121946)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.05060524129300216, 0.05060524129300216, 0.05060524129300216, 0.05060524129300216, 0.05060524129300216, 0.05060524129300216, 0.05027652950865874, 0.032180017393406625, 0.011630224445618545, 0.011630224445618545)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.043670158470644385, 0.043670158470644385, 0.043670158470644385, 0.043670158470644385, 0.043670158470644385, 0.043670158470644385, 0.04313069897321676, 0.027782187731151566, 0.01176138814023006, 0.01176138814023006)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.04718260291563998, 0.04718260291563998, 0.04718260291563998, 0.04718260291563998, 0.04718260291563998, 0.04718260291563998, 0.046744086701796375, 0.030009654606021424, 0.011639894189919175, 0.011639894189919175)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.04675497162050312, 0.04675497162050312, 0.04675497162050312, 0.04675497162050312, 0.04675497162050312, 0.04675497162050312, 0.04630740194891603, 0.02973828460805704, 0.011613267488918038, 0.011613267488918038)), (Array(39677, 39693, 39680, 39679, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.02922347731698308, 0.02922347731698308, 0.02922347731698308, 0.02922347731698308, 0.02922347731698308, 0.02922347731698308, 0.02856137645845995, 0.01860910369309368, 0.010781174428638705, 0.010781174428638705)), (Array(39677, 39693, 39680, 39674, 39682, 39679, 39681, 39676, 41932, 41967),Array(0.05098977390451263, 0.05098977390451263, 0.05098977390451263, 0.05098977390451263, 0.05098977390451263, 0.05098977390451263, 0.05065478074966324, 0.032424728159182487, 0.011804021891259129, 0.011804021891259129)), (Array(39677, 39693, 39680, 39674, 39682, 39679, 39681, 39676, 41932, 41967),Array(0.05458945924257291, 0.05458945924257291, 0.05458945924257291, 0.05458945924257291, 0.05458945924257291, 0.05458945924257291, 0.054382561204063574, 0.03470709039767808, 0.011833044488991173, 0.011833044488991173)), (Array(39677, 39693, 39680, 39679, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.02757805103727522, 0.02757805103727522, 0.02757805103727522, 0.02757805103727522, 0.02757805103727522, 0.02757805103727522, 0.026914567318365282, 0.017564142155031864, 0.010769649833867787, 0.010769649833867787)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.04651386476447619, 0.04651386476447619, 0.04651386476447619, 0.04651386476447619, 0.04651386476447619, 0.04651386476447619, 0.046074356990568124, 0.029584640688217628, 0.011466200232752964, 0.011466200232752964)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.05592908452117546, 0.05592908452117546, 0.05592908452117546, 0.05592908452117546, 0.05592908452117546, 0.05592908452117546, 0.055741511067049866, 0.03555776746162745, 0.01211237486139149, 0.01211237486139149)), (Array(39681, 39674, 39677, 39693, 39680, 39682, 39679, 39676, 41932, 41967),Array(0.06048967215526035, 0.060441959490269634, 0.060441959490269634, 0.060441959490269634, 0.060441959490269634, 0.060441959490269634, 0.060441959490269634, 0.03841642394224334, 0.011870824949431247, 0.011870824949431247)), (Array(39681, 39679, 39677, 39693, 39680, 39674, 39682, 39676, 41932, 41967),Array(0.06567035036792095, 0.06540012688944775, 0.06540012688944775, 0.06540012688944775, 0.06540012688944775, 0.06540012688944775, 0.06540012688944775, 0.041559067084071775, 0.012094068526188358, 0.012094068526188358)), (Array(39681, 39674, 39677, 39693, 39680, 39682, 39679, 39676, 41932, 41967),Array(0.07103855727399273, 0.07041257887551527, 0.07041257887551527, 0.07041257887551527, 0.07041257887551527, 0.07041257887551527, 0.07041257887551527, 0.04473147169952923, 0.011812341727214322, 0.011812341727214322)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.04379464422302749, 0.04379464422302749, 0.04379464422302749, 0.04379464422302749, 0.04379464422302749, 0.04379464422302749, 0.04327692350658171, 0.027860179926002853, 0.01152922335209424, 0.01152922335209424)), (Array(39677, 39693, 39680, 39679, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.04365837465882906, 0.04365837465882906, 0.04365837465882906, 0.04365837465882906, 0.04365837465882906, 0.04365837465882906, 0.04316378247947061, 0.02777238708460723, 0.011237658307104376, 0.011237658307104376)), (Array(39679, 39677, 39693, 39680, 39674, 39682, 39681, 39676, 41932, 41967),Array(0.04674235176753242, 0.04674235176753242, 0.04674235176753242, 0.04674235176753242, 0.04674235176753242, 0.04674235176753242, 0.0463101731327656, 0.02972951504690979, 0.011452462524389802, 0.011452462524389802)))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">top10ConversationsPerTopic</span><span class="o">.</span><span class="n">length</span> <span class="o">//</span> <span class="n">number</span> <span class="n">of</span> <span class="n">topics</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res52: Int = 20
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">em_DldaModel</span><span class="o">.</span><span class="n">topicDistributions</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note that the EMLDAOptimizer produces a DistributedLDAModel, which
stores not only the inferred topics but also the full training corpus
and topic distributions for each document in the training corpus.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topicIndices</span> <span class="o">=</span> <span class="n">em_ldaModel</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="n">maxTermsPerTopic</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>topicIndices: Array[(Array[Int], Array[Double])] = Array((Array(6435, 9153, 2611, 9555, 9235),Array(1.0844350865928232E-5, 1.4037356622456141E-6, 1.0198257636937534E-6, 1.010016392533973E-6, 9.877489659219E-7)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.2201894817101623E-5, 1.4560010186049552E-6, 1.0547580487281058E-6, 1.0446104695648421E-6, 1.0214202904824573E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(8.080320102037276E-6, 1.2828806625265042E-6, 9.387148884503143E-7, 9.296944883594565E-7, 9.095512260026888E-7)), (Array(0, 1, 2, 3, 4),Array(0.4097048012129488, 0.2966641691130405, 0.28104437242573427, 0.2068481221090779, 0.20178462784115517)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.7791420865642426E-5, 1.5285401934315644E-6, 1.1022151610359566E-6, 1.0916092052333647E-6, 1.0671154286074535E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.5488156532652564E-5, 1.5613578155095174E-6, 1.1250530213722066E-6, 1.1142275765190935E-6, 1.0891766415036671E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.66201985348282E-5, 1.5337088341752489E-6, 1.1062252459821718E-6, 1.0955808549686414E-6, 1.0710096202234095E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.6434785283305463E-5, 1.527062738898831E-6, 1.1015632294086975E-6, 1.0909636379478556E-6, 1.066504587082138E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(9.82890555944203E-6, 1.360381381982805E-6, 9.90695338703216E-7, 9.811686105969582E-7, 9.596620143926599E-7)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.8098274080649888E-5, 1.5662560052135424E-6, 1.127571968783498E-6, 1.1167221871321394E-6, 1.0915664277968502E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.9443267750173392E-5, 1.5746049595955017E-6, 1.1333735056120856E-6, 1.1224679386855895E-6, 1.0971718558358495E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(9.292996004992278E-6, 1.3619125930485615E-6, 9.924672219451632E-7, 9.82924355173023E-7, 9.614096002911668E-7)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.619330796598465E-5, 1.4932367796221485E-6, 1.0785114269963956E-6, 1.06813378362302E-6, 1.0442595139466752E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(2.0195445781462442E-5, 1.6338598744234947E-6, 1.1726861776132844E-6, 1.1614034519421386E-6, 1.1350541791534873E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(2.1543159186970775E-5, 1.5791785506830092E-6, 1.1358076217376717E-6, 1.1248786573437884E-6, 1.099486352793341E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(2.3565018803229148E-5, 1.6252544688003071E-6, 1.16608206417593E-6, 1.1548627950846766E-6, 1.1286452359926982E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(2.498926755354901E-5, 1.5618937315237142E-6, 1.1234358831022108E-6, 1.1126257210374892E-6, 1.0875181953216021E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.5342892698391062E-5, 1.5117065677915513E-6, 1.0917779017440848E-6, 1.0812727863583168E-6, 1.057095929328646E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.5018034022313325E-5, 1.4466343222454145E-6, 1.04735014561389E-6, 1.0372732437703543E-6, 1.0142213705569144E-6)), (Array(6435, 9153, 2611, 9555, 9235),Array(1.627670929533595E-5, 1.4917359134556584E-6, 1.0776961757775105E-6, 1.067326467379095E-6, 1.043483836251971E-6)))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">vocabList</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>vocabList: Array[String] = Array(know, just, like, want, think, right, going, good, yeah, tell, come, time, look, didn, mean, make, okay, really, little, sure, gonna, thing, people, said, maybe, need, sorry, love, talk, thought, doing, life, night, things, work, money, better, told, long, help, believe, years, shit, does, away, place, hell, doesn, great, home, feel, fuck, kind, remember, dead, course, wouldn, wait, kill, guess, understand, thank, girl, wrong, leave, listen, talking, real, hear, stop, nice, happened, fine, wanted, father, gotta, mind, fucking, house, wasn, getting, world, stay, mother, left, came, care, thanks, knew, room, trying, guys, went, looking, coming, heard, friend, haven, seen, best, tonight, live, used, matter, killed, pretty, business, idea, couldn, head, miss, says, wife, called, woman, morning, tomorrow, start, stuff, saying, play, hello, baby, hard, probably, minute, days, took, somebody, today, school, meet, gone, crazy, wants, damn, forget, problem, cause, deal, case, friends, point, hope, jesus, afraid, looks, knows, year, worry, exactly, aren, half, thinking, shut, hold, wanna, face, minutes, bring, word, read, doctor, everybody, supposed, makes, story, turn, true, watch, thousand, family, brother, kids, week, happen, fuckin, working, open, happy, lost, john, hurt, town, ready, alright, late, actually, married, gave, beautiful, soon, jack, times, sleep, door, having, drink, hand, easy, gets, chance, young, trouble, different, anybody, shot, rest, hate, death, second, later, asked, phone, wish, check, quite, walk, change, police, couple, question, close, taking, heart, hours, making, comes, anymore, truth, trust, dollars, important, captain, telling, funny, person, honey, goes, eyes, reason, inside, stand, break, means, number, tried, high, white, water, suppose, body, sick, game, excuse, party, women, country, answer, christ, waiting, office, send, pick, alive, sort, blood, black, daddy, line, husband, goddamn, book, fifty, thirty, fact, million, died, hands, power, stupid, started, shouldn, months, boys, city, sense, dinner, running, hour, shoot, fight, drive, speak, george, ship, living, figure, dear, street, ahead, lady, seven, scared, free, feeling, frank, able, children, safe, moment, outside, news, president, brought, write, happens, sent, bullshit, lose, light, glad, child, girls, sounds, sister, promise, lives, till, sound, weren, save, poor, cool, shall, asking, plan, king, bitch, daughter, weeks, beat, york, cold, worth, taken, harry, needs, piece, movie, fast, possible, small, goin, straight, human, hair, company, food, tired, lucky, pull, wonderful, touch, looked, thinks, state, picture, leaving, words, control, clear, known, special, buddy, luck, order, follow, expect, mary, catch, mouth, worked, mister, learn, playing, perfect, dream, calling, questions, hospital, takes, ride, coffee, miles, parents, works, secret, hotel, explain, kidding, worse, past, outta, general, felt, drop, unless, throw, interested, hang, certainly, absolutely, earth, loved, dark, wonder, accident, seeing, turned, clock, simple, doin, date, sweet, meeting, clean, sign, feet, handle, music, report, giving, army, fucked, cops, charlie, smart, yesterday, information, fall, fault, bank, class, month, blow, swear, caught, major, paul, road, talked, choice, plane, boss, david, paid, wear, american, worried, lord, paper, goodbye, clothes, ones, terrible, strange, given, mistake, finish, kept, blue, murder, hurry, apartment, sell, middle, nothin, careful, hasn, meant, walter, moving, changed, imagine, fair, difference, quiet, happening, near, quit, personal, marry, figured, future, rose, building, mama, michael, early, agent, kinda, watching, private, trip, record, certain, busy, jimmy, broke, sake, longer, store, boat, stick, finally, born, evening, sitting, bucks, ought, chief, lying, history, kiss, honor, darling, lunch, favor, fool, uncle, respect, rich, land, liked, killing, peter, tough, brain, interesting, completely, problems, welcome, nick, wake, honest, radio, dick, cash, dance, dude, james, bout, floor, weird, court, calls, jail, drunk, window, involved, johnny, officer, needed, asshole, situation, spend, books, relax, pain, service, grand, dangerous, letter, security, stopped, offer, realize, table, bastard, message, instead, killer, jake, deep, nervous, somethin, pass, evil, english, bought, short, step, ring, picked, likes, machine, eddie, voice, upset, forgot, carry, lived, afternoon, fear, quick, finished, count, forgive, wrote, named, decided, totally, space, team, pleasure, doubt, lawyer, station, gotten, suit, bother, prove, return, slow, pictures, bunch, strong, list, wearing, driving, join, tape, christmas, attack, appreciate, force, church, college, hungry, standing, present, dying, prison, missing, charge, board, truck, public, calm, gold, staying, ball, hardly, hadn, missed, lead, island, government, horse, cover, french, reach, joke, fish, star, mike, surprise, america, moved, soul, dress, seconds, club, self, putting, movies, lots, cost, listening, price, saved, smell, mark, peace, dreams, entire, crime, gives, usually, single, department, holy, beer, west, protect, stuck, wall, nose, ways, teach, forever, grow, train, type, awful, rock, detective, billy, walking, dumb, papers, beginning, planet, folks, park, attention, birthday, hide, card, master, share, reading, test, starting, lieutenant, field, partner, enjoy, twice, film, dollar, bomb, mess, blame, south, loves, girlfriend, round, records, using, plenty, especially, gentlemen, evidence, silly, experience, admit, fired, normal, talkin, mission, louis, memory, fighting, lock, notice, crap, wedding, promised, marriage, ground, guns, glass, idiot, orders, impossible, heaven, knock, hole, neck, animal, spent, green, wondering, nuts, press, drugs, broken, position, names, asleep, jerry, visit, boyfriend, acting, feels, plans, paris, smoke, tells, wind, cross, holding, sheriff, gimme, walked, mention, writing, double, brothers, code, judge, pardon, keeps, fellow, fell, closed, lovely, angry, cute, charles, surprised, percent, correct, bathroom, agree, address, andy, ridiculous, summer, tommy, rules, group, account, note, pulled, sleeping, sing, learned, proud, laugh, colonel, upstairs, river, difficult, built, jump, area, dirty, betty, bridge, breakfast, bobby, locked, amazing, north, feelings, alex, plus, definitely, worst, accept, kick, seriously, grace, steal, wild, stories, file, gettin, relationship, advice, nature, contact, spot, places, waste, knowing, beach, stole, apart, favorite, faith, level, loose, risk, song, eating, foot, played, patient, washington, turns, witness, action, build, obviously, begin, split, crew, command, games, tight, decide, nurse, keeping, runs, form, bird, copy, insane, complete, arrest, consider, taste, scene, jeffrey, teeth, shoes, career, henry, sooner, devil, monster, showed, weekend, gift, innocent, study, heavy, hall, comin, danger, greatest, track, keys, raise, destroy, concerned, program, carl, blind, apologize, suddenly, hanging, bruce, california, chicken, seventy, forward, drinking, sweetheart, medical, suspect, admiral, guard, shop, professor, legs, willing, camp, data, ticket, tree, goodnight, television, losing, senator, murdered, burn, dunno, paying, possibly, trick, dropped, credit, extra, starts, warm, hiding, meaning, sold, stone, taught, marty, lately, cheap, lookin, science, simply, jeff, corner, harold, following, majesty, queen, duty, cars, training, heads, seat, discuss, bear, enemy, helped, noticed, common, screw, dave)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vocabList</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res32: Int = 10000
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">topicIndices</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">termWeights</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">terms</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vocabList</span><span class="p">(</span><span class="n">_</span><span class="p">))</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">termWeights</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>topics: Array[Array[(String, Double)]] = Array(Array((just,0.030515134931284552), (like,0.02463563559747823), (want,0.022529385381465025), (damn,0.02094828832824297), (going,0.0203407289886203)), Array((yeah,0.10787301090151602), (look,0.0756831002291994), (know,0.04815746564274915), (wait,0.03897182014529944), (night,0.0341458394828345)), Array((gonna,0.08118584492034046), (money,0.051736711600637544), (shit,0.04620430294274594), (fuck,0.0399843125556081), (kill,0.03672740843080258)), Array((people,0.020091372023286612), (know,0.018613400462887356), (work,0.016775643603287843), (does,0.015522555458447744), (think,0.012161168331925723)), Array((know,0.031956573561538214), (just,0.030674598809934856), (want,0.027663491240851962), (tell,0.025727217382788027), (right,0.02300853167338119)), Array((love,0.05932570200934131), (father,0.030080735900045442), (life,0.01769248067468245), (true,0.016281752071881345), (young,0.014927950883812253)), Array((remember,0.03998401809663685), (went,0.01737965538107633), (lost,0.016916065536574213), (called,0.016443441316683228), (story,0.014849882671062261)), Array((house,0.028911209424810257), (miss,0.025669944694943093), (right,0.02091105252727788), (family,0.017862939987512365), (important,0.013959164390834044)), Array((saying,0.022939827090645636), (know,0.021335083902970984), (idea,0.017628999871937747), (business,0.017302568063786224), (police,0.012284217866942303)), Array((know,0.051876601466269136), (like,0.03828159069993671), (maybe,0.03754385940676905), (just,0.031938551661426284), (want,0.02876693222824349)), Array((years,0.032537676027398765), (going,0.030596831997667568), (case,0.02049555392502822), (doctor,0.018671171294737107), (working,0.017672067172167016)), Array((stuff,0.02236582778896705), (school,0.020057798194969816), (john,0.017134198006217606), (week,0.017075852415410653), (thousand,0.017013413435021035)), Array((little,0.08663446368316245), (girl,0.035120377589734936), (like,0.02992080326340266), (woman,0.0240813719635157), (baby,0.022471517953608963)), Array((know,0.0283115823590395), (leave,0.02744935904744228), (time,0.02050833156294194), (want,0.020124145131863225), (just,0.019466336438890477)), Array((didn,0.08220031921979461), (like,0.05062323326717784), (real,0.03087838046777391), (guess,0.02452989702353384), (says,0.022815035397008333)), Array((minutes,0.018541518543996716), (time,0.014737962244588431), (captain,0.012594614743931537), (thirty,0.01193707771669708), (ship,0.011260576815409516)), Array((okay,0.08153575328080886), (just,0.050004142902999975), (right,0.03438984898476042), (know,0.02821327795933634), (home,0.023397063860326372)), Array((country,0.011270500385627474), (power,0.010428408353623762), (president,0.009392162067926028), (fight,0.00799742811584178), (possible,0.007597974486019279)), Array((know,0.09541058020800194), (think,0.0698707939786508), (really,0.06881812755565207), (mean,0.02909700228968688), (just,0.028699687473471538)), Array((dead,0.03833642117149438), (like,0.017873711992106994), (hand,0.015280854355409379), (white,0.013718491413582671), (blood,0.012699265888344448)))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vocabList</span><span class="p">(</span><span class="mi">47</span><span class="p">)</span> <span class="o">//</span> <span class="mi">47</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">index</span> <span class="n">of</span> <span class="n">the</span> <span class="n">term</span> <span class="s1">&#39;university&#39;</span> <span class="ow">or</span> <span class="n">the</span> <span class="n">first</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">topics</span> <span class="o">-</span> <span class="n">this</span> <span class="n">may</span> <span class="n">change</span> <span class="n">due</span> <span class="n">to</span> <span class="n">randomness</span> <span class="ow">in</span> <span class="n">algorithm</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res33: String = doesn
</pre></div>
</div>
</div></blockquote>
<p>This is just doing it all at once.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">topicIndices</span> <span class="o">=</span> <span class="n">em_ldaModel</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="n">maxTermsPerTopic</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">val</span> <span class="n">vocabList</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">val</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">topicIndices</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">termWeights</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">terms</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vocabList</span><span class="p">(</span><span class="n">_</span><span class="p">))</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">termWeights</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;$numTopics topics:&quot;</span><span class="p">)</span>
<span class="n">topics</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">foreach</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">=&gt;</span>
  <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;TOPIC $i&quot;</span><span class="p">)</span>
  <span class="n">topic</span><span class="o">.</span><span class="n">foreach</span> <span class="p">{</span> <span class="n">case</span> <span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;$term</span><span class="se">\t</span><span class="s2">$weight&quot;</span><span class="p">)</span> <span class="p">}</span>
  <span class="n">println</span><span class="p">(</span><span class="n">s</span><span class="s2">&quot;==========&quot;</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>20 topics:
TOPIC 0
just	0.030515134931284552
like	0.02463563559747823
want	0.022529385381465025
damn	0.02094828832824297
going	0.0203407289886203
==========
TOPIC 1
yeah	0.10787301090151602
look	0.0756831002291994
know	0.04815746564274915
wait	0.03897182014529944
night	0.0341458394828345
==========
TOPIC 2
gonna	0.08118584492034046
money	0.051736711600637544
shit	0.04620430294274594
fuck	0.0399843125556081
kill	0.03672740843080258
==========
TOPIC 3
people	0.020091372023286612
know	0.018613400462887356
work	0.016775643603287843
does	0.015522555458447744
think	0.012161168331925723
==========
TOPIC 4
know	0.031956573561538214
just	0.030674598809934856
want	0.027663491240851962
tell	0.025727217382788027
right	0.02300853167338119
==========
TOPIC 5
love	0.05932570200934131
father	0.030080735900045442
life	0.01769248067468245
true	0.016281752071881345
young	0.014927950883812253
==========
TOPIC 6
remember	0.03998401809663685
went	0.01737965538107633
lost	0.016916065536574213
called	0.016443441316683228
story	0.014849882671062261
==========
TOPIC 7
house	0.028911209424810257
miss	0.025669944694943093
right	0.02091105252727788
family	0.017862939987512365
important	0.013959164390834044
==========
TOPIC 8
saying	0.022939827090645636
know	0.021335083902970984
idea	0.017628999871937747
business	0.017302568063786224
police	0.012284217866942303
==========
TOPIC 9
know	0.051876601466269136
like	0.03828159069993671
maybe	0.03754385940676905
just	0.031938551661426284
want	0.02876693222824349
==========
TOPIC 10
years	0.032537676027398765
going	0.030596831997667568
case	0.02049555392502822
doctor	0.018671171294737107
working	0.017672067172167016
==========
TOPIC 11
stuff	0.02236582778896705
school	0.020057798194969816
john	0.017134198006217606
week	0.017075852415410653
thousand	0.017013413435021035
==========
TOPIC 12
little	0.08663446368316245
girl	0.035120377589734936
like	0.02992080326340266
woman	0.0240813719635157
baby	0.022471517953608963
==========
TOPIC 13
know	0.0283115823590395
leave	0.02744935904744228
time	0.02050833156294194
want	0.020124145131863225
just	0.019466336438890477
==========
TOPIC 14
didn	0.08220031921979461
like	0.05062323326717784
real	0.03087838046777391
guess	0.02452989702353384
says	0.022815035397008333
==========
TOPIC 15
minutes	0.018541518543996716
time	0.014737962244588431
captain	0.012594614743931537
thirty	0.01193707771669708
ship	0.011260576815409516
==========
TOPIC 16
okay	0.08153575328080886
just	0.050004142902999975
right	0.03438984898476042
know	0.02821327795933634
home	0.023397063860326372
==========
TOPIC 17
country	0.011270500385627474
power	0.010428408353623762
president	0.009392162067926028
fight	0.00799742811584178
possible	0.007597974486019279
==========
TOPIC 18
know	0.09541058020800194
think	0.0698707939786508
really	0.06881812755565207
mean	0.02909700228968688
just	0.028699687473471538
==========
TOPIC 19
dead	0.03833642117149438
like	0.017873711992106994
hand	0.015280854355409379
white	0.013718491413582671
blood	0.012699265888344448
==========
topicIndices: Array[(Array[Int], Array[Double])] = Array((Array(1, 2, 3, 135, 6),Array(0.030515134931284552, 0.02463563559747823, 0.022529385381465025, 0.02094828832824297, 0.0203407289886203)), (Array(8, 12, 0, 57, 32),Array(0.10787301090151602, 0.0756831002291994, 0.04815746564274915, 0.03897182014529944, 0.0341458394828345)), (Array(20, 35, 42, 51, 58),Array(0.08118584492034046, 0.051736711600637544, 0.04620430294274594, 0.0399843125556081, 0.03672740843080258)), (Array(22, 0, 34, 43, 4),Array(0.020091372023286612, 0.018613400462887356, 0.016775643603287843, 0.015522555458447744, 0.012161168331925723)), (Array(0, 1, 3, 9, 5),Array(0.031956573561538214, 0.030674598809934856, 0.027663491240851962, 0.025727217382788027, 0.02300853167338119)), (Array(27, 74, 31, 168, 202),Array(0.05932570200934131, 0.030080735900045442, 0.01769248067468245, 0.016281752071881345, 0.014927950883812253)), (Array(53, 92, 180, 113, 166),Array(0.03998401809663685, 0.01737965538107633, 0.016916065536574213, 0.016443441316683228, 0.014849882671062261)), (Array(78, 110, 5, 171, 232),Array(0.028911209424810257, 0.025669944694943093, 0.02091105252727788, 0.017862939987512365, 0.013959164390834044)), (Array(119, 0, 107, 106, 219),Array(0.022939827090645636, 0.021335083902970984, 0.017628999871937747, 0.017302568063786224, 0.012284217866942303)), (Array(0, 2, 24, 1, 3),Array(0.051876601466269136, 0.03828159069993671, 0.03754385940676905, 0.031938551661426284, 0.02876693222824349)), (Array(41, 6, 140, 162, 177),Array(0.032537676027398765, 0.030596831997667568, 0.02049555392502822, 0.018671171294737107, 0.017672067172167016)), (Array(118, 130, 181, 174, 170),Array(0.02236582778896705, 0.020057798194969816, 0.017134198006217606, 0.017075852415410653, 0.017013413435021035)), (Array(18, 62, 2, 114, 122),Array(0.08663446368316245, 0.035120377589734936, 0.02992080326340266, 0.0240813719635157, 0.022471517953608963)), (Array(0, 64, 11, 3, 1),Array(0.0283115823590395, 0.02744935904744228, 0.02050833156294194, 0.020124145131863225, 0.019466336438890477)), (Array(13, 2, 67, 59, 111),Array(0.08220031921979461, 0.05062323326717784, 0.03087838046777391, 0.02452989702353384, 0.022815035397008333)), (Array(158, 11, 233, 274, 295),Array(0.018541518543996716, 0.014737962244588431, 0.012594614743931537, 0.01193707771669708, 0.011260576815409516)), (Array(16, 1, 5, 0, 49),Array(0.08153575328080886, 0.050004142902999975, 0.03438984898476042, 0.02821327795933634, 0.023397063860326372)), (Array(257, 279, 313, 291, 351),Array(0.011270500385627474, 0.010428408353623762, 0.009392162067926028, 0.00799742811584178, 0.007597974486019279)), (Array(0, 4, 17, 14, 1),Array(0.09541058020800194, 0.0698707939786508, 0.06881812755565207, 0.02909700228968688, 0.028699687473471538)), (Array(54, 2, 198, 248, 266),Array(0.03833642117149438, 0.017873711992106994, 0.015280854355409379, 0.013718491413582671, 0.012699265888344448)))
vocabList: Array[String] = Array(know, just, like, want, think, right, going, good, yeah, tell, come, time, look, didn, mean, make, okay, really, little, sure, gonna, thing, people, said, maybe, need, sorry, love, talk, thought, doing, life, night, things, work, money, better, told, long, help, believe, years, shit, does, away, place, hell, doesn, great, home, feel, fuck, kind, remember, dead, course, wouldn, wait, kill, guess, understand, thank, girl, wrong, leave, listen, talking, real, hear, stop, nice, happened, fine, wanted, father, gotta, mind, fucking, house, wasn, getting, world, stay, mother, left, came, care, thanks, knew, room, trying, guys, went, looking, coming, heard, friend, haven, seen, best, tonight, live, used, matter, killed, pretty, business, idea, couldn, head, miss, says, wife, called, woman, morning, tomorrow, start, stuff, saying, play, hello, baby, hard, probably, minute, days, took, somebody, today, school, meet, gone, crazy, wants, damn, forget, problem, cause, deal, case, friends, point, hope, jesus, afraid, looks, knows, year, worry, exactly, aren, half, thinking, shut, hold, wanna, face, minutes, bring, word, read, doctor, everybody, supposed, makes, story, turn, true, watch, thousand, family, brother, kids, week, happen, fuckin, working, open, happy, lost, john, hurt, town, ready, alright, late, actually, married, gave, beautiful, soon, jack, times, sleep, door, having, drink, hand, easy, gets, chance, young, trouble, different, anybody, shot, rest, hate, death, second, later, asked, phone, wish, check, quite, walk, change, police, couple, question, close, taking, heart, hours, making, comes, anymore, truth, trust, dollars, important, captain, telling, funny, person, honey, goes, eyes, reason, inside, stand, break, means, number, tried, high, white, water, suppose, body, sick, game, excuse, party, women, country, answer, christ, waiting, office, send, pick, alive, sort, blood, black, daddy, line, husband, goddamn, book, fifty, thirty, fact, million, died, hands, power, stupid, started, shouldn, months, boys, city, sense, dinner, running, hour, shoot, fight, drive, speak, george, ship, living, figure, dear, street, ahead, lady, seven, scared, free, feeling, frank, able, children, safe, moment, outside, news, president, brought, write, happens, sent, bullshit, lose, light, glad, child, girls, sounds, sister, promise, lives, till, sound, weren, save, poor, cool, shall, asking, plan, king, bitch, daughter, weeks, beat, york, cold, worth, taken, harry, needs, piece, movie, fast, possible, small, goin, straight, human, hair, company, food, tired, lucky, pull, wonderful, touch, looked, thinks, state, picture, leaving, words, control, clear, known, special, buddy, luck, order, follow, expect, mary, catch, mouth, worked, mister, learn, playing, perfect, dream, calling, questions, hospital, takes, ride, coffee, miles, parents, works, secret, hotel, explain, kidding, worse, past, outta, general, felt, drop, unless, throw, interested, hang, certainly, absolutely, earth, loved, dark, wonder, accident, seeing, turned, clock, simple, doin, date, sweet, meeting, clean, sign, feet, handle, music, report, giving, army, fucked, cops, charlie, smart, yesterday, information, fall, fault, bank, class, month, blow, swear, caught, major, paul, road, talked, choice, plane, boss, david, paid, wear, american, worried, lord, paper, goodbye, clothes, ones, terrible, strange, given, mistake, finish, kept, blue, murder, hurry, apartment, sell, middle, nothin, careful, hasn, meant, walter, moving, changed, imagine, fair, difference, quiet, happening, near, quit, personal, marry, figured, future, rose, building, mama, michael, early, agent, kinda, watching, private, trip, record, certain, busy, jimmy, broke, sake, longer, store, boat, stick, finally, born, evening, sitting, bucks, ought, chief, lying, history, kiss, honor, darling, lunch, favor, fool, uncle, respect, rich, land, liked, killing, peter, tough, brain, interesting, completely, problems, welcome, nick, wake, honest, radio, dick, cash, dance, dude, james, bout, floor, weird, court, calls, jail, drunk, window, involved, johnny, officer, needed, asshole, situation, spend, books, relax, pain, service, grand, dangerous, letter, security, stopped, offer, realize, table, bastard, message, instead, killer, jake, deep, nervous, somethin, pass, evil, english, bought, short, step, ring, picked, likes, machine, eddie, voice, upset, forgot, carry, lived, afternoon, fear, quick, finished, count, forgive, wrote, named, decided, totally, space, team, pleasure, doubt, lawyer, station, gotten, suit, bother, prove, return, slow, pictures, bunch, strong, list, wearing, driving, join, tape, christmas, attack, appreciate, force, church, college, hungry, standing, present, dying, prison, missing, charge, board, truck, public, calm, gold, staying, ball, hardly, hadn, missed, lead, island, government, horse, cover, french, reach, joke, fish, star, mike, surprise, america, moved, soul, dress, seconds, club, self, putting, movies, lots, cost, listening, price, saved, smell, mark, peace, dreams, entire, crime, gives, usually, single, department, holy, beer, west, protect, stuck, wall, nose, ways, teach, forever, grow, train, type, awful, rock, detective, billy, walking, dumb, papers, beginning, planet, folks, park, attention, birthday, hide, card, master, share, reading, test, starting, lieutenant, field, partner, enjoy, twice, film, dollar, bomb, mess, blame, south, loves, girlfriend, round, records, using, plenty, especially, gentlemen, evidence, silly, experience, admit, fired, normal, talkin, mission, louis, memory, fighting, lock, notice, crap, wedding, promised, marriage, ground, guns, glass, idiot, orders, impossible, heaven, knock, hole, neck, animal, spent, green, wondering, nuts, press, drugs, broken, position, names, asleep, jerry, visit, boyfriend, acting, feels, plans, paris, smoke, tells, wind, cross, holding, sheriff, gimme, walked, mention, writing, double, brothers, code, judge, pardon, keeps, fellow, fell, closed, lovely, angry, cute, charles, surprised, percent, correct, bathroom, agree, address, andy, ridiculous, summer, tommy, rules, group, account, note, pulled, sleeping, sing, learned, proud, laugh, colonel, upstairs, river, difficult, built, jump, area, dirty, betty, bridge, breakfast, bobby, locked, amazing, north, feelings, alex, plus, definitely, worst, accept, kick, seriously, grace, steal, wild, stories, file, gettin, relationship, advice, nature, contact, spot, places, waste, knowing, beach, stole, apart, favorite, faith, level, loose, risk, song, eating, foot, played, patient, washington, turns, witness, action, build, obviously, begin, split, crew, command, games, tight, decide, nurse, keeping, runs, form, bird, copy, insane, complete, arrest, consider, taste, scene, jeffrey, teeth, shoes, career, henry, sooner, devil, monster, showed, weekend, gift, innocent, study, heavy, hall, comin, danger, greatest, track, keys, raise, destroy, concerned, program, carl, blind, apologize, suddenly, hanging, bruce, california, chicken, seventy, forward, drinking, sweetheart, medical, suspect, admiral, guard, shop, professor, legs, willing, camp, data, ticket, tree, goodnight, television, losing, senator, murdered, burn, dunno, paying, possibly, trick, dropped, credit, extra, starts, warm, hiding, meaning, sold, stone, taught, marty, lately, cheap, lookin, science, simply, jeff, corner, harold, following, majesty, queen, duty, cars, training, heads, seat, discuss, bear, enemy, helped, noticed, common, screw, dave)
topics: Array[Array[(String, Double)]] = Array(Array((just,0.030515134931284552), (like,0.02463563559747823), (want,0.022529385381465025), (damn,0.02094828832824297), (going,0.0203407289886203)), Array((yeah,0.10787301090151602), (look,0.0756831002291994), (know,0.04815746564274915), (wait,0.03897182014529944), (night,0.0341458394828345)), Array((gonna,0.08118584492034046), (money,0.051736711600637544), (shit,0.04620430294274594), (fuck,0.0399843125556081), (kill,0.03672740843080258)), Array((people,0.020091372023286612), (know,0.018613400462887356), (work,0.016775643603287843), (does,0.015522555458447744), (think,0.012161168331925723)), Array((know,0.031956573561538214), (just,0.030674598809934856), (want,0.027663491240851962), (tell,0.025727217382788027), (right,0.02300853167338119)), Array((love,0.05932570200934131), (father,0.030080735900045442), (life,0.01769248067468245), (true,0.016281752071881345), (young,0.014927950883812253)), Array((remember,0.03998401809663685), (went,0.01737965538107633), (lost,0.016916065536574213), (called,0.016443441316683228), (story,0.014849882671062261)), Array((house,0.028911209424810257), (miss,0.025669944694943093), (right,0.02091105252727788), (family,0.017862939987512365), (important,0.013959164390834044)), Array((saying,0.022939827090645636), (know,0.021335083902970984), (idea,0.017628999871937747), (business,0.017302568063786224), (police,0.012284217866942303)), Array((know,0.051876601466269136), (like,0.03828159069993671), (maybe,0.03754385940676905), (just,0.031938551661426284), (want,0.02876693222824349)), Array((years,0.032537676027398765), (going,0.030596831997667568), (case,0.02049555392502822), (doctor,0.018671171294737107), (working,0.017672067172167016)), Array((stuff,0.02236582778896705), (school,0.020057798194969816), (john,0.017134198006217606), (week,0.017075852415410653), (thousand,0.017013413435021035)), Array((little,0.08663446368316245), (girl,0.035120377589734936), (like,0.02992080326340266), (woman,0.0240813719635157), (baby,0.022471517953608963)), Array((know,0.0283115823590395), (leave,0.02744935904744228), (time,0.02050833156294194), (want,0.020124145131863225), (just,0.019466336438890477)), Array((didn,0.08220031921979461), (like,0.05062323326717784), (real,0.03087838046777391), (guess,0.02452989702353384), (says,0.022815035397008333)), Array((minutes,0.018541518543996716), (time,0.014737962244588431), (captain,0.012594614743931537), (thirty,0.01193707771669708), (ship,0.011260576815409516)), Array((okay,0.08153575328080886), (just,0.050004142902999975), (right,0.03438984898476042), (know,0.02821327795933634), (home,0.023397063860326372)), Array((country,0.011270500385627474), (power,0.010428408353623762), (president,0.009392162067926028), (fight,0.00799742811584178), (possible,0.007597974486019279)), Array((know,0.09541058020800194), (think,0.0698707939786508), (really,0.06881812755565207), (mean,0.02909700228968688), (just,0.028699687473471538)), Array((dead,0.03833642117149438), (like,0.017873711992106994), (hand,0.015280854355409379), (white,0.013718491413582671), (blood,0.012699265888344448)))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">top10ConversationsPerTopic</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res54: (Array[Long], Array[Double]) = (Array(22243, 39967, 18136, 18149, 59043, 61513, 34087, 75874, 66270, 68876),Array(0.9986758340945384, 0.99866200816902, 0.9982983538060165, 0.9982983538060165, 0.9982983538060165, 0.9982983538060165, 0.9982983538060165, 0.9982983538060165, 0.9982983538060165, 0.9982983538060165))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">top10ConversationsPerTopic</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res55: Array[Long] = Array(22243, 39967, 18136, 18149, 59043, 61513, 34087, 75874, 66270, 68876)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">scenesForTopic2</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">top10ConversationsPerTopic</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>scenesForTopic2: org.apache.spark.sql.DataFrame = [id: bigint]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">scenesForTopic2</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpusDF</span><span class="p">,</span><span class="s2">&quot;id&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">top10ConversationsPerTopic</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpusDF</span><span class="p">,</span><span class="s2">&quot;id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">false</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-----+----------------------------------------------------------------------------------+----------------------+---------+
|id   |corpus                                                                            |movieTitle            |movieYear|
+-----+----------------------------------------------------------------------------------+----------------------+---------+
|22243|Fuck him. :-()-: Don&#39;t. :-()-: Fuck her too.                                      |panic room            |2002     |
|59043|Are you ok? :-()-: Fuck no.                                                       |magnolia              |1999     |
|66270|Hey now... what the fuck... ? :-()-: Again.                                       |red white black &amp; blue|2006     |
|75874|What about Moliere? :-()-: Fuck off.                                              |the beach             |2000/I   |
|68876|What the fuck is that? :-()-: A switchblade.                                      |seven                 |1979     |
|34087|Fuck me!  Yes! :-()-: Uh...                                                       |american pie          |1999     |
|61513|What the fuck is that?! :-()-: Screamer.                                          |arcade                |1993     |
|18136|What the fuck was that about? :-()-: She was jonesing for me.                     |made                  |2001     |
|18149|C&#39;mon... :-()-: Fuck...                                                           |made                  |2001     |
|39967|Shit, shit, shit... :-()-: You&#39;re almost there, you can do it -- can do -- can do.|broadcast news        |1987     |
+-----+----------------------------------------------------------------------------------+----------------------+---------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">top10ConversationsPerTopic</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">_1</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">corpusDF</span><span class="p">,</span><span class="s2">&quot;id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">false</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-----+---------------------------------------------------------+-----------------+---------+
|id   |corpus                                                   |movieTitle       |movieYear|
+-----+---------------------------------------------------------+-----------------+---------+
|68250|I love you man :-()-: I love you too.                    |say anything...  |1989     |
|31256|I love you. :-()-: I love you.                           |total recall     |1990     |
|868  |I love you. :-()-: I love you.                           |8mm              |1999     |
|17285|Do me. :-()-: I love you. :-()-: I love you.             |little nicky     |2000     |
|56529|Why do you love me? :-()-: Why do you love me?           |jerry maguire    |1996     |
|67529|I love you, too. :-()-: I love you.  I love you.         |runaway bride    |1999     |
|82132|Why did you say that? :-()-: Say what? :-()-: I love you.|willow           |1988     |
|50163|I love you, Bud. :-()-: I love you more.                 |frequency        |2000     |
|39173|I love you. :-()-: I love you too, Dad.                  |body of evidence |1993     |
|57385|Yes? :-()-: I love you...                                |kramer vs. kramer|1979     |
+-----+---------------------------------------------------------+-----------------+---------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">corpusDF</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-----+--------------------+------------+---------+
|   id|              corpus|  movieTitle|movieYear|
+-----+--------------------+------------+---------+
|17668|This would be fun...|lost horizon|     1937|
|17598|Cave, eh? Where? ...|lost horizon|     1937|
|17663|Something grand a...|lost horizon|     1937|
|17593|You see? You get ...|lost horizon|     1937|
|17658|Let me up! Let me...|lost horizon|     1937|
+-----+--------------------+------------+---------+
only showing top 5 rows
</pre></div>
</div>
</div></blockquote>
<p>We’ve managed to get some good results here. For example, we can easily
infer that Topic 2 is about space, Topic 3 is about israel, etc.</p>
<p>We still get some ambiguous results like Topic 0.</p>
<p>To improve our results further, we could employ some of the below
methods:</p>
<ul class="simple">
<li><p>Refilter data for additional data-specific stopwords</p></li>
<li><p>Use Stemming or Lemmatization to preprocess data</p></li>
<li><p>Experiment with a smaller number of topics, since some of these
topics in the 20 Newsgroups are pretty similar</p></li>
<li><p>Increase model’s MaxIterations</p></li>
</ul>
</div>
<div class="section" id="visualize-results">
<h2>Visualize Results<a class="headerlink" href="#visualize-results" title="Permalink to this headline">¶</a></h2>
<p>We will try visualizing the results obtained from the EM LDA model with
a d3 bubble chart.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Zip</span> <span class="n">topic</span> <span class="n">terms</span> <span class="k">with</span> <span class="n">topic</span> <span class="n">IDs</span>
<span class="n">val</span> <span class="n">termArray</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">zipWithIndex</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>termArray: Array[(Array[(String, Double)], Int)] = Array((Array((just,0.030515134931284552), (like,0.02463563559747823), (want,0.022529385381465025), (damn,0.02094828832824297), (going,0.0203407289886203)),0), (Array((yeah,0.10787301090151602), (look,0.0756831002291994), (know,0.04815746564274915), (wait,0.03897182014529944), (night,0.0341458394828345)),1), (Array((gonna,0.08118584492034046), (money,0.051736711600637544), (shit,0.04620430294274594), (fuck,0.0399843125556081), (kill,0.03672740843080258)),2), (Array((people,0.020091372023286612), (know,0.018613400462887356), (work,0.016775643603287843), (does,0.015522555458447744), (think,0.012161168331925723)),3), (Array((know,0.031956573561538214), (just,0.030674598809934856), (want,0.027663491240851962), (tell,0.025727217382788027), (right,0.02300853167338119)),4), (Array((love,0.05932570200934131), (father,0.030080735900045442), (life,0.01769248067468245), (true,0.016281752071881345), (young,0.014927950883812253)),5), (Array((remember,0.03998401809663685), (went,0.01737965538107633), (lost,0.016916065536574213), (called,0.016443441316683228), (story,0.014849882671062261)),6), (Array((house,0.028911209424810257), (miss,0.025669944694943093), (right,0.02091105252727788), (family,0.017862939987512365), (important,0.013959164390834044)),7), (Array((saying,0.022939827090645636), (know,0.021335083902970984), (idea,0.017628999871937747), (business,0.017302568063786224), (police,0.012284217866942303)),8), (Array((know,0.051876601466269136), (like,0.03828159069993671), (maybe,0.03754385940676905), (just,0.031938551661426284), (want,0.02876693222824349)),9), (Array((years,0.032537676027398765), (going,0.030596831997667568), (case,0.02049555392502822), (doctor,0.018671171294737107), (working,0.017672067172167016)),10), (Array((stuff,0.02236582778896705), (school,0.020057798194969816), (john,0.017134198006217606), (week,0.017075852415410653), (thousand,0.017013413435021035)),11), (Array((little,0.08663446368316245), (girl,0.035120377589734936), (like,0.02992080326340266), (woman,0.0240813719635157), (baby,0.022471517953608963)),12), (Array((know,0.0283115823590395), (leave,0.02744935904744228), (time,0.02050833156294194), (want,0.020124145131863225), (just,0.019466336438890477)),13), (Array((didn,0.08220031921979461), (like,0.05062323326717784), (real,0.03087838046777391), (guess,0.02452989702353384), (says,0.022815035397008333)),14), (Array((minutes,0.018541518543996716), (time,0.014737962244588431), (captain,0.012594614743931537), (thirty,0.01193707771669708), (ship,0.011260576815409516)),15), (Array((okay,0.08153575328080886), (just,0.050004142902999975), (right,0.03438984898476042), (know,0.02821327795933634), (home,0.023397063860326372)),16), (Array((country,0.011270500385627474), (power,0.010428408353623762), (president,0.009392162067926028), (fight,0.00799742811584178), (possible,0.007597974486019279)),17), (Array((know,0.09541058020800194), (think,0.0698707939786508), (really,0.06881812755565207), (mean,0.02909700228968688), (just,0.028699687473471538)),18), (Array((dead,0.03833642117149438), (like,0.017873711992106994), (hand,0.015280854355409379), (white,0.013718491413582671), (blood,0.012699265888344448)),19))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Transform</span> <span class="n">data</span> <span class="n">into</span> <span class="n">the</span> <span class="n">form</span> <span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">probability</span><span class="p">,</span> <span class="n">topicId</span><span class="p">)</span>
<span class="n">val</span> <span class="n">termRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">termArray</span><span class="p">)</span>
<span class="n">val</span> <span class="n">termRDD2</span> <span class="o">=</span><span class="n">termRDD</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">Array</span><span class="p">[(</span><span class="n">String</span><span class="p">,</span> <span class="n">Double</span><span class="p">)],</span> <span class="n">Int</span><span class="p">))</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="n">val</span> <span class="n">arrayOfTuple</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span>
  <span class="n">val</span> <span class="n">topicId</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span>
  <span class="n">arrayOfTuple</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">el</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">el</span><span class="o">.</span><span class="n">_1</span><span class="p">,</span> <span class="n">el</span><span class="o">.</span><span class="n">_2</span><span class="p">,</span> <span class="n">topicId</span><span class="p">))</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>termRDD: org.apache.spark.rdd.RDD[(Array[(String, Double)], Int)] = ParallelCollectionRDD[3066] at parallelize at &lt;console&gt;:109
termRDD2: org.apache.spark.rdd.RDD[(String, Double, Int)] = MapPartitionsRDD[3067] at flatMap at &lt;console&gt;:110
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Create</span> <span class="n">DF</span> <span class="k">with</span> <span class="n">proper</span> <span class="n">column</span> <span class="n">names</span>
<span class="n">val</span> <span class="n">termDF</span> <span class="o">=</span> <span class="n">termRDD2</span><span class="o">.</span><span class="n">toDF</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;_1&quot;</span><span class="p">,</span> <span class="s2">&quot;term&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;_2&quot;</span><span class="p">,</span> <span class="s2">&quot;probability&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;_3&quot;</span><span class="p">,</span> <span class="s2">&quot;topicId&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>termDF: org.apache.spark.sql.DataFrame = [term: string, probability: double, topicId: int]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">termDF</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>Truncated to 30 rows</p>
<p>We will convert the DataFrame into a JSON format, which will be passed
into d3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Create</span> <span class="n">JSON</span> <span class="n">data</span>
<span class="n">val</span> <span class="n">rawJson</span> <span class="o">=</span> <span class="n">termDF</span><span class="o">.</span><span class="n">toJSON</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rawJson: String = 
{&quot;term&quot;:&quot;just&quot;,&quot;probability&quot;:0.030515134931284552,&quot;topicId&quot;:0},
{&quot;term&quot;:&quot;like&quot;,&quot;probability&quot;:0.02463563559747823,&quot;topicId&quot;:0},
{&quot;term&quot;:&quot;want&quot;,&quot;probability&quot;:0.022529385381465025,&quot;topicId&quot;:0},
{&quot;term&quot;:&quot;damn&quot;,&quot;probability&quot;:0.02094828832824297,&quot;topicId&quot;:0},
{&quot;term&quot;:&quot;going&quot;,&quot;probability&quot;:0.0203407289886203,&quot;topicId&quot;:0},
{&quot;term&quot;:&quot;yeah&quot;,&quot;probability&quot;:0.10787301090151602,&quot;topicId&quot;:1},
{&quot;term&quot;:&quot;look&quot;,&quot;probability&quot;:0.0756831002291994,&quot;topicId&quot;:1},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.04815746564274915,&quot;topicId&quot;:1},
{&quot;term&quot;:&quot;wait&quot;,&quot;probability&quot;:0.03897182014529944,&quot;topicId&quot;:1},
{&quot;term&quot;:&quot;night&quot;,&quot;probability&quot;:0.0341458394828345,&quot;topicId&quot;:1},
{&quot;term&quot;:&quot;gonna&quot;,&quot;probability&quot;:0.08118584492034046,&quot;topicId&quot;:2},
{&quot;term&quot;:&quot;money&quot;,&quot;probability&quot;:0.051736711600637544,&quot;topicId&quot;:2},
{&quot;term&quot;:&quot;shit&quot;,&quot;probability&quot;:0.04620430294274594,&quot;topicId&quot;:2},
{&quot;term&quot;:&quot;fuck&quot;,&quot;probability&quot;:0.0399843125556081,&quot;topicId&quot;:2},
{&quot;term&quot;:&quot;kill&quot;,&quot;probability&quot;:0.03672740843080258,&quot;topicId&quot;:2},
{&quot;term&quot;:&quot;people&quot;,&quot;probability&quot;:0.020091372023286612,&quot;topicId&quot;:3},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.018613400462887356,&quot;topicId&quot;:3},
{&quot;term&quot;:&quot;work&quot;,&quot;probability&quot;:0.016775643603287843,&quot;topicId&quot;:3},
{&quot;term&quot;:&quot;does&quot;,&quot;probability&quot;:0.015522555458447744,&quot;topicId&quot;:3},
{&quot;term&quot;:&quot;think&quot;,&quot;probability&quot;:0.012161168331925723,&quot;topicId&quot;:3},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.031956573561538214,&quot;topicId&quot;:4},
{&quot;term&quot;:&quot;just&quot;,&quot;probability&quot;:0.030674598809934856,&quot;topicId&quot;:4},
{&quot;term&quot;:&quot;want&quot;,&quot;probability&quot;:0.027663491240851962,&quot;topicId&quot;:4},
{&quot;term&quot;:&quot;tell&quot;,&quot;probability&quot;:0.025727217382788027,&quot;topicId&quot;:4},
{&quot;term&quot;:&quot;right&quot;,&quot;probability&quot;:0.02300853167338119,&quot;topicId&quot;:4},
{&quot;term&quot;:&quot;love&quot;,&quot;probability&quot;:0.05932570200934131,&quot;topicId&quot;:5},
{&quot;term&quot;:&quot;father&quot;,&quot;probability&quot;:0.030080735900045442,&quot;topicId&quot;:5},
{&quot;term&quot;:&quot;life&quot;,&quot;probability&quot;:0.01769248067468245,&quot;topicId&quot;:5},
{&quot;term&quot;:&quot;true&quot;,&quot;probability&quot;:0.016281752071881345,&quot;topicId&quot;:5},
{&quot;term&quot;:&quot;young&quot;,&quot;probability&quot;:0.014927950883812253,&quot;topicId&quot;:5},
{&quot;term&quot;:&quot;remember&quot;,&quot;probability&quot;:0.03998401809663685,&quot;topicId&quot;:6},
{&quot;term&quot;:&quot;went&quot;,&quot;probability&quot;:0.01737965538107633,&quot;topicId&quot;:6},
{&quot;term&quot;:&quot;lost&quot;,&quot;probability&quot;:0.016916065536574213,&quot;topicId&quot;:6},
{&quot;term&quot;:&quot;called&quot;,&quot;probability&quot;:0.016443441316683228,&quot;topicId&quot;:6},
{&quot;term&quot;:&quot;story&quot;,&quot;probability&quot;:0.014849882671062261,&quot;topicId&quot;:6},
{&quot;term&quot;:&quot;house&quot;,&quot;probability&quot;:0.028911209424810257,&quot;topicId&quot;:7},
{&quot;term&quot;:&quot;miss&quot;,&quot;probability&quot;:0.025669944694943093,&quot;topicId&quot;:7},
{&quot;term&quot;:&quot;right&quot;,&quot;probability&quot;:0.02091105252727788,&quot;topicId&quot;:7},
{&quot;term&quot;:&quot;family&quot;,&quot;probability&quot;:0.017862939987512365,&quot;topicId&quot;:7},
{&quot;term&quot;:&quot;important&quot;,&quot;probability&quot;:0.013959164390834044,&quot;topicId&quot;:7},
{&quot;term&quot;:&quot;saying&quot;,&quot;probability&quot;:0.022939827090645636,&quot;topicId&quot;:8},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.021335083902970984,&quot;topicId&quot;:8},
{&quot;term&quot;:&quot;idea&quot;,&quot;probability&quot;:0.017628999871937747,&quot;topicId&quot;:8},
{&quot;term&quot;:&quot;business&quot;,&quot;probability&quot;:0.017302568063786224,&quot;topicId&quot;:8},
{&quot;term&quot;:&quot;police&quot;,&quot;probability&quot;:0.012284217866942303,&quot;topicId&quot;:8},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.051876601466269136,&quot;topicId&quot;:9},
{&quot;term&quot;:&quot;like&quot;,&quot;probability&quot;:0.03828159069993671,&quot;topicId&quot;:9},
{&quot;term&quot;:&quot;maybe&quot;,&quot;probability&quot;:0.03754385940676905,&quot;topicId&quot;:9},
{&quot;term&quot;:&quot;just&quot;,&quot;probability&quot;:0.031938551661426284,&quot;topicId&quot;:9},
{&quot;term&quot;:&quot;want&quot;,&quot;probability&quot;:0.02876693222824349,&quot;topicId&quot;:9},
{&quot;term&quot;:&quot;years&quot;,&quot;probability&quot;:0.032537676027398765,&quot;topicId&quot;:10},
{&quot;term&quot;:&quot;going&quot;,&quot;probability&quot;:0.030596831997667568,&quot;topicId&quot;:10},
{&quot;term&quot;:&quot;case&quot;,&quot;probability&quot;:0.02049555392502822,&quot;topicId&quot;:10},
{&quot;term&quot;:&quot;doctor&quot;,&quot;probability&quot;:0.018671171294737107,&quot;topicId&quot;:10},
{&quot;term&quot;:&quot;working&quot;,&quot;probability&quot;:0.017672067172167016,&quot;topicId&quot;:10},
{&quot;term&quot;:&quot;stuff&quot;,&quot;probability&quot;:0.02236582778896705,&quot;topicId&quot;:11},
{&quot;term&quot;:&quot;school&quot;,&quot;probability&quot;:0.020057798194969816,&quot;topicId&quot;:11},
{&quot;term&quot;:&quot;john&quot;,&quot;probability&quot;:0.017134198006217606,&quot;topicId&quot;:11},
{&quot;term&quot;:&quot;week&quot;,&quot;probability&quot;:0.017075852415410653,&quot;topicId&quot;:11},
{&quot;term&quot;:&quot;thousand&quot;,&quot;probability&quot;:0.017013413435021035,&quot;topicId&quot;:11},
{&quot;term&quot;:&quot;little&quot;,&quot;probability&quot;:0.08663446368316245,&quot;topicId&quot;:12},
{&quot;term&quot;:&quot;girl&quot;,&quot;probability&quot;:0.035120377589734936,&quot;topicId&quot;:12},
{&quot;term&quot;:&quot;like&quot;,&quot;probability&quot;:0.02992080326340266,&quot;topicId&quot;:12},
{&quot;term&quot;:&quot;woman&quot;,&quot;probability&quot;:0.0240813719635157,&quot;topicId&quot;:12},
{&quot;term&quot;:&quot;baby&quot;,&quot;probability&quot;:0.022471517953608963,&quot;topicId&quot;:12},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.0283115823590395,&quot;topicId&quot;:13},
{&quot;term&quot;:&quot;leave&quot;,&quot;probability&quot;:0.02744935904744228,&quot;topicId&quot;:13},
{&quot;term&quot;:&quot;time&quot;,&quot;probability&quot;:0.02050833156294194,&quot;topicId&quot;:13},
{&quot;term&quot;:&quot;want&quot;,&quot;probability&quot;:0.020124145131863225,&quot;topicId&quot;:13},
{&quot;term&quot;:&quot;just&quot;,&quot;probability&quot;:0.019466336438890477,&quot;topicId&quot;:13},
{&quot;term&quot;:&quot;didn&quot;,&quot;probability&quot;:0.08220031921979461,&quot;topicId&quot;:14},
{&quot;term&quot;:&quot;like&quot;,&quot;probability&quot;:0.05062323326717784,&quot;topicId&quot;:14},
{&quot;term&quot;:&quot;real&quot;,&quot;probability&quot;:0.03087838046777391,&quot;topicId&quot;:14},
{&quot;term&quot;:&quot;guess&quot;,&quot;probability&quot;:0.02452989702353384,&quot;topicId&quot;:14},
{&quot;term&quot;:&quot;says&quot;,&quot;probability&quot;:0.022815035397008333,&quot;topicId&quot;:14},
{&quot;term&quot;:&quot;minutes&quot;,&quot;probability&quot;:0.018541518543996716,&quot;topicId&quot;:15},
{&quot;term&quot;:&quot;time&quot;,&quot;probability&quot;:0.014737962244588431,&quot;topicId&quot;:15},
{&quot;term&quot;:&quot;captain&quot;,&quot;probability&quot;:0.012594614743931537,&quot;topicId&quot;:15},
{&quot;term&quot;:&quot;thirty&quot;,&quot;probability&quot;:0.01193707771669708,&quot;topicId&quot;:15},
{&quot;term&quot;:&quot;ship&quot;,&quot;probability&quot;:0.011260576815409516,&quot;topicId&quot;:15},
{&quot;term&quot;:&quot;okay&quot;,&quot;probability&quot;:0.08153575328080886,&quot;topicId&quot;:16},
{&quot;term&quot;:&quot;just&quot;,&quot;probability&quot;:0.050004142902999975,&quot;topicId&quot;:16},
{&quot;term&quot;:&quot;right&quot;,&quot;probability&quot;:0.03438984898476042,&quot;topicId&quot;:16},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.02821327795933634,&quot;topicId&quot;:16},
{&quot;term&quot;:&quot;home&quot;,&quot;probability&quot;:0.023397063860326372,&quot;topicId&quot;:16},
{&quot;term&quot;:&quot;country&quot;,&quot;probability&quot;:0.011270500385627474,&quot;topicId&quot;:17},
{&quot;term&quot;:&quot;power&quot;,&quot;probability&quot;:0.010428408353623762,&quot;topicId&quot;:17},
{&quot;term&quot;:&quot;president&quot;,&quot;probability&quot;:0.009392162067926028,&quot;topicId&quot;:17},
{&quot;term&quot;:&quot;fight&quot;,&quot;probability&quot;:0.00799742811584178,&quot;topicId&quot;:17},
{&quot;term&quot;:&quot;possible&quot;,&quot;probability&quot;:0.007597974486019279,&quot;topicId&quot;:17},
{&quot;term&quot;:&quot;know&quot;,&quot;probability&quot;:0.09541058020800194,&quot;topicId&quot;:18},
{&quot;term&quot;:&quot;think&quot;,&quot;probability&quot;:0.0698707939786508,&quot;topicId&quot;:18},
{&quot;term&quot;:&quot;really&quot;,&quot;probability&quot;:0.06881812755565207,&quot;topicId&quot;:18},
{&quot;term&quot;:&quot;mean&quot;,&quot;probability&quot;:0.02909700228968688,&quot;topicId&quot;:18},
{&quot;term&quot;:&quot;just&quot;,&quot;probability&quot;:0.028699687473471538,&quot;topicId&quot;:18},
{&quot;term&quot;:&quot;dead&quot;,&quot;probability&quot;:0.03833642117149438,&quot;topicId&quot;:19},
{&quot;term&quot;:&quot;like&quot;,&quot;probability&quot;:0.017873711992106994,&quot;topicId&quot;:19},
{&quot;term&quot;:&quot;hand&quot;,&quot;probability&quot;:0.015280854355409379,&quot;topicId&quot;:19},
{&quot;term&quot;:&quot;white&quot;,&quot;probability&quot;:0.013718491413582671,&quot;topicId&quot;:19},
{&quot;term&quot;:&quot;blood&quot;,&quot;probability&quot;:0.012699265888344448,&quot;topicId&quot;:19}
</pre></div>
</div>
</div></blockquote>
<p>We are now ready to use D3 on the rawJson data.</p>
</div>
<div class="section" id="step-1-downloading-and-loading-data-into-dbfs">
<h2>Step 1. Downloading and Loading Data into DBFS<a class="headerlink" href="#step-1-downloading-and-loading-data-into-dbfs" title="Permalink to this headline">¶</a></h2>
<p>Here are the steps taken for downloading and saving data to the
distributed file system. Uncomment them for repeating this process on
your databricks cluster or for downloading a new source of data.</p>
<p>Unfortunately, the original data at:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip">http://www.mpi-sws.org/~cristian/data/cornell<em>movie</em>dialogs_corpus.zip</a></p></li>
</ul>
<p>is not suited for manipulation and loading into dbfs easily. So the data
has been downloaded, directory renamed without white spaces, superfluous
OS-specific files removed, <code class="docutils literal notranslate"><span class="pre">dos2unix</span></code>’d, <code class="docutils literal notranslate"><span class="pre">tar</span> <span class="pre">-zcvf</span></code>’d and uploaded to
the following URL for an easily dbfs-loadable download:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://lamastex.org/datasets/public/nlp/cornell_movie_dialogs_corpus.tgz">http://lamastex.org/datasets/public/nlp/cornell<em>movie</em>dialogs_corpus.tgz</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">lamastex</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">public</span><span class="o">/</span><span class="n">nlp</span><span class="o">/</span><span class="n">cornell_movie_dialogs_corpus</span><span class="o">.</span><span class="n">tgz</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>--2019-05-17 15:34:09--  http://lamastex.org/datasets/public/nlp/cornell_movie_dialogs_corpus.tgz
Resolving lamastex.org (lamastex.org)... 166.62.28.100
Connecting to lamastex.org (lamastex.org)|166.62.28.100|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 9914415 (9.5M) [application/x-tar]
Saving to: ‘cornell_movie_dialogs_corpus.tgz’

     0K .......... .......... .......... .......... ..........  0%  149K 65s
    50K .......... .......... .......... .......... ..........  1%  300K 48s
   100K .......... .......... .......... .......... ..........  1% 5.69M 33s
   150K .......... .......... .......... .......... ..........  2%  312K 32s
   200K .......... .......... .......... .......... ..........  2% 22.5M 25s
   250K .......... .......... .......... .......... ..........  3% 8.00M 21s
   300K .......... .......... .......... .......... ..........  3% 52.2M 18s
   350K .......... .......... .......... .......... ..........  4%  314K 20s
   400K .......... .......... .......... .......... ..........  4% 37.3M 17s
   450K .......... .......... .......... .......... ..........  5% 41.2M 15s
   500K .......... .......... .......... .......... ..........  5% 9.28M 14s
   550K .......... .......... .......... .......... ..........  6% 54.1M 13s
   600K .......... .......... .......... .......... ..........  6% 26.1M 12s
   650K .......... .......... .......... .......... ..........  7% 49.2M 11s
   700K .......... .......... .......... .......... ..........  7%  322K 12s
   750K .......... .......... .......... .......... ..........  8% 33.0M 11s
   800K .......... .......... .......... .......... ..........  8% 39.0M 10s
   850K .......... .......... .......... .......... ..........  9% 38.2M 10s
   900K .......... .......... .......... .......... ..........  9% 51.5M 9s
   950K .......... .......... .......... .......... .......... 10% 12.6M 9s
  1000K .......... .......... .......... .......... .......... 10% 31.1M 8s
  1050K .......... .......... .......... .......... .......... 11% 41.1M 8s
  1100K .......... .......... .......... .......... .......... 11% 46.0M 8s
  1150K .......... .......... .......... .......... .......... 12% 56.3M 7s
  1200K .......... .......... .......... .......... .......... 12% 45.3M 7s
  1250K .......... .......... .......... .......... .......... 13% 57.1M 7s
  1300K .......... .......... .......... .......... .......... 13% 44.8M 6s
  1350K .......... .......... .......... .......... .......... 14%  329K 7s
  1400K .......... .......... .......... .......... .......... 14% 39.1M 7s
  1450K .......... .......... .......... .......... .......... 15% 54.5M 6s
  1500K .......... .......... .......... .......... .......... 16% 44.4M 6s
  1550K .......... .......... .......... .......... .......... 16% 24.1M 6s
  1600K .......... .......... .......... .......... .......... 17% 33.9M 6s
  1650K .......... .......... .......... .......... .......... 17% 67.3M 6s
  1700K .......... .......... .......... .......... .......... 18% 40.6M 5s
  1750K .......... .......... .......... .......... .......... 18% 23.7M 5s
  1800K .......... .......... .......... .......... .......... 19% 42.5M 5s
  1850K .......... .......... .......... .......... .......... 19% 37.4M 5s
  1900K .......... .......... .......... .......... .......... 20% 45.0M 5s
  1950K .......... .......... .......... .......... .......... 20% 20.0M 5s
  2000K .......... .......... .......... .......... .......... 21% 43.5M 4s
  2050K .......... .......... .......... .......... .......... 21% 44.3M 4s
  2100K .......... .......... .......... .......... .......... 22% 46.3M 4s
  2150K .......... .......... .......... .......... .......... 22% 38.8M 4s
  2200K .......... .......... .......... .......... .......... 23% 46.7M 4s
  2250K .......... .......... .......... .......... .......... 23% 47.0M 4s
  2300K .......... .......... .......... .......... .......... 24%  344K 4s
  2350K .......... .......... .......... .......... .......... 24% 63.1M 4s
  2400K .......... .......... .......... .......... .......... 25% 42.1M 4s
  2450K .......... .......... .......... .......... .......... 25% 13.6M 4s
  2500K .......... .......... .......... .......... .......... 26% 74.5M 4s
  2550K .......... .......... .......... .......... .......... 26% 78.4M 4s
  2600K .......... .......... .......... .......... .......... 27% 61.4M 4s
  2650K .......... .......... .......... .......... .......... 27% 16.6M 4s
  2700K .......... .......... .......... .......... .......... 28%  105M 3s
  2750K .......... .......... .......... .......... .......... 28%  209M 3s
  2800K .......... .......... .......... .......... .......... 29%  181M 3s
  2850K .......... .......... .......... .......... .......... 29% 28.0M 3s
  2900K .......... .......... .......... .......... .......... 30% 31.6M 3s
  2950K .......... .......... .......... .......... .......... 30% 39.0M 3s
  3000K .......... .......... .......... .......... .......... 31% 44.4M 3s
  3050K .......... .......... .......... .......... .......... 32% 43.9M 3s
  3100K .......... .......... .......... .......... .......... 32% 37.0M 3s
  3150K .......... .......... .......... .......... .......... 33% 42.1M 3s
  3200K .......... .......... .......... .......... .......... 33% 44.0M 3s
  3250K .......... .......... .......... .......... .......... 34% 43.8M 3s
  3300K .......... .......... .......... .......... .......... 34% 36.6M 3s
  3350K .......... .......... .......... .......... .......... 35% 43.6M 3s
  3400K .......... .......... .......... .......... .......... 35% 43.2M 2s
  3450K .......... .......... .......... .......... .......... 36% 33.5M 2s
  3500K .......... .......... .......... .......... .......... 36% 47.0M 2s
  3550K .......... .......... .......... .......... .......... 37% 39.0M 2s
  3600K .......... .......... .......... .......... .......... 37% 35.7M 2s
  3650K .......... .......... .......... .......... .......... 38%  369K 2s
  3700K .......... .......... .......... .......... .......... 38% 34.7M 2s
  3750K .......... .......... .......... .......... .......... 39% 39.0M 2s
  3800K .......... .......... .......... .......... .......... 39% 34.6M 2s
  3850K .......... .......... .......... .......... .......... 40% 34.9M 2s
  3900K .......... .......... .......... .......... .......... 40% 38.5M 2s
  3950K .......... .......... .......... .......... .......... 41% 41.9M 2s
  4000K .......... .......... .......... .......... .......... 41% 45.9M 2s
  4050K .......... .......... .......... .......... .......... 42% 48.1M 2s
  4100K .......... .......... .......... .......... .......... 42% 46.3M 2s
  4150K .......... .......... .......... .......... .......... 43% 46.0M 2s
  4200K .......... .......... .......... .......... .......... 43% 41.9M 2s
  4250K .......... .......... .......... .......... .......... 44% 41.0M 2s
  4300K .......... .......... .......... .......... .......... 44% 42.6M 2s
  4350K .......... .......... .......... .......... .......... 45% 45.4M 2s
  4400K .......... .......... .......... .......... .......... 45% 37.2M 2s
  4450K .......... .......... .......... .......... .......... 46% 43.7M 2s
  4500K .......... .......... .......... .......... .......... 46% 40.5M 2s
  4550K .......... .......... .......... .......... .......... 47% 38.8M 2s
  4600K .......... .......... .......... .......... .......... 48% 10.1M 2s
  4650K .......... .......... .......... .......... .......... 48% 69.1M 2s
  4700K .......... .......... .......... .......... .......... 49% 69.0M 2s
  4750K .......... .......... .......... .......... .......... 49% 61.6M 2s
  4800K .......... .......... .......... .......... .......... 50% 77.5M 2s
  4850K .......... .......... .......... .......... .......... 50% 61.0M 2s
  4900K .......... .......... .......... .......... .......... 51% 51.5M 1s
  4950K .......... .......... .......... .......... .......... 51% 35.4M 1s
  5000K .......... .......... .......... .......... .......... 52% 59.5M 1s
  5050K .......... .......... .......... .......... .......... 52% 54.1M 1s
  5100K .......... .......... .......... .......... .......... 53% 44.2M 1s
  5150K .......... .......... .......... .......... .......... 53% 35.5M 1s
  5200K .......... .......... .......... .......... .......... 54%  378K 1s
  5250K .......... .......... .......... .......... .......... 54% 48.9M 1s
  5300K .......... .......... .......... .......... .......... 55% 41.6M 1s
  5350K .......... .......... .......... .......... .......... 55% 27.6M 1s
  5400K .......... .......... .......... .......... .......... 56% 44.9M 1s
  5450K .......... .......... .......... .......... .......... 56% 38.6M 1s
  5500K .......... .......... .......... .......... .......... 57% 40.6M 1s
  5550K .......... .......... .......... .......... .......... 57% 41.9M 1s
  5600K .......... .......... .......... .......... .......... 58% 33.9M 1s
  5650K .......... .......... .......... .......... .......... 58% 42.5M 1s
  5700K .......... .......... .......... .......... .......... 59% 42.5M 1s
  5750K .......... .......... .......... .......... .......... 59% 49.9M 1s
  5800K .......... .......... .......... .......... .......... 60% 37.7M 1s
  5850K .......... .......... .......... .......... .......... 60% 33.6M 1s
  5900K .......... .......... .......... .......... .......... 61% 83.1M 1s
  5950K .......... .......... .......... .......... .......... 61% 44.4M 1s
  6000K .......... .......... .......... .......... .......... 62% 37.5M 1s
  6050K .......... .......... .......... .......... .......... 63% 40.7M 1s
  6100K .......... .......... .......... .......... .......... 63% 7.12M 1s
  6150K .......... .......... .......... .......... .......... 64%  151M 1s
  6200K .......... .......... .......... .......... .......... 64% 70.0M 1s
  6250K .......... .......... .......... .......... .......... 65% 68.6M 1s
  6300K .......... .......... .......... .......... .......... 65% 20.3M 1s
  6350K .......... .......... .......... .......... .......... 66% 75.8M 1s
  6400K .......... .......... .......... .......... .......... 66% 81.5M 1s
  6450K .......... .......... .......... .......... .......... 67% 91.8M 1s
  6500K .......... .......... .......... .......... .......... 67% 67.8M 1s
  6550K .......... .......... .......... .......... .......... 68% 86.9M 1s
  6600K .......... .......... .......... .......... .......... 68% 63.7M 1s
  6650K .......... .......... .......... .......... .......... 69% 73.2M 1s
  6700K .......... .......... .......... .......... .......... 69% 43.3M 1s
  6750K .......... .......... .......... .......... .......... 70%  380K 1s
  6800K .......... .......... .......... .......... .......... 70% 41.2M 1s
  6850K .......... .......... .......... .......... .......... 71% 31.4M 1s
  6900K .......... .......... .......... .......... .......... 71% 44.5M 1s
  6950K .......... .......... .......... .......... .......... 72% 44.1M 1s
  7000K .......... .......... .......... .......... .......... 72% 38.3M 1s
  7050K .......... .......... .......... .......... .......... 73% 36.5M 1s
  7100K .......... .......... .......... .......... .......... 73% 50.3M 1s
  7150K .......... .......... .......... .......... .......... 74% 34.5M 1s
  7200K .......... .......... .......... .......... .......... 74% 42.9M 1s
  7250K .......... .......... .......... .......... .......... 75% 32.7M 1s
  7300K .......... .......... .......... .......... .......... 75% 37.6M 1s
  7350K .......... .......... .......... .......... .......... 76% 45.9M 1s
  7400K .......... .......... .......... .......... .......... 76% 40.2M 1s
  7450K .......... .......... .......... .......... .......... 77% 45.2M 1s
  7500K .......... .......... .......... .......... .......... 77% 26.1M 1s
  7550K .......... .......... .......... .......... .......... 78% 36.2M 1s
  7600K .......... .......... .......... .......... .......... 79% 61.6M 0s
  7650K .......... .......... .......... .......... .......... 79% 66.4M 0s
  7700K .......... .......... .......... .......... .......... 80% 21.5M 0s
  7750K .......... .......... .......... .......... .......... 80% 64.6M 0s
  7800K .......... .......... .......... .......... .......... 81% 49.1M 0s
  7850K .......... .......... .......... .......... .......... 81% 30.5M 0s
  7900K .......... .......... .......... .......... .......... 82% 40.1M 0s
  7950K .......... .......... .......... .......... .......... 82% 37.1M 0s
  8000K .......... .......... .......... .......... .......... 83% 43.2M 0s
  8050K .......... .......... .......... .......... .......... 83% 38.5M 0s
  8100K .......... .......... .......... .......... .......... 84% 36.4M 0s
  8150K .......... .......... .......... .......... .......... 84% 42.9M 0s
  8200K .......... .......... .......... .......... .......... 85% 40.7M 0s
  8250K .......... .......... .......... .......... .......... 85%  383K 0s
  8300K .......... .......... .......... .......... .......... 86% 26.3M 0s
  8350K .......... .......... .......... .......... .......... 86% 46.3M 0s
  8400K .......... .......... .......... .......... .......... 87% 27.9M 0s
  8450K .......... .......... .......... .......... .......... 87% 51.4M 0s
  8500K .......... .......... .......... .......... .......... 88% 50.3M 0s
  8550K .......... .......... .......... .......... .......... 88% 34.7M 0s
  8600K .......... .......... .......... .......... .......... 89% 38.2M 0s
  8650K .......... .......... .......... .......... .......... 89% 48.4M 0s
  8700K .......... .......... .......... .......... .......... 90% 28.4M 0s
  8750K .......... .......... .......... .......... .......... 90% 42.9M 0s
  8800K .......... .......... .......... .......... .......... 91% 33.5M 0s
  8850K .......... .......... .......... .......... .......... 91% 33.7M 0s
  8900K .......... .......... .......... .......... .......... 92% 34.4M 0s
  8950K .......... .......... .......... .......... .......... 92% 55.0M 0s
  9000K .......... .......... .......... .......... .......... 93% 26.6M 0s
  9050K .......... .......... .......... .......... .......... 93% 66.4M 0s
  9100K .......... .......... .......... .......... .......... 94% 50.6M 0s
  9150K .......... .......... .......... .......... .......... 95% 49.7M 0s
  9200K .......... .......... .......... .......... .......... 95% 46.3M 0s
  9250K .......... .......... .......... .......... .......... 96% 46.0M 0s
  9300K .......... .......... .......... .......... .......... 96% 40.5M 0s
  9350K .......... .......... .......... .......... .......... 97% 41.9M 0s
  9400K .......... .......... .......... .......... .......... 97% 26.7M 0s
  9450K .......... .......... .......... .......... .......... 98% 30.9M 0s
  9500K .......... .......... .......... .......... .......... 98% 42.4M 0s
  9550K .......... .......... .......... .......... .......... 99% 40.1M 0s
  9600K .......... .......... .......... .......... .......... 99% 45.3M 0s
  9650K .......... .......... .......... ..                   100% 33.8M=2.1s

2019-05-17 15:34:11 (4.61 MB/s) - ‘cornell_movie_dialogs_corpus.tgz’ saved [9914415/9914415]
</pre></div>
</div>
</div></blockquote>
<p>Untar the file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar</span> <span class="n">zxvf</span> <span class="n">cornell_movie_dialogs_corpus</span><span class="o">.</span><span class="n">tgz</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cornell_movie_dialogs_corpus/
cornell_movie_dialogs_corpus/movie_lines.txt
cornell_movie_dialogs_corpus/movie_characters_metadata.txt
cornell_movie_dialogs_corpus/README.txt
cornell_movie_dialogs_corpus/raw_script_urls.txt
cornell_movie_dialogs_corpus/movie_titles_metadata.txt
cornell_movie_dialogs_corpus/movie_conversations.txt
cornell_movie_dialogs_corpus/chameleons.pdf
</pre></div>
</div>
</div></blockquote>
<p>Let us list and load all the files into dbfs after <code class="docutils literal notranslate"><span class="pre">dbfs.fs.mkdirs(...)</span></code>
to create the directory
<code class="docutils literal notranslate"><span class="pre">dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pwd</span> <span class="o">&amp;&amp;</span> <span class="n">ls</span> <span class="o">-</span><span class="n">al</span> <span class="n">cornell_movie_dialogs_corpus</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>/databricks/driver
total 41552
drwxr-xr-x 2 ubuntu ubuntu     4096 Jan 11  2017 .
drwxr-xr-x 1 root   root       4096 May 17 15:34 ..
-rw-r--r-- 1 ubuntu ubuntu   290691 May  9  2011 chameleons.pdf
-rw-r--r-- 1 ubuntu ubuntu   705695 Jan 11  2017 movie_characters_metadata.txt
-rw-r--r-- 1 ubuntu ubuntu  6760930 Jan 11  2017 movie_conversations.txt
-rw-r--r-- 1 ubuntu ubuntu 34641919 Jan 11  2017 movie_lines.txt
-rw-r--r-- 1 ubuntu ubuntu    67289 Jan 11  2017 movie_titles_metadata.txt
-rw-r--r-- 1 ubuntu ubuntu    56177 Jan 11  2017 raw_script_urls.txt
-rw-r--r-- 1 ubuntu ubuntu     4181 Jan 11  2017 README.txt
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/&quot;</span><span class="p">,</span><span class="n">true</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res4: Boolean = true
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">mkdirs</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res5: Boolean = true
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="s2">&quot;file:///databricks/driver/cornell_movie_dialogs_corpus/movie_characters_metadata.txt&quot;</span><span class="p">,</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_characters_metadata.txt&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="s2">&quot;file:///databricks/driver/cornell_movie_dialogs_corpus/movie_conversations.txt&quot;</span><span class="p">,</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_conversations.txt&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="s2">&quot;file:///databricks/driver/cornell_movie_dialogs_corpus/movie_lines.txt&quot;</span><span class="p">,</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_lines.txt&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="s2">&quot;file:///databricks/driver/cornell_movie_dialogs_corpus/movie_titles_metadata.txt&quot;</span><span class="p">,</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/movie_titles_metadata.txt&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="s2">&quot;file:///databricks/driver/cornell_movie_dialogs_corpus/raw_script_urls.txt&quot;</span><span class="p">,</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/raw_script_urls.txt&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="s2">&quot;file:///databricks/driver/cornell_movie_dialogs_corpus/README.txt&quot;</span><span class="p">,</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/README.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res6: Boolean = true
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="s2">&quot;dbfs:/datasets/sds/nlp/cornell_movie_dialogs_corpus/&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_1-sds-3-x"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html" title="previous page">Piped RDDs and Bayesian AB Testing</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>