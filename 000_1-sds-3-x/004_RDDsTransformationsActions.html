
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ScaDaMaLe, Scalable Data Science and Distributed Machine Learning &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="005_RDDsTransformationsActionsHOMEWORK.html" />
    <link rel="prev" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="003_01_scalaCrashCourse.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="000_ScaDaMaLe.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="001_whySpark.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="001_whySpark.html#why-apache-spark">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#notebooks">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Let’s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Let’s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#introduction-to-spark">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html#homework-notebook-rdds-transformations-and-actions">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#piped-rdds-and-bayesian-ab-testing">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html#word-count-on-us-state-of-the-union-sou-addresses">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html#spark-sql-programming-guide">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#getting-started">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007c_SparkSQLProgGuide_HW.html#getting-started-exercise">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#data-sources">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html#performance-tuning">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#distributed-sql-engine">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#introduction-to-spark-sql">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wiki-clickstream-analysis">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#plugging-into-gdelt-streams">
   Plugging into GDELT Streams
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#old-bailey-online-data-analysis-in-apache-spark">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html#topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks.html">
   Content with notebooks
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/000_1-sds-3-x/004_RDDsTransformationsActions.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/ScaDaMaLe"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/ScaDaMaLe/issues/new?title=Issue%20on%20page%20%2F000_1-sds-3-x/004_RDDsTransformationsActions.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-to-spark">
   Introduction to Spark
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spark-essentials-rdds-transformations-and-actions">
     Spark Essentials: RDDs, Transformations and Actions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#driver-program-cluster-manager-and-worker-nodes">
     Driver Program, Cluster Manager and Worker Nodes
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-abstraction-of-resilient-distributed-dataset-rdd">
     The Abstraction of Resilient Distributed Dataset (RDD)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rdd-is-a-fault-tolerant-collection-of-elements-that-can-be-operated-on-in-parallel">
       RDD is a fault-tolerant collection of elements that can be operated on in parallel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#two-types-of-operations-are-possible-on-an-rdd">
       Two types of Operations are possible on an RDD
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformations">
     Transformations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#actions">
     Actions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#key-points">
     Key Points
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-us-get-our-hands-dirty-in-spark-implementing-these-ideas">
     Let us get our hands dirty in Spark implementing these ideas!
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#do-now">
       DO NOW
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#let-us-look-at-the-legend-and-overview-of-the-visual-rdd-api-by-doing-the-following-first">
       Let us look at the legend and overview of the visual RDD Api by doing the following first:
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#running-spark">
       Running
       <strong>
        Spark
       </strong>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#we-will-do-the-following-next">
       We will do the following next:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entry-point">
     Entry Point
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-an-rdd-using-sc-parallelize">
       1. Create an RDD using
       <code class="docutils literal notranslate">
        <span class="pre">
         sc.parallelize
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-the-collect-action-on-the-rdd-and-find-the-number-of-partitions-it-is-made-of-using-getnumpartitions-action">
       2. Perform the
       <code class="docutils literal notranslate">
        <span class="pre">
         collect
        </span>
       </code>
       action on the RDD and find the number of partitions it is made of using
       <code class="docutils literal notranslate">
        <span class="pre">
         getNumPartitions
        </span>
       </code>
       action
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-collect-action-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the collect action in detail and return here to try out the example codes.
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-getnumpartitions-action-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the getNumPartitions action in detail and return here to try out the example codes.
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#you-try">
           You Try!
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-the-take-action-on-the-rdd">
       3. Perform the
       <code class="docutils literal notranslate">
        <span class="pre">
         take
        </span>
       </code>
       action on the RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id1">
         You Try!
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transform-the-rdd-by-map-to-make-another-rdd">
       4. Transform the RDD by
       <code class="docutils literal notranslate">
        <span class="pre">
         map
        </span>
       </code>
       to make another RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-map-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the map transformation in detail and return here to try out the example codes.
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transform-the-rdd-by-filter-to-make-another-rdd">
       5. Transform the RDD by
       <code class="docutils literal notranslate">
        <span class="pre">
         filter
        </span>
       </code>
       to make another RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#let-us-look-at-the-filter-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
         Let us look at the filter transformation in detail and return here to try out the example codes.
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-the-reduce-action-on-the-rdd">
       6. Perform the
       <code class="docutils literal notranslate">
        <span class="pre">
         reduce
        </span>
       </code>
       action on the RDD
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#let-us-look-at-the-reduce-action-in-detail-and-return-here-to-try-out-the-example-codes">
       Let us look at the reduce action in detail and return here to try out the example codes.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transform-an-rdd-by-flatmap-to-make-another-rdd">
       7. Transform an RDD by
       <code class="docutils literal notranslate">
        <span class="pre">
         flatMap
        </span>
       </code>
       to make another RDD
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#let-us-look-at-the-flatmap-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
       Let us look at the flatMap transformation in detail and return here to try out the example codes.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-a-pair-rdd">
       8. Create a Pair RDD
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#wide-transformations-and-shuffles">
       Wide Transformations and Shuffles
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#perform-some-transformations-on-a-pair-rdd">
       9. Perform some transformations on a Pair RDD
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id2">
         You Try!
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#understanding-closures-where-in-the-cluster-is-your-computation-running">
       10. Understanding Closures - Where in the cluster is your computation running?
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#shipping-closures-broadcast-variables-and-accumulator-variables">
       11. Shipping Closures, Broadcast Variables and Accumulator Variables
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#closures-broadcast-and-accumulator-variables">
         Closures, Broadcast and Accumulator Variables
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#summary">
         SUMMARY
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accumulators">
     Accumulators
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#broadcast-variables">
     Broadcast Variables
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-more-interesting-example-of-broadcast-variable">
       A more interesting example of broadcast variable
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#homework">
       13. HOMEWORK
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#importing-standard-scala-and-java-libraries">
       Importing Standard Scala and Java libraries
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="scadamale-scalable-data-science-and-distributed-machine-learning">
<h1><a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/3/x/">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a><a class="headerlink" href="#scadamale-scalable-data-science-and-distributed-machine-learning" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="introduction-to-spark">
<h1>Introduction to Spark<a class="headerlink" href="#introduction-to-spark" title="Permalink to this headline">¶</a></h1>
<div class="section" id="spark-essentials-rdds-transformations-and-actions">
<h2>Spark Essentials: RDDs, Transformations and Actions<a class="headerlink" href="#spark-essentials-rdds-transformations-and-actions" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>This introductory notebook describes how to get started running
Spark (Scala) code in Notebooks.</p></li>
<li><p>Working with Spark’s Resilient Distributed Datasets (RDDs)</p>
<ul>
<li><p>creating RDDs</p></li>
<li><p>performing basic transformations on RDDs</p></li>
<li><p>performing basic actions on RDDs</p></li>
</ul>
</li>
</ul>
<p><strong>RECOLLECT</strong> from <code class="docutils literal notranslate"><span class="pre">001_WhySpark</span></code> notebook and AJ’s videos that <em>Spark
does fault-tolerant, distributed, in-memory computing</em></p>
<p><strong>THEORY CAVEAT</strong> This module is focused on getting you to quickly write
Spark programs with a high-level appreciation of the underlying
concepts.</p>
<p>In the last module, we will spend more time on analyzing the core
algorithms in parallel and distributed setting of a typical Spark
cluster today – where several multi-core parallel computers (Spark
workers) are networked together to provide a fault-tolerant distributed
computing platform.</p>
</div>
</div>
<div class="section" id="spark-cluster-overview">
<h1>Spark Cluster Overview:<a class="headerlink" href="#spark-cluster-overview" title="Permalink to this headline">¶</a></h1>
<div class="section" id="driver-program-cluster-manager-and-worker-nodes">
<h2>Driver Program, Cluster Manager and Worker Nodes<a class="headerlink" href="#driver-program-cluster-manager-and-worker-nodes" title="Permalink to this headline">¶</a></h2>
<p>The <em>driver</em> does the following:</p>
<ol class="simple">
<li><p>connects to a <em>cluster manager</em> to allocate resources across
applications</p></li>
</ol>
<ul class="simple">
<li><p>acquire <em>executors</em> on cluster nodes</p>
<ul>
<li><p>executor processs run compute tasks and cache data in memory or
disk on a <em>worker node</em></p></li>
</ul>
</li>
<li><p>sends <em>application</em> (user program built on Spark) to the executors</p></li>
<li><p>sends <em>tasks</em> for the executors to run</p>
<ul>
<li><p>task is a unit of work that will be sent to one executor</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="http://spark.apache.org/docs/latest/img/cluster-overview.png" /></p>
<p>See <a class="reference external" href="http://spark.apache.org/docs/latest/cluster-overview.html">http://spark.apache.org/docs/latest/cluster-overview.html</a> for an
overview of the spark cluster.</p>
</div>
<div class="section" id="the-abstraction-of-resilient-distributed-dataset-rdd">
<h2>The Abstraction of Resilient Distributed Dataset (RDD)<a class="headerlink" href="#the-abstraction-of-resilient-distributed-dataset-rdd" title="Permalink to this headline">¶</a></h2>
<div class="section" id="rdd-is-a-fault-tolerant-collection-of-elements-that-can-be-operated-on-in-parallel">
<h3>RDD is a fault-tolerant collection of elements that can be operated on in parallel<a class="headerlink" href="#rdd-is-a-fault-tolerant-collection-of-elements-that-can-be-operated-on-in-parallel" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="two-types-of-operations-are-possible-on-an-rdd">
<h3>Two types of Operations are possible on an RDD<a class="headerlink" href="#two-types-of-operations-are-possible-on-an-rdd" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Transformations</p></li>
<li><p>Actions</p></li>
</ul>
<p><strong>(watch now 2:26)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=3nreQ1N7Jvk?rel=0&amp;autoplay=1&amp;modestbranding=1&amp;start=1&amp;end=146"><img alt="RDD in Spark by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/3nreQ1N7Jvk/0.jpg" /></a></p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="transformations">
<h2>Transformations<a class="headerlink" href="#transformations" title="Permalink to this headline">¶</a></h2>
<p><strong>(watch now 1:18)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=360UHWy052k?rel=0&amp;autoplay=1&amp;modestbranding=1"><img alt="Spark Transformations by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/360UHWy052k/0.jpg" /></a></p>
</div>
<hr class="docutils" />
<div class="section" id="actions">
<h2>Actions<a class="headerlink" href="#actions" title="Permalink to this headline">¶</a></h2>
<p><strong>(watch now 0:48)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=F2G4Wbc5ZWQ?rel=0&amp;autoplay=1&amp;modestbranding=1&amp;start=1&amp;end=48"><img alt="Spark Actions by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/F2G4Wbc5ZWQ/0.jpg" /></a></p>
</div>
<hr class="docutils" />
<div class="section" id="key-points">
<h2>Key Points<a class="headerlink" href="#key-points" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Resilient distributed datasets (RDDs) are the primary abstraction in
Spark.</p></li>
<li><p>RDDs are immutable once created:</p>
<ul>
<li><p>can transform it.</p></li>
<li><p>can perform actions on it.</p></li>
<li><p>but cannot change an RDD once you construct it.</p></li>
</ul>
</li>
<li><p>Spark tracks each RDD’s lineage information or recipe to enable its
efficient recomputation if a machine fails.</p></li>
<li><p>RDDs enable operations on collections of elements in parallel.</p></li>
<li><p>We can construct RDDs by:</p>
<ul>
<li><p>parallelizing Scala collections such as lists or arrays</p></li>
<li><p>by transforming an existing RDD,</p></li>
<li><p>from files in distributed file systems such as (HDFS, S3, etc.).</p></li>
</ul>
</li>
<li><p>We can specify the number of partitions for an RDD</p></li>
<li><p>The more partitions in an RDD, the more opportunities for
parallelism</p></li>
<li><p>There are <strong>two types of operations</strong> you can perform on an RDD:</p>
<ul>
<li><p><strong>transformations</strong> (are lazily evaluated)</p>
<ul>
<li><p>map</p></li>
<li><p>flatMap</p></li>
<li><p>filter</p></li>
<li><p>distinct</p></li>
<li><p>…</p></li>
</ul>
</li>
<li><p><strong>actions</strong> (actual evaluation happens)</p>
<ul>
<li><p>count</p></li>
<li><p>reduce</p></li>
<li><p>take</p></li>
<li><p>collect</p></li>
<li><p>takeOrdered</p></li>
<li><p>…</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Spark transformations enable us to create new RDDs from an existing
RDD.</p></li>
<li><p>RDD transformations are lazy evaluations (results are not computed
right away)</p></li>
<li><p>Spark remembers the set of transformations that are applied to a
base data set (this is the lineage graph of RDD)</p></li>
<li><p>The allows Spark to automatically recover RDDs from failures and
slow workers.</p></li>
<li><p>The lineage graph is a recipe for creating a result and it can be
optimized before execution.</p></li>
<li><p>A transformed RDD is executed only when an action runs on it.</p></li>
<li><p>You can also persist, or cache, RDDs in memory or on disk (this
speeds up iterative ML algorithms that transforms the initial RDD
iteratively).</p></li>
<li><p>Here is a great reference URL for programming guides for Spark that
one should try to cover first</p>
<ul>
<li><p><a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html">http://spark.apache.org/docs/latest/programming-guide.html</a>.</p></li>
<li><p>and specifically for RDDs:
<a class="reference external" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html">https://spark.apache.org/docs/latest/rdd-programming-guide.html</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="let-us-get-our-hands-dirty-in-spark-implementing-these-ideas">
<h2>Let us get our hands dirty in Spark implementing these ideas!<a class="headerlink" href="#let-us-get-our-hands-dirty-in-spark-implementing-these-ideas" title="Permalink to this headline">¶</a></h2>
<div class="section" id="do-now">
<h3>DO NOW<a class="headerlink" href="#do-now" title="Permalink to this headline">¶</a></h3>
<p>In your databricks community edition:</p>
<ol class="simple">
<li><p>In your <code class="docutils literal notranslate"><span class="pre">WorkSpace</span></code> create a Folder named <code class="docutils literal notranslate"><span class="pre">scalable-data-science</span></code></p></li>
<li><p><em>Import</em> the databricks archive file at the following URL:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/lamastex/scalable-data-science/raw/master/dbcArchives/2017/parts/xtraResources.dbc">https://github.com/lamastex/scalable-data-science/raw/master/dbcArchives/2017/parts/xtraResources.dbc</a></p></li>
</ul>
</li>
<li><p>This should open a structure of directories in with path:
<code class="docutils literal notranslate"><span class="pre">/Workspace/scalable-data-science/xtraResources/</span></code></p></li>
</ol>
</div>
<div class="section" id="let-us-look-at-the-legend-and-overview-of-the-visual-rdd-api-by-doing-the-following-first">
<h3>Let us look at the legend and overview of the visual RDD Api by doing the following first:<a class="headerlink" href="#let-us-look-at-the-legend-and-overview-of-the-visual-rdd-api-by-doing-the-following-first" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-1.png" /></p>
</div>
<div class="section" id="running-spark">
<h3>Running <strong>Spark</strong><a class="headerlink" href="#running-spark" title="Permalink to this headline">¶</a></h3>
<p>The variable <strong>sc</strong> allows you to access a Spark Context to run your
Spark programs. Recall <code class="docutils literal notranslate"><span class="pre">SparkContext</span></code> is in the Driver Program.</p>
<p><img alt="" src="http://spark.apache.org/docs/latest/img/cluster-overview.png" /></p>
<p>**NOTE: Do not create the <em>sc</em> variable - it is already initialized for
you in spark-shell REPL, that includes notebook environments like
databricks, Jupyter, zeppelin, etc. **</p>
</div>
<div class="section" id="we-will-do-the-following-next">
<h3>We will do the following next:<a class="headerlink" href="#we-will-do-the-following-next" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Create an RDD using <code class="docutils literal notranslate"><span class="pre">sc.parallelize</span></code></p></li>
</ol>
<ul class="simple">
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">collect</span></code> action on the RDD and find the number of
partitions it is made of using <code class="docutils literal notranslate"><span class="pre">getNumPartitions</span></code> action</p></li>
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">take</span></code> action on the RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">map</span></code> to make another RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">filter</span></code> to make another RDD</p></li>
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> action on the RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">flatMap</span></code> to make another RDD</p></li>
<li><p>Create a Pair RDD</p></li>
<li><p>Perform some transformations on a Pair RDD</p></li>
<li><p>Where in the cluster is your computation running?</p></li>
<li><p>Shipping Closures, Broadcast Variables and Accumulator Variables</p></li>
<li><p>Spark Essentials: Summary</p></li>
<li><p>HOMEWORK</p></li>
</ul>
</div>
</div>
<div class="section" id="entry-point">
<h2>Entry Point<a class="headerlink" href="#entry-point" title="Permalink to this headline">¶</a></h2>
<p>Now we are ready to start programming in Spark!</p>
<p>Our entry point for Spark 2.x applications is the class <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code>.
An instance of this object is already instantiated for us which can be
easily demonstrated by running the next cell</p>
<p>We will need these docs!</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/rdd/RDD.html">RDD Scala
Docs</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/sql/Dataset.html">Dataset Scala
Docs</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.1/api/scala/index.html">https://spark.apache.org/docs/3.0.1/api/scala/index.html</a> you can
simply search for other Spark classes, methods, etc here</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="n">spark</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>org.apache.spark.sql.SparkSession@4e90f6e2
</pre></div>
</div>
</div></blockquote>
<p>NOTE that since Spark 2.0 <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> is a replacement for the other
entry points: * <code class="docutils literal notranslate"><span class="pre">SparkContext</span></code>, available in our notebook as <strong>sc</strong>. *
<code class="docutils literal notranslate"><span class="pre">SQLContext</span></code>, or more specifically its subclass <code class="docutils literal notranslate"><span class="pre">HiveContext</span></code>, available
in our notebook as <strong>sqlContext</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">sqlContext</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>org.apache.spark.SparkContext@14f4984
org.apache.spark.sql.hive.HiveContext@57498b38
</pre></div>
</div>
</div></blockquote>
<p>We will be using the pre-made SparkContext <code class="docutils literal notranslate"><span class="pre">sc</span></code> when learning about
RDDs.</p>
<div class="section" id="create-an-rdd-using-sc-parallelize">
<h3>1. Create an RDD using <code class="docutils literal notranslate"><span class="pre">sc.parallelize</span></code><a class="headerlink" href="#create-an-rdd-using-sc-parallelize" title="Permalink to this headline">¶</a></h3>
<p>First, let us create an RDD of three elements (of integer type <code class="docutils literal notranslate"><span class="pre">Int</span></code>)
from a Scala <code class="docutils literal notranslate"><span class="pre">Seq</span></code> (or <code class="docutils literal notranslate"><span class="pre">List</span></code> or <code class="docutils literal notranslate"><span class="pre">Array</span></code>) with two partitions by using
the <code class="docutils literal notranslate"><span class="pre">parallelize</span></code> method of the available Spark Context <code class="docutils literal notranslate"><span class="pre">sc</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>    <span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span> <span class="p">(</span><span class="n">using</span> <span class="mi">2</span> <span class="n">partitions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at command-3398110674017707:1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">x</span><span class="o">.</span>  <span class="o">//</span> <span class="n">place</span> <span class="n">the</span> <span class="n">cursor</span> <span class="n">after</span> <span class="s1">&#39;x.&#39;</span> <span class="ow">and</span> <span class="n">hit</span> <span class="n">Tab</span> <span class="n">to</span> <span class="n">see</span> <span class="n">the</span> <span class="n">methods</span> <span class="n">available</span> <span class="k">for</span> <span class="n">the</span> <span class="n">RDD</span> <span class="n">x</span> <span class="n">we</span> <span class="n">created</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="perform-the-collect-action-on-the-rdd-and-find-the-number-of-partitions-it-is-made-of-using-getnumpartitions-action">
<h3>2. Perform the <code class="docutils literal notranslate"><span class="pre">collect</span></code> action on the RDD and find the number of partitions it is made of using <code class="docutils literal notranslate"><span class="pre">getNumPartitions</span></code> action<a class="headerlink" href="#perform-the-collect-action-on-the-rdd-and-find-the-number-of-partitions-it-is-made-of-using-getnumpartitions-action" title="Permalink to this headline">¶</a></h3>
<p>No action has been taken by <code class="docutils literal notranslate"><span class="pre">sc.parallelize</span></code> above. To see what is
“cooked” by the recipe for RDD <code class="docutils literal notranslate"><span class="pre">x</span></code> we need to take an action.</p>
<p>The simplest is the <code class="docutils literal notranslate"><span class="pre">collect</span></code> action which returns all of the elements
of the RDD as an <code class="docutils literal notranslate"><span class="pre">Array</span></code> to the driver program and displays it.</p>
<p><em>So you have to make sure that all of that data will fit in the driver
program if you call <code class="docutils literal notranslate"><span class="pre">collect</span></code> action!</em></p>
<div class="section" id="let-us-look-at-the-collect-action-in-detail-and-return-here-to-try-out-the-example-codes">
<h4>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/actions/collect">collect action in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-collect-action-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">¶</a></h4>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-90.png" /></p>
<p>Let us perform a <code class="docutils literal notranslate"><span class="pre">collect</span></code> action on RDD <code class="docutils literal notranslate"><span class="pre">x</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>    <span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">collect</span> <span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="n">elements</span> <span class="n">of</span> <span class="n">rdd</span><span class="p">;</span> <span class="n">should</span> <span class="n">be</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res2: Array[Int] = Array(1, 2, 3)
</pre></div>
</div>
</div></blockquote>
<p><em>CAUTION:</em> <code class="docutils literal notranslate"><span class="pre">collect</span></code> can crash the driver when called upon an RDD with
massively many elements.<br />
So, it is better to use other diplaying actions like <code class="docutils literal notranslate"><span class="pre">take</span></code> or
<code class="docutils literal notranslate"><span class="pre">takeOrdered</span></code> as follows:</p>
</div>
<div class="section" id="let-us-look-at-the-getnumpartitions-action-in-detail-and-return-here-to-try-out-the-example-codes">
<h4>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/actions/getNumPartitions">getNumPartitions action in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-getnumpartitions-action-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">¶</a></h4>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-88.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span> <span class="ow">and</span> <span class="n">find</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">partitions</span> <span class="ow">in</span> <span class="n">RDD</span> <span class="n">x</span>
<span class="n">x</span><span class="o">.</span><span class="n">getNumPartitions</span> 
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res3: Int = 2
</pre></div>
</div>
</div></blockquote>
<p>We can see which elements of the RDD are in which parition by calling
<code class="docutils literal notranslate"><span class="pre">glom()</span></code> before <code class="docutils literal notranslate"><span class="pre">collect()</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">glom()</span></code> flattens elements of the same partition into an <code class="docutils literal notranslate"><span class="pre">Array</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">glom</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">glom</span><span class="p">()</span> <span class="n">flattens</span> <span class="n">elements</span> <span class="n">on</span> <span class="n">the</span> <span class="n">same</span> <span class="n">partition</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res4: Array[Array[Int]] = Array(Array(1), Array(2, 3))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">glom</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>a: Array[Array[Int]] = Array(Array(1), Array(2, 3))
</pre></div>
</div>
</div></blockquote>
<p>Thus from the output above,
<code class="docutils literal notranslate"><span class="pre">Array[Array[Int]]</span> <span class="pre">=</span> <span class="pre">Array(Array(1),</span> <span class="pre">Array(2,</span> <span class="pre">3))</span></code>, we know that <code class="docutils literal notranslate"><span class="pre">1</span></code> is
in one partition while <code class="docutils literal notranslate"><span class="pre">2</span></code> and <code class="docutils literal notranslate"><span class="pre">3</span></code> are in another partition.</p>
<div class="section" id="you-try">
<h5>You Try!<a class="headerlink" href="#you-try" title="Permalink to this headline">¶</a></h5>
<p>Crate an RDD <code class="docutils literal notranslate"><span class="pre">x</span></code> with three elements, 1,2,3, and this time do not
specifiy the number of partitions. Then the default number of partitions
will be used. Find out what this is for the cluster you are attached to.</p>
<p>The default number of partitions for an RDD depends on the cluster this
notebook is attached to among others - see
<a class="reference external" href="http://spark.apache.org/docs/latest/programming-guide.html">programming-guide</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Seq</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>    <span class="o">//</span> <span class="o">&lt;</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span> <span class="p">(</span><span class="n">using</span> <span class="n">default</span> <span class="n">number</span> <span class="n">of</span> <span class="n">partitions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[3] at parallelize at command-3398110674017721:1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">getNumPartitions</span> <span class="o">//</span> <span class="o">&lt;</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res5: Int = 4
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">glom</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="o">&lt;</span><span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span><span class="o">&gt;</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">cell</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res6: Array[Array[Int]] = Array(Array(), Array(1), Array(2), Array(3))
</pre></div>
</div>
</div></blockquote>
</div>
</div>
</div>
<div class="section" id="perform-the-take-action-on-the-rdd">
<h3>3. Perform the <code class="docutils literal notranslate"><span class="pre">take</span></code> action on the RDD<a class="headerlink" href="#perform-the-take-action-on-the-rdd" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">.take(n)</span></code> action returns an array with the first <code class="docutils literal notranslate"><span class="pre">n</span></code> elements of
the RDD.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">take</span> <span class="n">two</span> <span class="n">elements</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">RDD</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res7: Array[Int] = Array(1, 2)
</pre></div>
</div>
</div></blockquote>
<div class="section" id="id1">
<h4>You Try!<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Fill in the parenthes <code class="docutils literal notranslate"><span class="pre">(</span> <span class="pre">)</span></code> below in order to <code class="docutils literal notranslate"><span class="pre">take</span></code> just one element
from RDD <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">x</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">uncomment</span> <span class="n">by</span> <span class="n">removing</span> <span class="s1">&#39;//&#39;</span> <span class="n">before</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">cell</span> <span class="ow">and</span> <span class="n">fill</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">parenthesis</span> <span class="n">to</span> <span class="n">take</span> <span class="n">just</span> <span class="n">one</span> <span class="n">element</span> <span class="kn">from</span> <span class="nn">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="transform-the-rdd-by-map-to-make-another-rdd">
<h3>4. Transform the RDD by <code class="docutils literal notranslate"><span class="pre">map</span></code> to make another RDD<a class="headerlink" href="#transform-the-rdd-by-map-to-make-another-rdd" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">map</span></code> transformation returns a new RDD that’s formed by passing each
element of the source RDD through a function (closure). The closure is
automatically passed on to the workers for evaluation (when an action is
called later).</p>
<div class="section" id="let-us-look-at-the-map-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
<h4>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/transformations/map">map transformation in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-map-transformation-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">¶</a></h4>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-18.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">RDD</span> <span class="n">y</span> <span class="n">that</span> <span class="ow">is</span> <span class="n">mapped</span> <span class="kn">from</span> <span class="nn">x</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">z</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                    <span class="o">//</span> <span class="nb">map</span> <span class="n">x</span> <span class="n">into</span> <span class="n">RDD</span> <span class="n">y</span><span class="p">:</span> <span class="p">[(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[5] at parallelize at command-3398110674017730:2
y: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[6] at map at command-3398110674017730:3
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">the</span> <span class="n">two</span> <span class="n">RDDs</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>b, a, c
(b,1), (a,1), (c,1)
</pre></div>
</div>
</div></blockquote>
</div>
</div>
<hr class="docutils" />
<div class="section" id="transform-the-rdd-by-filter-to-make-another-rdd">
<h3>5. Transform the RDD by <code class="docutils literal notranslate"><span class="pre">filter</span></code> to make another RDD<a class="headerlink" href="#transform-the-rdd-by-filter-to-make-another-rdd" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">filter</span></code> transformation returns a new RDD that’s formed by selecting
those elements of the source RDD on which the function returns <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<div class="section" id="let-us-look-at-the-filter-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
<h4>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/transformations/filter">filter transformation in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-filter-transformation-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">¶</a></h4>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-24.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="nb">filter</span> <span class="n">it</span> <span class="n">by</span> <span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">n</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">y</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="o">//</span> <span class="n">the</span> <span class="n">closure</span> <span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">n</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">in</span> <span class="n">the</span> <span class="nb">filter</span> <span class="n">will</span> 
<span class="o">//</span> <span class="k">return</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">element</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">RDD</span> <span class="n">x</span> <span class="n">has</span> <span class="n">remainder</span> <span class="mi">1</span> <span class="n">when</span> <span class="n">divided</span> <span class="n">by</span> <span class="mi">2</span> <span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">e</span><span class="o">.</span><span class="p">,</span> <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="n">odd</span><span class="p">)</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">n</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[7] at parallelize at command-3398110674017734:2
y: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[8] at filter at command-3398110674017734:5
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">the</span> <span class="n">two</span> <span class="n">RDDs</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="o">//</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1, 2, 3
1, 3
</pre></div>
</div>
</div></blockquote>
</div>
</div>
<hr class="docutils" />
<div class="section" id="perform-the-reduce-action-on-the-rdd">
<h3>6. Perform the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> action on the RDD<a class="headerlink" href="#perform-the-reduce-action-on-the-rdd" title="Permalink to this headline">¶</a></h3>
<p>Reduce aggregates a data set element using a function (closure). This
function takes two arguments and returns one and can often be seen as a
binary operator. This operator has to be commutative and associative so
that it can be computed correctly in parallel (where we have little
control over the order of the operations!).</p>
</div>
<div class="section" id="let-us-look-at-the-reduce-action-in-detail-and-return-here-to-try-out-the-example-codes">
<h3>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/actions/reduce">reduce action in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-reduce-action-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-94.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="n">of</span> <span class="n">inteegrs</span> <span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span> <span class="ow">and</span> <span class="n">reduce</span> <span class="n">it</span> <span class="n">to</span> <span class="nb">sum</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reduce</span><span class="p">((</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[9] at parallelize at command-3398110674017738:2
y: Int = 10
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">Int</span> <span class="n">y</span><span class="p">,</span> <span class="nb">sum</span> <span class="n">of</span> <span class="n">x</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1, 2, 3, 4
10
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="transform-an-rdd-by-flatmap-to-make-another-rdd">
<h3>7. Transform an RDD by <code class="docutils literal notranslate"><span class="pre">flatMap</span></code> to make another RDD<a class="headerlink" href="#transform-an-rdd-by-flatmap-to-make-another-rdd" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">flatMap</span></code> is similar to <code class="docutils literal notranslate"><span class="pre">map</span></code> but each element from input RDD can be
mapped to zero or more output elements. Therefore your function should
return a sequential collection such as an <code class="docutils literal notranslate"><span class="pre">Array</span></code> rather than a single
element as shown below.</p>
</div>
<div class="section" id="let-us-look-at-the-flatmap-transformation-in-detail-and-return-here-to-try-out-the-example-codes">
<h3>Let us look at the <a class="reference external" href="/#workspace/scalable-data-science/xtraResources/visualRDDApi/recall/transformations/flatMap">flatMap transformation in detail</a> and return here to try out the example codes.<a class="headerlink" href="#let-us-look-at-the-flatmap-transformation-in-detail-and-return-here-to-try-out-the-example-codes" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-31.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">flatMap</span> <span class="n">it</span> <span class="n">into</span> <span class="n">RDD</span> <span class="n">by</span> <span class="n">closure</span> <span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">Array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">42</span><span class="p">))</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">Array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">42</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[10] at parallelize at command-3398110674017742:2
y: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[11] at flatMap at command-3398110674017742:3
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">collect</span> <span class="ow">and</span> <span class="nb">print</span> <span class="n">RDDs</span> <span class="n">x</span> <span class="ow">and</span> <span class="n">y</span>
<span class="n">println</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">println</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
<span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">n</span> <span class="o">=&gt;</span> <span class="n">Array</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">42</span><span class="p">))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1, 2, 3
1, 100, 42, 2, 200, 42, 3, 300, 42
res11: Array[Array[Int]] = Array(Array(1, 100, 42), Array(2, 200, 42), Array(3, 300, 42))
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="create-a-pair-rdd">
<h3>8. Create a Pair RDD<a class="headerlink" href="#create-a-pair-rdd" title="Permalink to this headline">¶</a></h3>
<p>Let’s next work with RDD of <code class="docutils literal notranslate"><span class="pre">(key,value)</span></code> pairs called a <em>Pair RDD</em> or
<em>Key-Value RDD</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">RDD</span> <span class="n">words</span> <span class="ow">and</span> <span class="n">display</span> <span class="n">it</span> <span class="n">by</span> <span class="n">collect</span>
<span class="n">val</span> <span class="n">words</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">))</span>
<span class="n">words</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>words: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[14] at parallelize at command-3398110674017745:2
res12: Array[String] = Array(a, b, a, a, b, b, a, a, a, b, b)
</pre></div>
</div>
</div></blockquote>
<p>Let’s make a Pair RDD called <code class="docutils literal notranslate"><span class="pre">wordCountPairRDD</span></code> that is made of
(key,value) pairs with key=word and value=1 in order to encode each
occurrence of each word in the RDD <code class="docutils literal notranslate"><span class="pre">words</span></code>, as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="ow">and</span> <span class="n">collect</span> <span class="n">Pair</span> <span class="n">RDD</span> <span class="n">wordCountPairRDD</span>
<span class="n">val</span> <span class="n">wordCountPairRDD</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wordCountPairRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[15] at map at command-3398110674017747:2
res13: Array[(String, Int)] = Array((a,1), (b,1), (a,1), (a,1), (b,1), (b,1), (a,1), (a,1), (a,1), (b,1), (b,1))
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="wide-transformations-and-shuffles">
<h3>Wide Transformations and Shuffles<a class="headerlink" href="#wide-transformations-and-shuffles" title="Permalink to this headline">¶</a></h3>
<p>So far we have seen transformations that are <strong>narrow</strong> – with no data
transfer between partitions. Think of <code class="docutils literal notranslate"><span class="pre">map</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">ReduceByKey</span></code> and <code class="docutils literal notranslate"><span class="pre">GroupByKey</span></code> are <strong>wide</strong> transformations as data has
to be shuffled across the partitions in different executors – this is
generally very expensive operation.</p>
<p><img alt="" src="https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/db/visualapi/med/visualapi-40.png" /></p>
<p>READ the <strong>Background</strong> about Shuffles in the programming guide below.</p>
<blockquote>
<div><p>In Spark, data is generally not distributed across partitions to be in
the necessary place for a specific operation. During computations, a
single task will operate on a single partition - thus, to organize all
the data for a single reduceByKey reduce task to execute, Spark needs
to perform an all-to-all operation. It must read from all partitions
to find all the values for all keys, and then bring together values
across partitions to compute the final result for each key - this is
called the shuffle</p>
</div></blockquote>
<p>READ the <strong>Performance Impact</strong> about Shuffles in the programming guide
below.</p>
<blockquote>
<div><p>The Shuffle is an expensive operation since it involves disk I/O, data
serialization, and network I/O. To organize data for the shuffle,
Spark generates sets of tasks - map tasks to organize the data, and a
set of reduce tasks to aggregate it. This nomenclature comes from
MapReduce and does not directly relate to Spark’s map and reduce
operations.</p>
</div></blockquote>
<blockquote>
<div><p>Internally, results from individual map tasks are kept in memory until
they can’t fit. Then, these are sorted based on the target partition
and written to a single file. On the reduce side, tasks read the
relevant sorted blocks.</p>
</div></blockquote>
</div>
<div class="section" id="perform-some-transformations-on-a-pair-rdd">
<h3>9. Perform some transformations on a Pair RDD<a class="headerlink" href="#perform-some-transformations-on-a-pair-rdd" title="Permalink to this headline">¶</a></h3>
<p>Let’s next work with RDD of <code class="docutils literal notranslate"><span class="pre">(key,value)</span></code> pairs called a <em>Pair RDD</em> or
<em>Key-Value RDD</em>.</p>
<p>Now some of the Key-Value transformations that we could perform include
the following.</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">reduceByKey</span></code> transformation</strong></p>
<ul>
<li><p>which takes an RDD and returns a new RDD of key-value pairs,
such that:</p>
<ul>
<li><p>the values for each key are aggregated using the given
reduced function</p></li>
<li><p>and the reduce function has to be of the type that takes two
values and returns one value.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">sortByKey</span></code> transformation</strong></p>
<ul>
<li><p>this returns a new RDD of key-value pairs that’s sorted by keys
in ascending order</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">groupByKey</span></code> transformation</strong></p>
<ul>
<li><p>this returns a new RDD consisting of key and iterable-valued
pairs.</p></li>
</ul>
</li>
</ul>
<p>Let’s see some concrete examples next.</p>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-44.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">reduceByKey</span> <span class="ow">and</span> <span class="n">collect</span> <span class="n">wordcounts</span> <span class="n">RDD</span>
<span class="o">//</span><span class="n">val</span> <span class="n">wordcounts</span> <span class="o">=</span> <span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span> <span class="n">_</span> <span class="o">+</span> <span class="n">_</span> <span class="p">)</span>
<span class="n">val</span> <span class="n">wordcounts</span> <span class="o">=</span> <span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span> <span class="p">(</span><span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">value1</span> <span class="o">+</span> <span class="n">value2</span> <span class="p">)</span>
<span class="n">wordcounts</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wordcounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[17] at reduceByKey at command-3398110674017750:3
res15: Array[(String, Int)] = Array((a,6), (b,5))
</pre></div>
</div>
</div></blockquote>
<p>Now, let us do just the crucial steps and avoid collecting intermediate
RDDs (something we should avoid for large datasets anyways, as they may
not fit in the driver program).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span><span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">make</span> <span class="n">words</span> <span class="n">RDD</span> <span class="ow">and</span> <span class="n">do</span> <span class="n">the</span> <span class="n">word</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">two</span> <span class="n">lines</span>
<span class="n">val</span> <span class="n">words</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">))</span>
<span class="n">val</span> <span class="n">wordcounts</span> <span class="o">=</span> <span class="n">words</span>
                    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="n">_</span> <span class="o">+</span> <span class="n">_</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">collect</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>words: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[21] at parallelize at command-3398110674017752:2
wordcounts: Array[(String, Int)] = Array((a,6), (b,5))
</pre></div>
</div>
</div></blockquote>
<div class="section" id="id2">
<h4>You Try!<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>You try evaluating <code class="docutils literal notranslate"><span class="pre">sortByKey()</span></code> which will make a new RDD that consists
of the elements of the original pair RDD that are sorted by Keys.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="ow">and</span> <span class="n">comprehend</span> <span class="n">code</span>
<span class="n">val</span> <span class="n">words</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">))</span>
<span class="n">val</span> <span class="n">wordCountPairRDD</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">val</span> <span class="n">wordCountPairRDDSortedByKey</span> <span class="o">=</span> <span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">sortByKey</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>words: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[17] at parallelize at command-3398110674017754:2
wordCountPairRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[18] at map at command-3398110674017754:3
wordCountPairRDDSortedByKey: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[21] at sortByKey at command-3398110674017754:4
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wordCountPairRDD</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="ow">and</span> <span class="n">comprehend</span> <span class="n">code</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res8: Array[(String, Int)] = Array((a,1), (b,1), (a,1), (a,1), (b,1), (b,1), (a,1), (a,1), (a,1), (b,1), (b,1))
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wordCountPairRDDSortedByKey</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> <span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span> <span class="ow">and</span> <span class="n">comprehend</span> <span class="n">code</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res9: Array[(String, Int)] = Array((a,1), (a,1), (a,1), (a,1), (a,1), (a,1), (b,1), (b,1), (b,1), (b,1), (b,1))
</pre></div>
</div>
</div></blockquote>
<p>The next key value transformation we will see is <code class="docutils literal notranslate"><span class="pre">groupByKey</span></code></p>
<p>When we apply the <code class="docutils literal notranslate"><span class="pre">groupByKey</span></code> transformation to <code class="docutils literal notranslate"><span class="pre">wordCountPairRDD</span></code> we
end up with a new RDD that contains two elements. The first element is
the tuple <code class="docutils literal notranslate"><span class="pre">b</span></code> and an iterable <code class="docutils literal notranslate"><span class="pre">CompactBuffer(1,1,1,1,1)</span></code> obtained by
grouping the value <code class="docutils literal notranslate"><span class="pre">1</span></code> for each of the five key value pairs <code class="docutils literal notranslate"><span class="pre">(b,1)</span></code>.
Similarly the second element is the key <code class="docutils literal notranslate"><span class="pre">a</span></code> and an iterable
<code class="docutils literal notranslate"><span class="pre">CompactBuffer(1,1,1,1,1,1)</span></code> obtained by grouping the value <code class="docutils literal notranslate"><span class="pre">1</span></code> for each
of the six key value pairs <code class="docutils literal notranslate"><span class="pre">(a,1)</span></code>.</p>
<p><em>CAUTION</em>: <code class="docutils literal notranslate"><span class="pre">groupByKey</span></code> can cause a large amount of data movement across
the network. It also can create very large iterables at a worker.
Imagine you have an RDD where you have 1 billion pairs that have the key
<code class="docutils literal notranslate"><span class="pre">a</span></code>. All of the values will have to fit in a single worker if you use
group by key. So instead of a group by key, consider using reduced by
key.</p>
<p><img alt="" src="https://raw.githubusercontent.com/lamastex/scalable-data-science/master/db/visualapi/med/visualapi-45.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>val wordCountPairRDDGroupByKey = wordCountPairRDD.groupByKey() // &lt;Shift+Enter&gt; CAUTION: this transformation can be very wide!
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wordCountPairRDDGroupByKey: org.apache.spark.rdd.RDD[(String, Iterable[Int])] = ShuffledRDD[22] at groupByKey at command-3398110674017759:1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wordCountPairRDDGroupByKey</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="o">//</span> <span class="n">Cntrl</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res10: Array[(String, Iterable[Int])] = Array((a,CompactBuffer(1, 1, 1, 1, 1, 1)), (b,CompactBuffer(1, 1, 1, 1, 1)))
</pre></div>
</div>
</div></blockquote>
</div>
</div>
<div class="section" id="understanding-closures-where-in-the-cluster-is-your-computation-running">
<h3>10. Understanding Closures - Where in the cluster is your computation running?<a class="headerlink" href="#understanding-closures-where-in-the-cluster-is-your-computation-running" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>One of the harder things about Spark is understanding the scope and
life cycle of variables and methods when executing code across a
cluster. RDD operations that modify variables outside of their scope
can be a frequent source of confusion. In the example below we’ll look
at code that uses foreach() to increment a counter, but similar issues
can occur for other operations as well.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">var</span> <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">var</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="o">//</span> <span class="n">Wrong</span><span class="p">:</span> <span class="n">Don</span><span class="s1">&#39;t do this!!</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">counter</span> <span class="o">+=</span> <span class="n">x</span><span class="p">)</span>

<span class="n">println</span><span class="p">(</span><span class="s2">&quot;Counter value: &quot;</span> <span class="o">+</span> <span class="n">counter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Counter value: 0
data: Array[Int] = Array(1, 2, 3, 4, 5)
counter: Int = 0
rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[24] at parallelize at command-4158380413057402:3
</pre></div>
</div>
</div></blockquote>
<p>From RDD programming guide:</p>
<blockquote>
<div><p>The behavior of the above code is undefined, and may not work as
intended. To execute jobs, Spark breaks up the processing of RDD
operations into tasks, each of which is executed by an executor. Prior
to execution, Spark computes the task’s closure. The closure is those
variables and methods which must be visible for the executor to
perform its computations on the RDD (in this case foreach()). This
closure is serialized and sent to each executor.</p>
</div></blockquote>
<blockquote>
<div><p>The variables within the closure sent to each executor are now copies
and thus, when counter is referenced within the foreach function, it’s
no longer the counter on the driver node. There is still a counter in
the memory of the driver node but this is no longer visible to the
executors! The executors only see the copy from the serialized
closure. Thus, the final value of counter will still be zero since all
operations on counter were referencing the value within the serialized
closure.</p>
</div></blockquote>
</div>
<div class="section" id="shipping-closures-broadcast-variables-and-accumulator-variables">
<h3>11. Shipping Closures, Broadcast Variables and Accumulator Variables<a class="headerlink" href="#shipping-closures-broadcast-variables-and-accumulator-variables" title="Permalink to this headline">¶</a></h3>
<div class="section" id="closures-broadcast-and-accumulator-variables">
<h4>Closures, Broadcast and Accumulator Variables<a class="headerlink" href="#closures-broadcast-and-accumulator-variables" title="Permalink to this headline">¶</a></h4>
<p><strong>(watch now 2:06)</strong>:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=I9Zcr4R35Ao?rel=0&amp;autoplay=1&amp;modestbranding=1"><img alt="Closures, Broadcast and Accumulators by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/I9Zcr4R35Ao/0.jpg" /></a></p>
<p>We will use these variables in the sequel.</p>
</div>
<div class="section" id="summary">
<h4>SUMMARY<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h4>
<p>Spark automatically creates closures</p>
<ul class="simple">
<li><p>for functions that run on RDDs at workers,</p></li>
<li><p>and for any global variables that are used by those workers</p></li>
<li><p>one closure per worker is sent with every task</p></li>
<li><p>and there’s no communication between workers</p></li>
<li><p>closures are one way from the driver to the worker</p></li>
<li><p>any changes that you make to the global variables at the workers</p>
<ul>
<li><p>are not sent to the driver or</p></li>
<li><p>are not sent to other workers.</p></li>
</ul>
</li>
</ul>
<p>The problem we have is that these closures</p>
<ul class="simple">
<li><p>are automatically created are sent or re-sent with every job</p></li>
<li><p>with a large global variable it gets inefficient to send/resend lots
of data to each worker</p></li>
<li><p>we cannot communicate that back to the driver</p></li>
</ul>
<p>To do this, Spark provides shared variables in two different types.</p>
<ul class="simple">
<li><p><strong>broadcast variables</strong></p>
<ul>
<li><p>lets us to efficiently send large read-only values to all of the
workers</p></li>
<li><p>these are saved at the workers for use in one or more Spark
operations.</p></li>
</ul>
</li>
<li><p><strong>accumulator variables</strong></p>
<ul>
<li><p>These allow us to aggregate values from workers back to the
driver.</p></li>
<li><p>only the driver can access the value of the accumulator</p></li>
<li><p>for the tasks, the accumulators are basically write-only</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>### 12. Spark Essentials: Summary <strong>(watch now: 0:29)</strong></p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=F50Vty9Ia8Y?rel=0&amp;autoplay=1&amp;modestbranding=1"><img alt="Spark Essentials Summary by Anthony Joseph inBerkeleyX/CS100.1x" src="http://img.youtube.com/vi/F50Vty9Ia8Y/0.jpg" /></a></p>
<p><em>NOTE:</em> In databricks cluster, we (the course
coordinator/administrators) set the number of workers for you.</p>
</div>
</div>
</div>
<div class="section" id="accumulators">
<h2>Accumulators<a class="headerlink" href="#accumulators" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Accumulators are variables that are only “added” to through an
associative and commutative operation and can therefore be efficiently
supported in parallel. They can be used to implement counters (as in
MapReduce) or sums. Spark natively supports accumulators of numeric
types, and programmers can add support for new types.</p>
</div></blockquote>
<blockquote>
<div><p>A numeric accumulator can be created by calling
SparkContext.longAccumulator() or SparkContext.doubleAccumulator() to
accumulate values of type Long or Double, respectively. Tasks running
on a cluster can then add to it using the add method. However, they
cannot read its value. Only the driver program can read the
accumulator’s value, using its value method.</p>
</div></blockquote>
<blockquote>
<div><p>The code below shows an accumulator being used to add up the elements
of an array:</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">accum</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">longAccumulator</span><span class="p">(</span><span class="s2">&quot;My Accumulator&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>accum: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 780, name: Some(My Accumulator), value: 0)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">accum</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accum</span><span class="o">.</span><span class="n">value</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res18: Long = 10
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="broadcast-variables">
<h2>Broadcast Variables<a class="headerlink" href="#broadcast-variables" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Broadcast variables allow the programmer to keep a read-only variable
cached on each machine rather than shipping a copy of it with tasks.
They can be used, for example, to give every node a copy of a large
input dataset in an efficient manner. Spark also attempts to
distribute broadcast variables using efficient broadcast algorithms to
reduce communication cost.</p>
</div></blockquote>
<blockquote>
<div><p>Spark actions are executed through a set of stages, separated by
distributed “shuffle” operations. Spark automatically broadcasts the
common data needed by tasks within each stage. The data broadcasted
this way is cached in serialized form and deserialized before running
each task. This means that explicitly creating broadcast variables is
only useful when tasks across multiple stages need the same data or
when caching the data in deserialized form is important.</p>
</div></blockquote>
<blockquote>
<div><p>Broadcast variables are created from a variable v by calling
SparkContext.broadcast(v). The broadcast variable is a wrapper around
v, and its value can be accessed by calling the value method. The code
below shows this:</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">broadcastVar</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>broadcastVar: org.apache.spark.broadcast.Broadcast[Array[Int]] = Broadcast(27)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res19: Array[Int] = Array(1, 2, 3)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res20: Int = 1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="mi">1</span> <span class="n">to</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[26] at parallelize at command-4158380413057414:1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span><span class="o">.</span><span class="n">collect</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res21: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">%</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res22: Array[Int] = Array(1, 2, 0, 1, 2, 0, 1, 2, 0, 1)
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">x</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">+</span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="o">%</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">collect</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res23: Array[Int] = Array(3, 5, 4, 6, 8, 7, 9, 11, 10, 12)
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><p>After the broadcast variable is created, it should be used instead of
the value v in any functions run on the cluster so that v is not
shipped to the nodes more than once. In addition, the object v should
not be modified after it is broadcast in order to ensure that all
nodes get the same value of the broadcast variable (e.g. if the
variable is shipped to a new node later).</p>
</div></blockquote>
<blockquote>
<div><p>To release the resources that the broadcast variable copied onto
executors, call .unpersist(). If the broadcast is used again
afterwards, it will be re-broadcast. To permanently release all
resources used by the broadcast variable, call .destroy(). The
broadcast variable can’t be used after that. Note that these methods
do not block by default. To block until resources are freed, specify
blocking=true when calling them.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcastVar</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="a-more-interesting-example-of-broadcast-variable">
<h3>A more interesting example of broadcast variable<a class="headerlink" href="#a-more-interesting-example-of-broadcast-variable" title="Permalink to this headline">¶</a></h3>
<p>Let us broadcast maps and use them to lookup the values at each
executor. This example is taken from: -
<a class="reference external" href="https://sparkbyexamples.com/spark/spark-broadcast-variables/">https://sparkbyexamples.com/spark/spark-broadcast-variables/</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">states</span> <span class="o">=</span> <span class="n">Map</span><span class="p">((</span><span class="s2">&quot;NY&quot;</span><span class="p">,</span><span class="s2">&quot;New York&quot;</span><span class="p">),(</span><span class="s2">&quot;CA&quot;</span><span class="p">,</span><span class="s2">&quot;California&quot;</span><span class="p">),(</span><span class="s2">&quot;FL&quot;</span><span class="p">,</span><span class="s2">&quot;Florida&quot;</span><span class="p">))</span>
<span class="n">val</span> <span class="n">countries</span> <span class="o">=</span> <span class="n">Map</span><span class="p">((</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;United States of America&quot;</span><span class="p">),(</span><span class="s2">&quot;IN&quot;</span><span class="p">,</span><span class="s2">&quot;India&quot;</span><span class="p">))</span>

<span class="n">val</span> <span class="n">broadcastStates</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
<span class="n">val</span> <span class="n">broadcastCountries</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">countries</span><span class="p">)</span>

<span class="n">val</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">((</span><span class="s2">&quot;James&quot;</span><span class="p">,</span><span class="s2">&quot;Smith&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;CA&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Michael&quot;</span><span class="p">,</span><span class="s2">&quot;Rose&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;NY&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Robert&quot;</span><span class="p">,</span><span class="s2">&quot;Williams&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;CA&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Maria&quot;</span><span class="p">,</span><span class="s2">&quot;Jones&quot;</span><span class="p">,</span><span class="s2">&quot;USA&quot;</span><span class="p">,</span><span class="s2">&quot;FL&quot;</span><span class="p">))</span>

<span class="n">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">//</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">same</span> <span class="k">as</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span> <span class="ow">in</span> <span class="n">spark</span><span class="o">-</span><span class="n">shell</span><span class="o">/</span><span class="n">notebook</span>

  <span class="n">val</span> <span class="n">rdd2</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">f</span><span class="o">=&gt;</span><span class="p">{</span>
    <span class="n">val</span> <span class="n">country</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">_3</span>
    <span class="n">val</span> <span class="n">state</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">_4</span>
    <span class="n">val</span> <span class="n">fullCountry</span> <span class="o">=</span> <span class="n">broadcastCountries</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">country</span><span class="p">)</span><span class="o">.</span><span class="n">get</span>
    <span class="n">val</span> <span class="n">fullState</span> <span class="o">=</span> <span class="n">broadcastStates</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">get</span>
    <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">_1</span><span class="p">,</span><span class="n">f</span><span class="o">.</span><span class="n">_2</span><span class="p">,</span><span class="n">fullCountry</span><span class="p">,</span><span class="n">fullState</span><span class="p">)</span>
  <span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>states: scala.collection.immutable.Map[String,String] = Map(NY -&gt; New York, CA -&gt; California, FL -&gt; Florida)
countries: scala.collection.immutable.Map[String,String] = Map(USA -&gt; United States of America, IN -&gt; India)
broadcastStates: org.apache.spark.broadcast.Broadcast[scala.collection.immutable.Map[String,String]] = Broadcast(31)
broadcastCountries: org.apache.spark.broadcast.Broadcast[scala.collection.immutable.Map[String,String]] = Broadcast(32)
data: Seq[(String, String, String, String)] = List((James,Smith,USA,CA), (Michael,Rose,USA,NY), (Robert,Williams,USA,CA), (Maria,Jones,USA,FL))
rdd: org.apache.spark.rdd.RDD[(String, String, String, String)] = ParallelCollectionRDD[29] at parallelize at command-4158380413057424:12
rdd2: org.apache.spark.rdd.RDD[(String, String, String, String)] = MapPartitionsRDD[30] at map at command-4158380413057424:14
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="n">rdd2</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">mkString</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(James,Smith,United States of America,California)
(Michael,Rose,United States of America,New York)
(Robert,Williams,United States of America,California)
(Maria,Jones,United States of America,Florida)
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="homework">
<h3>13. HOMEWORK<a class="headerlink" href="#homework" title="Permalink to this headline">¶</a></h3>
<p>See the notebook in this folder named
<code class="docutils literal notranslate"><span class="pre">005_RDDsTransformationsActionsHOMEWORK</span></code>. This notebook will give you
more examples of the operations above as well as others we will be using
later, including:</p>
<ul class="simple">
<li><p>Perform the <code class="docutils literal notranslate"><span class="pre">takeOrdered</span></code> action on the RDD</p></li>
<li><p>Transform the RDD by <code class="docutils literal notranslate"><span class="pre">distinct</span></code> to make another RDD and</p></li>
<li><p>Doing a bunch of transformations to our RDD and performing an action
in a single cell.</p></li>
</ul>
<hr class="docutils" />
</div>
<hr class="docutils" />
<div class="section" id="importing-standard-scala-and-java-libraries">
<h3>Importing Standard Scala and Java libraries<a class="headerlink" href="#importing-standard-scala-and-java-libraries" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>For other libraries that are not available by default, you can
upload other libraries to the Workspace.</p></li>
<li><p>Refer to the
<strong><a class="reference external" href="https://docs.databricks.com/user-guide/libraries.html">Libraries</a></strong>
guide for more details.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scala.math._</span>
<span class="n">val</span> <span class="n">x</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import scala.math._
x: Int = 1
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.HashMap</span>
<span class="n">val</span> <span class="nb">map</span> <span class="o">=</span> <span class="n">new</span> <span class="n">HashMap</span><span class="p">[</span><span class="n">String</span><span class="p">,</span> <span class="n">Int</span><span class="p">]()</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">map</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;e&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import java.util.HashMap
map: java.util.HashMap[String,Int] = {a=1, b=2, c=3, d=4, e=5}
res26: Int = 0
</pre></div>
</div>
</div></blockquote>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_1-sds-3-x"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="003_01_scalaCrashCourse.html" title="previous page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>
    <a class='right-next' id="next-link" href="005_RDDsTransformationsActionsHOMEWORK.html" title="next page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>