
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ScaDaMaLe, Scalable Data Science and Distributed Machine Learning &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="ScaDaMaLe/000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="007d_SparkSQLProgGuide_HW.html" />
    <link rel="prev" title="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" href="007b_SparkSQLProgGuide_HW.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="ScaDaMaLe/000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning" />
<meta property="og:description" content="ScaDaMaLe, Scalable Data Science and Distributed Machine Learning  This is an elaboration of the http://spark.apache.org/docs/latest/sql-programming-guide.html " />
<meta property="og:image"       content="ScaDaMaLe/_static/logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="000_ScaDaMaLe.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="001_whySpark.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="001_whySpark.html#why-apache-spark">
   Why Apache Spark?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#you-should-all-have-databricks-community-edition-account-by-now">
   You Should All Have databricks community edition account by now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#import-course-content-now">
   Import Course Content Now!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_00_loginToDatabricks.html#cloud-free-computing-environment-optional-but-recommended">
   Cloud-free Computing Environment (Optional but recommended)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#notebooks">
   Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002_01_multiLingualNotebooks.html#further-reference-homework-recurrrent-points-of-reference">
   Further Reference / Homework / Recurrrent Points of Reference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#introduction-to-scala">
   Introduction to Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#let-s-get-our-hands-dirty-in-scala">
   Let’s get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#scala-types">
   Scala Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#expressions">
   Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#blocks">
   Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#functions">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#methods">
   Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#classes">
   Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#case-classes">
   Case Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#objects">
   Objects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#traits">
   Traits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#main-method">
   Main Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_00_scalaCrashCourse.html#what-i-try-not-do-while-learning-a-new-language">
   What I try not do while learning a new language?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#let-s-continue-to-get-our-hands-dirty-in-scala">
   Let’s continue to get our hands dirty in Scala
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-type-hierarchy">
   Scala Type Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#scala-collections">
   Scala Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#exercise-in-functional-programming">
   Exercise in Functional Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#lazy-evaluation">
   Lazy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003_01_scalaCrashCourse.html#recursions">
   Recursions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html#introduction-to-spark">
   Introduction to Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004_RDDsTransformationsActions.html#spark-cluster-overview">
   Spark Cluster Overview:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html#homework-notebook-rdds-transformations-and-actions">
   HOMEWORK notebook - RDDs Transformations and Actions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#piped-rdds-and-bayesian-ab-testing">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="006_WordCount.html#word-count-on-us-state-of-the-union-sou-addresses">
   Word Count on US State of the Union (SoU) Addresses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html#spark-sql-programming-guide">
   Spark Sql Programming Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#getting-started">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#id1">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#getting-started-exercise">
   Getting Started - Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#data-sources">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#id1">
   Data Sources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html#performance-tuning">
   Performance Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#distributed-sql-engine">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#id1">
   Distributed SQL Engine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#sql-pivoting-since-spark-2-4">
   SQL Pivoting since Spark 2.4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#load-data">
   Load Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-in-sql">
   Pivoting in SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
   Pivoting with Multiple Aggregate Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
   Pivoting with Multiple Grouping Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
   Pivoting with Multiple Pivot Columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#introduction-to-spark-sql">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#overview">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#datasets-and-dataframes">
   Datasets and DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wiki-clickstream-analysis">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#plugging-into-gdelt-streams">
   Plugging into GDELT Streams
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#this-is-just-dipping-our-pinky-toe-in-this-ocean-of-information">
   This is just dipping our pinky toe in this ocean of information!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="030_Spark_GDELT_project.html#download-from-gdelt-project">
   Download from gdelt-project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#old-bailey-online-data-analysis-in-apache-spark">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html">
   Piped RDDs and Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
   From a Local Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
   glom
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
   Checkpointing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
   Pipe RDDs to System Commands
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
   mapPartitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
   foreachPartition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
   Numerically Rigorous Bayesian AB Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
   Usage instructions for IsIt1or2Coins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
   Parsing the output from
   <code class="docutils literal notranslate">
    <span class="pre">
     IsIt1or2Coins
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
   Providing case classes for input and output for easy spark communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html#topic-modeling-of-movie-dialogs-with-latent-dirichlet-allocation">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks.html">
   Content with notebooks
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/000_1-sds-3-x/007c_SparkSQLProgGuide_HW.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/ScaDaMaLe"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/ScaDaMaLe/issues/new?title=Issue%20on%20page%20%2F000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-started-exercise">
   Getting Started - Exercise
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nyc-social-media-usage-data">
     NYC Social Media Usage Data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#overview">
       Overview
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-data">
     Load Data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#how-to-uoload-csv-file-and-make-a-table-in-databricks">
       How to uoload csv file and make a table in databricks
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spark-sql-and-dataframe-api">
       Spark SQL and DataFrame API
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interoperating-with-rdds">
     Interoperating with RDDs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#inferring-the-schema-using-reflection">
       Inferring the Schema Using Reflection
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#programmatically-specifying-the-schema">
       Programmatically Specifying the Schema
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-datasets">
     Creating Datasets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finally">
     Finally
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="scadamale-scalable-data-science-and-distributed-machine-learning">
<h1><a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/3/x/">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a><a class="headerlink" href="#scadamale-scalable-data-science-and-distributed-machine-learning" title="Permalink to this headline">¶</a></h1>
<p>This is an elaboration of the
<a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html">http://spark.apache.org/docs/latest/sql-programming-guide.html</a> by Ivan
Sadikov and Raazesh Sainudiin.</p>
</div>
<div class="section" id="getting-started-exercise">
<h1>Getting Started - Exercise<a class="headerlink" href="#getting-started-exercise" title="Permalink to this headline">¶</a></h1>
<p>After having gone through the simple example dataset in the programming
guide, let’s try a slightly larger dataset next.</p>
<p>Let us first create a table of social media usage from NYC</p>
<blockquote>
<div><p>See the <strong>Load Data</strong> section to create this <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code>
table from raw data.</p>
</div></blockquote>
<p>First let’s make sure this table is available for us. If you don’t see
<code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code> as a <code class="docutils literal notranslate"><span class="pre">name</span></code>d table in the output of the next cell
then we first need to ingest this dataset. Let’s do it using the
databricks’ GUI for creating <code class="docutils literal notranslate"><span class="pre">Data</span></code> as done next.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Let</span><span class="s1">&#39;s find out what tables are already available for loading</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----------------+--------+-----------+---------+-----------+
|            name|database|description|tableType|isTemporary|
+----------------+--------+-----------+---------+-----------+
|sentimentlex_csv| default|       null| EXTERNAL|      false|
|          people|    null|       null|TEMPORARY|       true|
+----------------+--------+-----------+---------+-----------+
</pre></div>
</div>
</div></blockquote>
<div class="section" id="nyc-social-media-usage-data">
<h2>NYC Social Media Usage Data<a class="headerlink" href="#nyc-social-media-usage-data" title="Permalink to this headline">¶</a></h2>
<p>This dataset is from
<a class="reference external" href="https://datahub.io/JohnSnowLabs/nyc-social-media-usage#readme">https://datahub.io/JohnSnowLabs/nyc-social-media-usage#readme</a></p>
<p>The Demographic Reports are produced by the Economic, Demographic and
Statistical Research unit within the Countywide Service Integration and
Planning Management (CSIPM) Division of the Fairfax County Department of
Neighborhood and Community Services. Information produced by the
Economic, Demographic and Statistical Research unit is used by every
county department, board, authority and the Fairfax County Public
Schools. In addition to the small area estimates and forecasts, state
and federal data on Fairfax County are collected and summarized, and
special studies and Quantitative research are conducted by the unit.</p>
<p>We are going to fetch this data, with slightly simplified column names,
from the following URL:</p>
<ul class="simple">
<li><p>http://lamastex.org/datasets/public/NYCUSA/social-media-usage.csv</p></li>
</ul>
<p>To turn the dataset into a registered table we will load it using the
GUI as follows:</p>
<ul class="simple">
<li><p>Download it to your local machine / laptop and then use the ‘Data’
button on the left to upload it (we will try this method now).</p>
<ul>
<li><p>This will put your data in the <code class="docutils literal notranslate"><span class="pre">Filestore</span></code> in databricks’
distributed file system.</p></li>
</ul>
</li>
</ul>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>Below we will show you how to create and query a table or DataFrame that
you uploaded to DBFS.
<a class="reference external" href="https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html">DBFS</a>
is a Databricks File System (their distributed file system) that allows
you to store data for querying inside of Databricks. This notebook
assumes that you have a file already inside of DBFS that you would like
to read from.</p>
<p>In other setups, you can have the data in s3 (say in AWS) or in hdfs in
your hadoop cluster, etc.</p>
<p>Alternatively, you can use <code class="docutils literal notranslate"><span class="pre">curl</span></code> or <code class="docutils literal notranslate"><span class="pre">wget</span></code> to download it to the local
file system in <code class="docutils literal notranslate"><span class="pre">/databricks/driver</span></code> and then load it into <code class="docutils literal notranslate"><span class="pre">dbfs</span></code>, after
this you can use read it via <code class="docutils literal notranslate"><span class="pre">spark</span></code> session into a dataframe and
register it as a hive table.</p>
<p>You can also get the data directly from here (but in this case you need
to change the column names in the databricks Data upload GUI or
programmatically to follow this notebook):</p>
<ul class="simple">
<li><p>http://datahub.io/JohnSnowLabs/nyc-social-media-usage</p></li>
</ul>
</div>
</div>
<div class="section" id="load-data">
<h2>Load Data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="how-to-uoload-csv-file-and-make-a-table-in-databricks">
<h3>How to uoload csv file and make a table in databricks<a class="headerlink" href="#how-to-uoload-csv-file-and-make-a-table-in-databricks" title="Permalink to this headline">¶</a></h3>
<p>Okay, so how did we actually make table <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code>? Databricks
allows us to upload/link external data and make it available as
registerd SQL table. It involves several steps:</p>
<ol class="simple">
<li><p>Dowload this <code class="docutils literal notranslate"><span class="pre">social-media-usage.csv</span></code> file from the following URL to
your laptop:</p></li>
</ol>
<ul>
<li><p>http://lamastex.org/datasets/public/NYCUSA/social-media-usage.csv</p></li>
<li><p>Go to Databricks cloud (where you log in to use Databricks
notebooks) and open tab <strong>Data</strong> on the left panel</p></li>
<li><p>On the very top of the left sub-menu you will see button <strong>+Add
Data</strong>, click on it</p></li>
<li><p>Choose <strong>Upload File</strong> for Data Sources by <strong>Browse</strong> or <strong>Drag and
Drop</strong>, where <strong>File</strong> means any file (Parquet, Avro, CSV), but it
works the best with CSV format</p></li>
<li><p>Upload <code class="docutils literal notranslate"><span class="pre">social-media-usage.csv</span></code> file you just downloaded to
databricks</p></li>
<li><p>Just note the path to the uploaded file, for example in my case:</p>
<blockquote>
<div><p>File uploaded to <code class="docutils literal notranslate"><span class="pre">/FileStore/tables/social_media_usage.csv</span></code></p>
</div></blockquote>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="o">//</span> <span class="n">File</span> <span class="n">location</span> <span class="ow">and</span> <span class="nb">type</span>
<span class="o">//</span> <span class="n">You</span> <span class="n">may</span> <span class="n">need</span> <span class="n">to</span> <span class="n">change</span> <span class="n">the</span> <span class="n">file_location</span> <span class="s2">&quot;social_media_usage-5dbee.csv&quot;</span> <span class="n">depending</span> <span class="n">on</span> <span class="n">your</span> <span class="n">location</span> <span class="n">given</span> <span class="n">by</span>
<span class="o">//</span> <span class="n">File</span> <span class="n">uploaded</span> <span class="n">to</span> <span class="o">/</span><span class="n">FileStore</span><span class="o">/</span><span class="n">tables</span><span class="o">/</span><span class="n">social_media_usage</span><span class="o">.</span><span class="n">csv</span>
<span class="n">val</span> <span class="n">file_location</span> <span class="o">=</span> <span class="s2">&quot;/FileStore/tables/social_media_usage.csv&quot;</span>
<span class="n">val</span> <span class="n">file_type</span> <span class="o">=</span> <span class="s2">&quot;csv&quot;</span>

<span class="o">//</span> <span class="n">CSV</span> <span class="n">options</span>
<span class="n">val</span> <span class="n">infer_schema</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
<span class="n">val</span> <span class="n">first_row_is_header</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
<span class="n">val</span> <span class="n">delimiter</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span>

<span class="o">//</span> <span class="n">The</span> <span class="n">applied</span> <span class="n">options</span> <span class="n">are</span> <span class="k">for</span> <span class="n">CSV</span> <span class="n">files</span><span class="o">.</span> <span class="n">For</span> <span class="n">other</span> <span class="n">file</span> <span class="n">types</span><span class="p">,</span> <span class="n">these</span> <span class="n">will</span> <span class="n">be</span> <span class="n">ignored</span><span class="o">.</span>
<span class="n">val</span> <span class="n">socialMediaDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file_type</span><span class="p">)</span> 
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="n">infer_schema</span><span class="p">)</span> 
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="n">first_row_is_header</span><span class="p">)</span> 
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;sep&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">)</span> 
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_location</span><span class="p">)</span>

<span class="n">socialMediaDF</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------+----------+--------------------+----------+------+
|agency|  platform|                 url|      date|visits|
+------+----------+--------------------+----------+------+
|   OEM|       SMS|                null|2012-02-17| 61652|
|   OEM|       SMS|                null|2012-11-09| 44547|
|   EDC|    Flickr|http://www.flickr...|2012-05-09|  null|
| NYCHA|Newsletter|                null|2012-05-09|  null|
|   DHS|   Twitter|www.twitter.com/n...|2012-06-13|   389|
|   DHS|   Twitter|www.twitter.com/n...|2012-08-02|   431|
|   DOH|   Android|       Condom Finder|2011-08-08|  5026|
|   DOT|   Android|         You The Man|2011-08-08|  null|
|  MOME|   Android|      MiNY Venor app|2011-08-08|   313|
|   DOT|Broadcastr|                null|2011-08-08|  null|
+------+----------+--------------------+----------+------+
only showing top 10 rows

file_location: String = /FileStore/tables/social_media_usage.csv
file_type: String = csv
infer_schema: String = true
first_row_is_header: String = true
delimiter: String = ,
socialMediaDF: org.apache.spark.sql.DataFrame = [agency: string, platform: string ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Let</span><span class="s1">&#39;s create a view or table</span>

<span class="n">val</span> <span class="n">temp_table_name</span> <span class="o">=</span> <span class="s2">&quot;social_media_usage&quot;</span>

<span class="n">socialMediaDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="n">temp_table_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>temp_table_name: String = social_media_usage
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Let</span><span class="s1">&#39;s find out what tables are already available for loading</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------------------+--------+-----------+---------+-----------+
|              name|database|description|tableType|isTemporary|
+------------------+--------+-----------+---------+-----------+
|  sentimentlex_csv| default|       null| EXTERNAL|      false|
|            people|    null|       null|TEMPORARY|       true|
|social_media_usage|    null|       null|TEMPORARY|       true|
+------------------+--------+-----------+---------+-----------+
</pre></div>
</div>
</div></blockquote>
<p>With this registered as a temporary view, <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code> will only
be available to this particular notebook.</p>
<p>If you’d like other users to be able to query this table (in the
databricks professional shard - not the free community edition; or in a
managed on-premise cluster), you can also create a table from the
DataFrame.</p>
<p>Once saved, this table will persist across cluster restarts as well as
allow various users across different notebooks to query this data. To do
so, choose your table name and use <code class="docutils literal notranslate"><span class="pre">saveAsTable</span></code> as done in the next
cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">permanent_table_name</span> <span class="o">=</span> <span class="s2">&quot;social_media_usage&quot;</span>
<span class="n">socialMediaDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="n">permanent_table_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>permanent_table_name: String = social_media_usage
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Let</span><span class="s1">&#39;s find out what tables are already available for loading</span>
<span class="o">//</span> <span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It looks like the table <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code> is available as a permanent
table (<code class="docutils literal notranslate"><span class="pre">isTemporary</span></code> set as <code class="docutils literal notranslate"><span class="pre">false</span></code>), if you have not uncommented the
last line in the previous cell (otherwise it will be available from a
parquet file as a permanent table - we will see more about parquet in
the sequel).</p>
<p>Next let us do the following:</p>
<ul class="simple">
<li><p>load this table as a DataFrame (yes, the dataframe already exists as
<code class="docutils literal notranslate"><span class="pre">socialMediaDF</span></code>, but we want to make a new DataFrame directly from
the table)</p></li>
<li><p>print its schema and</p></li>
<li><p>show the first 20 rows.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------------------+--------+-----------+---------+-----------+
|              name|database|description|tableType|isTemporary|
+------------------+--------+-----------+---------+-----------+
|  sentimentlex_csv| default|       null| EXTERNAL|      false|
|            people|    null|       null|TEMPORARY|       true|
|social_media_usage|    null|       null|TEMPORARY|       true|
+------------------+--------+-----------+---------+-----------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;social_media_usage&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>df: org.apache.spark.sql.DataFrame = [agency: string, platform: string ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<p>As you can see the immutable value <code class="docutils literal notranslate"><span class="pre">df</span></code> is a DataFrame and more
specifically it is:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.DataFrame</span> <span class="pre">=</span> <span class="pre">[agency:</span> <span class="pre">string,</span> <span class="pre">platform:</span> <span class="pre">string,</span> <span class="pre">url:</span> <span class="pre">string,</span> <span class="pre">date:</span> <span class="pre">timestamp,</span> <span class="pre">visits:</span> <span class="pre">integer]</span></code>.</p>
</div></blockquote>
<p>Now let us print schema of the DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code> and have a look at the
actual data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span>
<span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span> <span class="o">//</span> <span class="n">prints</span> <span class="n">schema</span> <span class="n">of</span> <span class="n">the</span> <span class="n">DataFrame</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="o">//</span> <span class="n">shows</span> <span class="n">first</span> <span class="n">n</span> <span class="p">(</span><span class="n">default</span> <span class="ow">is</span> <span class="mi">20</span><span class="p">)</span> <span class="n">rows</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>root
 |-- agency: string (nullable = true)
 |-- platform: string (nullable = true)
 |-- url: string (nullable = true)
 |-- date: string (nullable = true)
 |-- visits: integer (nullable = true)

+----------+----------+--------------------+----------+------+
|    agency|  platform|                 url|      date|visits|
+----------+----------+--------------------+----------+------+
|       OEM|       SMS|                null|2012-02-17| 61652|
|       OEM|       SMS|                null|2012-11-09| 44547|
|       EDC|    Flickr|http://www.flickr...|2012-05-09|  null|
|     NYCHA|Newsletter|                null|2012-05-09|  null|
|       DHS|   Twitter|www.twitter.com/n...|2012-06-13|   389|
|       DHS|   Twitter|www.twitter.com/n...|2012-08-02|   431|
|       DOH|   Android|       Condom Finder|2011-08-08|  5026|
|       DOT|   Android|         You The Man|2011-08-08|  null|
|      MOME|   Android|      MiNY Venor app|2011-08-08|   313|
|       DOT|Broadcastr|                null|2011-08-08|  null|
|       DPR|Broadcastr|http://beta.broad...|2011-08-08|  null|
|     ENDHT|  Facebook|http://www.facebo...|2011-08-08|     3|
|       VAC|  Facebook|https://www.faceb...|2011-08-08|    36|
|    PlaNYC|  Facebook|http://www.facebo...|2011-08-08|    47|
|      DFTA|  Facebook|http://www.facebo...|2011-08-08|    90|
| energyNYC|  Facebook|http://www.facebo...|2011-08-08|   105|
|      MOIA|  Facebook|http://www.facebo...|2011-08-08|   123|
|City Store|  Facebook|http://www.facebo...|2011-08-08|   119|
|      OCDV|  Facebook|http://www.facebo...|2011-08-08|   148|
|       HIA|  Facebook|http://www.facebo...|2011-08-08|   197|
+----------+----------+--------------------+----------+------+
only showing top 20 rows
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><p>Note that <code class="docutils literal notranslate"><span class="pre">(nullable</span> <span class="pre">=</span> <span class="pre">true)</span></code> simply means if the value is allowed to
be <code class="docutils literal notranslate"><span class="pre">null</span></code>.</p>
</div></blockquote>
<p>Let us count the number of rows in <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">get</span> <span class="mi">5898</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res16: Long = 5898
</pre></div>
</div>
</div></blockquote>
<p>So there are 5899 records or rows in the DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code>. Pretty good!
You can also select individual columns using so-called DataFrame API, as
follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">platforms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;platform&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>platforms: org.apache.spark.sql.DataFrame = [platform: string]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">platforms</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">count</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">rows</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res18: Long = 5898
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">platforms</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">show</span> <span class="n">top</span> <span class="mi">5</span> <span class="n">rows</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+----------+
|  platform|
+----------+
|       SMS|
|       SMS|
|    Flickr|
|Newsletter|
|   Twitter|
+----------+
only showing top 5 rows
</pre></div>
</div>
</div></blockquote>
<p>You can also apply <code class="docutils literal notranslate"><span class="pre">.distinct()</span></code> to extract only unique entries as
follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="n">uniquePlatforms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;platform&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span> <span class="o">//</span> <span class="n">Shift</span><span class="o">+</span><span class="n">Enter</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>uniquePlatforms: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [platform: string]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">uniquePlatforms</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">count</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">distinct</span> <span class="n">platforms</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>res21: Long = 23
</pre></div>
</div>
</div></blockquote>
<p>Let’s see all the rows of the DataFrame <code class="docutils literal notranslate"><span class="pre">uniquePlatforms</span></code>.</p>
<blockquote>
<div><p>Note that <code class="docutils literal notranslate"><span class="pre">display(uniquePlatforms)</span></code> unlike <code class="docutils literal notranslate"><span class="pre">uniquePlatforms.show()</span></code>
displays all rows of the DataFrame + gives you ability to select
different view, e.g. charts.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">uniquePlatforms</span><span class="p">)</span> <span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">show</span> <span class="nb">all</span> <span class="n">rows</span><span class="p">;</span> <span class="n">use</span> <span class="n">the</span> <span class="n">scroll</span><span class="o">-</span><span class="n">bar</span> <span class="n">on</span> <span class="n">the</span> <span class="n">right</span> <span class="n">of</span> <span class="n">the</span> <span class="n">display</span> <span class="n">to</span> <span class="n">see</span> <span class="nb">all</span> <span class="n">platforms</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
</div>
<div class="section" id="spark-sql-and-dataframe-api">
<h3>Spark SQL and DataFrame API<a class="headerlink" href="#spark-sql-and-dataframe-api" title="Permalink to this headline">¶</a></h3>
<p>Spark SQL provides DataFrame API that can perform relational operations
on both external data sources and internal collections, which is similar
to widely used data frame concept in R, but evaluates operations support
lazily (remember RDDs?), so that it can perform relational
optimizations. This API is also available in Java, Python and R, but
some functionality may not be available, although with every release of
Spark people minimize this gap.</p>
<p>So we give some examples how to query data in Python and R, but continue
with Scala. You can do all DataFrame operations in this notebook using
Python or R.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ctrl+Enter to evaluate this python cell, recall &#39;#&#39; is the pre-comment character in python</span>
<span class="c1"># Using Python to query our &quot;social_media_usage&quot; table</span>
<span class="n">pythonDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;social_media_usage&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;platform&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span>
<span class="n">pythonDF</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+--------+
|platform|
+--------+
|  Flickr|
|     SMS|
| Twitter|
+--------+
only showing top 3 rows
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>-- Ctrl+Enter to achieve the same result using standard SQL syntax!
select distinct platform from social_media_usage
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>Now it is time for some tips around how you use <code class="docutils literal notranslate"><span class="pre">select</span></code> and what the
difference is between <code class="docutils literal notranslate"><span class="pre">$&quot;a&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">col(&quot;a&quot;)</span></code>, <code class="docutils literal notranslate"><span class="pre">df(&quot;a&quot;)</span></code>.</p>
<p>As you probably have noticed by now, you can specify individual columns
to select by providing String values in select statement. But sometimes
you need to: - distinguish between columns with the same name - use it
to filter (actually you can still filter using full String expression) -
do some “magic” with joins and user-defined functions (this will be
shown later)</p>
<p>So Spark gives you ability to actually specify columns when you select.
Now the difference between all those three notations is … none, those
things are just aliases for a <code class="docutils literal notranslate"><span class="pre">Column</span></code> in Spark SQL, which means
following expressions yield the same result:</p>
<p>``` // Using string expressions df.select(“agency”, “visits”)</p>
<p>// Using “<span class="math notranslate nohighlight">\(&quot; alias for column df.select(\)</span>“agency”, $”visits”)</p>
<p>// Using “col” alias for column df.select(col(“agency”), col(“visits”))</p>
<p>// Using DataFrame name for column df.select(df(“agency”), df(“visits”))
```</p>
<p>This “same-difference” applies to filtering, i.e. you can either use
full expression to filter, or column as shown in the following example:</p>
<p>``` // Using column to filter df.select(“visits”).filter($”visits”
&gt; 100)</p>
<p>// Or you can use full expression as string
df.select(“visits”).filter(“visits &gt; 100”) ```</p>
<blockquote>
<div><p>Note that <code class="docutils literal notranslate"><span class="pre">$&quot;visits&quot;</span> <span class="pre">&gt;</span> <span class="pre">100</span></code> expression looks amazing, but under the
hood it is just another column, and it equals to
<code class="docutils literal notranslate"><span class="pre">df(&quot;visits&quot;).&gt;(100)</span></code>, where, thanks to Scala paradigm <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> is just
another function that you can define.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>val sms = df.select($&quot;agency&quot;, $&quot;platform&quot;, $&quot;visits&quot;).filter($&quot;platform&quot; === &quot;SMS&quot;)
sms.show() // Ctrl+Enter
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------+--------+------+
|agency|platform|visits|
+------+--------+------+
|   OEM|     SMS| 61652|
|   OEM|     SMS| 44547|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
|   OEM|     SMS|  null|
|   DOE|     SMS|  null|
| NYCHA|     SMS|  null|
|   OEM|     SMS|  null|
|   DOE|     SMS|  null|
| NYCHA|     SMS|  null|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
+------+--------+------+
only showing top 20 rows

sms: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [agency: string, platform: string ... 1 more field]
</pre></div>
</div>
</div></blockquote>
<p>Again you could have written the query above using any column aliases or
String names or even writing the query directly.</p>
<p>For example, we can do it using String names, as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">Note</span> <span class="n">that</span> <span class="n">we</span> <span class="n">are</span> <span class="n">using</span> <span class="s2">&quot;platform = &#39;SMS&#39;&quot;</span> <span class="n">since</span> <span class="n">it</span> <span class="n">will</span> <span class="n">be</span> <span class="n">evaluated</span> <span class="k">as</span> <span class="n">actual</span> <span class="n">SQL</span>
<span class="n">val</span> <span class="n">sms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="p">(</span><span class="s2">&quot;agency&quot;</span><span class="p">),</span> <span class="n">df</span><span class="p">(</span><span class="s2">&quot;platform&quot;</span><span class="p">),</span> <span class="n">df</span><span class="p">(</span><span class="s2">&quot;visits&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;platform = &#39;SMS&#39;&quot;</span><span class="p">)</span>
<span class="n">sms</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------+--------+------+
|agency|platform|visits|
+------+--------+------+
|   OEM|     SMS| 61652|
|   OEM|     SMS| 44547|
|   DOE|     SMS|   382|
| NYCHA|     SMS|  null|
|   OEM|     SMS| 61652|
+------+--------+------+
only showing top 5 rows

sms: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [agency: string, platform: string ... 1 more field]
</pre></div>
</div>
</div></blockquote>
<p>Refer to the <a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame
API</a>
for more detailed API. In addition to simple column references and
expressions, DataFrames also have a rich library of functions including
string manipulation, date arithmetic, common math operations and more.
The complete list is available in the <a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions%24">DataFrame Function
Reference</a>.</p>
<p>Let’s next explore some of the functionality that is available by
transforming this DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code> into a new DataFrame called <code class="docutils literal notranslate"><span class="pre">fixedDF</span></code>.</p>
<ul class="simple">
<li><p>First, note that some columns are not exactly what we want them to
be.</p>
<ul>
<li><p>visits should not contain null values, but <code class="docutils literal notranslate"><span class="pre">0</span></code>s instead.</p></li>
</ul>
</li>
<li><p>Let us fix it using some code that is briefly explained here (don’t
worry if you don’t get it completely now, you will get the hang of
it by playing more)</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">coalesce</span></code> function is similar to <code class="docutils literal notranslate"><span class="pre">if-else</span></code> statement, i.e.,
if first column in expression is <code class="docutils literal notranslate"><span class="pre">null</span></code>, then the value of the
second column is used and so on.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lit</span></code> just means column of constant value (<code class="docutils literal notranslate"><span class="pre">lit</span></code>erally
speaking!).</p></li>
<li><p>we also remove <code class="docutils literal notranslate"><span class="pre">TOTAL</span></code> value from <code class="docutils literal notranslate"><span class="pre">platform</span></code> column.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Ctrl+Enter to make fixedDF

// import the needed sql functions
import org.apache.spark.sql.functions.{coalesce, lit}

// make the fixedDF DataFrame
val fixedDF = df.
   select(
     $&quot;agency&quot;, 
     $&quot;platform&quot;, 
     $&quot;url&quot;, 
     $&quot;date&quot;, 
     coalesce($&quot;visits&quot;, lit(0)).as(&quot;visits&quot;))
    .filter($&quot;platform&quot; =!= &quot;TOTAL&quot;)

fixedDF.printSchema() // print its schema 
// and show the top 20 records fully
fixedDF.show(false) // the false argument does not truncate the rows, so you will not see something like this &quot;anot...&quot;
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>root
 |-- agency: string (nullable = true)
 |-- platform: string (nullable = true)
 |-- url: string (nullable = true)
 |-- date: string (nullable = true)
 |-- visits: integer (nullable = false)

+----------+----------+---------------------------------------------------------------------------------------+----------+------+
|agency    |platform  |url                                                                                    |date      |visits|
+----------+----------+---------------------------------------------------------------------------------------+----------+------+
|OEM       |SMS       |null                                                                                   |2012-02-17|61652 |
|OEM       |SMS       |null                                                                                   |2012-11-09|44547 |
|EDC       |Flickr    |http://www.flickr.com/nycedc                                                           |2012-05-09|0     |
|NYCHA     |Newsletter|null                                                                                   |2012-05-09|0     |
|DHS       |Twitter   |www.twitter.com/nycdhs                                                                 |2012-06-13|389   |
|DHS       |Twitter   |www.twitter.com/nycdhs                                                                 |2012-08-02|431   |
|DOH       |Android   |Condom Finder                                                                          |2011-08-08|5026  |
|DOT       |Android   |You The Man                                                                            |2011-08-08|0     |
|MOME      |Android   |MiNY Venor app                                                                         |2011-08-08|313   |
|DOT       |Broadcastr|null                                                                                   |2011-08-08|0     |
|DPR       |Broadcastr|http://beta.broadcastr.com/Echo.html?audioId=670026-4001                               |2011-08-08|0     |
|ENDHT     |Facebook  |http://www.facebook.com/pages/NYC-Lets-End-Human-Trafficking/125730490795659?sk=wall   |2011-08-08|3     |
|VAC       |Facebook  |https://www.facebook.com/pages/NYC-Voter-Assistance-Commission/110226709012110         |2011-08-08|36    |
|PlaNYC    |Facebook  |http://www.facebook.com/pages/New-York-NY/PlaNYC/160454173971169?ref=ts                |2011-08-08|47    |
|DFTA      |Facebook  |http://www.facebook.com/pages/NYC-Department-for-the-Aging/109028655823590             |2011-08-08|90    |
|energyNYC |Facebook  |http://www.facebook.com/EnergyNYC?sk=wall                                              |2011-08-08|105   |
|MOIA      |Facebook  |http://www.facebook.com/ihwnyc                                                         |2011-08-08|123   |
|City Store|Facebook  |http://www.facebook.com/citystorenyc                                                   |2011-08-08|119   |
|OCDV      |Facebook  |http://www.facebook.com/pages/NYC-Healthy-Relationship-Training-Academy/134637829901065|2011-08-08|148   |
|HIA       |Facebook  |http://www.facebook.com/pages/New-York-City-Health-Insurance-Link/145920551598         |2011-08-08|197   |
+----------+----------+---------------------------------------------------------------------------------------+----------+------+
only showing top 20 rows

import org.apache.spark.sql.functions.{coalesce, lit}
fixedDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [agency: string, platform: string ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<p>Okay, this is better, but <code class="docutils literal notranslate"><span class="pre">url</span></code>s are still inconsistent.</p>
<p>Let’s fix this by writing our own UDF (user-defined function) to deal
with special cases.</p>
<p>Note that if you <strong>CAN USE Spark functions library</strong>, do it. But for the
sake of the example, custom UDF is shown below.</p>
<p>We take value of a column as String type and return the same String
type, but ignore values that do not start with <code class="docutils literal notranslate"><span class="pre">http</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">this</span> <span class="n">UDF</span> <span class="n">which</span> <span class="n">takes</span> <span class="n">a</span> <span class="nb">input</span> <span class="n">String</span> <span class="n">called</span> <span class="s2">&quot;value&quot;</span>
<span class="o">//</span> <span class="ow">and</span> <span class="n">converts</span> <span class="n">it</span> <span class="n">into</span> <span class="n">lower</span><span class="o">-</span><span class="n">case</span> <span class="k">if</span> <span class="n">it</span> <span class="n">begins</span> <span class="k">with</span> <span class="n">http</span> <span class="ow">and</span> <span class="n">otherwise</span> <span class="n">leaves</span> <span class="n">it</span> <span class="k">as</span> <span class="n">null</span><span class="p">,</span> <span class="n">so</span> <span class="n">we</span> <span class="n">sort</span> <span class="n">of</span> <span class="n">remove</span> <span class="n">non</span> <span class="n">valid</span> <span class="n">web</span><span class="o">-</span><span class="n">urls</span>
<span class="n">val</span> <span class="n">cleanUrl</span> <span class="o">=</span> <span class="n">udf</span><span class="p">((</span><span class="n">value</span><span class="p">:</span> <span class="n">String</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="k">if</span> <span class="p">(</span><span class="n">value</span> <span class="o">!=</span> <span class="n">null</span> <span class="o">&amp;&amp;</span> <span class="n">value</span><span class="o">.</span><span class="n">startsWith</span><span class="p">(</span><span class="s2">&quot;http&quot;</span><span class="p">))</span> <span class="n">value</span><span class="o">.</span><span class="n">toLowerCase</span><span class="p">()</span> <span class="k">else</span> <span class="n">null</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cleanUrl: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$6230/869691273@375f4166,StringType,List(Some(class[value[0]: string])),None,true,true)
</pre></div>
</div>
</div></blockquote>
<p>Let us apply our UDF on <code class="docutils literal notranslate"><span class="pre">fixedDF</span></code> to create a new DataFrame called
<code class="docutils literal notranslate"><span class="pre">cleanedDF</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Ctrl+Enter
val cleanedDF = fixedDF.select($&quot;agency&quot;, $&quot;platform&quot;, cleanUrl($&quot;url&quot;).as(&quot;url&quot;), $&quot;date&quot;, $&quot;visits&quot;)
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cleanedDF: org.apache.spark.sql.DataFrame = [agency: string, platform: string ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<p>Now, let’s check that it actually worked by seeing the first 5 rows of
the <code class="docutils literal notranslate"><span class="pre">cleanedDF</span></code> whose <code class="docutils literal notranslate"><span class="pre">url</span></code> <code class="docutils literal notranslate"><span class="pre">isNull</span></code> and <code class="docutils literal notranslate"><span class="pre">isNotNull</span></code>, as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Shift+Enter
cleanedDF.filter($&quot;url&quot;.isNull).show(5)
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------+----------+----+----------+------+
|agency|  platform| url|      date|visits|
+------+----------+----+----------+------+
|   OEM|       SMS|null|2012-02-17| 61652|
|   OEM|       SMS|null|2012-11-09| 44547|
| NYCHA|Newsletter|null|2012-05-09|     0|
|   DHS|   Twitter|null|2012-06-13|   389|
|   DHS|   Twitter|null|2012-08-02|   431|
+------+----------+----+----------+------+
only showing top 5 rows
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// Ctrl+Enter
cleanedDF.filter($&quot;url&quot;.isNotNull).show(5, false) // false in .show(5, false) shows rows untruncated
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------+----------+------------------------------------------------------------------------------------+----------+------+
|agency|platform  |url                                                                                 |date      |visits|
+------+----------+------------------------------------------------------------------------------------+----------+------+
|EDC   |Flickr    |http://www.flickr.com/nycedc                                                        |2012-05-09|0     |
|DPR   |Broadcastr|http://beta.broadcastr.com/echo.html?audioid=670026-4001                            |2011-08-08|0     |
|ENDHT |Facebook  |http://www.facebook.com/pages/nyc-lets-end-human-trafficking/125730490795659?sk=wall|2011-08-08|3     |
|VAC   |Facebook  |https://www.facebook.com/pages/nyc-voter-assistance-commission/110226709012110      |2011-08-08|36    |
|PlaNYC|Facebook  |http://www.facebook.com/pages/new-york-ny/planyc/160454173971169?ref=ts             |2011-08-08|47    |
+------+----------+------------------------------------------------------------------------------------+----------+------+
only showing top 5 rows
</pre></div>
</div>
</div></blockquote>
<p>Now there is a suggestion from you manager’s manager’s manager that due
to some perceived privacy concerns we want to replace <code class="docutils literal notranslate"><span class="pre">agency</span></code> with some
unique identifier.</p>
<p>So we need to do the following:</p>
<ul class="simple">
<li><p>create unique list of agencies with ids and</p></li>
<li><p>join them with main DataFrame.</p></li>
</ul>
<p>Sounds easy, right? Let’s do it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Crtl</span><span class="o">+</span><span class="n">Enter</span>
<span class="o">//</span> <span class="n">Import</span> <span class="n">Spark</span> <span class="n">SQL</span> <span class="n">function</span> <span class="n">that</span> <span class="n">will</span> <span class="n">give</span> <span class="n">us</span> <span class="n">unique</span> <span class="nb">id</span> <span class="n">across</span> <span class="nb">all</span> <span class="n">the</span> <span class="n">records</span> <span class="ow">in</span> <span class="n">this</span> <span class="n">DataFrame</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.functions.monotonically_increasing_id</span>

<span class="o">//</span> <span class="n">We</span> <span class="n">append</span> <span class="n">column</span> <span class="k">as</span> <span class="n">SQL</span> <span class="n">function</span> <span class="n">that</span> <span class="n">creates</span> <span class="n">unique</span> <span class="n">ids</span> <span class="n">across</span> <span class="nb">all</span> <span class="n">records</span> <span class="ow">in</span> <span class="n">DataFrames</span> 
<span class="n">val</span> <span class="n">agencies</span> <span class="o">=</span> <span class="n">cleanedDF</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">cleanedDF</span><span class="p">(</span><span class="s2">&quot;agency&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">distinct</span><span class="p">()</span>
                        <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="n">monotonically_increasing_id</span><span class="p">())</span>
<span class="n">agencies</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+--------------------+-----------+
|              agency|         id|
+--------------------+-----------+
|              PlaNYC|34359738368|
|                 HIA|34359738369|
|NYC Digital: exte...|34359738370|
|           NYCGLOBAL|42949672960|
|              nycgov|68719476736|
+--------------------+-----------+
only showing top 5 rows

import org.apache.spark.sql.functions.monotonically_increasing_id
agencies: org.apache.spark.sql.DataFrame = [agency: string, id: bigint]
</pre></div>
</div>
</div></blockquote>
<p>Those who want to understand left/right inner/outer joins can see the
video lectures in Module 3 of Anthony Joseph’s Introduction to Big data
edX course.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Ctrl</span><span class="o">+</span><span class="n">Enter</span>
<span class="o">//</span> <span class="n">And</span> <span class="n">join</span> <span class="k">with</span> <span class="n">the</span> <span class="n">rest</span> <span class="n">of</span> <span class="n">the</span> <span class="n">data</span><span class="p">,</span> <span class="n">note</span> <span class="n">how</span> <span class="n">join</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">specified</span> 
<span class="n">val</span> <span class="n">anonym</span> <span class="o">=</span> <span class="n">cleanedDF</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">agencies</span><span class="p">,</span> <span class="n">cleanedDF</span><span class="p">(</span><span class="s2">&quot;agency&quot;</span><span class="p">)</span> <span class="o">===</span> <span class="n">agencies</span><span class="p">(</span><span class="s2">&quot;agency&quot;</span><span class="p">),</span> <span class="s2">&quot;inner&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;platform&quot;</span><span class="p">,</span> <span class="s2">&quot;url&quot;</span><span class="p">,</span> <span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="s2">&quot;visits&quot;</span><span class="p">)</span>

<span class="o">//</span> <span class="n">We</span> <span class="n">also</span> <span class="n">cache</span> <span class="n">DataFrame</span> <span class="n">since</span> <span class="n">it</span> <span class="n">can</span> <span class="n">be</span> <span class="n">quite</span> <span class="n">expensive</span> <span class="n">to</span> <span class="n">recompute</span> <span class="n">join</span>
<span class="n">anonym</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="o">//</span> <span class="n">Display</span> <span class="n">result</span>
<span class="n">anonym</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+-------------+----------+--------------------+----------+------+
|           id|  platform|                 url|      date|visits|
+-------------+----------+--------------------+----------+------+
|1580547964928|       SMS|                null|2012-02-17| 61652|
|1580547964928|       SMS|                null|2012-11-09| 44547|
| 412316860416|    Flickr|http://www.flickr...|2012-05-09|     0|
|1649267441664|Newsletter|                null|2012-05-09|     0|
|1529008357376|   Twitter|                null|2012-06-13|   389|
+-------------+----------+--------------------+----------+------+
only showing top 5 rows

anonym: org.apache.spark.sql.DataFrame = [id: bigint, platform: string ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="o">//</span> <span class="n">look</span> <span class="n">at</span> <span class="n">the</span> <span class="n">available</span> <span class="n">tables</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+------------------+--------+-----------+---------+-----------+
|              name|database|description|tableType|isTemporary|
+------------------+--------+-----------+---------+-----------+
|  sentimentlex_csv| default|       null| EXTERNAL|      false|
|            people|    null|       null|TEMPORARY|       true|
|social_media_usage|    null|       null|TEMPORARY|       true|
+------------------+--------+-----------+---------+-----------+
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">to</span> <span class="n">remove</span> <span class="n">a</span> <span class="n">TempTable</span> <span class="k">if</span> <span class="n">it</span> <span class="n">exists</span> <span class="n">already</span>
<span class="n">drop</span> <span class="n">table</span> <span class="k">if</span> <span class="n">exists</span> <span class="n">anonym</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Register</span> <span class="n">table</span> <span class="k">for</span> <span class="n">Spark</span> <span class="n">SQL</span><span class="p">,</span> <span class="n">we</span> <span class="n">also</span> <span class="kn">import</span> <span class="s2">&quot;month&quot;</span> <span class="n">function</span> 
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.functions.month</span>

<span class="n">anonym</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;anonym&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.sql.functions.month
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Interesting</span><span class="o">.</span> <span class="n">Now</span> <span class="n">let</span><span class="s1">&#39;s do some aggregation. Display platform, month, visits</span>
<span class="o">--</span> <span class="n">Date</span> <span class="n">column</span> <span class="n">allows</span> <span class="n">us</span> <span class="n">to</span> <span class="n">extract</span> <span class="n">month</span> <span class="n">directly</span>

<span class="n">select</span> <span class="n">platform</span><span class="p">,</span> <span class="n">month</span><span class="p">(</span><span class="n">date</span><span class="p">)</span> <span class="k">as</span> <span class="n">month</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">visits</span><span class="p">)</span> <span class="k">as</span> <span class="n">visits</span> <span class="kn">from</span> <span class="nn">anonym</span> <span class="n">group</span> <span class="n">by</span> <span class="n">platform</span><span class="p">,</span> <span class="n">month</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<p>Truncated to 30 rows</p>
<p>Note, that we could have done aggregation using DataFrame API instead of
Spark SQL.</p>
<p>Alright, now let’s see some <em>cool</em> operations with window functions.</p>
<p>Our next task is to compute <code class="docutils literal notranslate"><span class="pre">(daily</span> <span class="pre">visits</span> <span class="pre">/</span> <span class="pre">monthly</span> <span class="pre">average)</span></code> for all
platforms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.sql.functions.{dayofmonth, month, row_number, sum}
import org.apache.spark.sql.expressions.Window

val coolDF = anonym.select($&quot;id&quot;, $&quot;platform&quot;, dayofmonth($&quot;date&quot;).as(&quot;day&quot;), month($&quot;date&quot;).as(&quot;month&quot;), $&quot;visits&quot;).
  groupBy($&quot;id&quot;, $&quot;platform&quot;, $&quot;day&quot;, $&quot;month&quot;).agg(sum(&quot;visits&quot;).as(&quot;visits&quot;))

// Run window aggregation on visits per month and platform
val window = coolDF.select($&quot;id&quot;, $&quot;day&quot;, $&quot;visits&quot;, sum($&quot;visits&quot;).over(Window.partitionBy(&quot;platform&quot;, &quot;month&quot;)).as(&quot;monthly_visits&quot;))

// Create and register percent table
val percent = window.select($&quot;id&quot;, $&quot;day&quot;, ($&quot;visits&quot; / $&quot;monthly_visits&quot;).as(&quot;percent&quot;))

percent.createOrReplaceTempView(&quot;percent&quot;)
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import org.apache.spark.sql.functions.{dayofmonth, month, row_number, sum}
import org.apache.spark.sql.expressions.Window
coolDF: org.apache.spark.sql.DataFrame = [id: bigint, platform: string ... 3 more fields]
window: org.apache.spark.sql.DataFrame = [id: bigint, day: int ... 2 more fields]
percent: org.apache.spark.sql.DataFrame = [id: bigint, day: int ... 1 more field]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>-- A little bit of visualization as result of our efforts
select id, day, `percent` from percent where `percent` &gt; 0.3 and day = 2
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">You</span> <span class="n">also</span> <span class="n">could</span> <span class="n">just</span> <span class="n">use</span> <span class="n">plain</span> <span class="n">SQL</span> <span class="n">to</span> <span class="n">write</span> <span class="n">query</span> <span class="n">above</span><span class="p">,</span> <span class="n">note</span> <span class="n">that</span> <span class="n">you</span> <span class="n">might</span> <span class="n">need</span> <span class="n">to</span> <span class="n">group</span> <span class="n">by</span> <span class="nb">id</span> <span class="ow">and</span> <span class="n">day</span> <span class="k">as</span> <span class="n">well</span><span class="o">.</span>
<span class="k">with</span> <span class="n">aggr</span> <span class="k">as</span> <span class="p">(</span>
  <span class="n">select</span> <span class="nb">id</span><span class="p">,</span> <span class="n">dayofmonth</span><span class="p">(</span><span class="n">date</span><span class="p">)</span> <span class="k">as</span> <span class="n">day</span><span class="p">,</span> <span class="n">visits</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">visits</span><span class="p">)</span> <span class="n">over</span> <span class="p">(</span><span class="n">partition</span> <span class="n">by</span> <span class="p">(</span><span class="n">platform</span><span class="p">,</span> <span class="n">month</span><span class="p">(</span><span class="n">date</span><span class="p">)))</span> <span class="k">as</span> <span class="n">percent</span>
  <span class="kn">from</span> <span class="nn">anonym</span>
<span class="p">)</span>
<span class="n">select</span> <span class="o">*</span> <span class="kn">from</span> <span class="nn">aggr</span> <span class="n">where</span> <span class="n">day</span> <span class="o">=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">percent</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
</pre></div>
</div>
</div>
</div>
<p>[TABLE]</p>
</div>
</div>
<div class="section" id="interoperating-with-rdds">
<h2>Interoperating with RDDs<a class="headerlink" href="#interoperating-with-rdds" title="Permalink to this headline">¶</a></h2>
<p>Spark SQL supports two different methods for converting existing RDDs
into DataFrames. The first method uses reflection to infer the schema of
an RDD that contains specific types of objects. This reflection based
approach leads to more concise code and works well when you already know
the schema.</p>
<p>The second method for creating DataFrames is through a programmatic
interface that allows you to construct a schema and then apply it to an
existing RDD. While this method is more verbose, it allows you to
construct DataFrames when the columns and their types are not known
until runtime.</p>
<div class="section" id="inferring-the-schema-using-reflection">
<h3>Inferring the Schema Using Reflection<a class="headerlink" href="#inferring-the-schema-using-reflection" title="Permalink to this headline">¶</a></h3>
<p>The Scala interface for Spark SQL supports automatically converting an
RDD containing case classes to a DataFrame. The case class defines the
schema of the table. The names of the arguments to the case class are
read using reflection and become the names of the columns. Case classes
can also be nested or contain complex types such as Sequences or Arrays.
This RDD can be implicitly converted to a DataFrame and then be
registered as a table.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Define</span> <span class="n">case</span> <span class="k">class</span> <span class="nc">that</span> <span class="n">will</span> <span class="n">be</span> <span class="n">our</span> <span class="n">schema</span> <span class="k">for</span> <span class="n">DataFrame</span>
<span class="n">case</span> <span class="k">class</span> <span class="nc">Hubot</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">year</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">manufacturer</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">version</span><span class="p">:</span> <span class="n">Array</span><span class="p">[</span><span class="n">Int</span><span class="p">],</span> <span class="n">details</span><span class="p">:</span> <span class="n">Map</span><span class="p">[</span><span class="n">String</span><span class="p">,</span> <span class="n">String</span><span class="p">])</span>

<span class="o">//</span> <span class="n">You</span> <span class="n">can</span> <span class="n">process</span> <span class="n">a</span> <span class="n">text</span> <span class="n">file</span><span class="p">,</span> <span class="k">for</span> <span class="n">example</span><span class="p">,</span> <span class="n">to</span> <span class="n">convert</span> <span class="n">every</span> <span class="n">row</span> <span class="n">to</span> <span class="n">our</span> <span class="n">Hubot</span><span class="p">,</span> <span class="n">but</span> <span class="n">we</span> <span class="n">will</span> <span class="n">create</span> <span class="n">RDD</span> <span class="n">manually</span>
<span class="n">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
  <span class="n">Array</span><span class="p">(</span>
    <span class="n">Hubot</span><span class="p">(</span><span class="s2">&quot;Jerry&quot;</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="s2">&quot;LCorp&quot;</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">Map</span><span class="p">(</span><span class="s2">&quot;eat&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;sleep&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;drink&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;yes&quot;</span><span class="p">)),</span>
    <span class="n">Hubot</span><span class="p">(</span><span class="s2">&quot;Mozart&quot;</span><span class="p">,</span> <span class="mi">2010</span><span class="p">,</span> <span class="s2">&quot;LCorp&quot;</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">Map</span><span class="p">(</span><span class="s2">&quot;eat&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span> <span class="s2">&quot;sleep&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span> <span class="s2">&quot;drink&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;no&quot;</span><span class="p">)),</span>
    <span class="n">Hubot</span><span class="p">(</span><span class="s2">&quot;Einstein&quot;</span><span class="p">,</span> <span class="mi">2012</span><span class="p">,</span> <span class="s2">&quot;LCorp&quot;</span><span class="p">,</span> <span class="n">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">Map</span><span class="p">(</span><span class="s2">&quot;eat&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;sleep&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;drink&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;no&quot;</span><span class="p">))</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>defined class Hubot
rdd: org.apache.spark.rdd.RDD[Hubot] = ParallelCollectionRDD[136] at parallelize at command-1267216879634399:5
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">In</span> <span class="n">order</span> <span class="n">to</span> <span class="n">convert</span> <span class="n">RDD</span> <span class="n">into</span> <span class="n">DataFrame</span> <span class="n">you</span> <span class="n">need</span> <span class="n">to</span> <span class="n">do</span> <span class="n">this</span><span class="p">:</span>
<span class="n">val</span> <span class="n">hubots</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>

<span class="o">//</span> <span class="n">Display</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">note</span> <span class="n">how</span> <span class="n">array</span> <span class="ow">and</span> <span class="nb">map</span> <span class="n">fields</span> <span class="n">are</span> <span class="n">displayed</span>
<span class="n">hubots</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="n">hubots</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>root
 |-- name: string (nullable = true)
 |-- year: integer (nullable = false)
 |-- manufacturer: string (nullable = true)
 |-- version: array (nullable = true)
 |    |-- element: integer (containsNull = false)
 |-- details: map (nullable = true)
 |    |-- key: string
 |    |-- value: string (valueContainsNull = true)

+--------+----+------------+---------+--------------------+
|    name|year|manufacturer|  version|             details|
+--------+----+------------+---------+--------------------+
|   Jerry|2015|       LCorp|[1, 2, 3]|[eat -&gt; yes, slee...|
|  Mozart|2010|       LCorp|   [1, 2]|[eat -&gt; no, sleep...|
|Einstein|2012|       LCorp|[1, 2, 3]|[eat -&gt; yes, slee...|
+--------+----+------------+---------+--------------------+

hubots: org.apache.spark.sql.DataFrame = [name: string, year: int ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// You can query complex type the same as you query any other column
// By the way you can use `sql` function to invoke Spark SQL to create DataFrame
hubots.createOrReplaceTempView(&quot;hubots&quot;)

val onesThatEat = sqlContext.sql(&quot;select name, details.eat from hubots where details.eat = &#39;yes&#39;&quot;)

onesThatEat.show()
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+--------+---+
|    name|eat|
+--------+---+
|   Jerry|yes|
|Einstein|yes|
+--------+---+

onesThatEat: org.apache.spark.sql.DataFrame = [name: string, eat: string]
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="programmatically-specifying-the-schema">
<h3>Programmatically Specifying the Schema<a class="headerlink" href="#programmatically-specifying-the-schema" title="Permalink to this headline">¶</a></h3>
<p>When case classes cannot be defined ahead of time (for example, the
structure of records is encoded in a string, or a text dataset will be
parsed and fields will be projected differently for different users), a
<code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> can be created programmatically with three steps.</p>
<ol class="simple">
<li><p>Create an RDD of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s from the original RDD</p></li>
<li><p>Create the schema represented by a
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.StructType">StructType</a>
and
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.StructField">StructField</a>
classes matching the structure of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s in the RDD created in
Step 1.</p></li>
<li><p>Apply the schema to the RDD of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s via <code class="docutils literal notranslate"><span class="pre">createDataFrame</span></code> method
provided by <code class="docutils literal notranslate"><span class="pre">SQLContext</span></code>.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.sql.types._</span>

<span class="o">//</span> <span class="n">Let</span><span class="s1">&#39;s say we have an RDD of String and we need to convert it into a DataFrame with schema &quot;name&quot;, &quot;year&quot;, and &quot;manufacturer&quot;</span>
<span class="o">//</span> <span class="n">As</span> <span class="n">you</span> <span class="n">can</span> <span class="n">see</span> <span class="n">every</span> <span class="n">record</span> <span class="ow">is</span> <span class="n">space</span><span class="o">-</span><span class="n">separated</span><span class="o">.</span>
<span class="n">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
  <span class="n">Array</span><span class="p">(</span>
    <span class="s2">&quot;Jerry 2015 LCorp&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Mozart 2010 LCorp&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Einstein 2012 LCorp&quot;</span>
  <span class="p">)</span>
<span class="p">)</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">schema</span> <span class="k">as</span> <span class="n">StructType</span> <span class="o">//</span>
<span class="n">val</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">false</span><span class="p">)</span> <span class="p">::</span> 
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">false</span><span class="p">)</span> <span class="p">::</span> 
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;manufacturer&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">false</span><span class="p">)</span> <span class="p">::</span> 
  <span class="n">Nil</span>
<span class="p">)</span>

<span class="o">//</span> <span class="n">Prepare</span> <span class="n">RDD</span><span class="p">[</span><span class="n">Row</span><span class="p">]</span>
<span class="n">val</span> <span class="n">rows</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="n">entry</span> <span class="o">=&gt;</span> 
  <span class="n">val</span> <span class="n">arr</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">s+&quot;</span><span class="p">)</span>
  <span class="n">val</span> <span class="n">name</span> <span class="o">=</span> <span class="n">arr</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">val</span> <span class="n">year</span> <span class="o">=</span> <span class="n">arr</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">toInt</span>
  <span class="n">val</span> <span class="n">manufacturer</span> <span class="o">=</span> <span class="n">arr</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
  
  <span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">manufacturer</span><span class="p">)</span>
<span class="p">}</span>

<span class="o">//</span> <span class="n">Create</span> <span class="n">DataFrame</span>
<span class="n">val</span> <span class="n">bots</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="n">bots</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="n">bots</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>root
 |-- name: string (nullable = false)
 |-- year: integer (nullable = false)
 |-- manufacturer: string (nullable = false)

+--------+----+------------+
|    name|year|manufacturer|
+--------+----+------------+
|   Jerry|2015|       LCorp|
|  Mozart|2010|       LCorp|
|Einstein|2012|       LCorp|
+--------+----+------------+

import org.apache.spark.sql.types._
rdd: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[141] at parallelize at command-1267216879634403:5
schema: org.apache.spark.sql.types.StructType = StructType(StructField(name,StringType,false), StructField(year,IntegerType,false), StructField(manufacturer,StringType,false))
rows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[142] at map at command-1267216879634403:22
bots: org.apache.spark.sql.DataFrame = [name: string, year: int ... 1 more field]
</pre></div>
</div>
</div></blockquote>
</div>
</div>
<div class="section" id="creating-datasets">
<h2>Creating Datasets<a class="headerlink" href="#creating-datasets" title="Permalink to this headline">¶</a></h2>
<p>A
<a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">Dataset</a>
is a strongly-typed, immutable collection of objects that are mapped to
a relational schema. At the core of the Dataset API is a new concept
called an
<a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Encoder">encoder</a>,
which is responsible for converting between JVM objects and tabular
representation. The tabular representation is stored using Spark’s
internal Tungsten binary format, allowing for operations on serialized
data and improved memory utilization. Spark 2.2 comes with support for
automatically generating encoders for a wide variety of types, including
primitive types (e.g. String, Integer, Long), and Scala case classes.</p>
<blockquote>
<div><p>Simply put, you will get all the benefits of DataFrames with fair
amount of flexibility of RDD API.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">We</span> <span class="n">can</span> <span class="n">start</span> <span class="n">working</span> <span class="k">with</span> <span class="n">Datasets</span> <span class="n">by</span> <span class="n">using</span> <span class="n">our</span> <span class="s2">&quot;hubots&quot;</span> <span class="n">table</span>

<span class="o">//</span> <span class="n">To</span> <span class="n">create</span> <span class="n">Dataset</span> <span class="kn">from</span> <span class="nn">DataFrame</span> <span class="n">do</span> <span class="n">this</span> <span class="p">(</span><span class="n">assuming</span> <span class="n">that</span> <span class="n">case</span> <span class="k">class</span> <span class="nc">Hubot</span> <span class="n">exists</span><span class="p">):</span>
<span class="n">val</span> <span class="n">ds</span> <span class="o">=</span> <span class="n">hubots</span><span class="o">.</span><span class="k">as</span><span class="p">[</span><span class="n">Hubot</span><span class="p">]</span>
<span class="n">ds</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>+--------+----+------------+---------+--------------------+
|    name|year|manufacturer|  version|             details|
+--------+----+------------+---------+--------------------+
|   Jerry|2015|       LCorp|[1, 2, 3]|[eat -&gt; yes, slee...|
|  Mozart|2010|       LCorp|   [1, 2]|[eat -&gt; no, sleep...|
|Einstein|2012|       LCorp|[1, 2, 3]|[eat -&gt; yes, slee...|
+--------+----+------------+---------+--------------------+

ds: org.apache.spark.sql.Dataset[Hubot] = [name: string, year: int ... 3 more fields]
</pre></div>
</div>
</div></blockquote>
<blockquote>
<div><p><strong>Side-note:</strong> Dataset API is first-class citizen in Spark, and
DataFrame is an alias for Dataset[Row]. Note that Python and R use
DataFrames (since they are dynamically typed), but it is essentially a
Dataset.</p>
</div></blockquote>
</div>
<div class="section" id="finally">
<h2>Finally<a class="headerlink" href="#finally" title="Permalink to this headline">¶</a></h2>
<p>DataFrames and Datasets can simplify and improve most of the
applications pipelines by bringing concise syntax and performance
optimizations. We would highly recommend you to check out the official
API documentation, specifically around</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame
API</a>,</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions%24">Spark SQL functions
library</a>,</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.GroupedData">GroupBy clause and aggregated
functions</a>.</p></li>
</ul>
<p>Unfortunately, this is just <em>a getting started quickly</em> course, and we
skip features like custom aggregations, types, pivoting, etc., but if
you are keen to know then start from the links above and this notebook
and others in this directory.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./000_1-sds-3-x"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="007b_SparkSQLProgGuide_HW.html" title="previous page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>
    <a class='right-next' id="next-link" href="007d_SparkSQLProgGuide_HW.html" title="next page">ScaDaMaLe, Scalable Data Science and Distributed Machine Learning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>