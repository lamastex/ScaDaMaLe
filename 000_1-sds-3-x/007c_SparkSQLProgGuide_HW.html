
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Getting Started - Exercise &#8212; Scalable Data Science &amp; Distributed Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Data Sources" href="007d_SparkSQLProgGuide_HW.html" />
    <link rel="prev" title="Getting Started" href="007b_SparkSQLProgGuide_HW.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scalable Data Science & Distributed Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="000_ScaDaMaLe.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark Core
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="001_whySpark.html">
   Why Apache Spark?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="002_00_loginToDatabricks.html">
     Login to databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="002_00_loginToDatabricks.html#import-course-content-now">
     Import Course Content Now!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="002_00_loginToDatabricks.html#cloud-free-computing-environment">
     Cloud-free Computing Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="002_01_multiLingualNotebooks.html">
     Multi-lingual Notebooks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="003_00_scalaCrashCourse.html">
   Scala Crash Course
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="003_01_scalaCrashCourse.html">
     Scala Crash Course Continued
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="004_RDDsTransformationsActions.html">
   Introduction to Spark
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="005_RDDsTransformationsActionsHOMEWORK.html">
     HOMEWORK on RDD Transformations and Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006a_PipedRDD.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="006_WordCount.html">
     Word Count on US State of the Union (SoU) Addresses
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Apache Spark SQL
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html">
   Introduction to Spark SQL
  </a>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="007_SparkSQLIntroBasics.html#getting-started-in-spark-2-x">
   Getting Started in Spark 2.x
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="007a_SparkSQLProgGuide_HW.html">
     Spark Sql Programming Guide
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007b_SparkSQLProgGuide_HW.html#id1">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Getting Started - Exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007d_SparkSQLProgGuide_HW.html#id1">
     Data Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007e_SparkSQLProgGuide_HW.html">
     Performance Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007f_SparkSQLProgGuide_HW.html#id1">
     Distributed SQL Engine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html">
     SQL Pivoting since Spark 2.4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#load-data">
     Load Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-in-sql">
     Pivoting in SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-aggregate-expressions">
     Pivoting with Multiple Aggregate Expressions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-grouping-columns">
     Pivoting with Multiple Grouping Columns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="007g_PivotInSQL.html#pivoting-with-multiple-pivot-columns">
     Pivoting with Multiple Pivot Columns
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Extract Transform and Load
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html">
   Diamonds ML Pipeline Workflow - DataFrame ETL and EDA Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#step-1-load-data-as-dataframe">
   Step 1. Load data as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#step-2-understand-the-data">
   Step 2. Understand the data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#let-us-run-through-some-basic-inteactive-sql-queries-next">
   Let us run through some basic inteactive SQL queries next
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#why-do-we-need-to-know-these-interactive-sql-queries">
   Why do we need to know these interactive SQL queries?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="008_DiamondsPipeline_01ETLEDA.html#we-will-continue-later-with-ml-pipelines-to-do-prediction-with-a-fitted-model-from-this-dataset">
   We will continue later with ML pipelines to do prediction with a fitted model from this dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html">
   Power Plant ML Pipeline Application - DataFrame Part
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-1-business-understanding">
   Step 1: Business Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-2-load-your-data">
   Step 2: Load Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#use-this-for-other-smallish-datasets-you-want-to-import-to-your-ce">
   USE THIS FOR OTHER SMALLish DataSets you want to import to your CE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-3-explore-your-data">
   Step 3: Explore Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="009_PowerPlantPipeline_01ETLEDA.html#step-4-visualize-your-data">
   Step 4: Visualize Your Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html">
   Wiki Clickstream Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="010_wikipediaClickStream_01ETLEDA.html#wikipedia-logo">
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="033_OBO_LoadExtract.html">
   Old Bailey Online Data Analysis in Apache Spark
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="033_OBO_LoadExtract.html#analysing-the-full-old-bailey-online-sessions-papers-dataset">
   Analysing the Full Old Bailey Online Sessions Papers Dataset
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html">
     Piped RDDs and Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#from-a-local-collection">
     From a Local Collection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#glom">
     glom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#checkpointing">
     Checkpointing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#pipe-rdds-to-system-commands">
     Pipe RDDs to System Commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#mappartitions">
     mapPartitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#foreachpartition">
     foreachPartition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#numerically-rigorous-bayesian-ab-testing">
     Numerically Rigorous Bayesian AB Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#usage-instructions-for-isit1or2coins">
     Usage instructions for IsIt1or2Coins
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#parsing-the-output-from-isit1or2coins">
     Parsing the output from
     <code class="docutils literal notranslate">
      <span class="pre">
       IsIt1or2Coins
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="033_OBO_PipedRDD_RigorousBayesianABTesting.html#providing-case-classes-for-input-and-output-for-easy-spark-communication">
     Providing case classes for input and output for easy spark communication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="035_LDA_CornellMovieDialogs.html">
   Topic Modeling of Movie Dialogs with Latent Dirichlet Allocation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Trends in Money and News
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_9-sds-3-x-trends/000_TrendsInFinancialStocksAndNewsEvents.html">
   Trends in Financial Stocks and News Events
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/00a_FX1M.html">
     Historical FX-1-M Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/00b_yfinance.html">
     yfinance Stock Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/000a_finance_utils.html">
     Utilities Needed for Financial Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/000b_gdelt_utils.html">
     Utilities Needed for Mass Media Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_9-sds-3-x-trends/01_trend_calculus_showcase.html">
   Finding trends in oil price data.
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/02_streamable_trend_calculus.html">
     Streaming Trend Calculus with Maximum Necessary Reversals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/03_streamable_trend_calculus_estimators.html">
     Markov Model for Trend Calculus
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_9-sds-3-x-trends/030_Spark_GDELT_project_001.html">
   Plugging into GDELT Mass Media Streams
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/030a_gdelt_EOI_detection.html">
     Detecting Events of Interest to OIL/GAS Price Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_9-sds-3-x-trends/030b_gdelt_POI_detection.html">
     Detecting Persons of Interest to OIL/GAS Price Trends
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Distributed Deep Learning with Horovod
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_7-sds-3-x-ddl/00_DDL_Introduction.html">
   Introduction to Distributed Deep Learning (DDL) with Horovod over Tensorflow/keras and Pytorch
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_7-sds-3-x-ddl/0x_mnist-tensorflow-keras.html">
     Distributed deep learning training using TensorFlow and Keras with HorovodRunner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_7-sds-3-x-ddl/0y_mnist-pytorch.html">
     Distributed deep learning training using PyTorch with HorovodRunner for MNIST
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  WASP AI-Track Student Projects
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/00_download_data.html">
   The two cultures
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/01_load_data.html">
     Preprocessing and loading the relevant data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/02_logisticregression.html">
     The two cultures - Classifying threads with logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/03_word2vec.html">
     Classification using Word2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-01_group-TheTwoCultures/04_LDA.html">
     Topic Modeling with LDA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-02_group-LiUUmeaSceneGraphMotifs/01_SceneGraphMotifs.html">
   Exploring the GQA Scene Graph Dataset Structure and Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-03_group-GuangyiZhang/01_triads.html">
   Signed Triads in Social Media
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-04_group-DistributedLinearAlgebra/01_DistributedSVD.html">
   Distributed Linear Algebra
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-04_group-DistributedLinearAlgebra/02_CollaborativeFiltering.html">
     Music Recommendation System
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-05_group-LundDirichletAnalysts/01_Wikipedia_LDA_Analysis.html">
   Wikipedia analysis using Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/00_Introduction.html">
   Unsupervised clustering of particle physics data with distributed training
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/01_data_and_preprocessing.html">
     Data and preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/02_dl_single_machine.html">
     UCluster on a single machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/03_dl_horovod.html">
     UCluster with distributed learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-06_group-ParticleClustering/04_evaluate.html">
     Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/01_Coding_Motifs.html">
   Motif Finding
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/01_Coding_Motifs.html#application">
   Application
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/03_graph_string_converter.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-07_group-MathAtKTH/03_graph_string_converter.html#examples">
     Examples
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html">
   Distributed ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html#distributed-ensembles-prediction-api">
   Distributed ensembles prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html#application-example-distributed-predictions">
   Application example: Distributed predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-08_group-DistributedEnsemble/00_project.html#application-example-out-of-distribution-detection">
   Application example: Out of distribution detection
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/01_Introduction.html">
   Topic Modeling with SARS-Cov-2 Genome 🧬
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/02_Data_Processing.html">
     Data Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/03_LDA.html">
     LDA - Extract Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/04_Classification_CountVector.html">
     Classification CountVector
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html">
     Load processed data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html#explore-data">
     Explore data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html#classification">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/05_Classification.html#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-09_group-TopicModeling/06_Results.html">
     Results and Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/01_Introduction.html">
   Twitter Streaming Using Geolocation and Emoji Based Sentiment Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/02_ClusteringEmoticonsBasedOnTweets.html">
     Clustering emoticons based on tweets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/03_Dynamic_Tweet_Maps.html">
     Dynamic Tweet Maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/04_conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/05_appendix_get-cc-data.html">
     Notebook for collecting tweets with country codes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/07_a_appendix_extendedTwitterUtils2run.html#extended-spark-streaming-twitter-twitterutils">
     Extended spark.streaming.twitter.TwitterUtils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-10_group-Geosmus/07_b_appendix_TTTDFfunctions.html">
     ScaDaMaLe, Scalable Data Science and Distributed Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-11_group-Sketchings/00_QuantileEstimation.html">
   Anomaly Detection with Iterative Quantile Estimation and T-digest
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/00_ProjectDescriptionAndPlanning.html">
   Project Description and Introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/01_DownloadFilesPeriodicallyScript.html">
     Download Files Periodically
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/01_StreamToFile.html">
     Stream to parquet file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/021_DataPreprocess_Explain.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/02_DataPreprocess.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/02_DataPreprocess.html#preprocessing">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html">
     This notebook is for explosive analysis of features in data.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#statistics-of-invariant-features">
     Statistics of invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-invariant-features">
     Correlation between invariant features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/03_ExplosiveAnalysis.html#correlation-between-new-case-per-million-total-case-new-death-per-million-total-death-per-million-reproduction-rate-and-stringency-index">
     Correlation between new case per million, total case, new death per million, total death per million, reproduction rate and stringency index.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html">
     Show reproduction rate of selected countries i.e. Sweden, Germany, Danmark, Finland, Norway
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#visualize-total-cases-total-deaths-new-cases-and-new-deaths-during-pandemic">
     Visualize total cases, total deaths, new cases and new deaths during pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#total-deaths">
     Total Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#new-cases">
     New Cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/04_DataVisualize.html#new-deaths">
     New Deaths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/05_Clustering.html">
     Clustering of country features in the Covid 19 dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/06_DataPredicton_LR.html">
     Prediction with Linear Regression (LR) Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/07_DataPredicton_ARIMA.html">
     Prediction with Time Series model - ARIMA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-12_group-CovidPandemic/08_DataPrediction_GP.html">
     Prediction with time series model - Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html">
   Genomics Analysis with Glow and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#load-libs-and-define-helper-functions">
   Load libs and define helper functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#read-data">
   Read data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#pca">
   PCA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#predicting-ethinicity">
   Predicting Ethinicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-13_group-Genomics/01_1000genomes.html#filtering-of-snps-based-on-chi-squared-test">
   Filtering of SNPs based on chi-squared test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-14_group-NullHypothesisEvaluationCriteria/00_distributed_combinatorial_bandit.html">
   Distributed combinatorial bandits
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/00_video.html">
   Reinforcement Learning for Intraday Trading
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html">
     Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/01_rl_intraday_trading.html#summary-and-outlook">
     Summary and Outlook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html">
     Reinforcement Learning - Distributed model tuning with Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#elephas">
     Elephas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/02_rl_intraday_trading_elephas.html#notes-to-the-elephas-training">
     Notes to the elephas training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-15_group-FinancialDataStreams/03_resources.html">
     Resources
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-16_group-IntrusionDetection/00_Introduction.html">
   Intrusion Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-16_group-IntrusionDetection/00_Introduction.html#preparing-the-dataframe-for-training-classifers">
   Preparing the DataFrame for training classifers
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-17_group-TowardsScalableTDA/00_introduction.html">
   Density Estimation via Voronoi Diagrams in High Dimensions
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-17_group-TowardsScalableTDA/01_methodology.html">
     Methodology
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-17_group-TowardsScalableTDA/02_gaussian_analysis.html">
     Gaussian Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-17_group-TowardsScalableTDA/03_robotics_dataset.html">
     Robotics Dataset
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/00_Problem_Description.html">
   Recommender System
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/01_The_ALS_method.html">
     <span class="xref myst">
      The Alternating Least Squares method (ALS)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-small-dataset">
     <span class="xref myst">
      On a small dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/01_The_ALS_method.html#on-a-large-dataset-netflix-dataset">
     <span class="xref myst">
      On a large dataset - Netflix dataset
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-18_group-ProjectRL/02_Extensions.html">
     Extensions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-19_group-Featuring/01_FundamentalMatrix.html">
   Fundamental Matrix
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/01_Background.html">
   MixUp and Generalization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/02_Random_Forest.html">
     Random Forests and MixUp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/03_CNN_MNIST.html">
     CNN for MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/04_CNN_Intel_Image.html">
     CNN for Intel Image Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-20_group-Generalization/05_Horovod_test.html">
     CNNs and MixUp with Horovod
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/00_introduction.html">
   Graph Spectral Analysis
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/01_preprocess_data.html">
     Preprocess the data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/02_generate_graphs.html">
     Generate random graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/03_compute_rsvd.html">
     Compute RSVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-21_group-GraphSpectralAnalysis/04_analyse_eigenvalues.html">
     Analyse the eigenvalue spectrum
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-22_group-SwapWithDDP/00_Introduction.html">
   SWAP
   <em>
    With
   </em>
   DDP
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../000_0-sds-3-x-projects/student-project-22_group-SwapWithDDP/01_SWAP_with_DDP.html">
     SWAP
     <em>
      With
     </em>
     DDP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/000_1-sds-3-x/007c_SparkSQLProgGuide_HW.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://lamastex.github.io/ScaDaMaLe/index.html/issues/new?title=Issue%20on%20page%20%2F000_1-sds-3-x/007c_SparkSQLProgGuide_HW.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nyc-social-media-usage-data">
   NYC Social Media Usage Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data">
   Load Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-uoload-csv-file-and-make-a-table-in-databricks">
     How to uoload csv file and make a table in databricks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spark-sql-and-dataframe-api">
     Spark SQL and DataFrame API
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interoperating-with-rdds">
   Interoperating with RDDs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inferring-the-schema-using-reflection">
     Inferring the Schema Using Reflection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#programmatically-specifying-the-schema">
     Programmatically Specifying the Schema
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-datasets">
   Creating Datasets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finally">
   Finally
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>ScaDaMaLe Course
<a class="reference external" href="https://lamastex.github.io/scalable-data-science/sds/3/x/">site</a> and
<a class="reference external" href="https://lamastex.github.io/ScaDaMaLe/index.html">book</a></p>
<p>This is an elaboration of the
<a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html">http://spark.apache.org/docs/latest/sql-programming-guide.html</a> by Ivan
Sadikov and Raazesh Sainudiin.</p>
<div class="section" id="getting-started-exercise">
<h1>Getting Started - Exercise<a class="headerlink" href="#getting-started-exercise" title="Permalink to this headline">¶</a></h1>
<p>After having gone through the simple example dataset in the programming
guide, let’s try a slightly larger dataset next.</p>
<p>Let us first create a table of social media usage from NYC</p>
<blockquote>
<div><p>See the <strong>Load Data</strong> section to create this <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code>
table from raw data.</p>
</div></blockquote>
<p>First let’s make sure this table is available for us. If you don’t see
<code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code> as a <code class="docutils literal notranslate"><span class="pre">name</span></code>d table in the output of the next cell
then we first need to ingest this dataset. Let’s do it using the
databricks’ GUI for creating <code class="docutils literal notranslate"><span class="pre">Data</span></code> as done next.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Let&#39;s find out what tables are already available for loading</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="nyc-social-media-usage-data">
<h2>NYC Social Media Usage Data<a class="headerlink" href="#nyc-social-media-usage-data" title="Permalink to this headline">¶</a></h2>
<p>This dataset is from
<a class="reference external" href="https://datahub.io/JohnSnowLabs/nyc-social-media-usage#readme">https://datahub.io/JohnSnowLabs/nyc-social-media-usage#readme</a></p>
<p>The Demographic Reports are produced by the Economic, Demographic and
Statistical Research unit within the Countywide Service Integration and
Planning Management (CSIPM) Division of the Fairfax County Department of
Neighborhood and Community Services. Information produced by the
Economic, Demographic and Statistical Research unit is used by every
county department, board, authority and the Fairfax County Public
Schools. In addition to the small area estimates and forecasts, state
and federal data on Fairfax County are collected and summarized, and
special studies and Quantitative research are conducted by the unit.</p>
<p>We are going to fetch this data, with slightly simplified column names,
from the following URL:</p>
<ul class="simple">
<li><p>http://lamastex.org/datasets/public/NYCUSA/social-media-usage.csv</p></li>
</ul>
<p>To turn the dataset into a registered table we will load it using the
GUI as follows:</p>
<ul class="simple">
<li><p>Download it to your local machine / laptop and then use the ‘Data’
button on the left to upload it (we will try this method now).</p>
<ul>
<li><p>This will put your data in the <code class="docutils literal notranslate"><span class="pre">Filestore</span></code> in databricks’
distributed file system.</p></li>
</ul>
</li>
</ul>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>Below we will show you how to create and query a table or DataFrame that
you uploaded to DBFS.
<a class="reference external" href="https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html">DBFS</a>
is a Databricks File System (their distributed file system) that allows
you to store data for querying inside of Databricks. This notebook
assumes that you have a file already inside of DBFS that you would like
to read from.</p>
<p>In other setups, you can have the data in s3 (say in AWS) or in hdfs in
your hadoop cluster, etc.</p>
<p>Alternatively, you can use <code class="docutils literal notranslate"><span class="pre">curl</span></code> or <code class="docutils literal notranslate"><span class="pre">wget</span></code> to download it to the local
file system in <code class="docutils literal notranslate"><span class="pre">/databricks/driver</span></code> and then load it into <code class="docutils literal notranslate"><span class="pre">dbfs</span></code>, after
this you can use read it via <code class="docutils literal notranslate"><span class="pre">spark</span></code> session into a dataframe and
register it as a hive table.</p>
<p>You can also get the data directly from here (but in this case you need
to change the column names in the databricks Data upload GUI or
programmatically to follow this notebook):</p>
<ul class="simple">
<li><p>http://datahub.io/JohnSnowLabs/nyc-social-media-usage</p></li>
</ul>
</div>
</div>
<div class="section" id="load-data">
<h2>Load Data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="how-to-uoload-csv-file-and-make-a-table-in-databricks">
<h3>How to uoload csv file and make a table in databricks<a class="headerlink" href="#how-to-uoload-csv-file-and-make-a-table-in-databricks" title="Permalink to this headline">¶</a></h3>
<p>Okay, so how did we actually make table <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code>? Databricks
allows us to upload/link external data and make it available as
registerd SQL table. It involves several steps:</p>
<ol class="simple">
<li><p>Dowload this <code class="docutils literal notranslate"><span class="pre">social-media-usage.csv</span></code> file from the following URL to
your laptop:</p></li>
</ol>
<ul>
<li><p>http://lamastex.org/datasets/public/NYCUSA/social-media-usage.csv</p></li>
<li><p>Go to Databricks cloud (where you log in to use Databricks
notebooks) and open tab <strong>Data</strong> on the left panel</p></li>
<li><p>On the very top of the left sub-menu you will see button <strong>+Add
Data</strong>, click on it</p></li>
<li><p>Choose <strong>Upload File</strong> for Data Sources by <strong>Browse</strong> or <strong>Drag and
Drop</strong>, where <strong>File</strong> means any file (Parquet, Avro, CSV), but it
works the best with CSV format</p></li>
<li><p>Upload <code class="docutils literal notranslate"><span class="pre">social-media-usage.csv</span></code> file you just downloaded to
databricks</p></li>
<li><p>Just note the path to the uploaded file, for example in my case:</p>
<blockquote>
<div><p>File uploaded to <code class="docutils literal notranslate"><span class="pre">/FileStore/tables/social_media_usage.csv</span></code></p>
</div></blockquote>
</li>
</ul>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>

<span class="c1">// File location and type</span>
<span class="c1">// You may need to change the file_location &quot;social_media_usage-5dbee.csv&quot; depending on your location given by</span>
<span class="c1">// File uploaded to /FileStore/tables/social_media_usage.csv</span>
<span class="k">val</span> <span class="n">file_location</span> <span class="o">=</span> <span class="s">&quot;/FileStore/tables/social_media_usage.csv&quot;</span>
<span class="k">val</span> <span class="n">file_type</span> <span class="o">=</span> <span class="s">&quot;csv&quot;</span>

<span class="c1">// CSV options</span>
<span class="k">val</span> <span class="n">infer_schema</span> <span class="o">=</span> <span class="s">&quot;true&quot;</span>
<span class="k">val</span> <span class="n">first_row_is_header</span> <span class="o">=</span> <span class="s">&quot;true&quot;</span>
<span class="k">val</span> <span class="n">delimiter</span> <span class="o">=</span> <span class="s">&quot;,&quot;</span>

<span class="c1">// The applied options are for CSV files. For other file types, these will be ignored.</span>
<span class="k">val</span> <span class="n">socialMediaDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="n">file_type</span><span class="o">)</span> 
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;inferSchema&quot;</span><span class="o">,</span> <span class="n">infer_schema</span><span class="o">)</span> 
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;header&quot;</span><span class="o">,</span> <span class="n">first_row_is_header</span><span class="o">)</span> 
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;sep&quot;</span><span class="o">,</span> <span class="n">delimiter</span><span class="o">)</span> 
  <span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">file_location</span><span class="o">)</span>

<span class="n">socialMediaDF</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Let&#39;s create a view or table</span>

<span class="k">val</span> <span class="n">temp_table_name</span> <span class="o">=</span> <span class="s">&quot;social_media_usage&quot;</span>

<span class="n">socialMediaDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="n">temp_table_name</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Let&#39;s find out what tables are already available for loading</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<p>With this registered as a temporary view, <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code> will only
be available to this particular notebook.</p>
<p>If you’d like other users to be able to query this table (in the
databricks professional shard - not the free community edition; or in a
managed on-premise cluster), you can also create a table from the
DataFrame.</p>
<p>Once saved, this table will persist across cluster restarts as well as
allow various users across different notebooks to query this data. To do
so, choose your table name and use <code class="docutils literal notranslate"><span class="pre">saveAsTable</span></code> as done in the next
cell.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">val</span> <span class="n">permanent_table_name</span> <span class="o">=</span> <span class="s">&quot;social_media_usage&quot;</span>
<span class="n">socialMediaDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;parquet&quot;</span><span class="o">).</span><span class="n">saveAsTable</span><span class="o">(</span><span class="n">permanent_table_name</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Let&#39;s find out what tables are already available for loading</span>
<span class="c1">// spark.catalog.listTables.show(100)</span>
</pre></div>
</div>
</div>
</div>
<p>It looks like the table <code class="docutils literal notranslate"><span class="pre">social_media_usage</span></code> is available as a permanent
table (<code class="docutils literal notranslate"><span class="pre">isTemporary</span></code> set as <code class="docutils literal notranslate"><span class="pre">false</span></code>), if you have not uncommented the
last line in the previous cell (otherwise it will be available from a
parquet file as a permanent table - we will see more about parquet in
the sequel).</p>
<p>Next let us do the following:</p>
<ul class="simple">
<li><p>load this table as a DataFrame (yes, the dataframe already exists as
<code class="docutils literal notranslate"><span class="pre">socialMediaDF</span></code>, but we want to make a new DataFrame directly from
the table)</p></li>
<li><p>print its schema and</p></li>
<li><p>show the first 20 rows.</p></li>
</ul>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">val</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="o">(</span><span class="s">&quot;social_media_usage&quot;</span><span class="o">)</span> <span class="c1">// Ctrl+Enter</span>
</pre></div>
</div>
</div>
</div>
<p>As you can see the immutable value <code class="docutils literal notranslate"><span class="pre">df</span></code> is a DataFrame and more
specifically it is:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.DataFrame</span> <span class="pre">=</span> <span class="pre">[agency:</span> <span class="pre">string,</span> <span class="pre">platform:</span> <span class="pre">string,</span> <span class="pre">url:</span> <span class="pre">string,</span> <span class="pre">date:</span> <span class="pre">timestamp,</span> <span class="pre">visits:</span> <span class="pre">integer]</span></code>.</p>
</div></blockquote>
<p>Now let us print schema of the DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code> and have a look at the
actual data:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter</span>
<span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="o">()</span> <span class="c1">// prints schema of the DataFrame</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="o">()</span> <span class="c1">// shows first n (default is 20) rows</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Note that <code class="docutils literal notranslate"><span class="pre">(nullable</span> <span class="pre">=</span> <span class="pre">true)</span></code> simply means if the value is allowed to
be <code class="docutils literal notranslate"><span class="pre">null</span></code>.</p>
</div></blockquote>
<p>Let us count the number of rows in <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="o">()</span> <span class="c1">// Ctrl+Enter to get 5898</span>
</pre></div>
</div>
</div>
</div>
<p>So there are 5899 records or rows in the DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code>. Pretty good!
You can also select individual columns using so-called DataFrame API, as
follows:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">val</span> <span class="n">platforms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;platform&quot;</span><span class="o">)</span> <span class="c1">// Shift+Enter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">platforms</span><span class="o">.</span><span class="n">count</span><span class="o">()</span> <span class="c1">// Shift+Enter to count the number of rows</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">platforms</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span> <span class="c1">// Ctrl+Enter to show top 5 rows</span>
</pre></div>
</div>
</div>
</div>
<p>You can also apply <code class="docutils literal notranslate"><span class="pre">.distinct()</span></code> to extract only unique entries as
follows:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">val</span> <span class="n">uniquePlatforms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;platform&quot;</span><span class="o">).</span><span class="n">distinct</span><span class="o">()</span> <span class="c1">// Shift+Enter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">uniquePlatforms</span><span class="o">.</span><span class="n">count</span><span class="o">()</span> <span class="c1">// Ctrl+Enter to count the number of distinct platforms</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see all the rows of the DataFrame <code class="docutils literal notranslate"><span class="pre">uniquePlatforms</span></code>.</p>
<blockquote>
<div><p>Note that <code class="docutils literal notranslate"><span class="pre">display(uniquePlatforms)</span></code> unlike <code class="docutils literal notranslate"><span class="pre">uniquePlatforms.show()</span></code>
displays all rows of the DataFrame + gives you ability to select
different view, e.g. charts.</p>
</div></blockquote>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">display</span><span class="o">(</span><span class="n">uniquePlatforms</span><span class="o">)</span> <span class="c1">// Ctrl+Enter to show all rows; use the scroll-bar on the right of the display to see all platforms</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="spark-sql-and-dataframe-api">
<h3>Spark SQL and DataFrame API<a class="headerlink" href="#spark-sql-and-dataframe-api" title="Permalink to this headline">¶</a></h3>
<p>Spark SQL provides DataFrame API that can perform relational operations
on both external data sources and internal collections, which is similar
to widely used data frame concept in R, but evaluates operations support
lazily (remember RDDs?), so that it can perform relational
optimizations. This API is also available in Java, Python and R, but
some functionality may not be available, although with every release of
Spark people minimize this gap.</p>
<p>So we give some examples how to query data in Python and R, but continue
with Scala. You can do all DataFrame operations in this notebook using
Python or R.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">python</span>
<span class="o">#</span> <span class="nc">Ctrl</span><span class="o">+</span><span class="nc">Enter</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="k">this</span> <span class="n">python</span> <span class="n">cell</span><span class="o">,</span> <span class="n">recall</span> <span class="sc">&#39;#&#39;</span> <span class="n">is</span> <span class="n">the</span> <span class="n">pre</span><span class="o">-</span><span class="n">comment</span> <span class="n">character</span> <span class="n">in</span> <span class="n">python</span>
<span class="o">#</span> <span class="nc">Using</span> <span class="nc">Python</span> <span class="n">to</span> <span class="n">query</span> <span class="n">our</span> <span class="s">&quot;social_media_usage&quot;</span> <span class="n">table</span>
<span class="n">pythonDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="o">(</span><span class="s">&quot;social_media_usage&quot;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;platform&quot;</span><span class="o">).</span><span class="n">distinct</span><span class="o">()</span>
<span class="n">pythonDF</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">sql</span>
<span class="o">--</span> <span class="nc">Ctrl</span><span class="o">+</span><span class="nc">Enter</span> <span class="n">to</span> <span class="n">achieve</span> <span class="n">the</span> <span class="n">same</span> <span class="n">result</span> <span class="n">using</span> <span class="n">standard</span> <span class="nc">SQL</span> <span class="n">syntax</span><span class="o">!</span>
<span class="n">select</span> <span class="n">distinct</span> <span class="n">platform</span> <span class="n">from</span> <span class="n">social_media_usage</span>
</pre></div>
</div>
</div>
</div>
<p>Now it is time for some tips around how you use <code class="docutils literal notranslate"><span class="pre">select</span></code> and what the
difference is between <code class="docutils literal notranslate"><span class="pre">$&quot;a&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">col(&quot;a&quot;)</span></code>, <code class="docutils literal notranslate"><span class="pre">df(&quot;a&quot;)</span></code>.</p>
<p>As you probably have noticed by now, you can specify individual columns
to select by providing String values in select statement. But sometimes
you need to: - distinguish between columns with the same name - use it
to filter (actually you can still filter using full String expression) -
do some “magic” with joins and user-defined functions (this will be
shown later)</p>
<p>So Spark gives you ability to actually specify columns when you select.
Now the difference between all those three notations is … none, those
things are just aliases for a <code class="docutils literal notranslate"><span class="pre">Column</span></code> in Spark SQL, which means
following expressions yield the same result:</p>
<p>``` // Using string expressions df.select(“agency”, “visits”)</p>
<p>// Using “<span class="math notranslate nohighlight">\(&quot; alias for column df.select(\)</span>“agency”, $”visits”)</p>
<p>// Using “col” alias for column df.select(col(“agency”), col(“visits”))</p>
<p>// Using DataFrame name for column df.select(df(“agency”), df(“visits”))
```</p>
<p>This “same-difference” applies to filtering, i.e. you can either use
full expression to filter, or column as shown in the following example:</p>
<p>``` // Using column to filter df.select(“visits”).filter($”visits”
&gt; 100)</p>
<p>// Or you can use full expression as string
df.select(“visits”).filter(“visits &gt; 100”) ```</p>
<blockquote>
<div><p>Note that <code class="docutils literal notranslate"><span class="pre">$&quot;visits&quot;</span> <span class="pre">&gt;</span> <span class="pre">100</span></code> expression looks amazing, but under the
hood it is just another column, and it equals to
<code class="docutils literal notranslate"><span class="pre">df(&quot;visits&quot;).&gt;(100)</span></code>, where, thanks to Scala paradigm <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> is just
another function that you can define.</p>
</div></blockquote>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">val</span> <span class="n">sms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;agency&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;platform&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;visits&quot;</span><span class="o">).</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;platform&quot;</span> <span class="o">===</span> <span class="s">&quot;SMS&quot;</span><span class="o">)</span>
<span class="n">sms</span><span class="o">.</span><span class="n">show</span><span class="o">()</span> <span class="c1">// Ctrl+Enter</span>
</pre></div>
</div>
</div>
</div>
<p>Again you could have written the query above using any column aliases or
String names or even writing the query directly.</p>
<p>For example, we can do it using String names, as follows:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter Note that we are using &quot;platform = &#39;SMS&#39;&quot; since it will be evaluated as actual SQL</span>
<span class="k">val</span> <span class="n">sms</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">df</span><span class="o">(</span><span class="s">&quot;agency&quot;</span><span class="o">),</span> <span class="n">df</span><span class="o">(</span><span class="s">&quot;platform&quot;</span><span class="o">),</span> <span class="n">df</span><span class="o">(</span><span class="s">&quot;visits&quot;</span><span class="o">)).</span><span class="n">filter</span><span class="o">(</span><span class="s">&quot;platform = &#39;SMS&#39;&quot;</span><span class="o">)</span>
<span class="n">sms</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<p>Refer to the <a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame
API</a>
for more detailed API. In addition to simple column references and
expressions, DataFrames also have a rich library of functions including
string manipulation, date arithmetic, common math operations and more.
The complete list is available in the <a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions%24">DataFrame Function
Reference</a>.</p>
<p>Let’s next explore some of the functionality that is available by
transforming this DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code> into a new DataFrame called <code class="docutils literal notranslate"><span class="pre">fixedDF</span></code>.</p>
<ul class="simple">
<li><p>First, note that some columns are not exactly what we want them to
be.</p>
<ul>
<li><p>visits should not contain null values, but <code class="docutils literal notranslate"><span class="pre">0</span></code>s instead.</p></li>
</ul>
</li>
<li><p>Let us fix it using some code that is briefly explained here (don’t
worry if you don’t get it completely now, you will get the hang of
it by playing more)</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">coalesce</span></code> function is similar to <code class="docutils literal notranslate"><span class="pre">if-else</span></code> statement, i.e.,
if first column in expression is <code class="docutils literal notranslate"><span class="pre">null</span></code>, then the value of the
second column is used and so on.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lit</span></code> just means column of constant value (<code class="docutils literal notranslate"><span class="pre">lit</span></code>erally
speaking!).</p></li>
<li><p>we also remove <code class="docutils literal notranslate"><span class="pre">TOTAL</span></code> value from <code class="docutils literal notranslate"><span class="pre">platform</span></code> column.</p></li>
</ul>
</li>
</ul>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter to make fixedDF</span>

<span class="c1">// import the needed sql functions</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.</span><span class="o">{</span><span class="n">coalesce</span><span class="o">,</span> <span class="n">lit</span><span class="o">}</span>

<span class="c1">// make the fixedDF DataFrame</span>
<span class="k">val</span> <span class="n">fixedDF</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span>
   <span class="n">select</span><span class="o">(</span>
     <span class="n">$</span><span class="s">&quot;agency&quot;</span><span class="o">,</span> 
     <span class="n">$</span><span class="s">&quot;platform&quot;</span><span class="o">,</span> 
     <span class="n">$</span><span class="s">&quot;url&quot;</span><span class="o">,</span> 
     <span class="n">$</span><span class="s">&quot;date&quot;</span><span class="o">,</span> 
     <span class="n">coalesce</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;visits&quot;</span><span class="o">,</span> <span class="n">lit</span><span class="o">(</span><span class="mi">0</span><span class="o">)).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;visits&quot;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;platform&quot;</span> <span class="o">=!=</span> <span class="s">&quot;TOTAL&quot;</span><span class="o">)</span>

<span class="n">fixedDF</span><span class="o">.</span><span class="n">printSchema</span><span class="o">()</span> <span class="c1">// print its schema </span>
<span class="c1">// and show the top 20 records fully</span>
<span class="n">fixedDF</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> <span class="c1">// the false argument does not truncate the rows, so you will not see something like this &quot;anot...&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Okay, this is better, but <code class="docutils literal notranslate"><span class="pre">url</span></code>s are still inconsistent.</p>
<p>Let’s fix this by writing our own UDF (user-defined function) to deal
with special cases.</p>
<p>Note that if you <strong>CAN USE Spark functions library</strong>, do it. But for the
sake of the example, custom UDF is shown below.</p>
<p>We take value of a column as String type and return the same String
type, but ignore values that do not start with <code class="docutils literal notranslate"><span class="pre">http</span></code>.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter to evaluate this UDF which takes a input String called &quot;value&quot;</span>
<span class="c1">// and converts it into lower-case if it begins with http and otherwise leaves it as null, so we sort of remove non valid web-urls</span>
<span class="k">val</span> <span class="n">cleanUrl</span> <span class="o">=</span> <span class="n">udf</span><span class="o">((</span><span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="k">if</span> <span class="o">(</span><span class="n">value</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">&amp;&amp;</span> <span class="n">value</span><span class="o">.</span><span class="n">startsWith</span><span class="o">(</span><span class="s">&quot;http&quot;</span><span class="o">))</span> <span class="n">value</span><span class="o">.</span><span class="n">toLowerCase</span><span class="o">()</span> <span class="k">else</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us apply our UDF on <code class="docutils literal notranslate"><span class="pre">fixedDF</span></code> to create a new DataFrame called
<code class="docutils literal notranslate"><span class="pre">cleanedDF</span></code> as follows:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter</span>
<span class="k">val</span> <span class="n">cleanedDF</span> <span class="o">=</span> <span class="n">fixedDF</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;agency&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;platform&quot;</span><span class="o">,</span> <span class="n">cleanUrl</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;url&quot;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;url&quot;</span><span class="o">),</span> <span class="n">$</span><span class="s">&quot;date&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;visits&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s check that it actually worked by seeing the first 5 rows of
the <code class="docutils literal notranslate"><span class="pre">cleanedDF</span></code> whose <code class="docutils literal notranslate"><span class="pre">url</span></code> <code class="docutils literal notranslate"><span class="pre">isNull</span></code> and <code class="docutils literal notranslate"><span class="pre">isNotNull</span></code>, as follows:</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Shift+Enter</span>
<span class="n">cleanedDF</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;url&quot;</span><span class="o">.</span><span class="n">isNull</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter</span>
<span class="n">cleanedDF</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;url&quot;</span><span class="o">.</span><span class="n">isNotNull</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="c1">// false in .show(5, false) shows rows untruncated</span>
</pre></div>
</div>
</div>
</div>
<p>Now there is a suggestion from you manager’s manager’s manager that due
to some perceived privacy concerns we want to replace <code class="docutils literal notranslate"><span class="pre">agency</span></code> with some
unique identifier.</p>
<p>So we need to do the following:</p>
<ul class="simple">
<li><p>create unique list of agencies with ids and</p></li>
<li><p>join them with main DataFrame.</p></li>
</ul>
<p>Sounds easy, right? Let’s do it.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Crtl+Enter</span>
<span class="c1">// Import Spark SQL function that will give us unique id across all the records in this DataFrame</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.monotonically_increasing_id</span>

<span class="c1">// We append column as SQL function that creates unique ids across all records in DataFrames </span>
<span class="k">val</span> <span class="n">agencies</span> <span class="o">=</span> <span class="n">cleanedDF</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">cleanedDF</span><span class="o">(</span><span class="s">&quot;agency&quot;</span><span class="o">))</span>
                        <span class="o">.</span><span class="n">distinct</span><span class="o">()</span>
                        <span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">monotonically_increasing_id</span><span class="o">())</span>
<span class="n">agencies</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<p>Those who want to understand left/right inner/outer joins can see the
video lectures in Module 3 of Anthony Joseph’s Introduction to Big data
edX course.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Ctrl+Enter</span>
<span class="c1">// And join with the rest of the data, note how join condition is specified </span>
<span class="k">val</span> <span class="n">anonym</span> <span class="o">=</span> <span class="n">cleanedDF</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">agencies</span><span class="o">,</span> <span class="n">cleanedDF</span><span class="o">(</span><span class="s">&quot;agency&quot;</span><span class="o">)</span> <span class="o">===</span> <span class="n">agencies</span><span class="o">(</span><span class="s">&quot;agency&quot;</span><span class="o">),</span> <span class="s">&quot;inner&quot;</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;platform&quot;</span><span class="o">,</span> <span class="s">&quot;url&quot;</span><span class="o">,</span> <span class="s">&quot;date&quot;</span><span class="o">,</span> <span class="s">&quot;visits&quot;</span><span class="o">)</span>

<span class="c1">// We also cache DataFrame since it can be quite expensive to recompute join</span>
<span class="n">anonym</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>

<span class="c1">// Display result</span>
<span class="n">anonym</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">listTables</span><span class="o">().</span><span class="n">show</span><span class="o">()</span> <span class="c1">// look at the available tables</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">sql</span>
<span class="o">--</span> <span class="n">to</span> <span class="n">remove</span> <span class="n">a</span> <span class="nc">TempTable</span> <span class="k">if</span> <span class="n">it</span> <span class="n">exists</span> <span class="n">already</span>
<span class="n">drop</span> <span class="n">table</span> <span class="k">if</span> <span class="n">exists</span> <span class="n">anonym</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Register table for Spark SQL, we also import &quot;month&quot; function </span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.month</span>

<span class="n">anonym</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;anonym&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">sql</span>
<span class="o">--</span> <span class="nc">Interesting</span><span class="o">.</span> <span class="nc">Now</span> <span class="n">let</span><span class=" -Symbol">&#39;s</span> <span class="k">do</span> <span class="n">some</span> <span class="n">aggregation</span><span class="o">.</span> <span class="nc">Display</span> <span class="n">platform</span><span class="o">,</span> <span class="n">month</span><span class="o">,</span> <span class="n">visits</span>
<span class="o">--</span> <span class="nc">Date</span> <span class="n">column</span> <span class="n">allows</span> <span class="n">us</span> <span class="n">to</span> <span class="n">extract</span> <span class="n">month</span> <span class="n">directly</span>

<span class="n">select</span> <span class="n">platform</span><span class="o">,</span> <span class="n">month</span><span class="o">(</span><span class="n">date</span><span class="o">)</span> <span class="n">as</span> <span class="n">month</span><span class="o">,</span> <span class="n">sum</span><span class="o">(</span><span class="n">visits</span><span class="o">)</span> <span class="n">as</span> <span class="n">visits</span> <span class="n">from</span> <span class="n">anonym</span> <span class="n">group</span> <span class="n">by</span> <span class="n">platform</span><span class="o">,</span> <span class="n">month</span><span class="o">(</span><span class="n">date</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note, that we could have done aggregation using DataFrame API instead of
Spark SQL.</p>
<p>Alright, now let’s see some <em>cool</em> operations with window functions.</p>
<p>Our next task is to compute <code class="docutils literal notranslate"><span class="pre">(daily</span> <span class="pre">visits</span> <span class="pre">/</span> <span class="pre">monthly</span> <span class="pre">average)</span></code> for all
platforms.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.</span><span class="o">{</span><span class="n">dayofmonth</span><span class="o">,</span> <span class="n">month</span><span class="o">,</span> <span class="n">row_number</span><span class="o">,</span> <span class="n">sum</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.expressions.Window</span>

<span class="k">val</span> <span class="n">coolDF</span> <span class="o">=</span> <span class="n">anonym</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;platform&quot;</span><span class="o">,</span> <span class="n">dayofmonth</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;date&quot;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;day&quot;</span><span class="o">),</span> <span class="n">month</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;date&quot;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;month&quot;</span><span class="o">),</span> <span class="n">$</span><span class="s">&quot;visits&quot;</span><span class="o">).</span>
  <span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;platform&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;day&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;month&quot;</span><span class="o">).</span><span class="n">agg</span><span class="o">(</span><span class="n">sum</span><span class="o">(</span><span class="s">&quot;visits&quot;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;visits&quot;</span><span class="o">))</span>

<span class="c1">// Run window aggregation on visits per month and platform</span>
<span class="k">val</span> <span class="n">window</span> <span class="o">=</span> <span class="n">coolDF</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;day&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;visits&quot;</span><span class="o">,</span> <span class="n">sum</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;visits&quot;</span><span class="o">).</span><span class="n">over</span><span class="o">(</span><span class="nc">Window</span><span class="o">.</span><span class="n">partitionBy</span><span class="o">(</span><span class="s">&quot;platform&quot;</span><span class="o">,</span> <span class="s">&quot;month&quot;</span><span class="o">)).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;monthly_visits&quot;</span><span class="o">))</span>

<span class="c1">// Create and register percent table</span>
<span class="k">val</span> <span class="n">percent</span> <span class="o">=</span> <span class="n">window</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;day&quot;</span><span class="o">,</span> <span class="o">(</span><span class="n">$</span><span class="s">&quot;visits&quot;</span> <span class="o">/</span> <span class="n">$</span><span class="s">&quot;monthly_visits&quot;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&quot;percent&quot;</span><span class="o">))</span>

<span class="n">percent</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;percent&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">sql</span>
<span class="o">--</span> <span class="n">A</span> <span class="n">little</span> <span class="n">bit</span> <span class="n">of</span> <span class="n">visualization</span> <span class="n">as</span> <span class="n">result</span> <span class="n">of</span> <span class="n">our</span> <span class="n">efforts</span>
<span class="n">select</span> <span class="n">id</span><span class="o">,</span> <span class="n">day</span><span class="o">,</span> <span class="n">`percent`</span> <span class="n">from</span> <span class="n">percent</span> <span class="n">where</span> <span class="n">`percent`</span> <span class="o">&gt;</span> <span class="mf">0.3</span> <span class="n">and</span> <span class="n">day</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">sql</span>
<span class="o">--</span> <span class="nc">You</span> <span class="n">also</span> <span class="n">could</span> <span class="n">just</span> <span class="n">use</span> <span class="n">plain</span> <span class="nc">SQL</span> <span class="n">to</span> <span class="n">write</span> <span class="n">query</span> <span class="n">above</span><span class="o">,</span> <span class="n">note</span> <span class="n">that</span> <span class="n">you</span> <span class="n">might</span> <span class="n">need</span> <span class="n">to</span> <span class="n">group</span> <span class="n">by</span> <span class="n">id</span> <span class="n">and</span> <span class="n">day</span> <span class="n">as</span> <span class="n">well</span><span class="o">.</span>
<span class="k">with</span> <span class="n">aggr</span> <span class="n">as</span> <span class="o">(</span>
  <span class="n">select</span> <span class="n">id</span><span class="o">,</span> <span class="n">dayofmonth</span><span class="o">(</span><span class="n">date</span><span class="o">)</span> <span class="n">as</span> <span class="n">day</span><span class="o">,</span> <span class="n">visits</span> <span class="o">/</span> <span class="n">sum</span><span class="o">(</span><span class="n">visits</span><span class="o">)</span> <span class="n">over</span> <span class="o">(</span><span class="n">partition</span> <span class="n">by</span> <span class="o">(</span><span class="n">platform</span><span class="o">,</span> <span class="n">month</span><span class="o">(</span><span class="n">date</span><span class="o">)))</span> <span class="n">as</span> <span class="n">percent</span>
  <span class="n">from</span> <span class="n">anonym</span>
<span class="o">)</span>
<span class="n">select</span> <span class="o">*</span> <span class="n">from</span> <span class="n">aggr</span> <span class="n">where</span> <span class="n">day</span> <span class="o">=</span> <span class="mi">2</span> <span class="n">and</span> <span class="n">percent</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="interoperating-with-rdds">
<h2>Interoperating with RDDs<a class="headerlink" href="#interoperating-with-rdds" title="Permalink to this headline">¶</a></h2>
<p>Spark SQL supports two different methods for converting existing RDDs
into DataFrames. The first method uses reflection to infer the schema of
an RDD that contains specific types of objects. This reflection based
approach leads to more concise code and works well when you already know
the schema.</p>
<p>The second method for creating DataFrames is through a programmatic
interface that allows you to construct a schema and then apply it to an
existing RDD. While this method is more verbose, it allows you to
construct DataFrames when the columns and their types are not known
until runtime.</p>
<div class="section" id="inferring-the-schema-using-reflection">
<h3>Inferring the Schema Using Reflection<a class="headerlink" href="#inferring-the-schema-using-reflection" title="Permalink to this headline">¶</a></h3>
<p>The Scala interface for Spark SQL supports automatically converting an
RDD containing case classes to a DataFrame. The case class defines the
schema of the table. The names of the arguments to the case class are
read using reflection and become the names of the columns. Case classes
can also be nested or contain complex types such as Sequences or Arrays.
This RDD can be implicitly converted to a DataFrame and then be
registered as a table.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// Define case class that will be our schema for DataFrame</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Hubot</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">year</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">manufacturer</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">version</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">],</span> <span class="n">details</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span><span class="p">,</span> <span class="kt">String</span><span class="o">])</span>

<span class="c1">// You can process a text file, for example, to convert every row to our Hubot, but we will create RDD manually</span>
<span class="k">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span>
    <span class="nc">Hubot</span><span class="o">(</span><span class="s">&quot;Jerry&quot;</span><span class="o">,</span> <span class="mi">2015</span><span class="o">,</span> <span class="s">&quot;LCorp&quot;</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span> <span class="nc">Map</span><span class="o">(</span><span class="s">&quot;eat&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;yes&quot;</span><span class="o">,</span> <span class="s">&quot;sleep&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;yes&quot;</span><span class="o">,</span> <span class="s">&quot;drink&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;yes&quot;</span><span class="o">)),</span>
    <span class="nc">Hubot</span><span class="o">(</span><span class="s">&quot;Mozart&quot;</span><span class="o">,</span> <span class="mi">2010</span><span class="o">,</span> <span class="s">&quot;LCorp&quot;</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="nc">Map</span><span class="o">(</span><span class="s">&quot;eat&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;no&quot;</span><span class="o">,</span> <span class="s">&quot;sleep&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;no&quot;</span><span class="o">,</span> <span class="s">&quot;drink&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;no&quot;</span><span class="o">)),</span>
    <span class="nc">Hubot</span><span class="o">(</span><span class="s">&quot;Einstein&quot;</span><span class="o">,</span> <span class="mi">2012</span><span class="o">,</span> <span class="s">&quot;LCorp&quot;</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span> <span class="nc">Map</span><span class="o">(</span><span class="s">&quot;eat&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;yes&quot;</span><span class="o">,</span> <span class="s">&quot;sleep&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;yes&quot;</span><span class="o">,</span> <span class="s">&quot;drink&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;no&quot;</span><span class="o">))</span>
  <span class="o">)</span>
<span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// In order to convert RDD into DataFrame you need to do this:</span>
<span class="k">val</span> <span class="n">hubots</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">toDF</span><span class="o">()</span>

<span class="c1">// Display DataFrame, note how array and map fields are displayed</span>
<span class="n">hubots</span><span class="o">.</span><span class="n">printSchema</span><span class="o">()</span>
<span class="n">hubots</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// You can query complex type the same as you query any other column</span>
<span class="c1">// By the way you can use `sql` function to invoke Spark SQL to create DataFrame</span>
<span class="n">hubots</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;hubots&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">onesThatEat</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;select name, details.eat from hubots where details.eat = &#39;yes&#39;&quot;</span><span class="o">)</span>

<span class="n">onesThatEat</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="programmatically-specifying-the-schema">
<h3>Programmatically Specifying the Schema<a class="headerlink" href="#programmatically-specifying-the-schema" title="Permalink to this headline">¶</a></h3>
<p>When case classes cannot be defined ahead of time (for example, the
structure of records is encoded in a string, or a text dataset will be
parsed and fields will be projected differently for different users), a
<code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> can be created programmatically with three steps.</p>
<ol class="simple">
<li><p>Create an RDD of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s from the original RDD</p></li>
<li><p>Create the schema represented by a
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.StructType">StructType</a>
and
<a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.types.StructField">StructField</a>
classes matching the structure of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s in the RDD created in
Step 1.</p></li>
<li><p>Apply the schema to the RDD of <code class="docutils literal notranslate"><span class="pre">Row</span></code>s via <code class="docutils literal notranslate"><span class="pre">createDataFrame</span></code> method
provided by <code class="docutils literal notranslate"><span class="pre">SQLContext</span></code>.</p></li>
</ol>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.types._</span>

<span class="c1">// Let&#39;s say we have an RDD of String and we need to convert it into a DataFrame with schema &quot;name&quot;, &quot;year&quot;, and &quot;manufacturer&quot;</span>
<span class="c1">// As you can see every record is space-separated.</span>
<span class="k">val</span> <span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span>
    <span class="s">&quot;Jerry 2015 LCorp&quot;</span><span class="o">,</span>
    <span class="s">&quot;Mozart 2010 LCorp&quot;</span><span class="o">,</span>
    <span class="s">&quot;Einstein 2012 LCorp&quot;</span>
  <span class="o">)</span>
<span class="o">)</span>

<span class="c1">// Create schema as StructType //</span>
<span class="k">val</span> <span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="o">(</span>
  <span class="nc">StructField</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="o">::</span> 
  <span class="nc">StructField</span><span class="o">(</span><span class="s">&quot;year&quot;</span><span class="o">,</span> <span class="nc">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="o">::</span> 
  <span class="nc">StructField</span><span class="o">(</span><span class="s">&quot;manufacturer&quot;</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span> <span class="o">::</span> 
  <span class="nc">Nil</span>
<span class="o">)</span>

<span class="c1">// Prepare RDD[Row]</span>
<span class="k">val</span> <span class="n">rows</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">entry</span> <span class="o">=&gt;</span> 
  <span class="k">val</span> <span class="n">arr</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;\\s+&quot;</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">name</span> <span class="o">=</span> <span class="n">arr</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">year</span> <span class="o">=</span> <span class="n">arr</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">toInt</span>
  <span class="k">val</span> <span class="n">manufacturer</span> <span class="o">=</span> <span class="n">arr</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  
  <span class="nc">Row</span><span class="o">(</span><span class="n">name</span><span class="o">,</span> <span class="n">year</span><span class="o">,</span> <span class="n">manufacturer</span><span class="o">)</span>
<span class="o">}</span>

<span class="c1">// Create DataFrame</span>
<span class="k">val</span> <span class="n">bots</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">rows</span><span class="o">,</span> <span class="n">schema</span><span class="o">)</span>
<span class="n">bots</span><span class="o">.</span><span class="n">printSchema</span><span class="o">()</span>
<span class="n">bots</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="creating-datasets">
<h2>Creating Datasets<a class="headerlink" href="#creating-datasets" title="Permalink to this headline">¶</a></h2>
<p>A
<a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset">Dataset</a>
is a strongly-typed, immutable collection of objects that are mapped to
a relational schema. At the core of the Dataset API is a new concept
called an
<a class="reference external" href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Encoder">encoder</a>,
which is responsible for converting between JVM objects and tabular
representation. The tabular representation is stored using Spark’s
internal Tungsten binary format, allowing for operations on serialized
data and improved memory utilization. Spark 2.2 comes with support for
automatically generating encoders for a wide variety of types, including
primitive types (e.g. String, Integer, Long), and Scala case classes.</p>
<blockquote>
<div><p>Simply put, you will get all the benefits of DataFrames with fair
amount of flexibility of RDD API.</p>
</div></blockquote>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">scala</span>
<span class="c1">// We can start working with Datasets by using our &quot;hubots&quot; table</span>

<span class="c1">// To create Dataset from DataFrame do this (assuming that case class Hubot exists):</span>
<span class="k">val</span> <span class="n">ds</span> <span class="o">=</span> <span class="n">hubots</span><span class="o">.</span><span class="n">as</span><span class="o">[</span><span class="kt">Hubot</span><span class="o">]</span>
<span class="n">ds</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><strong>Side-note:</strong> Dataset API is first-class citizen in Spark, and
DataFrame is an alias for Dataset[Row]. Note that Python and R use
DataFrames (since they are dynamically typed), but it is essentially a
Dataset.</p>
</div></blockquote>
</div>
<div class="section" id="finally">
<h2>Finally<a class="headerlink" href="#finally" title="Permalink to this headline">¶</a></h2>
<p>DataFrames and Datasets can simplify and improve most of the
applications pipelines by bringing concise syntax and performance
optimizations. We would highly recommend you to check out the official
API documentation, specifically around</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame
API</a>,</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions%24">Spark SQL functions
library</a>,</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.GroupedData">GroupBy clause and aggregated
functions</a>.</p></li>
</ul>
<p>Unfortunately, this is just <em>a getting started quickly</em> course, and we
skip features like custom aggregations, types, pivoting, etc., but if
you are keen to know then start from the links above and this notebook
and others in this directory.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "scala212"
        },
        kernelOptions: {
            kernelName: "scala212",
            path: "./000_1-sds-3-x"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'scala212'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="007b_SparkSQLProgGuide_HW.html" title="previous page">Getting Started</a>
    <a class='right-next' id="next-link" href="007d_SparkSQLProgGuide_HW.html" title="next page">Data Sources</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ScaDaMaLe Team<br/>
        
            &copy; Copyright 2020 Creative Commons Zero v1.0 Universal.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>